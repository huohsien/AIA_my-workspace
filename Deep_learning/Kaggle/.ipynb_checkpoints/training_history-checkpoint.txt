Epoch: 1 	Training Loss: 1.797097 	Validation Loss: 1.817386 	 time: 0.3
Validation loss decreased from inf to 1.817386. Model was saved
Epoch: 2 	Training Loss: 1.817009 	Validation Loss: 1.803621 	 time: 0.3
Validation loss decreased from 1.817386 to 1.803621. Model was saved
Epoch: 3 	Training Loss: 1.803172 	Validation Loss: 1.791372 	 time: 0.3
Validation loss decreased from 1.803621 to 1.791372. Model was saved
Epoch: 4 	Training Loss: 1.790626 	Validation Loss: 1.785452 	 time: 0.3
Validation loss decreased from 1.791372 to 1.785452. Model was saved
Epoch: 5 	Training Loss: 1.783887 	Validation Loss: 1.783445 	 time: 0.3
Validation loss decreased from 1.785452 to 1.783445. Model was saved
Epoch: 6 	Training Loss: 1.780511 	Validation Loss: 1.778731 	 time: 0.3
Validation loss decreased from 1.783445 to 1.778731. Model was saved
Epoch: 7 	Training Loss: 1.773878 	Validation Loss: 1.767826 	 time: 0.3
Validation loss decreased from 1.778731 to 1.767826. Model was saved
Epoch: 8 	Training Loss: 1.761084 	Validation Loss: 1.751793 	 time: 0.3
Validation loss decreased from 1.767826 to 1.751793. Model was saved
Epoch: 9 	Training Loss: 1.743632 	Validation Loss: 1.731985 	 time: 0.3
Validation loss decreased from 1.751793 to 1.731985. Model was saved
Epoch: 10 	Training Loss: 1.722249 	Validation Loss: 1.711105 	 time: 0.2
Validation loss decreased from 1.731985 to 1.711105. Model was saved
Epoch: 11 	Training Loss: 1.699554 	Validation Loss: 1.690512 	 time: 0.2
Validation loss decreased from 1.711105 to 1.690512. Model was saved
Epoch: 12 	Training Loss: 1.677718 	Validation Loss: 1.672238 	 time: 0.3
Validation loss decreased from 1.690512 to 1.672238. Model was saved
Epoch: 13 	Training Loss: 1.657198 	Validation Loss: 1.655165 	 time: 0.3
Validation loss decreased from 1.672238 to 1.655165. Model was saved
Epoch: 14 	Training Loss: 1.637807 	Validation Loss: 1.639048 	 time: 0.3
Validation loss decreased from 1.655165 to 1.639048. Model was saved
Epoch: 15 	Training Loss: 1.619246 	Validation Loss: 1.624384 	 time: 0.2
Validation loss decreased from 1.639048 to 1.624384. Model was saved
Epoch: 16 	Training Loss: 1.601306 	Validation Loss: 1.610192 	 time: 0.3
Validation loss decreased from 1.624384 to 1.610192. Model was saved
Epoch: 17 	Training Loss: 1.585043 	Validation Loss: 1.598201 	 time: 0.3
Validation loss decreased from 1.610192 to 1.598201. Model was saved
Epoch: 18 	Training Loss: 1.569761 	Validation Loss: 1.582918 	 time: 0.3
Validation loss decreased from 1.598201 to 1.582918. Model was saved
Epoch: 19 	Training Loss: 1.555503 	Validation Loss: 1.577405 	 time: 0.3
Validation loss decreased from 1.582918 to 1.577405. Model was saved
Epoch: 20 	Training Loss: 1.544980 	Validation Loss: 1.561356 	 time: 0.2
Validation loss decreased from 1.577405 to 1.561356. Model was saved
Epoch: 21 	Training Loss: 1.534659 	Validation Loss: 1.552726 	 time: 0.2
Validation loss decreased from 1.561356 to 1.552726. Model was saved
Epoch: 22 	Training Loss: 1.519736 	Validation Loss: 1.550788 	 time: 0.2
Validation loss decreased from 1.552726 to 1.550788. Model was saved
Epoch: 23 	Training Loss: 1.512210 	Validation Loss: 1.537935 	 time: 0.3
Validation loss decreased from 1.550788 to 1.537935. Model was saved
Epoch: 24 	Training Loss: 1.497329 	Validation Loss: 1.531636 	 time: 0.3
Validation loss decreased from 1.537935 to 1.531636. Model was saved
Epoch: 25 	Training Loss: 1.491272 	Validation Loss: 1.524410 	 time: 0.2
Validation loss decreased from 1.531636 to 1.524410. Model was saved
Epoch: 26 	Training Loss: 1.481423 	Validation Loss: 1.522664 	 time: 0.2
Validation loss decreased from 1.524410 to 1.522664. Model was saved
Epoch: 27 	Training Loss: 1.477158 	Validation Loss: 1.515657 	 time: 0.3
Validation loss decreased from 1.522664 to 1.515657. Model was saved
Epoch: 28 	Training Loss: 1.469516 	Validation Loss: 1.512232 	 time: 0.3
Validation loss decreased from 1.515657 to 1.512232. Model was saved
Epoch: 29 	Training Loss: 1.465611 	Validation Loss: 1.508785 	 time: 0.3
Validation loss decreased from 1.512232 to 1.508785. Model was saved
Epoch: 30 	Training Loss: 1.459705 	Validation Loss: 1.507611 	 time: 0.3
Validation loss decreased from 1.508785 to 1.507611. Model was saved
Epoch: 31 	Training Loss: 1.455506 	Validation Loss: 1.503475 	 time: 0.2
Validation loss decreased from 1.507611 to 1.503475. Model was saved
Epoch: 32 	Training Loss: 1.451173 	Validation Loss: 1.500518 	 time: 0.3
Validation loss decreased from 1.503475 to 1.500518. Model was saved
Epoch: 33 	Training Loss: 1.446686 	Validation Loss: 1.498670 	 time: 0.2
Validation loss decreased from 1.500518 to 1.498670. Model was saved
Epoch: 34 	Training Loss: 1.443669 	Validation Loss: 1.495972 	 time: 0.2
Validation loss decreased from 1.498670 to 1.495972. Model was saved
Epoch: 35 	Training Loss: 1.439334 	Validation Loss: 1.494115 	 time: 0.3
Validation loss decreased from 1.495972 to 1.494115. Model was saved
Epoch: 36 	Training Loss: 1.436909 	Validation Loss: 1.491623 	 time: 0.3
Validation loss decreased from 1.494115 to 1.491623. Model was saved
Epoch: 37 	Training Loss: 1.432733 	Validation Loss: 1.490461 	 time: 0.3
Validation loss decreased from 1.491623 to 1.490461. Model was saved
Epoch: 38 	Training Loss: 1.430607 	Validation Loss: 1.487243 	 time: 0.3
Validation loss decreased from 1.490461 to 1.487243. Model was saved
Epoch: 39 	Training Loss: 1.426659 	Validation Loss: 1.485645 	 time: 0.2
Validation loss decreased from 1.487243 to 1.485645. Model was saved
Epoch: 40 	Training Loss: 1.424891 	Validation Loss: 1.482828 	 time: 0.2
Validation loss decreased from 1.485645 to 1.482828. Model was saved
Epoch: 41 	Training Loss: 1.421351 	Validation Loss: 1.481211 	 time: 0.2
Validation loss decreased from 1.482828 to 1.481211. Model was saved
Epoch: 42 	Training Loss: 1.419469 	Validation Loss: 1.478947 	 time: 0.3
Validation loss decreased from 1.481211 to 1.478947. Model was saved
Epoch: 43 	Training Loss: 1.416317 	Validation Loss: 1.476697 	 time: 0.3
Validation loss decreased from 1.478947 to 1.476697. Model was saved
Epoch: 44 	Training Loss: 1.414360 	Validation Loss: 1.473454 	 time: 0.3
Validation loss decreased from 1.476697 to 1.473454. Model was saved
Epoch: 45 	Training Loss: 1.411942 	Validation Loss: 1.473346 	 time: 0.3
Validation loss decreased from 1.473454 to 1.473346. Model was saved
Epoch: 46 	Training Loss: 1.409507 	Validation Loss: 1.472273 	 time: 0.3
Validation loss decreased from 1.473346 to 1.472273. Model was saved
Epoch: 47 	Training Loss: 1.407729 	Validation Loss: 1.469194 	 time: 0.3
Validation loss decreased from 1.472273 to 1.469194. Model was saved
Epoch: 48 	Training Loss: 1.404982 	Validation Loss: 1.468268 	 time: 0.3
Validation loss decreased from 1.469194 to 1.468268. Model was saved
Epoch: 49 	Training Loss: 1.403150 	Validation Loss: 1.467574 	 time: 0.2
Validation loss decreased from 1.468268 to 1.467574. Model was saved
Epoch: 50 	Training Loss: 1.400781 	Validation Loss: 1.467955 	 time: 0.3
Epoch: 51 	Training Loss: 1.398777 	Validation Loss: 1.465868 	 time: 0.3
Validation loss decreased from 1.467574 to 1.465868. Model was saved
Epoch: 52 	Training Loss: 1.397395 	Validation Loss: 1.466884 	 time: 0.2
Epoch: 53 	Training Loss: 1.395444 	Validation Loss: 1.466382 	 time: 0.2
Epoch: 54 	Training Loss: 1.394771 	Validation Loss: 1.468264 	 time: 0.3
Epoch: 55 	Training Loss: 1.392500 	Validation Loss: 1.463131 	 time: 0.3
Validation loss decreased from 1.465868 to 1.463131. Model was saved
Epoch: 56 	Training Loss: 1.388939 	Validation Loss: 1.462741 	 time: 0.2
Validation loss decreased from 1.463131 to 1.462741. Model was saved
Epoch: 57 	Training Loss: 1.386495 	Validation Loss: 1.464772 	 time: 0.2
Epoch: 58 	Training Loss: 1.385374 	Validation Loss: 1.462724 	 time: 0.2
Validation loss decreased from 1.462741 to 1.462724. Model was saved
Epoch: 59 	Training Loss: 1.383888 	Validation Loss: 1.461305 	 time: 0.3
Validation loss decreased from 1.462724 to 1.461305. Model was saved
Epoch: 60 	Training Loss: 1.381147 	Validation Loss: 1.459878 	 time: 0.3
Validation loss decreased from 1.461305 to 1.459878. Model was saved
Epoch: 61 	Training Loss: 1.378588 	Validation Loss: 1.458685 	 time: 0.3
Validation loss decreased from 1.459878 to 1.458685. Model was saved
Epoch: 62 	Training Loss: 1.377146 	Validation Loss: 1.458851 	 time: 0.2
Epoch: 63 	Training Loss: 1.375731 	Validation Loss: 1.456948 	 time: 0.3
Validation loss decreased from 1.458685 to 1.456948. Model was saved
Epoch: 64 	Training Loss: 1.373938 	Validation Loss: 1.455604 	 time: 0.3
Validation loss decreased from 1.456948 to 1.455604. Model was saved
Epoch: 65 	Training Loss: 1.370682 	Validation Loss: 1.455307 	 time: 0.3
Validation loss decreased from 1.455604 to 1.455307. Model was saved
Epoch: 66 	Training Loss: 1.369390 	Validation Loss: 1.454314 	 time: 0.2
Validation loss decreased from 1.455307 to 1.454314. Model was saved
Epoch: 67 	Training Loss: 1.368292 	Validation Loss: 1.452789 	 time: 0.2
Validation loss decreased from 1.454314 to 1.452789. Model was saved
Epoch: 68 	Training Loss: 1.365955 	Validation Loss: 1.451042 	 time: 0.3
Validation loss decreased from 1.452789 to 1.451042. Model was saved
Epoch: 69 	Training Loss: 1.363771 	Validation Loss: 1.452167 	 time: 0.3
Epoch: 70 	Training Loss: 1.362396 	Validation Loss: 1.448035 	 time: 0.3
Validation loss decreased from 1.451042 to 1.448035. Model was saved
Epoch: 71 	Training Loss: 1.360177 	Validation Loss: 1.447731 	 time: 0.3
Validation loss decreased from 1.448035 to 1.447731. Model was saved
Epoch: 72 	Training Loss: 1.358400 	Validation Loss: 1.450561 	 time: 0.3
Epoch: 73 	Training Loss: 1.357471 	Validation Loss: 1.445392 	 time: 0.3
Validation loss decreased from 1.447731 to 1.445392. Model was saved
Epoch: 74 	Training Loss: 1.355590 	Validation Loss: 1.445223 	 time: 0.3
Validation loss decreased from 1.445392 to 1.445223. Model was saved
Epoch: 75 	Training Loss: 1.353408 	Validation Loss: 1.447054 	 time: 0.2
Epoch: 76 	Training Loss: 1.352233 	Validation Loss: 1.442704 	 time: 0.2
Validation loss decreased from 1.445223 to 1.442704. Model was saved
Epoch: 77 	Training Loss: 1.350987 	Validation Loss: 1.443871 	 time: 0.3
Epoch: 78 	Training Loss: 1.348737 	Validation Loss: 1.441114 	 time: 0.2
Validation loss decreased from 1.442704 to 1.441114. Model was saved
Epoch: 79 	Training Loss: 1.346856 	Validation Loss: 1.439136 	 time: 0.2
Validation loss decreased from 1.441114 to 1.439136. Model was saved
Epoch: 80 	Training Loss: 1.345724 	Validation Loss: 1.440658 	 time: 0.3
Epoch: 81 	Training Loss: 1.344014 	Validation Loss: 1.438483 	 time: 0.2
Validation loss decreased from 1.439136 to 1.438483. Model was saved
Epoch: 82 	Training Loss: 1.342048 	Validation Loss: 1.436566 	 time: 0.3
Validation loss decreased from 1.438483 to 1.436566. Model was saved
Epoch: 83 	Training Loss: 1.341119 	Validation Loss: 1.440494 	 time: 0.3
Epoch: 84 	Training Loss: 1.340586 	Validation Loss: 1.436903 	 time: 0.3
Epoch: 85 	Training Loss: 1.340319 	Validation Loss: 1.442715 	 time: 0.3
Epoch: 86 	Training Loss: 1.342472 	Validation Loss: 1.441718 	 time: 0.3
Epoch: 87 	Training Loss: 1.342890 	Validation Loss: 1.444770 	 time: 0.2
Epoch: 88 	Training Loss: 1.341129 	Validation Loss: 1.434129 	 time: 0.3
Validation loss decreased from 1.436566 to 1.434129. Model was saved
Epoch: 89 	Training Loss: 1.333905 	Validation Loss: 1.440418 	 time: 0.2
Epoch: 90 	Training Loss: 1.337590 	Validation Loss: 1.440653 	 time: 0.2
Epoch: 91 	Training Loss: 1.334985 	Validation Loss: 1.433493 	 time: 0.2
Validation loss decreased from 1.434129 to 1.433493. Model was saved
Epoch: 92 	Training Loss: 1.334472 	Validation Loss: 1.433061 	 time: 0.3
Validation loss decreased from 1.433493 to 1.433061. Model was saved
Epoch: 93 	Training Loss: 1.330197 	Validation Loss: 1.437450 	 time: 0.3
Epoch: 94 	Training Loss: 1.331776 	Validation Loss: 1.430584 	 time: 0.2
Validation loss decreased from 1.433061 to 1.430584. Model was saved
Epoch: 95 	Training Loss: 1.326560 	Validation Loss: 1.427931 	 time: 0.3
Validation loss decreased from 1.430584 to 1.427931. Model was saved
Epoch: 96 	Training Loss: 1.328681 	Validation Loss: 1.431486 	 time: 0.3
Epoch: 97 	Training Loss: 1.324519 	Validation Loss: 1.432856 	 time: 0.2
Epoch: 98 	Training Loss: 1.326174 	Validation Loss: 1.425979 	 time: 0.2
Validation loss decreased from 1.427931 to 1.425979. Model was saved
Epoch: 99 	Training Loss: 1.322117 	Validation Loss: 1.427538 	 time: 0.3
Epoch: 100 	Training Loss: 1.323024 	Validation Loss: 1.428320 	 time: 0.2
Epoch: 101 	Training Loss: 1.320152 	Validation Loss: 1.426270 	 time: 0.2
Epoch: 102 	Training Loss: 1.320661 	Validation Loss: 1.423257 	 time: 0.2
Validation loss decreased from 1.425979 to 1.423257. Model was saved
Epoch: 103 	Training Loss: 1.317553 	Validation Loss: 1.425074 	 time: 0.2
Epoch: 104 	Training Loss: 1.318060 	Validation Loss: 1.423392 	 time: 0.2
Epoch: 105 	Training Loss: 1.315750 	Validation Loss: 1.423558 	 time: 0.3
Epoch: 106 	Training Loss: 1.315995 	Validation Loss: 1.423355 	 time: 0.2
Epoch: 107 	Training Loss: 1.313747 	Validation Loss: 1.422294 	 time: 0.2
Validation loss decreased from 1.423257 to 1.422294. Model was saved
Epoch: 108 	Training Loss: 1.313672 	Validation Loss: 1.422584 	 time: 0.2
Epoch: 109 	Training Loss: 1.311771 	Validation Loss: 1.423376 	 time: 0.3
Epoch: 110 	Training Loss: 1.311645 	Validation Loss: 1.421020 	 time: 0.2
Validation loss decreased from 1.422294 to 1.421020. Model was saved
Epoch: 111 	Training Loss: 1.310091 	Validation Loss: 1.420723 	 time: 0.3
Validation loss decreased from 1.421020 to 1.420723. Model was saved
Epoch: 112 	Training Loss: 1.309398 	Validation Loss: 1.421122 	 time: 0.3
Epoch: 113 	Training Loss: 1.308117 	Validation Loss: 1.420576 	 time: 0.3
Validation loss decreased from 1.420723 to 1.420576. Model was saved
Epoch: 114 	Training Loss: 1.307052 	Validation Loss: 1.420079 	 time: 0.3
Validation loss decreased from 1.420576 to 1.420079. Model was saved
Epoch: 115 	Training Loss: 1.306537 	Validation Loss: 1.418539 	 time: 0.3
Validation loss decreased from 1.420079 to 1.418539. Model was saved
Epoch: 116 	Training Loss: 1.305080 	Validation Loss: 1.421189 	 time: 0.3
Epoch: 117 	Training Loss: 1.304832 	Validation Loss: 1.417745 	 time: 0.2
Validation loss decreased from 1.418539 to 1.417745. Model was saved
Epoch: 118 	Training Loss: 1.303512 	Validation Loss: 1.419722 	 time: 0.3
Epoch: 119 	Training Loss: 1.302783 	Validation Loss: 1.418645 	 time: 0.3
Epoch: 120 	Training Loss: 1.302162 	Validation Loss: 1.420447 	 time: 0.3
Epoch: 121 	Training Loss: 1.302276 	Validation Loss: 1.414930 	 time: 0.3
Validation loss decreased from 1.417745 to 1.414930. Model was saved
Epoch: 122 	Training Loss: 1.304179 	Validation Loss: 1.423145 	 time: 0.3
Epoch: 123 	Training Loss: 1.304112 	Validation Loss: 1.415015 	 time: 0.3
Epoch: 124 	Training Loss: 1.301679 	Validation Loss: 1.418647 	 time: 0.3
Epoch: 125 	Training Loss: 1.299153 	Validation Loss: 1.418862 	 time: 0.2
Epoch: 126 	Training Loss: 1.296841 	Validation Loss: 1.418806 	 time: 0.2
Epoch: 127 	Training Loss: 1.300968 	Validation Loss: 1.427325 	 time: 0.3
Epoch: 128 	Training Loss: 1.306669 	Validation Loss: 1.413882 	 time: 0.3
Validation loss decreased from 1.414930 to 1.413882. Model was saved
Epoch: 129 	Training Loss: 1.298378 	Validation Loss: 1.422184 	 time: 0.3
Epoch: 130 	Training Loss: 1.300629 	Validation Loss: 1.427543 	 time: 0.2
Epoch: 131 	Training Loss: 1.308207 	Validation Loss: 1.414075 	 time: 0.2
Epoch: 132 	Training Loss: 1.298847 	Validation Loss: 1.416055 	 time: 0.3
Epoch: 133 	Training Loss: 1.301496 	Validation Loss: 1.420600 	 time: 0.3
Epoch: 134 	Training Loss: 1.294650 	Validation Loss: 1.421309 	 time: 0.3
Epoch: 135 	Training Loss: 1.297490 	Validation Loss: 1.412468 	 time: 0.2
Validation loss decreased from 1.413882 to 1.412468. Model was saved
Epoch: 136 	Training Loss: 1.292379 	Validation Loss: 1.413174 	 time: 0.3
Epoch: 137 	Training Loss: 1.295585 	Validation Loss: 1.416100 	 time: 0.2
Epoch: 138 	Training Loss: 1.288483 	Validation Loss: 1.419259 	 time: 0.3
Epoch: 139 	Training Loss: 1.293000 	Validation Loss: 1.413859 	 time: 0.3
Epoch: 140 	Training Loss: 1.287426 	Validation Loss: 1.411950 	 time: 0.2
Validation loss decreased from 1.412468 to 1.411950. Model was saved
Epoch: 141 	Training Loss: 1.288692 	Validation Loss: 1.412074 	 time: 0.3
Epoch: 142 	Training Loss: 1.286001 	Validation Loss: 1.414310 	 time: 0.3
Epoch: 143 	Training Loss: 1.285925 	Validation Loss: 1.412772 	 time: 0.3
Epoch: 144 	Training Loss: 1.284010 	Validation Loss: 1.412739 	 time: 0.3
Epoch: 145 	Training Loss: 1.283365 	Validation Loss: 1.411160 	 time: 0.3
Validation loss decreased from 1.411950 to 1.411160. Model was saved
Epoch: 146 	Training Loss: 1.282013 	Validation Loss: 1.412213 	 time: 0.3
Epoch: 147 	Training Loss: 1.280253 	Validation Loss: 1.413560 	 time: 0.3
Epoch: 148 	Training Loss: 1.280702 	Validation Loss: 1.410739 	 time: 0.3
Validation loss decreased from 1.411160 to 1.410739. Model was saved
Epoch: 149 	Training Loss: 1.277761 	Validation Loss: 1.410934 	 time: 0.3
Epoch: 150 	Training Loss: 1.278914 	Validation Loss: 1.409953 	 time: 0.3
Validation loss decreased from 1.410739 to 1.409953. Model was saved
Epoch: 151 	Training Loss: 1.275797 	Validation Loss: 1.411649 	 time: 0.3
Epoch: 152 	Training Loss: 1.276760 	Validation Loss: 1.409124 	 time: 0.2
Validation loss decreased from 1.409953 to 1.409124. Model was saved
Epoch: 153 	Training Loss: 1.274288 	Validation Loss: 1.408400 	 time: 0.3
Validation loss decreased from 1.409124 to 1.408400. Model was saved
Epoch: 154 	Training Loss: 1.274248 	Validation Loss: 1.409027 	 time: 0.3
Epoch: 155 	Training Loss: 1.272962 	Validation Loss: 1.408378 	 time: 0.3
Validation loss decreased from 1.408400 to 1.408378. Model was saved
Epoch: 156 	Training Loss: 1.272433 	Validation Loss: 1.407598 	 time: 0.3
Validation loss decreased from 1.408378 to 1.407598. Model was saved
Epoch: 157 	Training Loss: 1.271366 	Validation Loss: 1.406762 	 time: 0.3
Validation loss decreased from 1.407598 to 1.406762. Model was saved
Epoch: 158 	Training Loss: 1.270756 	Validation Loss: 1.406637 	 time: 0.3
Validation loss decreased from 1.406762 to 1.406637. Model was saved
Epoch: 159 	Training Loss: 1.269612 	Validation Loss: 1.405369 	 time: 0.3
Validation loss decreased from 1.406637 to 1.405369. Model was saved
Epoch: 160 	Training Loss: 1.269452 	Validation Loss: 1.403785 	 time: 0.3
Validation loss decreased from 1.405369 to 1.403785. Model was saved
Epoch: 161 	Training Loss: 1.267990 	Validation Loss: 1.403328 	 time: 0.2
Validation loss decreased from 1.403785 to 1.403328. Model was saved
Epoch: 162 	Training Loss: 1.267992 	Validation Loss: 1.402394 	 time: 0.3
Validation loss decreased from 1.403328 to 1.402394. Model was saved
Epoch: 163 	Training Loss: 1.266643 	Validation Loss: 1.402351 	 time: 0.3
Validation loss decreased from 1.402394 to 1.402351. Model was saved
Epoch: 164 	Training Loss: 1.266483 	Validation Loss: 1.401487 	 time: 0.3
Validation loss decreased from 1.402351 to 1.401487. Model was saved
Epoch: 165 	Training Loss: 1.265375 	Validation Loss: 1.400994 	 time: 0.2
Validation loss decreased from 1.401487 to 1.400994. Model was saved
Epoch: 166 	Training Loss: 1.264948 	Validation Loss: 1.400117 	 time: 0.2
Validation loss decreased from 1.400994 to 1.400117. Model was saved
Epoch: 167 	Training Loss: 1.264147 	Validation Loss: 1.399473 	 time: 0.3
Validation loss decreased from 1.400117 to 1.399473. Model was saved
Epoch: 168 	Training Loss: 1.263503 	Validation Loss: 1.400140 	 time: 0.2
Epoch: 169 	Training Loss: 1.262925 	Validation Loss: 1.399140 	 time: 0.2
Validation loss decreased from 1.399473 to 1.399140. Model was saved
Epoch: 170 	Training Loss: 1.262095 	Validation Loss: 1.398236 	 time: 0.2
Validation loss decreased from 1.399140 to 1.398236. Model was saved
Epoch: 171 	Training Loss: 1.261769 	Validation Loss: 1.398342 	 time: 0.2
Epoch: 172 	Training Loss: 1.260914 	Validation Loss: 1.398219 	 time: 0.3
Validation loss decreased from 1.398236 to 1.398219. Model was saved
Epoch: 173 	Training Loss: 1.260504 	Validation Loss: 1.397441 	 time: 0.3
Validation loss decreased from 1.398219 to 1.397441. Model was saved
Epoch: 174 	Training Loss: 1.259749 	Validation Loss: 1.396779 	 time: 0.2
Validation loss decreased from 1.397441 to 1.396779. Model was saved
Epoch: 175 	Training Loss: 1.259176 	Validation Loss: 1.396731 	 time: 0.2
Validation loss decreased from 1.396779 to 1.396731. Model was saved
Epoch: 176 	Training Loss: 1.258595 	Validation Loss: 1.396666 	 time: 0.3
Validation loss decreased from 1.396731 to 1.396666. Model was saved
Epoch: 177 	Training Loss: 1.258005 	Validation Loss: 1.396062 	 time: 0.3
Validation loss decreased from 1.396666 to 1.396062. Model was saved
Epoch: 178 	Training Loss: 1.257576 	Validation Loss: 1.395923 	 time: 0.3
Validation loss decreased from 1.396062 to 1.395923. Model was saved
Epoch: 179 	Training Loss: 1.256915 	Validation Loss: 1.395204 	 time: 0.3
Validation loss decreased from 1.395923 to 1.395204. Model was saved
Epoch: 180 	Training Loss: 1.256467 	Validation Loss: 1.395198 	 time: 0.3
Validation loss decreased from 1.395204 to 1.395198. Model was saved
Epoch: 181 	Training Loss: 1.255838 	Validation Loss: 1.394467 	 time: 0.3
Validation loss decreased from 1.395198 to 1.394467. Model was saved
Epoch: 182 	Training Loss: 1.255329 	Validation Loss: 1.394901 	 time: 0.3
Epoch: 183 	Training Loss: 1.254780 	Validation Loss: 1.393723 	 time: 0.3
Validation loss decreased from 1.394467 to 1.393723. Model was saved
Epoch: 184 	Training Loss: 1.254260 	Validation Loss: 1.393300 	 time: 0.3
Validation loss decreased from 1.393723 to 1.393300. Model was saved
Epoch: 185 	Training Loss: 1.253813 	Validation Loss: 1.393522 	 time: 0.3
Epoch: 186 	Training Loss: 1.253360 	Validation Loss: 1.393145 	 time: 0.3
Validation loss decreased from 1.393300 to 1.393145. Model was saved
Epoch: 187 	Training Loss: 1.252894 	Validation Loss: 1.392057 	 time: 0.2
Validation loss decreased from 1.393145 to 1.392057. Model was saved
Epoch: 188 	Training Loss: 1.252514 	Validation Loss: 1.392828 	 time: 0.2
Epoch: 189 	Training Loss: 1.252087 	Validation Loss: 1.392290 	 time: 0.3
Epoch: 190 	Training Loss: 1.251739 	Validation Loss: 1.392844 	 time: 0.2
Epoch: 191 	Training Loss: 1.251467 	Validation Loss: 1.392467 	 time: 0.3
Epoch: 192 	Training Loss: 1.251556 	Validation Loss: 1.395183 	 time: 0.2
Epoch: 193 	Training Loss: 1.252987 	Validation Loss: 1.395715 	 time: 0.2
Epoch: 194 	Training Loss: 1.255795 	Validation Loss: 1.406665 	 time: 0.2
Epoch: 195 	Training Loss: 1.264910 	Validation Loss: 1.397158 	 time: 0.3
Epoch: 196 	Training Loss: 1.264534 	Validation Loss: 1.398336 	 time: 0.3
Epoch: 197 	Training Loss: 1.254034 	Validation Loss: 1.401101 	 time: 0.2
Epoch: 198 	Training Loss: 1.259329 	Validation Loss: 1.390834 	 time: 0.2
Validation loss decreased from 1.392057 to 1.390834. Model was saved
Epoch: 199 	Training Loss: 1.259057 	Validation Loss: 1.392141 	 time: 0.3
Epoch: 200 	Training Loss: 1.257290 	Validation Loss: 1.396821 	 time: 0.3
Epoch: 201 	Training Loss: 1.253517 	Validation Loss: 1.398357 	 time: 0.2
Epoch: 202 	Training Loss: 1.255942 	Validation Loss: 1.390282 	 time: 0.2
Validation loss decreased from 1.390834 to 1.390282. Model was saved
Epoch: 203 	Training Loss: 1.253792 	Validation Loss: 1.394602 	 time: 0.2
Epoch: 204 	Training Loss: 1.251765 	Validation Loss: 1.399715 	 time: 0.3
Epoch: 205 	Training Loss: 1.251694 	Validation Loss: 1.392193 	 time: 0.2
Epoch: 206 	Training Loss: 1.249477 	Validation Loss: 1.390850 	 time: 0.2
Epoch: 207 	Training Loss: 1.250018 	Validation Loss: 1.394137 	 time: 0.2
Epoch: 208 	Training Loss: 1.247840 	Validation Loss: 1.398446 	 time: 0.3
Epoch: 209 	Training Loss: 1.249580 	Validation Loss: 1.391186 	 time: 0.3
Epoch: 210 	Training Loss: 1.246073 	Validation Loss: 1.390711 	 time: 0.2
Epoch: 211 	Training Loss: 1.249046 	Validation Loss: 1.392379 	 time: 0.3
Epoch: 212 	Training Loss: 1.245463 	Validation Loss: 1.397019 	 time: 0.2
Epoch: 213 	Training Loss: 1.247946 	Validation Loss: 1.390708 	 time: 0.2
Epoch: 214 	Training Loss: 1.244629 	Validation Loss: 1.387598 	 time: 0.2
Validation loss decreased from 1.390282 to 1.387598. Model was saved
Epoch: 215 	Training Loss: 1.246253 	Validation Loss: 1.387125 	 time: 0.3
Validation loss decreased from 1.387598 to 1.387125. Model was saved
Epoch: 216 	Training Loss: 1.244557 	Validation Loss: 1.390311 	 time: 0.2
Epoch: 217 	Training Loss: 1.243815 	Validation Loss: 1.390573 	 time: 0.3
Epoch: 218 	Training Loss: 1.243967 	Validation Loss: 1.387307 	 time: 0.3
Epoch: 219 	Training Loss: 1.242881 	Validation Loss: 1.387052 	 time: 0.3
Validation loss decreased from 1.387125 to 1.387052. Model was saved
Epoch: 220 	Training Loss: 1.243442 	Validation Loss: 1.388182 	 time: 0.3
Epoch: 221 	Training Loss: 1.241831 	Validation Loss: 1.391311 	 time: 0.2
Epoch: 222 	Training Loss: 1.242445 	Validation Loss: 1.390556 	 time: 0.3
Epoch: 223 	Training Loss: 1.241379 	Validation Loss: 1.388860 	 time: 0.3
Epoch: 224 	Training Loss: 1.241182 	Validation Loss: 1.388862 	 time: 0.3
Epoch: 225 	Training Loss: 1.240871 	Validation Loss: 1.391297 	 time: 0.2
Epoch: 226 	Training Loss: 1.240360 	Validation Loss: 1.392153 	 time: 0.2
Epoch: 227 	Training Loss: 1.240270 	Validation Loss: 1.389293 	 time: 0.3
Epoch: 228 	Training Loss: 1.239603 	Validation Loss: 1.387758 	 time: 0.2
Epoch: 229 	Training Loss: 1.239806 	Validation Loss: 1.388150 	 time: 0.2
Epoch: 230 	Training Loss: 1.239027 	Validation Loss: 1.390252 	 time: 0.2
Epoch: 231 	Training Loss: 1.238983 	Validation Loss: 1.390344 	 time: 0.2
Epoch: 232 	Training Loss: 1.238534 	Validation Loss: 1.388878 	 time: 0.3
Epoch: 233 	Training Loss: 1.238377 	Validation Loss: 1.388360 	 time: 0.3
Epoch: 234 	Training Loss: 1.237993 	Validation Loss: 1.389400 	 time: 0.2
Epoch: 235 	Training Loss: 1.237661 	Validation Loss: 1.389702 	 time: 0.3
Epoch: 236 	Training Loss: 1.237446 	Validation Loss: 1.388605 	 time: 0.3
Epoch: 237 	Training Loss: 1.237034 	Validation Loss: 1.387897 	 time: 0.3
Epoch: 238 	Training Loss: 1.236910 	Validation Loss: 1.388594 	 time: 0.3
Epoch: 239 	Training Loss: 1.236422 	Validation Loss: 1.389662 	 time: 0.3
Epoch: 240 	Training Loss: 1.236306 	Validation Loss: 1.388966 	 time: 0.3
Epoch: 241 	Training Loss: 1.235914 	Validation Loss: 1.388411 	 time: 0.3
Epoch: 242 	Training Loss: 1.235715 	Validation Loss: 1.388193 	 time: 0.2
Epoch: 243 	Training Loss: 1.235313 	Validation Loss: 1.389098 	 time: 0.2
Epoch: 244 	Training Loss: 1.235080 	Validation Loss: 1.388902 	 time: 0.2
Epoch: 245 	Training Loss: 1.234662 	Validation Loss: 1.388585 	 time: 0.3
Epoch: 246 	Training Loss: 1.234321 	Validation Loss: 1.388551 	 time: 0.3
Epoch: 247 	Training Loss: 1.233923 	Validation Loss: 1.389039 	 time: 0.3
Epoch: 248 	Training Loss: 1.233527 	Validation Loss: 1.389046 	 time: 0.3
Epoch: 249 	Training Loss: 1.233124 	Validation Loss: 1.388453 	 time: 0.3
Epoch: 250 	Training Loss: 1.232764 	Validation Loss: 1.388171 	 time: 0.3
Epoch: 251 	Training Loss: 1.232351 	Validation Loss: 1.388218 	 time: 0.2
Epoch: 252 	Training Loss: 1.231979 	Validation Loss: 1.387727 	 time: 0.2
Epoch: 253 	Training Loss: 1.231630 	Validation Loss: 1.386821 	 time: 0.3
Validation loss decreased from 1.387052 to 1.386821. Model was saved
Epoch: 254 	Training Loss: 1.231235 	Validation Loss: 1.386148 	 time: 0.3
Validation loss decreased from 1.386821 to 1.386148. Model was saved
Epoch: 255 	Training Loss: 1.230872 	Validation Loss: 1.386129 	 time: 0.3
Validation loss decreased from 1.386148 to 1.386129. Model was saved
Epoch: 256 	Training Loss: 1.230555 	Validation Loss: 1.385220 	 time: 0.3
Validation loss decreased from 1.386129 to 1.385220. Model was saved
Epoch: 257 	Training Loss: 1.230515 	Validation Loss: 1.385580 	 time: 0.3
Epoch: 258 	Training Loss: 1.231267 	Validation Loss: 1.387136 	 time: 0.3
Epoch: 259 	Training Loss: 1.233681 	Validation Loss: 1.393326 	 time: 0.3
Epoch: 260 	Training Loss: 1.241748 	Validation Loss: 1.390919 	 time: 0.3
Epoch: 261 	Training Loss: 1.243270 	Validation Loss: 1.388675 	 time: 0.3
Epoch: 262 	Training Loss: 1.238398 	Validation Loss: 1.381558 	 time: 0.3
Validation loss decreased from 1.385220 to 1.381558. Model was saved
Epoch: 263 	Training Loss: 1.230012 	Validation Loss: 1.387406 	 time: 0.3
Epoch: 264 	Training Loss: 1.238914 	Validation Loss: 1.391399 	 time: 0.3
Epoch: 265 	Training Loss: 1.243627 	Validation Loss: 1.388734 	 time: 0.3
Epoch: 266 	Training Loss: 1.237864 	Validation Loss: 1.391252 	 time: 0.3
Epoch: 267 	Training Loss: 1.237646 	Validation Loss: 1.379645 	 time: 0.3
Validation loss decreased from 1.381558 to 1.379645. Model was saved
Epoch: 268 	Training Loss: 1.229167 	Validation Loss: 1.381205 	 time: 0.3
Epoch: 269 	Training Loss: 1.228970 	Validation Loss: 1.383469 	 time: 0.3
Epoch: 270 	Training Loss: 1.228818 	Validation Loss: 1.383926 	 time: 0.2
Epoch: 271 	Training Loss: 1.229511 	Validation Loss: 1.380619 	 time: 0.3
Epoch: 272 	Training Loss: 1.227460 	Validation Loss: 1.377712 	 time: 0.3
Validation loss decreased from 1.379645 to 1.377712. Model was saved
Epoch: 273 	Training Loss: 1.226890 	Validation Loss: 1.381816 	 time: 0.3
Epoch: 274 	Training Loss: 1.226915 	Validation Loss: 1.383721 	 time: 0.2
Epoch: 275 	Training Loss: 1.227287 	Validation Loss: 1.375742 	 time: 0.2
Validation loss decreased from 1.377712 to 1.375742. Model was saved
Epoch: 276 	Training Loss: 1.223428 	Validation Loss: 1.376467 	 time: 0.3
Epoch: 277 	Training Loss: 1.225046 	Validation Loss: 1.378049 	 time: 0.3
Epoch: 278 	Training Loss: 1.223655 	Validation Loss: 1.379527 	 time: 0.2
Epoch: 279 	Training Loss: 1.223078 	Validation Loss: 1.377106 	 time: 0.3
Epoch: 280 	Training Loss: 1.222062 	Validation Loss: 1.375102 	 time: 0.3
Validation loss decreased from 1.375742 to 1.375102. Model was saved
Epoch: 281 	Training Loss: 1.221560 	Validation Loss: 1.374942 	 time: 0.3
Validation loss decreased from 1.375102 to 1.374942. Model was saved
Epoch: 282 	Training Loss: 1.221490 	Validation Loss: 1.375708 	 time: 0.3
Epoch: 283 	Training Loss: 1.221404 	Validation Loss: 1.373107 	 time: 0.2
Validation loss decreased from 1.374942 to 1.373107. Model was saved
Epoch: 284 	Training Loss: 1.220158 	Validation Loss: 1.371515 	 time: 0.3
Validation loss decreased from 1.373107 to 1.371515. Model was saved
Epoch: 285 	Training Loss: 1.220089 	Validation Loss: 1.372247 	 time: 0.2
Epoch: 286 	Training Loss: 1.219974 	Validation Loss: 1.373413 	 time: 0.3
Epoch: 287 	Training Loss: 1.218720 	Validation Loss: 1.373189 	 time: 0.2
Epoch: 288 	Training Loss: 1.218802 	Validation Loss: 1.372753 	 time: 0.2
Epoch: 289 	Training Loss: 1.218690 	Validation Loss: 1.372297 	 time: 0.3
Epoch: 290 	Training Loss: 1.218211 	Validation Loss: 1.372268 	 time: 0.3
Epoch: 291 	Training Loss: 1.217808 	Validation Loss: 1.371611 	 time: 0.3
Epoch: 292 	Training Loss: 1.217751 	Validation Loss: 1.369857 	 time: 0.3
Validation loss decreased from 1.371515 to 1.369857. Model was saved
Epoch: 293 	Training Loss: 1.217195 	Validation Loss: 1.370153 	 time: 0.2
Epoch: 294 	Training Loss: 1.217365 	Validation Loss: 1.370672 	 time: 0.3
Epoch: 295 	Training Loss: 1.216781 	Validation Loss: 1.370569 	 time: 0.2
Epoch: 296 	Training Loss: 1.216410 	Validation Loss: 1.370744 	 time: 0.2
Epoch: 297 	Training Loss: 1.216219 	Validation Loss: 1.371441 	 time: 0.2
Epoch: 298 	Training Loss: 1.216169 	Validation Loss: 1.370511 	 time: 0.3
Epoch: 299 	Training Loss: 1.215501 	Validation Loss: 1.370903 	 time: 0.2
Epoch: 300 	Training Loss: 1.215378 	Validation Loss: 1.370563 	 time: 0.2
Epoch: 301 	Training Loss: 1.215292 	Validation Loss: 1.368939 	 time: 0.2
Validation loss decreased from 1.369857 to 1.368939. Model was saved
Epoch: 302 	Training Loss: 1.214823 	Validation Loss: 1.368458 	 time: 0.2
Validation loss decreased from 1.368939 to 1.368458. Model was saved
Epoch: 303 	Training Loss: 1.214628 	Validation Loss: 1.368910 	 time: 0.3
Epoch: 304 	Training Loss: 1.214521 	Validation Loss: 1.368504 	 time: 0.3
Epoch: 305 	Training Loss: 1.214205 	Validation Loss: 1.367173 	 time: 0.3
Validation loss decreased from 1.368458 to 1.367173. Model was saved
Epoch: 306 	Training Loss: 1.213889 	Validation Loss: 1.367237 	 time: 0.3
Epoch: 307 	Training Loss: 1.213789 	Validation Loss: 1.368335 	 time: 0.3
Epoch: 308 	Training Loss: 1.213639 	Validation Loss: 1.368054 	 time: 0.3
Epoch: 309 	Training Loss: 1.213377 	Validation Loss: 1.367143 	 time: 0.2
Validation loss decreased from 1.367173 to 1.367143. Model was saved
Epoch: 310 	Training Loss: 1.213084 	Validation Loss: 1.367294 	 time: 0.2
Epoch: 311 	Training Loss: 1.212890 	Validation Loss: 1.367617 	 time: 0.2
Epoch: 312 	Training Loss: 1.212702 	Validation Loss: 1.367065 	 time: 0.3
Validation loss decreased from 1.367143 to 1.367065. Model was saved
Epoch: 313 	Training Loss: 1.212402 	Validation Loss: 1.366065 	 time: 0.3
Validation loss decreased from 1.367065 to 1.366065. Model was saved
Epoch: 314 	Training Loss: 1.212086 	Validation Loss: 1.366147 	 time: 0.2
Epoch: 315 	Training Loss: 1.211840 	Validation Loss: 1.366403 	 time: 0.2
Epoch: 316 	Training Loss: 1.211635 	Validation Loss: 1.365645 	 time: 0.3
Validation loss decreased from 1.366065 to 1.365645. Model was saved
Epoch: 317 	Training Loss: 1.211350 	Validation Loss: 1.365626 	 time: 0.3
Validation loss decreased from 1.365645 to 1.365626. Model was saved
Epoch: 318 	Training Loss: 1.211019 	Validation Loss: 1.366278 	 time: 0.3
Epoch: 319 	Training Loss: 1.210652 	Validation Loss: 1.366056 	 time: 0.3
Epoch: 320 	Training Loss: 1.210357 	Validation Loss: 1.365637 	 time: 0.2
Epoch: 321 	Training Loss: 1.210134 	Validation Loss: 1.365355 	 time: 0.3
Validation loss decreased from 1.365626 to 1.365355. Model was saved
Epoch: 322 	Training Loss: 1.209942 	Validation Loss: 1.365866 	 time: 0.3
Epoch: 323 	Training Loss: 1.209729 	Validation Loss: 1.365168 	 time: 0.2
Validation loss decreased from 1.365355 to 1.365168. Model was saved
Epoch: 324 	Training Loss: 1.209521 	Validation Loss: 1.364949 	 time: 0.2
Validation loss decreased from 1.365168 to 1.364949. Model was saved
Epoch: 325 	Training Loss: 1.209322 	Validation Loss: 1.364809 	 time: 0.3
Validation loss decreased from 1.364949 to 1.364809. Model was saved
Epoch: 326 	Training Loss: 1.209123 	Validation Loss: 1.364624 	 time: 0.3
Validation loss decreased from 1.364809 to 1.364624. Model was saved
Epoch: 327 	Training Loss: 1.208930 	Validation Loss: 1.364057 	 time: 0.3
Validation loss decreased from 1.364624 to 1.364057. Model was saved
Epoch: 328 	Training Loss: 1.208738 	Validation Loss: 1.363396 	 time: 0.3
Validation loss decreased from 1.364057 to 1.363396. Model was saved
Epoch: 329 	Training Loss: 1.208565 	Validation Loss: 1.363370 	 time: 0.3
Validation loss decreased from 1.363396 to 1.363370. Model was saved
Epoch: 330 	Training Loss: 1.208370 	Validation Loss: 1.363394 	 time: 0.3
Epoch: 331 	Training Loss: 1.208173 	Validation Loss: 1.363706 	 time: 0.3
Epoch: 332 	Training Loss: 1.207934 	Validation Loss: 1.363678 	 time: 0.3
Epoch: 333 	Training Loss: 1.207679 	Validation Loss: 1.364427 	 time: 0.3
Epoch: 334 	Training Loss: 1.207440 	Validation Loss: 1.364305 	 time: 0.3
Epoch: 335 	Training Loss: 1.207227 	Validation Loss: 1.364092 	 time: 0.3
Epoch: 336 	Training Loss: 1.207026 	Validation Loss: 1.363516 	 time: 0.3
Epoch: 337 	Training Loss: 1.206851 	Validation Loss: 1.363600 	 time: 0.2
Epoch: 338 	Training Loss: 1.206684 	Validation Loss: 1.363086 	 time: 0.3
Validation loss decreased from 1.363370 to 1.363086. Model was saved
Epoch: 339 	Training Loss: 1.206520 	Validation Loss: 1.363019 	 time: 0.3
Validation loss decreased from 1.363086 to 1.363019. Model was saved
Epoch: 340 	Training Loss: 1.206366 	Validation Loss: 1.362692 	 time: 0.3
Validation loss decreased from 1.363019 to 1.362692. Model was saved
Epoch: 341 	Training Loss: 1.206249 	Validation Loss: 1.363264 	 time: 0.3
Epoch: 342 	Training Loss: 1.206191 	Validation Loss: 1.362409 	 time: 0.3
Validation loss decreased from 1.362692 to 1.362409. Model was saved
Epoch: 343 	Training Loss: 1.206278 	Validation Loss: 1.363989 	 time: 0.3
Epoch: 344 	Training Loss: 1.206452 	Validation Loss: 1.362477 	 time: 0.2
Epoch: 345 	Training Loss: 1.207077 	Validation Loss: 1.366184 	 time: 0.3
Epoch: 346 	Training Loss: 1.207348 	Validation Loss: 1.362346 	 time: 0.3
Validation loss decreased from 1.362409 to 1.362346. Model was saved
Epoch: 347 	Training Loss: 1.208190 	Validation Loss: 1.366267 	 time: 0.3
Epoch: 348 	Training Loss: 1.206996 	Validation Loss: 1.361902 	 time: 0.2
Validation loss decreased from 1.362346 to 1.361902. Model was saved
Epoch: 349 	Training Loss: 1.205593 	Validation Loss: 1.361790 	 time: 0.3
Validation loss decreased from 1.361902 to 1.361790. Model was saved
Epoch: 350 	Training Loss: 1.205210 	Validation Loss: 1.365888 	 time: 0.2
Epoch: 351 	Training Loss: 1.205988 	Validation Loss: 1.362099 	 time: 0.2
Epoch: 352 	Training Loss: 1.206295 	Validation Loss: 1.365200 	 time: 0.2
Epoch: 353 	Training Loss: 1.205080 	Validation Loss: 1.363018 	 time: 0.3
Epoch: 354 	Training Loss: 1.204326 	Validation Loss: 1.362077 	 time: 0.3
Epoch: 355 	Training Loss: 1.204621 	Validation Loss: 1.365054 	 time: 0.2
Epoch: 356 	Training Loss: 1.204674 	Validation Loss: 1.362113 	 time: 0.2
Epoch: 357 	Training Loss: 1.204135 	Validation Loss: 1.362435 	 time: 0.3
Epoch: 358 	Training Loss: 1.203701 	Validation Loss: 1.363315 	 time: 0.3
Epoch: 359 	Training Loss: 1.203824 	Validation Loss: 1.360885 	 time: 0.2
Validation loss decreased from 1.361790 to 1.360885. Model was saved
Epoch: 360 	Training Loss: 1.204023 	Validation Loss: 1.362883 	 time: 0.2
Epoch: 361 	Training Loss: 1.203675 	Validation Loss: 1.360086 	 time: 0.2
Validation loss decreased from 1.360885 to 1.360086. Model was saved
Epoch: 362 	Training Loss: 1.203242 	Validation Loss: 1.360865 	 time: 0.3
Epoch: 363 	Training Loss: 1.202882 	Validation Loss: 1.361824 	 time: 0.3
Epoch: 364 	Training Loss: 1.202847 	Validation Loss: 1.359744 	 time: 0.3
Validation loss decreased from 1.360086 to 1.359744. Model was saved
Epoch: 365 	Training Loss: 1.202998 	Validation Loss: 1.362323 	 time: 0.2
Epoch: 366 	Training Loss: 1.202924 	Validation Loss: 1.359957 	 time: 0.3
Epoch: 367 	Training Loss: 1.203099 	Validation Loss: 1.362577 	 time: 0.3
Epoch: 368 	Training Loss: 1.202823 	Validation Loss: 1.358974 	 time: 0.3
Validation loss decreased from 1.359744 to 1.358974. Model was saved
Epoch: 369 	Training Loss: 1.202631 	Validation Loss: 1.360430 	 time: 0.3
Epoch: 370 	Training Loss: 1.201813 	Validation Loss: 1.359913 	 time: 0.3
Epoch: 371 	Training Loss: 1.201478 	Validation Loss: 1.358641 	 time: 0.3
Validation loss decreased from 1.358974 to 1.358641. Model was saved
Epoch: 372 	Training Loss: 1.201734 	Validation Loss: 1.360632 	 time: 0.3
Epoch: 373 	Training Loss: 1.201874 	Validation Loss: 1.358987 	 time: 0.3
Epoch: 374 	Training Loss: 1.201851 	Validation Loss: 1.361326 	 time: 0.3
Epoch: 375 	Training Loss: 1.201545 	Validation Loss: 1.358720 	 time: 0.3
Epoch: 376 	Training Loss: 1.201233 	Validation Loss: 1.360078 	 time: 0.3
Epoch: 377 	Training Loss: 1.200641 	Validation Loss: 1.360224 	 time: 0.3
Epoch: 378 	Training Loss: 1.200404 	Validation Loss: 1.359431 	 time: 0.3
Epoch: 379 	Training Loss: 1.200562 	Validation Loss: 1.361084 	 time: 0.3
Epoch: 380 	Training Loss: 1.200747 	Validation Loss: 1.360184 	 time: 0.3
Epoch: 381 	Training Loss: 1.200966 	Validation Loss: 1.362459 	 time: 0.3
Epoch: 382 	Training Loss: 1.201034 	Validation Loss: 1.359985 	 time: 0.2
Epoch: 383 	Training Loss: 1.201422 	Validation Loss: 1.362244 	 time: 0.3
Epoch: 384 	Training Loss: 1.200778 	Validation Loss: 1.359997 	 time: 0.3
Epoch: 385 	Training Loss: 1.199744 	Validation Loss: 1.360172 	 time: 0.3
Epoch: 386 	Training Loss: 1.199383 	Validation Loss: 1.362306 	 time: 0.3
Epoch: 387 	Training Loss: 1.199834 	Validation Loss: 1.360875 	 time: 0.2
Epoch: 388 	Training Loss: 1.199903 	Validation Loss: 1.362043 	 time: 0.3
Epoch: 389 	Training Loss: 1.199356 	Validation Loss: 1.360978 	 time: 0.2
Epoch: 390 	Training Loss: 1.198598 	Validation Loss: 1.361494 	 time: 0.3
Epoch: 391 	Training Loss: 1.198138 	Validation Loss: 1.361924 	 time: 0.2
Epoch: 392 	Training Loss: 1.198304 	Validation Loss: 1.362213 	 time: 0.2
Epoch: 393 	Training Loss: 1.198578 	Validation Loss: 1.362113 	 time: 0.3
Epoch: 394 	Training Loss: 1.198398 	Validation Loss: 1.362364 	 time: 0.2
Epoch: 395 	Training Loss: 1.198111 	Validation Loss: 1.361653 	 time: 0.3
Epoch: 396 	Training Loss: 1.197586 	Validation Loss: 1.361378 	 time: 0.3
Epoch: 397 	Training Loss: 1.197261 	Validation Loss: 1.361172 	 time: 0.2
Epoch: 398 	Training Loss: 1.197289 	Validation Loss: 1.361558 	 time: 0.3
Epoch: 399 	Training Loss: 1.197356 	Validation Loss: 1.361311 	 time: 0.3
Epoch: 400 	Training Loss: 1.197252 	Validation Loss: 1.362330 	 time: 0.2
Epoch: 401 	Training Loss: 1.196971 	Validation Loss: 1.361767 	 time: 0.2
Epoch: 402 	Training Loss: 1.196668 	Validation Loss: 1.362042 	 time: 0.2
Epoch: 403 	Training Loss: 1.196354 	Validation Loss: 1.362279 	 time: 0.3
Epoch: 404 	Training Loss: 1.196198 	Validation Loss: 1.362099 	 time: 0.3
Epoch: 405 	Training Loss: 1.196179 	Validation Loss: 1.361550 	 time: 0.2
Epoch: 406 	Training Loss: 1.196284 	Validation Loss: 1.362574 	 time: 0.2
Epoch: 407 	Training Loss: 1.196511 	Validation Loss: 1.362134 	 time: 0.3
Epoch: 408 	Training Loss: 1.196686 	Validation Loss: 1.362285 	 time: 0.3
Epoch: 409 	Training Loss: 1.197291 	Validation Loss: 1.362482 	 time: 0.2
Epoch: 410 	Training Loss: 1.197285 	Validation Loss: 1.361704 	 time: 0.2
Epoch: 411 	Training Loss: 1.196998 	Validation Loss: 1.361960 	 time: 0.2
Epoch: 412 	Training Loss: 1.195487 	Validation Loss: 1.362804 	 time: 0.3
Epoch: 413 	Training Loss: 1.195466 	Validation Loss: 1.362246 	 time: 0.2
Epoch: 414 	Training Loss: 1.196540 	Validation Loss: 1.361451 	 time: 0.2
Epoch: 415 	Training Loss: 1.196638 	Validation Loss: 1.361490 	 time: 0.2
Epoch: 416 	Training Loss: 1.195104 	Validation Loss: 1.362391 	 time: 0.3
Epoch: 417 	Training Loss: 1.194566 	Validation Loss: 1.362748 	 time: 0.3
Epoch: 418 	Training Loss: 1.195279 	Validation Loss: 1.361690 	 time: 0.2
Epoch: 419 	Training Loss: 1.195994 	Validation Loss: 1.363670 	 time: 0.2
Epoch: 420 	Training Loss: 1.195210 	Validation Loss: 1.361675 	 time: 0.2
Epoch: 421 	Training Loss: 1.194327 	Validation Loss: 1.360538 	 time: 0.3
Epoch: 422 	Training Loss: 1.194012 	Validation Loss: 1.361395 	 time: 0.3
Epoch: 423 	Training Loss: 1.194306 	Validation Loss: 1.360697 	 time: 0.3
Epoch: 424 	Training Loss: 1.194552 	Validation Loss: 1.360141 	 time: 0.2
Epoch: 425 	Training Loss: 1.194222 	Validation Loss: 1.360917 	 time: 0.3
Epoch: 426 	Training Loss: 1.193500 	Validation Loss: 1.361615 	 time: 0.3
Epoch: 427 	Training Loss: 1.194039 	Validation Loss: 1.360636 	 time: 0.3
Epoch: 428 	Training Loss: 1.194216 	Validation Loss: 1.359841 	 time: 0.2
Epoch: 429 	Training Loss: 1.194058 	Validation Loss: 1.361570 	 time: 0.2
Epoch: 430 	Training Loss: 1.193337 	Validation Loss: 1.360757 	 time: 0.3
Epoch: 431 	Training Loss: 1.193468 	Validation Loss: 1.359550 	 time: 0.3
Epoch: 432 	Training Loss: 1.194218 	Validation Loss: 1.360175 	 time: 0.3
Epoch: 433 	Training Loss: 1.193590 	Validation Loss: 1.360480 	 time: 0.3
Epoch: 434 	Training Loss: 1.193099 	Validation Loss: 1.359113 	 time: 0.3
Epoch: 435 	Training Loss: 1.192794 	Validation Loss: 1.359927 	 time: 0.3
Epoch: 436 	Training Loss: 1.192982 	Validation Loss: 1.360205 	 time: 0.3
Epoch: 437 	Training Loss: 1.192677 	Validation Loss: 1.359683 	 time: 0.2
Epoch: 438 	Training Loss: 1.192431 	Validation Loss: 1.359648 	 time: 0.2
Epoch: 439 	Training Loss: 1.192326 	Validation Loss: 1.359456 	 time: 0.3
Epoch: 440 	Training Loss: 1.192373 	Validation Loss: 1.358698 	 time: 0.3
Epoch: 441 	Training Loss: 1.192260 	Validation Loss: 1.359056 	 time: 0.3
Epoch: 442 	Training Loss: 1.192052 	Validation Loss: 1.359765 	 time: 0.3
Epoch: 443 	Training Loss: 1.192012 	Validation Loss: 1.359564 	 time: 0.3
Epoch: 444 	Training Loss: 1.191924 	Validation Loss: 1.360353 	 time: 0.3
Epoch: 445 	Training Loss: 1.191969 	Validation Loss: 1.360152 	 time: 0.2
Epoch: 446 	Training Loss: 1.191869 	Validation Loss: 1.360007 	 time: 0.3
Epoch: 447 	Training Loss: 1.191769 	Validation Loss: 1.359728 	 time: 0.2
Epoch: 448 	Training Loss: 1.191579 	Validation Loss: 1.360161 	 time: 0.2
Epoch: 449 	Training Loss: 1.191509 	Validation Loss: 1.359714 	 time: 0.2
Epoch: 450 	Training Loss: 1.191474 	Validation Loss: 1.359052 	 time: 0.3
Epoch: 451 	Training Loss: 1.191422 	Validation Loss: 1.359917 	 time: 0.3
Epoch: 452 	Training Loss: 1.191312 	Validation Loss: 1.359666 	 time: 0.3
Epoch: 453 	Training Loss: 1.191188 	Validation Loss: 1.359227 	 time: 0.3
Epoch: 454 	Training Loss: 1.191129 	Validation Loss: 1.359965 	 time: 0.3
Epoch: 455 	Training Loss: 1.191033 	Validation Loss: 1.360219 	 time: 0.3
Epoch: 456 	Training Loss: 1.190987 	Validation Loss: 1.359792 	 time: 0.3
Epoch: 457 	Training Loss: 1.190905 	Validation Loss: 1.359431 	 time: 0.2
Epoch: 458 	Training Loss: 1.190843 	Validation Loss: 1.359787 	 time: 0.2
Epoch: 459 	Training Loss: 1.190756 	Validation Loss: 1.359164 	 time: 0.3
Epoch: 460 	Training Loss: 1.190685 	Validation Loss: 1.359452 	 time: 0.3
Epoch: 461 	Training Loss: 1.190620 	Validation Loss: 1.359497 	 time: 0.3
Epoch: 462 	Training Loss: 1.190549 	Validation Loss: 1.359500 	 time: 0.2
Epoch: 463 	Training Loss: 1.190472 	Validation Loss: 1.359330 	 time: 0.3
Epoch: 464 	Training Loss: 1.190382 	Validation Loss: 1.359410 	 time: 0.3
Epoch: 465 	Training Loss: 1.190304 	Validation Loss: 1.358880 	 time: 0.3
Epoch: 466 	Training Loss: 1.190232 	Validation Loss: 1.358741 	 time: 0.3
Epoch: 467 	Training Loss: 1.190168 	Validation Loss: 1.358766 	 time: 0.2
Epoch: 468 	Training Loss: 1.190093 	Validation Loss: 1.358413 	 time: 0.3
Validation loss decreased from 1.358641 to 1.358413. Model was saved
Epoch: 469 	Training Loss: 1.190007 	Validation Loss: 1.358407 	 time: 0.3
Validation loss decreased from 1.358413 to 1.358407. Model was saved
Epoch: 470 	Training Loss: 1.189922 	Validation Loss: 1.358431 	 time: 0.3
Epoch: 471 	Training Loss: 1.189825 	Validation Loss: 1.358237 	 time: 0.2
Validation loss decreased from 1.358407 to 1.358237. Model was saved
Epoch: 472 	Training Loss: 1.189747 	Validation Loss: 1.358040 	 time: 0.3
Validation loss decreased from 1.358237 to 1.358040. Model was saved
Epoch: 473 	Training Loss: 1.189684 	Validation Loss: 1.358079 	 time: 0.3
Epoch: 474 	Training Loss: 1.189609 	Validation Loss: 1.357752 	 time: 0.3
Validation loss decreased from 1.358040 to 1.357752. Model was saved
Epoch: 475 	Training Loss: 1.189494 	Validation Loss: 1.357959 	 time: 0.3
Epoch: 476 	Training Loss: 1.189412 	Validation Loss: 1.357934 	 time: 0.2
Epoch: 477 	Training Loss: 1.189359 	Validation Loss: 1.358436 	 time: 0.3
Epoch: 478 	Training Loss: 1.189331 	Validation Loss: 1.358249 	 time: 0.3
Epoch: 479 	Training Loss: 1.189302 	Validation Loss: 1.358811 	 time: 0.2
Epoch: 480 	Training Loss: 1.189306 	Validation Loss: 1.358455 	 time: 0.3
Epoch: 481 	Training Loss: 1.189278 	Validation Loss: 1.359077 	 time: 0.2
Epoch: 482 	Training Loss: 1.189295 	Validation Loss: 1.358775 	 time: 0.3
Epoch: 483 	Training Loss: 1.189260 	Validation Loss: 1.359402 	 time: 0.3
Epoch: 484 	Training Loss: 1.189334 	Validation Loss: 1.358943 	 time: 0.2
Epoch: 485 	Training Loss: 1.189380 	Validation Loss: 1.359533 	 time: 0.3
Epoch: 486 	Training Loss: 1.189574 	Validation Loss: 1.359761 	 time: 0.3
Epoch: 487 	Training Loss: 1.189537 	Validation Loss: 1.359657 	 time: 0.2
Epoch: 488 	Training Loss: 1.189657 	Validation Loss: 1.359978 	 time: 0.2
Epoch: 489 	Training Loss: 1.189437 	Validation Loss: 1.359774 	 time: 0.2
Epoch: 490 	Training Loss: 1.189001 	Validation Loss: 1.359673 	 time: 0.3
Epoch: 491 	Training Loss: 1.188327 	Validation Loss: 1.360189 	 time: 0.3
Epoch: 492 	Training Loss: 1.188268 	Validation Loss: 1.361423 	 time: 0.3
Epoch: 493 	Training Loss: 1.188712 	Validation Loss: 1.360202 	 time: 0.2
Epoch: 494 	Training Loss: 1.189201 	Validation Loss: 1.361688 	 time: 0.3
Epoch: 495 	Training Loss: 1.189671 	Validation Loss: 1.362654 	 time: 0.3
Epoch: 496 	Training Loss: 1.190646 	Validation Loss: 1.361538 	 time: 0.3
Epoch: 497 	Training Loss: 1.193266 	Validation Loss: 1.367550 	 time: 0.3
Epoch: 498 	Training Loss: 1.199089 	Validation Loss: 1.388911 	 time: 0.3
Epoch: 499 	Training Loss: 1.240285 	Validation Loss: 1.418688 	 time: 0.2
Epoch: 500 	Training Loss: 1.318364 	Validation Loss: 1.409400 	 time: 0.3
Epoch: 501 	Training Loss: 1.305239 	Validation Loss: 1.411902 	 time: 0.3
Epoch: 502 	Training Loss: 1.260515 	Validation Loss: 1.417643 	 time: 0.3
Epoch: 503 	Training Loss: 1.290395 	Validation Loss: 1.424704 	 time: 0.2
Epoch: 504 	Training Loss: 1.309494 	Validation Loss: 1.392527 	 time: 0.2
Epoch: 505 	Training Loss: 1.255831 	Validation Loss: 1.402691 	 time: 0.3
Epoch: 506 	Training Loss: 1.258761 	Validation Loss: 1.404678 	 time: 0.3
Epoch: 507 	Training Loss: 1.277606 	Validation Loss: 1.392196 	 time: 0.3
Epoch: 508 	Training Loss: 1.259253 	Validation Loss: 1.379400 	 time: 0.2
Epoch: 509 	Training Loss: 1.236467 	Validation Loss: 1.377685 	 time: 0.3
Epoch: 510 	Training Loss: 1.238350 	Validation Loss: 1.377406 	 time: 0.3
Epoch: 511 	Training Loss: 1.239983 	Validation Loss: 1.380606 	 time: 0.2
Epoch: 512 	Training Loss: 1.240074 	Validation Loss: 1.382757 	 time: 0.2
Epoch: 513 	Training Loss: 1.231230 	Validation Loss: 1.386332 	 time: 0.3
Epoch: 514 	Training Loss: 1.224218 	Validation Loss: 1.374800 	 time: 0.3
Epoch: 515 	Training Loss: 1.217472 	Validation Loss: 1.372449 	 time: 0.3
Epoch: 516 	Training Loss: 1.215508 	Validation Loss: 1.372903 	 time: 0.3
Epoch: 517 	Training Loss: 1.213986 	Validation Loss: 1.370079 	 time: 0.3
Epoch: 518 	Training Loss: 1.212313 	Validation Loss: 1.367941 	 time: 0.3
Epoch: 519 	Training Loss: 1.209765 	Validation Loss: 1.366030 	 time: 0.3
Epoch: 520 	Training Loss: 1.207014 	Validation Loss: 1.366931 	 time: 0.3
Epoch: 521 	Training Loss: 1.205664 	Validation Loss: 1.363629 	 time: 0.2
Epoch: 522 	Training Loss: 1.202451 	Validation Loss: 1.360125 	 time: 0.2
Epoch: 523 	Training Loss: 1.201133 	Validation Loss: 1.358766 	 time: 0.3
Epoch: 524 	Training Loss: 1.200105 	Validation Loss: 1.359127 	 time: 0.3
Epoch: 525 	Training Loss: 1.199134 	Validation Loss: 1.358095 	 time: 0.3
Epoch: 526 	Training Loss: 1.197698 	Validation Loss: 1.356964 	 time: 0.2
Validation loss decreased from 1.357752 to 1.356964. Model was saved
Epoch: 527 	Training Loss: 1.196928 	Validation Loss: 1.356652 	 time: 0.3
Validation loss decreased from 1.356964 to 1.356652. Model was saved
Epoch: 528 	Training Loss: 1.196088 	Validation Loss: 1.355447 	 time: 0.2
Validation loss decreased from 1.356652 to 1.355447. Model was saved
Epoch: 529 	Training Loss: 1.195126 	Validation Loss: 1.355374 	 time: 0.3
Validation loss decreased from 1.355447 to 1.355374. Model was saved
Epoch: 530 	Training Loss: 1.194259 	Validation Loss: 1.355899 	 time: 0.2
Epoch: 531 	Training Loss: 1.193413 	Validation Loss: 1.355220 	 time: 0.2
Validation loss decreased from 1.355374 to 1.355220. Model was saved
Epoch: 532 	Training Loss: 1.192634 	Validation Loss: 1.353957 	 time: 0.3
Validation loss decreased from 1.355220 to 1.353957. Model was saved
Epoch: 533 	Training Loss: 1.191844 	Validation Loss: 1.353301 	 time: 0.3
Validation loss decreased from 1.353957 to 1.353301. Model was saved
Epoch: 534 	Training Loss: 1.191341 	Validation Loss: 1.353269 	 time: 0.3
Validation loss decreased from 1.353301 to 1.353269. Model was saved
Epoch: 535 	Training Loss: 1.190791 	Validation Loss: 1.353561 	 time: 0.3
Epoch: 536 	Training Loss: 1.190440 	Validation Loss: 1.353208 	 time: 0.3
Validation loss decreased from 1.353269 to 1.353208. Model was saved
Epoch: 537 	Training Loss: 1.190143 	Validation Loss: 1.352427 	 time: 0.2
Validation loss decreased from 1.353208 to 1.352427. Model was saved
Epoch: 538 	Training Loss: 1.189741 	Validation Loss: 1.351030 	 time: 0.3
Validation loss decreased from 1.352427 to 1.351030. Model was saved
Epoch: 539 	Training Loss: 1.189293 	Validation Loss: 1.349419 	 time: 0.2
Validation loss decreased from 1.351030 to 1.349419. Model was saved
Epoch: 540 	Training Loss: 1.188947 	Validation Loss: 1.348225 	 time: 0.3
Validation loss decreased from 1.349419 to 1.348225. Model was saved
Epoch: 541 	Training Loss: 1.188670 	Validation Loss: 1.347268 	 time: 0.3
Validation loss decreased from 1.348225 to 1.347268. Model was saved
Epoch: 542 	Training Loss: 1.188384 	Validation Loss: 1.347031 	 time: 0.3
Validation loss decreased from 1.347268 to 1.347031. Model was saved
Epoch: 543 	Training Loss: 1.188101 	Validation Loss: 1.347417 	 time: 0.3
Epoch: 544 	Training Loss: 1.187864 	Validation Loss: 1.347332 	 time: 0.2
Epoch: 545 	Training Loss: 1.187638 	Validation Loss: 1.346642 	 time: 0.3
Validation loss decreased from 1.347031 to 1.346642. Model was saved
Epoch: 546 	Training Loss: 1.187368 	Validation Loss: 1.346336 	 time: 0.3
Validation loss decreased from 1.346642 to 1.346336. Model was saved
Epoch: 547 	Training Loss: 1.187106 	Validation Loss: 1.346211 	 time: 0.3
Validation loss decreased from 1.346336 to 1.346211. Model was saved
Epoch: 548 	Training Loss: 1.186764 	Validation Loss: 1.346115 	 time: 0.3
Validation loss decreased from 1.346211 to 1.346115. Model was saved
Epoch: 549 	Training Loss: 1.186543 	Validation Loss: 1.345922 	 time: 0.2
Validation loss decreased from 1.346115 to 1.345922. Model was saved
Epoch: 550 	Training Loss: 1.186358 	Validation Loss: 1.345659 	 time: 0.3
Validation loss decreased from 1.345922 to 1.345659. Model was saved
Epoch: 551 	Training Loss: 1.186165 	Validation Loss: 1.345481 	 time: 0.3
Validation loss decreased from 1.345659 to 1.345481. Model was saved
Epoch: 552 	Training Loss: 1.185990 	Validation Loss: 1.345400 	 time: 0.3
Validation loss decreased from 1.345481 to 1.345400. Model was saved
Epoch: 553 	Training Loss: 1.185869 	Validation Loss: 1.345195 	 time: 0.3
Validation loss decreased from 1.345400 to 1.345195. Model was saved
Epoch: 554 	Training Loss: 1.185750 	Validation Loss: 1.345068 	 time: 0.3
Validation loss decreased from 1.345195 to 1.345068. Model was saved
Epoch: 555 	Training Loss: 1.185610 	Validation Loss: 1.345062 	 time: 0.3
Validation loss decreased from 1.345068 to 1.345062. Model was saved
Epoch: 556 	Training Loss: 1.185481 	Validation Loss: 1.344892 	 time: 0.3
Validation loss decreased from 1.345062 to 1.344892. Model was saved
Epoch: 557 	Training Loss: 1.185358 	Validation Loss: 1.344666 	 time: 0.3
Validation loss decreased from 1.344892 to 1.344666. Model was saved
Epoch: 558 	Training Loss: 1.185227 	Validation Loss: 1.344669 	 time: 0.3
Epoch: 559 	Training Loss: 1.185114 	Validation Loss: 1.344833 	 time: 0.2
Epoch: 560 	Training Loss: 1.184988 	Validation Loss: 1.345018 	 time: 0.3
Epoch: 561 	Training Loss: 1.184851 	Validation Loss: 1.345188 	 time: 0.3
Epoch: 562 	Training Loss: 1.184707 	Validation Loss: 1.345276 	 time: 0.3
Epoch: 563 	Training Loss: 1.184568 	Validation Loss: 1.345285 	 time: 0.2
Epoch: 564 	Training Loss: 1.184431 	Validation Loss: 1.345165 	 time: 0.3
Epoch: 565 	Training Loss: 1.184297 	Validation Loss: 1.345010 	 time: 0.2
Epoch: 566 	Training Loss: 1.184175 	Validation Loss: 1.345030 	 time: 0.2
Epoch: 567 	Training Loss: 1.184072 	Validation Loss: 1.345192 	 time: 0.3
Epoch: 568 	Training Loss: 1.183955 	Validation Loss: 1.345282 	 time: 0.2
Epoch: 569 	Training Loss: 1.183834 	Validation Loss: 1.345074 	 time: 0.3
Epoch: 570 	Training Loss: 1.183705 	Validation Loss: 1.344608 	 time: 0.2
Validation loss decreased from 1.344666 to 1.344608. Model was saved
Epoch: 571 	Training Loss: 1.183560 	Validation Loss: 1.344030 	 time: 0.2
Validation loss decreased from 1.344608 to 1.344030. Model was saved
Epoch: 572 	Training Loss: 1.183420 	Validation Loss: 1.343364 	 time: 0.3
Validation loss decreased from 1.344030 to 1.343364. Model was saved
Epoch: 573 	Training Loss: 1.183294 	Validation Loss: 1.342731 	 time: 0.3
Validation loss decreased from 1.343364 to 1.342731. Model was saved
Epoch: 574 	Training Loss: 1.183190 	Validation Loss: 1.342356 	 time: 0.2
Validation loss decreased from 1.342731 to 1.342356. Model was saved
Epoch: 575 	Training Loss: 1.183103 	Validation Loss: 1.342245 	 time: 0.3
Validation loss decreased from 1.342356 to 1.342245. Model was saved
Epoch: 576 	Training Loss: 1.183015 	Validation Loss: 1.342233 	 time: 0.3
Validation loss decreased from 1.342245 to 1.342233. Model was saved
Epoch: 577 	Training Loss: 1.182925 	Validation Loss: 1.342162 	 time: 0.3
Validation loss decreased from 1.342233 to 1.342162. Model was saved
Epoch: 578 	Training Loss: 1.182827 	Validation Loss: 1.342006 	 time: 0.3
Validation loss decreased from 1.342162 to 1.342006. Model was saved
Epoch: 579 	Training Loss: 1.182714 	Validation Loss: 1.341769 	 time: 0.2
Validation loss decreased from 1.342006 to 1.341769. Model was saved
Epoch: 580 	Training Loss: 1.182588 	Validation Loss: 1.341486 	 time: 0.3
Validation loss decreased from 1.341769 to 1.341486. Model was saved
Epoch: 581 	Training Loss: 1.182493 	Validation Loss: 1.341260 	 time: 0.3
Validation loss decreased from 1.341486 to 1.341260. Model was saved
Epoch: 582 	Training Loss: 1.182427 	Validation Loss: 1.341202 	 time: 0.3
Validation loss decreased from 1.341260 to 1.341202. Model was saved
Epoch: 583 	Training Loss: 1.182361 	Validation Loss: 1.341269 	 time: 0.2
Epoch: 584 	Training Loss: 1.182292 	Validation Loss: 1.341349 	 time: 0.2
Epoch: 585 	Training Loss: 1.182220 	Validation Loss: 1.341446 	 time: 0.2
Epoch: 586 	Training Loss: 1.182145 	Validation Loss: 1.341538 	 time: 0.2
Epoch: 587 	Training Loss: 1.182074 	Validation Loss: 1.341519 	 time: 0.3
Epoch: 588 	Training Loss: 1.182016 	Validation Loss: 1.341386 	 time: 0.2
Epoch: 589 	Training Loss: 1.181952 	Validation Loss: 1.341251 	 time: 0.2
Epoch: 590 	Training Loss: 1.181878 	Validation Loss: 1.341168 	 time: 0.3
Validation loss decreased from 1.341202 to 1.341168. Model was saved
Epoch: 591 	Training Loss: 1.181807 	Validation Loss: 1.341113 	 time: 0.3
Validation loss decreased from 1.341168 to 1.341113. Model was saved
Epoch: 592 	Training Loss: 1.181747 	Validation Loss: 1.341125 	 time: 0.2
Epoch: 593 	Training Loss: 1.181691 	Validation Loss: 1.341194 	 time: 0.2
Epoch: 594 	Training Loss: 1.181640 	Validation Loss: 1.341234 	 time: 0.2
Epoch: 595 	Training Loss: 1.181592 	Validation Loss: 1.341197 	 time: 0.2
Epoch: 596 	Training Loss: 1.181542 	Validation Loss: 1.341104 	 time: 0.3
Validation loss decreased from 1.341113 to 1.341104. Model was saved
Epoch: 597 	Training Loss: 1.181479 	Validation Loss: 1.340989 	 time: 0.3
Validation loss decreased from 1.341104 to 1.340989. Model was saved
Epoch: 598 	Training Loss: 1.181421 	Validation Loss: 1.340873 	 time: 0.3
Validation loss decreased from 1.340989 to 1.340873. Model was saved
Epoch: 599 	Training Loss: 1.181368 	Validation Loss: 1.340697 	 time: 0.3
Validation loss decreased from 1.340873 to 1.340697. Model was saved
Epoch: 600 	Training Loss: 1.181279 	Validation Loss: 1.340520 	 time: 0.3
Validation loss decreased from 1.340697 to 1.340520. Model was saved
Epoch: 601 	Training Loss: 1.181188 	Validation Loss: 1.340341 	 time: 0.3
Validation loss decreased from 1.340520 to 1.340341. Model was saved
Epoch: 602 	Training Loss: 1.181073 	Validation Loss: 1.340018 	 time: 0.3
Validation loss decreased from 1.340341 to 1.340018. Model was saved
Epoch: 603 	Training Loss: 1.180985 	Validation Loss: 1.339589 	 time: 0.3
Validation loss decreased from 1.340018 to 1.339589. Model was saved
Epoch: 604 	Training Loss: 1.180929 	Validation Loss: 1.339298 	 time: 0.3
Validation loss decreased from 1.339589 to 1.339298. Model was saved
Epoch: 605 	Training Loss: 1.180866 	Validation Loss: 1.339115 	 time: 0.3
Validation loss decreased from 1.339298 to 1.339115. Model was saved
Epoch: 606 	Training Loss: 1.180789 	Validation Loss: 1.338928 	 time: 0.2
Validation loss decreased from 1.339115 to 1.338928. Model was saved
Epoch: 607 	Training Loss: 1.180709 	Validation Loss: 1.338759 	 time: 0.2
Validation loss decreased from 1.338928 to 1.338759. Model was saved
Epoch: 608 	Training Loss: 1.180647 	Validation Loss: 1.338655 	 time: 0.2
Validation loss decreased from 1.338759 to 1.338655. Model was saved
Epoch: 609 	Training Loss: 1.180598 	Validation Loss: 1.338693 	 time: 0.3
Epoch: 610 	Training Loss: 1.180547 	Validation Loss: 1.338740 	 time: 0.3
Epoch: 611 	Training Loss: 1.180484 	Validation Loss: 1.338820 	 time: 0.3
Epoch: 612 	Training Loss: 1.180397 	Validation Loss: 1.338913 	 time: 0.3
Epoch: 613 	Training Loss: 1.180300 	Validation Loss: 1.338900 	 time: 0.2
Epoch: 614 	Training Loss: 1.180234 	Validation Loss: 1.338770 	 time: 0.3
Epoch: 615 	Training Loss: 1.180156 	Validation Loss: 1.338703 	 time: 0.3
Epoch: 616 	Training Loss: 1.180058 	Validation Loss: 1.338696 	 time: 0.2
Epoch: 617 	Training Loss: 1.179983 	Validation Loss: 1.338697 	 time: 0.3
Epoch: 618 	Training Loss: 1.179934 	Validation Loss: 1.338791 	 time: 0.3
Epoch: 619 	Training Loss: 1.179890 	Validation Loss: 1.338938 	 time: 0.2
Epoch: 620 	Training Loss: 1.179851 	Validation Loss: 1.339017 	 time: 0.2
Epoch: 621 	Training Loss: 1.179813 	Validation Loss: 1.339032 	 time: 0.2
Epoch: 622 	Training Loss: 1.179776 	Validation Loss: 1.339046 	 time: 0.3
Epoch: 623 	Training Loss: 1.179739 	Validation Loss: 1.339083 	 time: 0.2
Epoch: 624 	Training Loss: 1.179705 	Validation Loss: 1.339095 	 time: 0.2
Epoch: 625 	Training Loss: 1.179669 	Validation Loss: 1.339113 	 time: 0.3
Epoch: 626 	Training Loss: 1.179633 	Validation Loss: 1.339129 	 time: 0.3
Epoch: 627 	Training Loss: 1.179598 	Validation Loss: 1.339069 	 time: 0.2
Epoch: 628 	Training Loss: 1.179564 	Validation Loss: 1.338940 	 time: 0.2
Epoch: 629 	Training Loss: 1.179529 	Validation Loss: 1.338829 	 time: 0.2
Epoch: 630 	Training Loss: 1.179495 	Validation Loss: 1.338770 	 time: 0.2
Epoch: 631 	Training Loss: 1.179462 	Validation Loss: 1.338737 	 time: 0.3
Epoch: 632 	Training Loss: 1.179427 	Validation Loss: 1.338767 	 time: 0.3
Epoch: 633 	Training Loss: 1.179385 	Validation Loss: 1.338888 	 time: 0.3
Epoch: 634 	Training Loss: 1.179326 	Validation Loss: 1.339031 	 time: 0.3
Epoch: 635 	Training Loss: 1.179258 	Validation Loss: 1.339016 	 time: 0.3
Epoch: 636 	Training Loss: 1.179211 	Validation Loss: 1.338949 	 time: 0.3
Epoch: 637 	Training Loss: 1.179174 	Validation Loss: 1.338990 	 time: 0.3
Epoch: 638 	Training Loss: 1.179133 	Validation Loss: 1.338966 	 time: 0.3
Epoch: 639 	Training Loss: 1.179096 	Validation Loss: 1.338991 	 time: 0.3
Epoch: 640 	Training Loss: 1.179066 	Validation Loss: 1.339258 	 time: 0.3
Epoch: 641 	Training Loss: 1.179033 	Validation Loss: 1.339457 	 time: 0.3
Epoch: 642 	Training Loss: 1.179001 	Validation Loss: 1.339471 	 time: 0.3
Epoch: 643 	Training Loss: 1.178963 	Validation Loss: 1.339463 	 time: 0.3
Epoch: 644 	Training Loss: 1.178926 	Validation Loss: 1.339475 	 time: 0.3
Epoch: 645 	Training Loss: 1.178878 	Validation Loss: 1.339413 	 time: 0.3
Epoch: 646 	Training Loss: 1.178817 	Validation Loss: 1.339377 	 time: 0.3
Epoch: 647 	Training Loss: 1.178768 	Validation Loss: 1.339471 	 time: 0.3
Epoch: 648 	Training Loss: 1.178713 	Validation Loss: 1.339574 	 time: 0.3
Epoch: 649 	Training Loss: 1.178661 	Validation Loss: 1.339648 	 time: 0.3
Epoch: 650 	Training Loss: 1.178610 	Validation Loss: 1.339788 	 time: 0.3
Epoch: 651 	Training Loss: 1.178571 	Validation Loss: 1.339860 	 time: 0.3
Epoch: 652 	Training Loss: 1.178537 	Validation Loss: 1.339837 	 time: 0.2
Epoch: 653 	Training Loss: 1.178499 	Validation Loss: 1.339798 	 time: 0.3
Epoch: 654 	Training Loss: 1.178461 	Validation Loss: 1.339805 	 time: 0.3
Epoch: 655 	Training Loss: 1.178427 	Validation Loss: 1.339803 	 time: 0.2
Epoch: 656 	Training Loss: 1.178391 	Validation Loss: 1.339802 	 time: 0.3
Epoch: 657 	Training Loss: 1.178353 	Validation Loss: 1.339828 	 time: 0.2
Epoch: 658 	Training Loss: 1.178311 	Validation Loss: 1.339782 	 time: 0.3
Epoch: 659 	Training Loss: 1.178277 	Validation Loss: 1.339638 	 time: 0.3
Epoch: 660 	Training Loss: 1.178244 	Validation Loss: 1.339542 	 time: 0.2
Epoch: 661 	Training Loss: 1.178206 	Validation Loss: 1.339503 	 time: 0.2
Epoch: 662 	Training Loss: 1.178166 	Validation Loss: 1.339471 	 time: 0.3
Epoch: 663 	Training Loss: 1.178128 	Validation Loss: 1.339551 	 time: 0.3
Epoch: 664 	Training Loss: 1.178091 	Validation Loss: 1.339734 	 time: 0.3
Epoch: 665 	Training Loss: 1.178054 	Validation Loss: 1.339858 	 time: 0.2
Epoch: 666 	Training Loss: 1.178025 	Validation Loss: 1.339894 	 time: 0.2
Epoch: 667 	Training Loss: 1.178000 	Validation Loss: 1.339895 	 time: 0.3
Epoch: 668 	Training Loss: 1.177974 	Validation Loss: 1.339841 	 time: 0.3
Epoch: 669 	Training Loss: 1.177948 	Validation Loss: 1.339738 	 time: 0.2
Epoch: 670 	Training Loss: 1.177920 	Validation Loss: 1.339666 	 time: 0.2
Epoch: 671 	Training Loss: 1.177884 	Validation Loss: 1.339591 	 time: 0.3
Epoch: 672 	Training Loss: 1.177840 	Validation Loss: 1.339453 	 time: 0.3
Epoch: 673 	Training Loss: 1.177797 	Validation Loss: 1.339338 	 time: 0.3
Epoch: 674 	Training Loss: 1.177761 	Validation Loss: 1.339282 	 time: 0.3
Epoch: 675 	Training Loss: 1.177722 	Validation Loss: 1.339213 	 time: 0.2
Epoch: 676 	Training Loss: 1.177684 	Validation Loss: 1.339139 	 time: 0.3
Epoch: 677 	Training Loss: 1.177646 	Validation Loss: 1.339085 	 time: 0.3
Epoch: 678 	Training Loss: 1.177604 	Validation Loss: 1.339000 	 time: 0.3
Epoch: 679 	Training Loss: 1.177564 	Validation Loss: 1.338885 	 time: 0.2
Epoch: 680 	Training Loss: 1.177528 	Validation Loss: 1.338780 	 time: 0.2
Epoch: 681 	Training Loss: 1.177490 	Validation Loss: 1.338647 	 time: 0.3
Validation loss decreased from 1.338655 to 1.338647. Model was saved
Epoch: 682 	Training Loss: 1.177445 	Validation Loss: 1.338426 	 time: 0.3
Validation loss decreased from 1.338647 to 1.338426. Model was saved
Epoch: 683 	Training Loss: 1.177408 	Validation Loss: 1.338179 	 time: 0.2
Validation loss decreased from 1.338426 to 1.338179. Model was saved
Epoch: 684 	Training Loss: 1.177379 	Validation Loss: 1.338003 	 time: 0.2
Validation loss decreased from 1.338179 to 1.338003. Model was saved
Epoch: 685 	Training Loss: 1.177355 	Validation Loss: 1.337878 	 time: 0.2
Validation loss decreased from 1.338003 to 1.337878. Model was saved
Epoch: 686 	Training Loss: 1.177330 	Validation Loss: 1.337816 	 time: 0.3
Validation loss decreased from 1.337878 to 1.337816. Model was saved
Epoch: 687 	Training Loss: 1.177304 	Validation Loss: 1.337841 	 time: 0.2
Epoch: 688 	Training Loss: 1.177277 	Validation Loss: 1.337912 	 time: 0.2
Epoch: 689 	Training Loss: 1.177246 	Validation Loss: 1.337990 	 time: 0.2
Epoch: 690 	Training Loss: 1.177217 	Validation Loss: 1.338026 	 time: 0.3
Epoch: 691 	Training Loss: 1.177190 	Validation Loss: 1.337997 	 time: 0.3
Epoch: 692 	Training Loss: 1.177159 	Validation Loss: 1.337930 	 time: 0.2
Epoch: 693 	Training Loss: 1.177127 	Validation Loss: 1.337853 	 time: 0.3
Epoch: 694 	Training Loss: 1.177097 	Validation Loss: 1.337756 	 time: 0.3
Validation loss decreased from 1.337816 to 1.337756. Model was saved
Epoch: 695 	Training Loss: 1.177070 	Validation Loss: 1.337646 	 time: 0.3
Validation loss decreased from 1.337756 to 1.337646. Model was saved
Epoch: 696 	Training Loss: 1.177043 	Validation Loss: 1.337563 	 time: 0.3
Validation loss decreased from 1.337646 to 1.337563. Model was saved
Epoch: 697 	Training Loss: 1.177010 	Validation Loss: 1.337499 	 time: 0.3
Validation loss decreased from 1.337563 to 1.337499. Model was saved
Epoch: 698 	Training Loss: 1.176959 	Validation Loss: 1.337466 	 time: 0.3
Validation loss decreased from 1.337499 to 1.337466. Model was saved
Epoch: 699 	Training Loss: 1.176883 	Validation Loss: 1.337443 	 time: 0.3
Validation loss decreased from 1.337466 to 1.337443. Model was saved
Epoch: 700 	Training Loss: 1.176819 	Validation Loss: 1.337373 	 time: 0.2
Validation loss decreased from 1.337443 to 1.337373. Model was saved
Epoch: 701 	Training Loss: 1.176762 	Validation Loss: 1.337320 	 time: 0.2
Validation loss decreased from 1.337373 to 1.337320. Model was saved
Epoch: 702 	Training Loss: 1.176715 	Validation Loss: 1.337328 	 time: 0.2
Epoch: 703 	Training Loss: 1.176668 	Validation Loss: 1.337297 	 time: 0.2
Validation loss decreased from 1.337320 to 1.337297. Model was saved
Epoch: 704 	Training Loss: 1.176631 	Validation Loss: 1.337148 	 time: 0.3
Validation loss decreased from 1.337297 to 1.337148. Model was saved
Epoch: 705 	Training Loss: 1.176597 	Validation Loss: 1.336980 	 time: 0.3
Validation loss decreased from 1.337148 to 1.336980. Model was saved
Epoch: 706 	Training Loss: 1.176562 	Validation Loss: 1.336873 	 time: 0.3
Validation loss decreased from 1.336980 to 1.336873. Model was saved
Epoch: 707 	Training Loss: 1.176527 	Validation Loss: 1.336814 	 time: 0.3
Validation loss decreased from 1.336873 to 1.336814. Model was saved
Epoch: 708 	Training Loss: 1.176494 	Validation Loss: 1.336770 	 time: 0.3
Validation loss decreased from 1.336814 to 1.336770. Model was saved
Epoch: 709 	Training Loss: 1.176462 	Validation Loss: 1.336747 	 time: 0.3
Validation loss decreased from 1.336770 to 1.336747. Model was saved
Epoch: 710 	Training Loss: 1.176428 	Validation Loss: 1.336791 	 time: 0.3
Epoch: 711 	Training Loss: 1.176394 	Validation Loss: 1.336933 	 time: 0.2
Epoch: 712 	Training Loss: 1.176351 	Validation Loss: 1.337212 	 time: 0.3
Epoch: 713 	Training Loss: 1.176304 	Validation Loss: 1.337442 	 time: 0.3
Epoch: 714 	Training Loss: 1.176268 	Validation Loss: 1.337581 	 time: 0.3
Epoch: 715 	Training Loss: 1.176198 	Validation Loss: 1.337799 	 time: 0.3
Epoch: 716 	Training Loss: 1.176149 	Validation Loss: 1.337846 	 time: 0.2
Epoch: 717 	Training Loss: 1.176107 	Validation Loss: 1.337797 	 time: 0.3
Epoch: 718 	Training Loss: 1.176072 	Validation Loss: 1.337703 	 time: 0.2
Epoch: 719 	Training Loss: 1.176042 	Validation Loss: 1.337400 	 time: 0.2
Epoch: 720 	Training Loss: 1.176013 	Validation Loss: 1.337503 	 time: 0.2
Epoch: 721 	Training Loss: 1.175991 	Validation Loss: 1.337486 	 time: 0.3
Epoch: 722 	Training Loss: 1.175943 	Validation Loss: 1.337585 	 time: 0.3
Epoch: 723 	Training Loss: 1.175904 	Validation Loss: 1.337401 	 time: 0.3
Epoch: 724 	Training Loss: 1.175834 	Validation Loss: 1.337485 	 time: 0.3
Epoch: 725 	Training Loss: 1.175733 	Validation Loss: 1.337143 	 time: 0.3
Epoch: 726 	Training Loss: 1.175650 	Validation Loss: 1.337098 	 time: 0.3
Epoch: 727 	Training Loss: 1.175610 	Validation Loss: 1.337332 	 time: 0.3
Epoch: 728 	Training Loss: 1.175556 	Validation Loss: 1.337429 	 time: 0.2
Epoch: 729 	Training Loss: 1.175498 	Validation Loss: 1.337452 	 time: 0.2
Epoch: 730 	Training Loss: 1.175462 	Validation Loss: 1.337603 	 time: 0.2
Epoch: 731 	Training Loss: 1.175427 	Validation Loss: 1.337709 	 time: 0.3
Epoch: 732 	Training Loss: 1.175404 	Validation Loss: 1.337544 	 time: 0.3
Epoch: 733 	Training Loss: 1.175395 	Validation Loss: 1.337701 	 time: 0.3
Epoch: 734 	Training Loss: 1.175404 	Validation Loss: 1.337612 	 time: 0.3
Epoch: 735 	Training Loss: 1.175458 	Validation Loss: 1.337839 	 time: 0.3
Epoch: 736 	Training Loss: 1.175639 	Validation Loss: 1.337769 	 time: 0.3
Epoch: 737 	Training Loss: 1.175702 	Validation Loss: 1.338259 	 time: 0.2
Epoch: 738 	Training Loss: 1.175733 	Validation Loss: 1.337586 	 time: 0.3
Epoch: 739 	Training Loss: 1.175467 	Validation Loss: 1.337681 	 time: 0.3
Epoch: 1 	Training Loss: 1.799176 	Validation Loss: 1.819242 	 time: 0.3
Validation loss decreased from inf to 1.819242. Model was saved
Epoch: 2 	Training Loss: 1.817621 	Validation Loss: 1.799715 	 time: 0.3
Validation loss decreased from 1.819242 to 1.799715. Model was saved
Epoch: 3 	Training Loss: 1.798856 	Validation Loss: 1.783536 	 time: 0.3
Validation loss decreased from 1.799715 to 1.783536. Model was saved
Epoch: 4 	Training Loss: 1.783101 	Validation Loss: 1.772716 	 time: 0.3
Validation loss decreased from 1.783536 to 1.772716. Model was saved
Epoch: 5 	Training Loss: 1.772148 	Validation Loss: 1.759943 	 time: 0.3
Validation loss decreased from 1.772716 to 1.759943. Model was saved
Epoch: 6 	Training Loss: 1.759604 	Validation Loss: 1.744785 	 time: 0.3
Validation loss decreased from 1.759943 to 1.744785. Model was saved
Epoch: 7 	Training Loss: 1.745294 	Validation Loss: 1.726852 	 time: 0.3
Validation loss decreased from 1.744785 to 1.726852. Model was saved
Epoch: 8 	Training Loss: 1.726322 	Validation Loss: 1.711206 	 time: 0.3
Validation loss decreased from 1.726852 to 1.711206. Model was saved
Epoch: 9 	Training Loss: 1.707553 	Validation Loss: 1.695170 	 time: 0.3
Validation loss decreased from 1.711206 to 1.695170. Model was saved
Epoch: 10 	Training Loss: 1.689002 	Validation Loss: 1.678772 	 time: 0.3
Validation loss decreased from 1.695170 to 1.678772. Model was saved
Epoch: 11 	Training Loss: 1.670529 	Validation Loss: 1.664277 	 time: 0.3
Validation loss decreased from 1.678772 to 1.664277. Model was saved
Epoch: 12 	Training Loss: 1.651686 	Validation Loss: 1.650703 	 time: 0.3
Validation loss decreased from 1.664277 to 1.650703. Model was saved
Epoch: 13 	Training Loss: 1.633700 	Validation Loss: 1.637441 	 time: 0.2
Validation loss decreased from 1.650703 to 1.637441. Model was saved
Epoch: 14 	Training Loss: 1.617525 	Validation Loss: 1.629277 	 time: 0.3
Validation loss decreased from 1.637441 to 1.629277. Model was saved
Epoch: 15 	Training Loss: 1.603886 	Validation Loss: 1.622040 	 time: 0.3
Validation loss decreased from 1.629277 to 1.622040. Model was saved
Epoch: 16 	Training Loss: 1.590390 	Validation Loss: 1.611985 	 time: 0.3
Validation loss decreased from 1.622040 to 1.611985. Model was saved
Epoch: 17 	Training Loss: 1.577554 	Validation Loss: 1.601652 	 time: 0.3
Validation loss decreased from 1.611985 to 1.601652. Model was saved
Epoch: 18 	Training Loss: 1.566393 	Validation Loss: 1.592516 	 time: 0.2
Validation loss decreased from 1.601652 to 1.592516. Model was saved
Epoch: 19 	Training Loss: 1.556648 	Validation Loss: 1.582877 	 time: 0.3
Validation loss decreased from 1.592516 to 1.582877. Model was saved
Epoch: 20 	Training Loss: 1.546892 	Validation Loss: 1.574509 	 time: 0.3
Validation loss decreased from 1.582877 to 1.574509. Model was saved
Epoch: 21 	Training Loss: 1.537905 	Validation Loss: 1.567320 	 time: 0.3
Validation loss decreased from 1.574509 to 1.567320. Model was saved
Epoch: 22 	Training Loss: 1.529490 	Validation Loss: 1.560764 	 time: 0.3
Validation loss decreased from 1.567320 to 1.560764. Model was saved
Epoch: 23 	Training Loss: 1.521795 	Validation Loss: 1.555331 	 time: 0.3
Validation loss decreased from 1.560764 to 1.555331. Model was saved
Epoch: 24 	Training Loss: 1.514920 	Validation Loss: 1.552785 	 time: 0.3
Validation loss decreased from 1.555331 to 1.552785. Model was saved
Epoch: 25 	Training Loss: 1.508217 	Validation Loss: 1.548830 	 time: 0.3
Validation loss decreased from 1.552785 to 1.548830. Model was saved
Epoch: 26 	Training Loss: 1.501732 	Validation Loss: 1.546365 	 time: 0.3
Validation loss decreased from 1.548830 to 1.546365. Model was saved
Epoch: 27 	Training Loss: 1.496021 	Validation Loss: 1.544622 	 time: 0.3
Validation loss decreased from 1.546365 to 1.544622. Model was saved
Epoch: 28 	Training Loss: 1.491129 	Validation Loss: 1.543417 	 time: 0.3
Validation loss decreased from 1.544622 to 1.543417. Model was saved
Epoch: 29 	Training Loss: 1.486847 	Validation Loss: 1.539559 	 time: 0.3
Validation loss decreased from 1.543417 to 1.539559. Model was saved
Epoch: 30 	Training Loss: 1.483168 	Validation Loss: 1.541129 	 time: 0.3
Epoch: 31 	Training Loss: 1.480084 	Validation Loss: 1.532946 	 time: 0.3
Validation loss decreased from 1.539559 to 1.532946. Model was saved
Epoch: 32 	Training Loss: 1.477488 	Validation Loss: 1.532040 	 time: 0.3
Validation loss decreased from 1.532946 to 1.532040. Model was saved
Epoch: 33 	Training Loss: 1.470662 	Validation Loss: 1.532770 	 time: 0.3
Epoch: 34 	Training Loss: 1.469271 	Validation Loss: 1.524268 	 time: 0.3
Validation loss decreased from 1.532040 to 1.524268. Model was saved
Epoch: 35 	Training Loss: 1.465768 	Validation Loss: 1.522358 	 time: 0.3
Validation loss decreased from 1.524268 to 1.522358. Model was saved
Epoch: 36 	Training Loss: 1.461191 	Validation Loss: 1.527780 	 time: 0.3
Epoch: 37 	Training Loss: 1.460992 	Validation Loss: 1.517313 	 time: 0.3
Validation loss decreased from 1.522358 to 1.517313. Model was saved
Epoch: 38 	Training Loss: 1.455454 	Validation Loss: 1.514231 	 time: 0.3
Validation loss decreased from 1.517313 to 1.514231. Model was saved
Epoch: 39 	Training Loss: 1.454139 	Validation Loss: 1.516786 	 time: 0.3
Epoch: 40 	Training Loss: 1.450811 	Validation Loss: 1.512654 	 time: 0.2
Validation loss decreased from 1.514231 to 1.512654. Model was saved
Epoch: 41 	Training Loss: 1.447639 	Validation Loss: 1.508653 	 time: 0.3
Validation loss decreased from 1.512654 to 1.508653. Model was saved
Epoch: 42 	Training Loss: 1.446566 	Validation Loss: 1.507569 	 time: 0.3
Validation loss decreased from 1.508653 to 1.507569. Model was saved
Epoch: 43 	Training Loss: 1.443276 	Validation Loss: 1.508918 	 time: 0.3
Epoch: 44 	Training Loss: 1.442692 	Validation Loss: 1.503601 	 time: 0.3
Validation loss decreased from 1.507569 to 1.503601. Model was saved
Epoch: 45 	Training Loss: 1.439600 	Validation Loss: 1.502732 	 time: 0.3
Validation loss decreased from 1.503601 to 1.502732. Model was saved
Epoch: 46 	Training Loss: 1.437688 	Validation Loss: 1.503710 	 time: 0.3
Epoch: 47 	Training Loss: 1.436072 	Validation Loss: 1.501229 	 time: 0.3
Validation loss decreased from 1.502732 to 1.501229. Model was saved
Epoch: 48 	Training Loss: 1.433088 	Validation Loss: 1.500721 	 time: 0.3
Validation loss decreased from 1.501229 to 1.500721. Model was saved
Epoch: 49 	Training Loss: 1.432050 	Validation Loss: 1.501025 	 time: 0.3
Epoch: 50 	Training Loss: 1.430119 	Validation Loss: 1.498695 	 time: 0.2
Validation loss decreased from 1.500721 to 1.498695. Model was saved
Epoch: 51 	Training Loss: 1.427562 	Validation Loss: 1.498532 	 time: 0.3
Validation loss decreased from 1.498695 to 1.498532. Model was saved
Epoch: 52 	Training Loss: 1.426237 	Validation Loss: 1.498197 	 time: 0.3
Validation loss decreased from 1.498532 to 1.498197. Model was saved
Epoch: 53 	Training Loss: 1.424412 	Validation Loss: 1.496510 	 time: 0.3
Validation loss decreased from 1.498197 to 1.496510. Model was saved
Epoch: 54 	Training Loss: 1.422059 	Validation Loss: 1.496245 	 time: 0.3
Validation loss decreased from 1.496510 to 1.496245. Model was saved
Epoch: 55 	Training Loss: 1.420332 	Validation Loss: 1.495206 	 time: 0.3
Validation loss decreased from 1.496245 to 1.495206. Model was saved
Epoch: 56 	Training Loss: 1.418935 	Validation Loss: 1.494850 	 time: 0.3
Validation loss decreased from 1.495206 to 1.494850. Model was saved
Epoch: 57 	Training Loss: 1.417078 	Validation Loss: 1.492485 	 time: 0.3
Validation loss decreased from 1.494850 to 1.492485. Model was saved
Epoch: 58 	Training Loss: 1.414515 	Validation Loss: 1.491129 	 time: 0.3
Validation loss decreased from 1.492485 to 1.491129. Model was saved
Epoch: 59 	Training Loss: 1.412111 	Validation Loss: 1.487334 	 time: 0.3
Validation loss decreased from 1.491129 to 1.487334. Model was saved
Epoch: 60 	Training Loss: 1.410119 	Validation Loss: 1.488265 	 time: 0.3
Epoch: 61 	Training Loss: 1.408350 	Validation Loss: 1.483585 	 time: 0.2
Validation loss decreased from 1.487334 to 1.483585. Model was saved
Epoch: 62 	Training Loss: 1.407516 	Validation Loss: 1.488062 	 time: 0.3
Epoch: 63 	Training Loss: 1.405365 	Validation Loss: 1.480432 	 time: 0.3
Validation loss decreased from 1.483585 to 1.480432. Model was saved
Epoch: 64 	Training Loss: 1.403773 	Validation Loss: 1.480683 	 time: 0.3
Epoch: 65 	Training Loss: 1.399213 	Validation Loss: 1.481800 	 time: 0.3
Epoch: 66 	Training Loss: 1.397834 	Validation Loss: 1.476235 	 time: 0.2
Validation loss decreased from 1.480432 to 1.476235. Model was saved
Epoch: 67 	Training Loss: 1.396381 	Validation Loss: 1.474292 	 time: 0.3
Validation loss decreased from 1.476235 to 1.474292. Model was saved
Epoch: 68 	Training Loss: 1.391292 	Validation Loss: 1.481501 	 time: 0.3
Epoch: 69 	Training Loss: 1.392817 	Validation Loss: 1.473658 	 time: 0.3
Validation loss decreased from 1.474292 to 1.473658. Model was saved
Epoch: 70 	Training Loss: 1.390248 	Validation Loss: 1.470399 	 time: 0.3
Validation loss decreased from 1.473658 to 1.470399. Model was saved
Epoch: 71 	Training Loss: 1.385759 	Validation Loss: 1.477035 	 time: 0.3
Epoch: 72 	Training Loss: 1.387807 	Validation Loss: 1.467912 	 time: 0.2
Validation loss decreased from 1.470399 to 1.467912. Model was saved
Epoch: 73 	Training Loss: 1.383300 	Validation Loss: 1.467851 	 time: 0.3
Validation loss decreased from 1.467912 to 1.467851. Model was saved
Epoch: 74 	Training Loss: 1.382077 	Validation Loss: 1.468648 	 time: 0.3
Epoch: 75 	Training Loss: 1.380497 	Validation Loss: 1.464843 	 time: 0.3
Validation loss decreased from 1.467851 to 1.464843. Model was saved
Epoch: 76 	Training Loss: 1.377195 	Validation Loss: 1.465523 	 time: 0.3
Epoch: 77 	Training Loss: 1.377507 	Validation Loss: 1.462740 	 time: 0.2
Validation loss decreased from 1.464843 to 1.462740. Model was saved
Epoch: 78 	Training Loss: 1.373536 	Validation Loss: 1.463663 	 time: 0.3
Epoch: 79 	Training Loss: 1.373385 	Validation Loss: 1.461737 	 time: 0.3
Validation loss decreased from 1.462740 to 1.461737. Model was saved
Epoch: 80 	Training Loss: 1.371788 	Validation Loss: 1.459390 	 time: 0.3
Validation loss decreased from 1.461737 to 1.459390. Model was saved
Epoch: 81 	Training Loss: 1.368789 	Validation Loss: 1.460895 	 time: 0.3
Epoch: 82 	Training Loss: 1.369245 	Validation Loss: 1.457835 	 time: 0.3
Validation loss decreased from 1.459390 to 1.457835. Model was saved
Epoch: 83 	Training Loss: 1.366816 	Validation Loss: 1.457256 	 time: 0.3
Validation loss decreased from 1.457835 to 1.457256. Model was saved
Epoch: 84 	Training Loss: 1.365059 	Validation Loss: 1.457033 	 time: 0.3
Validation loss decreased from 1.457256 to 1.457033. Model was saved
Epoch: 85 	Training Loss: 1.364993 	Validation Loss: 1.455657 	 time: 0.3
Validation loss decreased from 1.457033 to 1.455657. Model was saved
Epoch: 86 	Training Loss: 1.361666 	Validation Loss: 1.455626 	 time: 0.3
Validation loss decreased from 1.455657 to 1.455626. Model was saved
Epoch: 87 	Training Loss: 1.361315 	Validation Loss: 1.455455 	 time: 0.3
Validation loss decreased from 1.455626 to 1.455455. Model was saved
Epoch: 88 	Training Loss: 1.359524 	Validation Loss: 1.453168 	 time: 0.3
Validation loss decreased from 1.455455 to 1.453168. Model was saved
Epoch: 89 	Training Loss: 1.358484 	Validation Loss: 1.454085 	 time: 0.3
Epoch: 90 	Training Loss: 1.358772 	Validation Loss: 1.451964 	 time: 0.3
Validation loss decreased from 1.453168 to 1.451964. Model was saved
Epoch: 91 	Training Loss: 1.355665 	Validation Loss: 1.451594 	 time: 0.3
Validation loss decreased from 1.451964 to 1.451594. Model was saved
Epoch: 92 	Training Loss: 1.353579 	Validation Loss: 1.448605 	 time: 0.2
Validation loss decreased from 1.451594 to 1.448605. Model was saved
Epoch: 93 	Training Loss: 1.351126 	Validation Loss: 1.447655 	 time: 0.3
Validation loss decreased from 1.448605 to 1.447655. Model was saved
Epoch: 94 	Training Loss: 1.349455 	Validation Loss: 1.448403 	 time: 0.3
Epoch: 95 	Training Loss: 1.348923 	Validation Loss: 1.448328 	 time: 0.3
Epoch: 96 	Training Loss: 1.348815 	Validation Loss: 1.448320 	 time: 0.3
Epoch: 97 	Training Loss: 1.347964 	Validation Loss: 1.446106 	 time: 0.3
Validation loss decreased from 1.447655 to 1.446106. Model was saved
Epoch: 98 	Training Loss: 1.345660 	Validation Loss: 1.444934 	 time: 0.3
Validation loss decreased from 1.446106 to 1.444934. Model was saved
Epoch: 99 	Training Loss: 1.342493 	Validation Loss: 1.444219 	 time: 0.3
Validation loss decreased from 1.444934 to 1.444219. Model was saved
Epoch: 100 	Training Loss: 1.341025 	Validation Loss: 1.442484 	 time: 0.3
Validation loss decreased from 1.444219 to 1.442484. Model was saved
Epoch: 101 	Training Loss: 1.339186 	Validation Loss: 1.442544 	 time: 0.3
Epoch: 102 	Training Loss: 1.338881 	Validation Loss: 1.443274 	 time: 0.3
Epoch: 103 	Training Loss: 1.339852 	Validation Loss: 1.443936 	 time: 0.3
Epoch: 104 	Training Loss: 1.337994 	Validation Loss: 1.440623 	 time: 0.3
Validation loss decreased from 1.442484 to 1.440623. Model was saved
Epoch: 105 	Training Loss: 1.336540 	Validation Loss: 1.441487 	 time: 0.3
Epoch: 106 	Training Loss: 1.333526 	Validation Loss: 1.438774 	 time: 0.3
Validation loss decreased from 1.440623 to 1.438774. Model was saved
Epoch: 107 	Training Loss: 1.330506 	Validation Loss: 1.437647 	 time: 0.3
Validation loss decreased from 1.438774 to 1.437647. Model was saved
Epoch: 108 	Training Loss: 1.329884 	Validation Loss: 1.439479 	 time: 0.3
Epoch: 109 	Training Loss: 1.329557 	Validation Loss: 1.437484 	 time: 0.3
Validation loss decreased from 1.437647 to 1.437484. Model was saved
Epoch: 110 	Training Loss: 1.329072 	Validation Loss: 1.436981 	 time: 0.3
Validation loss decreased from 1.437484 to 1.436981. Model was saved
Epoch: 111 	Training Loss: 1.326795 	Validation Loss: 1.435345 	 time: 0.3
Validation loss decreased from 1.436981 to 1.435345. Model was saved
Epoch: 112 	Training Loss: 1.323671 	Validation Loss: 1.434849 	 time: 0.3
Validation loss decreased from 1.435345 to 1.434849. Model was saved
Epoch: 113 	Training Loss: 1.321897 	Validation Loss: 1.434265 	 time: 0.3
Validation loss decreased from 1.434849 to 1.434265. Model was saved
Epoch: 114 	Training Loss: 1.321550 	Validation Loss: 1.433345 	 time: 0.3
Validation loss decreased from 1.434265 to 1.433345. Model was saved
Epoch: 115 	Training Loss: 1.320311 	Validation Loss: 1.432942 	 time: 0.3
Validation loss decreased from 1.433345 to 1.432942. Model was saved
Epoch: 116 	Training Loss: 1.318389 	Validation Loss: 1.429917 	 time: 0.3
Validation loss decreased from 1.432942 to 1.429917. Model was saved
Epoch: 117 	Training Loss: 1.316962 	Validation Loss: 1.430743 	 time: 0.3
Epoch: 118 	Training Loss: 1.314911 	Validation Loss: 1.428518 	 time: 0.3
Validation loss decreased from 1.429917 to 1.428518. Model was saved
Epoch: 119 	Training Loss: 1.313118 	Validation Loss: 1.427538 	 time: 0.3
Validation loss decreased from 1.428518 to 1.427538. Model was saved
Epoch: 120 	Training Loss: 1.311735 	Validation Loss: 1.427550 	 time: 0.3
Epoch: 121 	Training Loss: 1.310548 	Validation Loss: 1.426013 	 time: 0.3
Validation loss decreased from 1.427538 to 1.426013. Model was saved
Epoch: 122 	Training Loss: 1.308562 	Validation Loss: 1.423759 	 time: 0.3
Validation loss decreased from 1.426013 to 1.423759. Model was saved
Epoch: 123 	Training Loss: 1.307498 	Validation Loss: 1.426146 	 time: 0.3
Epoch: 124 	Training Loss: 1.306946 	Validation Loss: 1.422052 	 time: 0.3
Validation loss decreased from 1.423759 to 1.422052. Model was saved
Epoch: 125 	Training Loss: 1.306053 	Validation Loss: 1.425139 	 time: 0.3
Epoch: 126 	Training Loss: 1.305678 	Validation Loss: 1.424446 	 time: 0.3
Epoch: 127 	Training Loss: 1.307196 	Validation Loss: 1.422864 	 time: 0.3
Epoch: 128 	Training Loss: 1.302760 	Validation Loss: 1.420180 	 time: 0.3
Validation loss decreased from 1.422052 to 1.420180. Model was saved
Epoch: 129 	Training Loss: 1.299230 	Validation Loss: 1.419357 	 time: 0.3
Validation loss decreased from 1.420180 to 1.419357. Model was saved
Epoch: 130 	Training Loss: 1.297729 	Validation Loss: 1.420672 	 time: 0.3
Epoch: 131 	Training Loss: 1.298216 	Validation Loss: 1.420002 	 time: 0.3
Epoch: 132 	Training Loss: 1.299010 	Validation Loss: 1.419377 	 time: 0.3
Epoch: 133 	Training Loss: 1.294868 	Validation Loss: 1.417172 	 time: 0.3
Validation loss decreased from 1.419357 to 1.417172. Model was saved
Epoch: 134 	Training Loss: 1.292344 	Validation Loss: 1.417044 	 time: 0.3
Validation loss decreased from 1.417172 to 1.417044. Model was saved
Epoch: 135 	Training Loss: 1.291370 	Validation Loss: 1.416629 	 time: 0.3
Validation loss decreased from 1.417044 to 1.416629. Model was saved
Epoch: 136 	Training Loss: 1.291453 	Validation Loss: 1.417328 	 time: 0.3
Epoch: 137 	Training Loss: 1.291697 	Validation Loss: 1.416040 	 time: 0.3
Validation loss decreased from 1.416629 to 1.416040. Model was saved
Epoch: 138 	Training Loss: 1.288315 	Validation Loss: 1.414240 	 time: 0.3
Validation loss decreased from 1.416040 to 1.414240. Model was saved
Epoch: 139 	Training Loss: 1.286129 	Validation Loss: 1.414660 	 time: 0.3
Epoch: 140 	Training Loss: 1.285207 	Validation Loss: 1.413145 	 time: 0.3
Validation loss decreased from 1.414240 to 1.413145. Model was saved
Epoch: 141 	Training Loss: 1.284787 	Validation Loss: 1.414175 	 time: 0.3
Epoch: 142 	Training Loss: 1.284576 	Validation Loss: 1.411556 	 time: 0.3
Validation loss decreased from 1.413145 to 1.411556. Model was saved
Epoch: 143 	Training Loss: 1.283133 	Validation Loss: 1.411465 	 time: 0.3
Validation loss decreased from 1.411556 to 1.411465. Model was saved
Epoch: 144 	Training Loss: 1.280863 	Validation Loss: 1.411414 	 time: 0.3
Validation loss decreased from 1.411465 to 1.411414. Model was saved
Epoch: 145 	Training Loss: 1.279658 	Validation Loss: 1.407694 	 time: 0.3
Validation loss decreased from 1.411414 to 1.407694. Model was saved
Epoch: 146 	Training Loss: 1.280228 	Validation Loss: 1.411418 	 time: 0.3
Epoch: 147 	Training Loss: 1.281190 	Validation Loss: 1.409096 	 time: 0.3
Epoch: 148 	Training Loss: 1.281630 	Validation Loss: 1.411749 	 time: 0.3
Epoch: 149 	Training Loss: 1.283639 	Validation Loss: 1.416998 	 time: 0.2
Epoch: 150 	Training Loss: 1.288575 	Validation Loss: 1.401046 	 time: 0.3
Validation loss decreased from 1.407694 to 1.401046. Model was saved
Epoch: 151 	Training Loss: 1.274143 	Validation Loss: 1.410173 	 time: 0.3
Epoch: 152 	Training Loss: 1.285939 	Validation Loss: 1.420244 	 time: 0.3
Epoch: 153 	Training Loss: 1.293042 	Validation Loss: 1.407351 	 time: 0.3
Epoch: 154 	Training Loss: 1.279083 	Validation Loss: 1.402242 	 time: 0.3
Epoch: 155 	Training Loss: 1.280861 	Validation Loss: 1.405205 	 time: 0.3
Epoch: 156 	Training Loss: 1.272756 	Validation Loss: 1.411018 	 time: 0.3
Epoch: 157 	Training Loss: 1.280553 	Validation Loss: 1.398477 	 time: 0.3
Validation loss decreased from 1.401046 to 1.398477. Model was saved
Epoch: 158 	Training Loss: 1.268201 	Validation Loss: 1.401400 	 time: 0.3
Epoch: 159 	Training Loss: 1.277749 	Validation Loss: 1.396366 	 time: 0.3
Validation loss decreased from 1.398477 to 1.396366. Model was saved
Epoch: 160 	Training Loss: 1.264444 	Validation Loss: 1.409524 	 time: 0.3
Epoch: 161 	Training Loss: 1.271272 	Validation Loss: 1.401471 	 time: 0.3
Epoch: 162 	Training Loss: 1.263067 	Validation Loss: 1.394849 	 time: 0.3
Validation loss decreased from 1.396366 to 1.394849. Model was saved
Epoch: 163 	Training Loss: 1.263295 	Validation Loss: 1.395806 	 time: 0.3
Epoch: 164 	Training Loss: 1.263850 	Validation Loss: 1.395858 	 time: 0.3
Epoch: 165 	Training Loss: 1.259858 	Validation Loss: 1.396241 	 time: 0.3
Epoch: 166 	Training Loss: 1.258400 	Validation Loss: 1.398103 	 time: 0.3
Epoch: 167 	Training Loss: 1.260146 	Validation Loss: 1.393090 	 time: 0.3
Validation loss decreased from 1.394849 to 1.393090. Model was saved
Epoch: 168 	Training Loss: 1.255740 	Validation Loss: 1.391321 	 time: 0.3
Validation loss decreased from 1.393090 to 1.391321. Model was saved
Epoch: 169 	Training Loss: 1.256402 	Validation Loss: 1.388745 	 time: 0.3
Validation loss decreased from 1.391321 to 1.388745. Model was saved
Epoch: 170 	Training Loss: 1.255241 	Validation Loss: 1.389264 	 time: 0.3
Epoch: 171 	Training Loss: 1.251687 	Validation Loss: 1.393804 	 time: 0.3
Epoch: 172 	Training Loss: 1.253663 	Validation Loss: 1.389807 	 time: 0.3
Epoch: 173 	Training Loss: 1.250335 	Validation Loss: 1.386891 	 time: 0.2
Validation loss decreased from 1.388745 to 1.386891. Model was saved
Epoch: 174 	Training Loss: 1.249134 	Validation Loss: 1.386859 	 time: 0.3
Validation loss decreased from 1.386891 to 1.386859. Model was saved
Epoch: 175 	Training Loss: 1.249664 	Validation Loss: 1.385373 	 time: 0.3
Validation loss decreased from 1.386859 to 1.385373. Model was saved
Epoch: 176 	Training Loss: 1.246465 	Validation Loss: 1.387579 	 time: 0.3
Epoch: 177 	Training Loss: 1.247095 	Validation Loss: 1.386299 	 time: 0.3
Epoch: 178 	Training Loss: 1.246382 	Validation Loss: 1.384463 	 time: 0.3
Validation loss decreased from 1.385373 to 1.384463. Model was saved
Epoch: 179 	Training Loss: 1.244962 	Validation Loss: 1.381363 	 time: 0.3
Validation loss decreased from 1.384463 to 1.381363. Model was saved
Epoch: 180 	Training Loss: 1.245100 	Validation Loss: 1.383455 	 time: 0.3
Epoch: 181 	Training Loss: 1.242699 	Validation Loss: 1.384558 	 time: 0.3
Epoch: 182 	Training Loss: 1.241721 	Validation Loss: 1.384247 	 time: 0.3
Epoch: 183 	Training Loss: 1.243089 	Validation Loss: 1.387026 	 time: 0.3
Epoch: 184 	Training Loss: 1.243338 	Validation Loss: 1.381755 	 time: 0.3
Epoch: 185 	Training Loss: 1.244104 	Validation Loss: 1.384074 	 time: 0.3
Epoch: 186 	Training Loss: 1.241911 	Validation Loss: 1.382966 	 time: 0.3
Epoch: 187 	Training Loss: 1.239523 	Validation Loss: 1.382460 	 time: 0.3
Epoch: 188 	Training Loss: 1.241295 	Validation Loss: 1.384201 	 time: 0.2
Epoch: 189 	Training Loss: 1.240091 	Validation Loss: 1.381689 	 time: 0.3
Epoch: 190 	Training Loss: 1.236999 	Validation Loss: 1.380307 	 time: 0.3
Validation loss decreased from 1.381363 to 1.380307. Model was saved
Epoch: 191 	Training Loss: 1.237043 	Validation Loss: 1.382749 	 time: 0.3
Epoch: 192 	Training Loss: 1.237192 	Validation Loss: 1.381890 	 time: 0.3
Epoch: 193 	Training Loss: 1.235668 	Validation Loss: 1.377551 	 time: 0.3
Validation loss decreased from 1.380307 to 1.377551. Model was saved
Epoch: 194 	Training Loss: 1.234546 	Validation Loss: 1.378500 	 time: 0.3
Epoch: 195 	Training Loss: 1.235828 	Validation Loss: 1.379873 	 time: 0.2
Epoch: 196 	Training Loss: 1.233828 	Validation Loss: 1.380053 	 time: 0.3
Epoch: 197 	Training Loss: 1.232964 	Validation Loss: 1.380696 	 time: 0.3
Epoch: 198 	Training Loss: 1.233364 	Validation Loss: 1.378037 	 time: 0.3
Epoch: 199 	Training Loss: 1.231982 	Validation Loss: 1.377146 	 time: 0.3
Validation loss decreased from 1.377551 to 1.377146. Model was saved
Epoch: 200 	Training Loss: 1.232610 	Validation Loss: 1.377807 	 time: 0.3
Epoch: 201 	Training Loss: 1.232186 	Validation Loss: 1.376897 	 time: 0.2
Validation loss decreased from 1.377146 to 1.376897. Model was saved
Epoch: 202 	Training Loss: 1.229314 	Validation Loss: 1.378554 	 time: 0.3
Epoch: 203 	Training Loss: 1.230054 	Validation Loss: 1.378065 	 time: 0.3
Epoch: 204 	Training Loss: 1.229001 	Validation Loss: 1.374182 	 time: 0.3
Validation loss decreased from 1.376897 to 1.374182. Model was saved
Epoch: 205 	Training Loss: 1.226872 	Validation Loss: 1.374272 	 time: 0.3
Epoch: 206 	Training Loss: 1.229275 	Validation Loss: 1.375776 	 time: 0.2
Epoch: 207 	Training Loss: 1.227751 	Validation Loss: 1.376276 	 time: 0.2
Epoch: 208 	Training Loss: 1.225740 	Validation Loss: 1.377297 	 time: 0.3
Epoch: 209 	Training Loss: 1.227081 	Validation Loss: 1.375275 	 time: 0.3
Epoch: 210 	Training Loss: 1.225494 	Validation Loss: 1.372765 	 time: 0.3
Validation loss decreased from 1.374182 to 1.372765. Model was saved
Epoch: 211 	Training Loss: 1.223697 	Validation Loss: 1.373543 	 time: 0.3
Epoch: 212 	Training Loss: 1.225434 	Validation Loss: 1.372465 	 time: 0.3
Validation loss decreased from 1.372765 to 1.372465. Model was saved
Epoch: 213 	Training Loss: 1.223586 	Validation Loss: 1.372917 	 time: 0.3
Epoch: 214 	Training Loss: 1.222365 	Validation Loss: 1.374029 	 time: 0.3
Epoch: 215 	Training Loss: 1.223153 	Validation Loss: 1.372151 	 time: 0.3
Validation loss decreased from 1.372465 to 1.372151. Model was saved
Epoch: 216 	Training Loss: 1.221316 	Validation Loss: 1.369595 	 time: 0.3
Validation loss decreased from 1.372151 to 1.369595. Model was saved
Epoch: 217 	Training Loss: 1.220554 	Validation Loss: 1.370380 	 time: 0.2
Epoch: 218 	Training Loss: 1.221182 	Validation Loss: 1.371628 	 time: 0.3
Epoch: 219 	Training Loss: 1.219794 	Validation Loss: 1.371598 	 time: 0.3
Epoch: 220 	Training Loss: 1.218942 	Validation Loss: 1.371688 	 time: 0.3
Epoch: 221 	Training Loss: 1.219446 	Validation Loss: 1.372396 	 time: 0.3
Epoch: 222 	Training Loss: 1.218318 	Validation Loss: 1.369327 	 time: 0.3
Validation loss decreased from 1.369595 to 1.369327. Model was saved
Epoch: 223 	Training Loss: 1.217408 	Validation Loss: 1.368678 	 time: 0.3
Validation loss decreased from 1.369327 to 1.368678. Model was saved
Epoch: 224 	Training Loss: 1.217458 	Validation Loss: 1.370660 	 time: 0.3
Epoch: 225 	Training Loss: 1.216665 	Validation Loss: 1.370678 	 time: 0.3
Epoch: 226 	Training Loss: 1.216102 	Validation Loss: 1.370489 	 time: 0.3
Epoch: 227 	Training Loss: 1.215562 	Validation Loss: 1.370192 	 time: 0.3
Epoch: 228 	Training Loss: 1.214958 	Validation Loss: 1.369045 	 time: 0.3
Epoch: 229 	Training Loss: 1.214795 	Validation Loss: 1.369266 	 time: 0.3
Epoch: 230 	Training Loss: 1.214063 	Validation Loss: 1.370157 	 time: 0.3
Epoch: 231 	Training Loss: 1.213465 	Validation Loss: 1.370422 	 time: 0.3
Epoch: 232 	Training Loss: 1.213487 	Validation Loss: 1.371163 	 time: 0.3
Epoch: 233 	Training Loss: 1.213145 	Validation Loss: 1.369011 	 time: 0.3
Epoch: 234 	Training Loss: 1.212973 	Validation Loss: 1.369641 	 time: 0.3
Epoch: 235 	Training Loss: 1.212607 	Validation Loss: 1.369153 	 time: 0.2
Epoch: 236 	Training Loss: 1.211829 	Validation Loss: 1.370346 	 time: 0.3
Epoch: 237 	Training Loss: 1.211708 	Validation Loss: 1.370521 	 time: 0.3
Epoch: 238 	Training Loss: 1.211034 	Validation Loss: 1.369151 	 time: 0.3
Epoch: 239 	Training Loss: 1.210163 	Validation Loss: 1.369040 	 time: 0.3
Epoch: 240 	Training Loss: 1.210032 	Validation Loss: 1.369089 	 time: 0.3
Epoch: 241 	Training Loss: 1.209849 	Validation Loss: 1.370720 	 time: 0.3
Epoch: 242 	Training Loss: 1.210215 	Validation Loss: 1.370389 	 time: 0.3
Epoch: 243 	Training Loss: 1.210069 	Validation Loss: 1.371079 	 time: 0.3
Epoch: 244 	Training Loss: 1.209996 	Validation Loss: 1.369860 	 time: 0.3
Epoch: 245 	Training Loss: 1.210082 	Validation Loss: 1.370916 	 time: 0.3
Epoch: 246 	Training Loss: 1.210191 	Validation Loss: 1.368687 	 time: 0.3
Epoch: 247 	Training Loss: 1.208816 	Validation Loss: 1.369227 	 time: 0.3
Epoch: 248 	Training Loss: 1.207481 	Validation Loss: 1.368700 	 time: 0.3
Epoch: 249 	Training Loss: 1.206975 	Validation Loss: 1.367260 	 time: 0.3
Validation loss decreased from 1.368678 to 1.367260. Model was saved
Epoch: 250 	Training Loss: 1.207374 	Validation Loss: 1.368782 	 time: 0.3
Epoch: 251 	Training Loss: 1.207953 	Validation Loss: 1.367083 	 time: 0.3
Validation loss decreased from 1.367260 to 1.367083. Model was saved
Epoch: 252 	Training Loss: 1.207283 	Validation Loss: 1.367783 	 time: 0.3
Epoch: 253 	Training Loss: 1.206633 	Validation Loss: 1.366461 	 time: 0.3
Validation loss decreased from 1.367083 to 1.366461. Model was saved
Epoch: 254 	Training Loss: 1.205340 	Validation Loss: 1.366336 	 time: 0.3
Validation loss decreased from 1.366461 to 1.366336. Model was saved
Epoch: 255 	Training Loss: 1.205046 	Validation Loss: 1.367344 	 time: 0.3
Epoch: 256 	Training Loss: 1.205226 	Validation Loss: 1.366690 	 time: 0.2
Epoch: 257 	Training Loss: 1.204820 	Validation Loss: 1.367372 	 time: 0.3
Epoch: 258 	Training Loss: 1.204679 	Validation Loss: 1.367295 	 time: 0.3
Epoch: 259 	Training Loss: 1.204264 	Validation Loss: 1.365977 	 time: 0.3
Validation loss decreased from 1.366336 to 1.365977. Model was saved
Epoch: 260 	Training Loss: 1.204066 	Validation Loss: 1.366776 	 time: 0.3
Epoch: 261 	Training Loss: 1.203163 	Validation Loss: 1.365371 	 time: 0.3
Validation loss decreased from 1.365977 to 1.365371. Model was saved
Epoch: 262 	Training Loss: 1.202375 	Validation Loss: 1.365820 	 time: 0.3
Epoch: 263 	Training Loss: 1.202167 	Validation Loss: 1.367839 	 time: 0.3
Epoch: 264 	Training Loss: 1.202621 	Validation Loss: 1.366439 	 time: 0.3
Epoch: 265 	Training Loss: 1.203856 	Validation Loss: 1.369830 	 time: 0.3
Epoch: 266 	Training Loss: 1.205043 	Validation Loss: 1.367849 	 time: 0.3
Epoch: 267 	Training Loss: 1.208252 	Validation Loss: 1.371428 	 time: 0.2
Epoch: 268 	Training Loss: 1.207596 	Validation Loss: 1.365627 	 time: 0.3
Epoch: 269 	Training Loss: 1.208313 	Validation Loss: 1.367704 	 time: 0.3
Epoch: 270 	Training Loss: 1.207707 	Validation Loss: 1.368262 	 time: 0.3
Epoch: 271 	Training Loss: 1.206048 	Validation Loss: 1.367405 	 time: 0.3
Epoch: 272 	Training Loss: 1.209762 	Validation Loss: 1.369749 	 time: 0.3
Epoch: 273 	Training Loss: 1.207940 	Validation Loss: 1.365772 	 time: 0.3
Epoch: 274 	Training Loss: 1.202913 	Validation Loss: 1.360208 	 time: 0.3
Validation loss decreased from 1.365371 to 1.360208. Model was saved
Epoch: 275 	Training Loss: 1.205938 	Validation Loss: 1.364238 	 time: 0.3
Epoch: 276 	Training Loss: 1.205398 	Validation Loss: 1.371299 	 time: 0.3
Epoch: 277 	Training Loss: 1.206348 	Validation Loss: 1.363601 	 time: 0.3
Epoch: 278 	Training Loss: 1.208539 	Validation Loss: 1.361475 	 time: 0.3
Epoch: 279 	Training Loss: 1.203007 	Validation Loss: 1.369705 	 time: 0.3
Epoch: 280 	Training Loss: 1.204311 	Validation Loss: 1.364061 	 time: 0.3
Epoch: 281 	Training Loss: 1.200488 	Validation Loss: 1.358295 	 time: 0.3
Validation loss decreased from 1.360208 to 1.358295. Model was saved
Epoch: 282 	Training Loss: 1.202236 	Validation Loss: 1.360165 	 time: 0.3
Epoch: 283 	Training Loss: 1.199692 	Validation Loss: 1.367824 	 time: 0.3
Epoch: 284 	Training Loss: 1.199894 	Validation Loss: 1.365633 	 time: 0.3
Epoch: 285 	Training Loss: 1.198617 	Validation Loss: 1.361678 	 time: 0.3
Epoch: 286 	Training Loss: 1.199054 	Validation Loss: 1.362705 	 time: 0.2
Epoch: 287 	Training Loss: 1.199632 	Validation Loss: 1.366153 	 time: 0.3
Epoch: 288 	Training Loss: 1.198271 	Validation Loss: 1.368348 	 time: 0.3
Epoch: 289 	Training Loss: 1.198366 	Validation Loss: 1.364136 	 time: 0.2
Epoch: 290 	Training Loss: 1.197887 	Validation Loss: 1.361612 	 time: 0.3
Epoch: 291 	Training Loss: 1.197796 	Validation Loss: 1.364558 	 time: 0.3
Epoch: 292 	Training Loss: 1.197290 	Validation Loss: 1.368311 	 time: 0.3
Epoch: 293 	Training Loss: 1.197469 	Validation Loss: 1.363599 	 time: 0.3
Epoch: 294 	Training Loss: 1.195202 	Validation Loss: 1.361923 	 time: 0.3
Epoch: 295 	Training Loss: 1.196576 	Validation Loss: 1.362721 	 time: 0.2
Epoch: 296 	Training Loss: 1.194396 	Validation Loss: 1.366205 	 time: 0.3
Epoch: 297 	Training Loss: 1.195561 	Validation Loss: 1.361565 	 time: 0.3
Epoch: 298 	Training Loss: 1.194052 	Validation Loss: 1.359141 	 time: 0.2
Epoch: 299 	Training Loss: 1.193927 	Validation Loss: 1.362081 	 time: 0.3
Epoch: 300 	Training Loss: 1.193125 	Validation Loss: 1.365205 	 time: 0.3
Epoch: 301 	Training Loss: 1.193109 	Validation Loss: 1.362877 	 time: 0.3
Epoch: 302 	Training Loss: 1.192286 	Validation Loss: 1.360516 	 time: 0.3
Epoch: 303 	Training Loss: 1.192155 	Validation Loss: 1.360918 	 time: 0.2
Epoch: 304 	Training Loss: 1.191854 	Validation Loss: 1.363175 	 time: 0.3
Epoch: 305 	Training Loss: 1.191304 	Validation Loss: 1.362079 	 time: 0.3
Epoch: 306 	Training Loss: 1.190703 	Validation Loss: 1.361390 	 time: 0.2
Epoch: 307 	Training Loss: 1.190914 	Validation Loss: 1.361774 	 time: 0.2
Epoch: 308 	Training Loss: 1.190109 	Validation Loss: 1.362088 	 time: 0.3
Epoch: 309 	Training Loss: 1.190067 	Validation Loss: 1.360327 	 time: 0.3
Epoch: 310 	Training Loss: 1.189411 	Validation Loss: 1.360387 	 time: 0.2
Epoch: 311 	Training Loss: 1.189511 	Validation Loss: 1.362183 	 time: 0.3
Epoch: 312 	Training Loss: 1.189196 	Validation Loss: 1.361696 	 time: 0.3
Epoch: 313 	Training Loss: 1.188566 	Validation Loss: 1.360729 	 time: 0.3
Epoch: 314 	Training Loss: 1.188446 	Validation Loss: 1.360997 	 time: 0.3
Epoch: 315 	Training Loss: 1.188239 	Validation Loss: 1.362565 	 time: 0.2
Epoch: 316 	Training Loss: 1.187911 	Validation Loss: 1.361447 	 time: 0.2
Epoch: 317 	Training Loss: 1.187266 	Validation Loss: 1.360076 	 time: 0.3
Epoch: 318 	Training Loss: 1.187158 	Validation Loss: 1.361068 	 time: 0.3
Epoch: 319 	Training Loss: 1.186912 	Validation Loss: 1.361935 	 time: 0.3
Epoch: 320 	Training Loss: 1.186904 	Validation Loss: 1.359544 	 time: 0.3
Epoch: 321 	Training Loss: 1.186433 	Validation Loss: 1.360032 	 time: 0.3
Epoch: 322 	Training Loss: 1.186016 	Validation Loss: 1.361051 	 time: 0.3
Epoch: 323 	Training Loss: 1.185920 	Validation Loss: 1.359477 	 time: 0.3
Epoch: 324 	Training Loss: 1.185780 	Validation Loss: 1.359692 	 time: 0.3
Epoch: 325 	Training Loss: 1.185645 	Validation Loss: 1.360137 	 time: 0.2
Epoch: 326 	Training Loss: 1.185238 	Validation Loss: 1.358915 	 time: 0.2
Epoch: 327 	Training Loss: 1.184845 	Validation Loss: 1.359130 	 time: 0.3
Epoch: 328 	Training Loss: 1.184690 	Validation Loss: 1.360114 	 time: 0.2
Epoch: 329 	Training Loss: 1.184502 	Validation Loss: 1.359920 	 time: 0.3
Epoch: 330 	Training Loss: 1.184303 	Validation Loss: 1.359577 	 time: 0.3
Epoch: 331 	Training Loss: 1.184135 	Validation Loss: 1.359715 	 time: 0.3
Epoch: 332 	Training Loss: 1.183834 	Validation Loss: 1.360856 	 time: 0.2
Epoch: 333 	Training Loss: 1.183615 	Validation Loss: 1.359500 	 time: 0.3
Epoch: 334 	Training Loss: 1.183297 	Validation Loss: 1.359510 	 time: 0.3
Epoch: 335 	Training Loss: 1.182997 	Validation Loss: 1.360624 	 time: 0.3
Epoch: 336 	Training Loss: 1.182802 	Validation Loss: 1.359382 	 time: 0.3
Epoch: 337 	Training Loss: 1.182581 	Validation Loss: 1.360387 	 time: 0.3
Epoch: 338 	Training Loss: 1.182262 	Validation Loss: 1.360840 	 time: 0.3
Epoch: 339 	Training Loss: 1.182135 	Validation Loss: 1.359911 	 time: 0.3
Epoch: 340 	Training Loss: 1.181913 	Validation Loss: 1.360971 	 time: 0.3
Epoch: 341 	Training Loss: 1.181868 	Validation Loss: 1.361500 	 time: 0.2
Epoch: 342 	Training Loss: 1.182279 	Validation Loss: 1.360457 	 time: 0.3
Epoch: 343 	Training Loss: 1.182287 	Validation Loss: 1.362395 	 time: 0.3
Epoch: 344 	Training Loss: 1.183716 	Validation Loss: 1.360157 	 time: 0.2
Epoch: 345 	Training Loss: 1.186191 	Validation Loss: 1.368759 	 time: 0.3
Epoch: 346 	Training Loss: 1.194933 	Validation Loss: 1.362962 	 time: 0.3
Epoch: 347 	Training Loss: 1.195421 	Validation Loss: 1.365417 	 time: 0.3
Epoch: 348 	Training Loss: 1.196151 	Validation Loss: 1.367042 	 time: 0.3
Epoch: 349 	Training Loss: 1.190570 	Validation Loss: 1.361882 	 time: 0.3
Epoch: 350 	Training Loss: 1.201193 	Validation Loss: 1.365533 	 time: 0.2
Epoch: 351 	Training Loss: 1.200184 	Validation Loss: 1.375097 	 time: 0.3
Epoch: 352 	Training Loss: 1.203927 	Validation Loss: 1.365168 	 time: 0.3
Epoch: 353 	Training Loss: 1.203875 	Validation Loss: 1.369209 	 time: 0.2
Epoch: 354 	Training Loss: 1.207474 	Validation Loss: 1.363876 	 time: 0.3
Epoch: 355 	Training Loss: 1.197016 	Validation Loss: 1.374654 	 time: 0.3
Epoch: 356 	Training Loss: 1.205889 	Validation Loss: 1.366152 	 time: 0.3
Epoch: 357 	Training Loss: 1.195297 	Validation Loss: 1.354860 	 time: 0.3
Validation loss decreased from 1.358295 to 1.354860. Model was saved
Epoch: 358 	Training Loss: 1.191604 	Validation Loss: 1.364918 	 time: 0.3
Epoch: 359 	Training Loss: 1.204356 	Validation Loss: 1.361834 	 time: 0.3
Epoch: 360 	Training Loss: 1.189335 	Validation Loss: 1.379677 	 time: 0.3
Epoch: 361 	Training Loss: 1.209667 	Validation Loss: 1.360525 	 time: 0.3
Epoch: 362 	Training Loss: 1.184406 	Validation Loss: 1.365129 	 time: 0.3
Epoch: 363 	Training Loss: 1.206002 	Validation Loss: 1.360367 	 time: 0.3
Epoch: 364 	Training Loss: 1.199665 	Validation Loss: 1.364977 	 time: 0.3
Epoch: 365 	Training Loss: 1.192911 	Validation Loss: 1.369546 	 time: 0.3
Epoch: 366 	Training Loss: 1.197258 	Validation Loss: 1.367744 	 time: 0.3
Epoch: 367 	Training Loss: 1.194517 	Validation Loss: 1.361525 	 time: 0.3
Epoch: 368 	Training Loss: 1.186805 	Validation Loss: 1.362463 	 time: 0.3
Epoch: 369 	Training Loss: 1.194947 	Validation Loss: 1.359123 	 time: 0.2
Epoch: 370 	Training Loss: 1.187557 	Validation Loss: 1.367483 	 time: 0.3
Epoch: 371 	Training Loss: 1.186635 	Validation Loss: 1.369093 	 time: 0.3
Epoch: 372 	Training Loss: 1.185742 	Validation Loss: 1.368825 	 time: 0.3
Epoch: 373 	Training Loss: 1.186732 	Validation Loss: 1.361831 	 time: 0.3
Epoch: 374 	Training Loss: 1.182722 	Validation Loss: 1.356502 	 time: 0.3
Epoch: 375 	Training Loss: 1.183090 	Validation Loss: 1.356138 	 time: 0.3
Epoch: 376 	Training Loss: 1.184692 	Validation Loss: 1.359600 	 time: 0.3
Epoch: 377 	Training Loss: 1.180796 	Validation Loss: 1.364727 	 time: 0.3
Epoch: 378 	Training Loss: 1.180890 	Validation Loss: 1.368088 	 time: 0.3
Epoch: 379 	Training Loss: 1.182698 	Validation Loss: 1.365078 	 time: 0.3
Epoch: 380 	Training Loss: 1.179448 	Validation Loss: 1.360031 	 time: 0.3
Epoch: 381 	Training Loss: 1.178669 	Validation Loss: 1.357590 	 time: 0.3
Epoch: 382 	Training Loss: 1.180343 	Validation Loss: 1.359304 	 time: 0.3
Epoch: 383 	Training Loss: 1.178461 	Validation Loss: 1.363434 	 time: 0.2
Epoch: 384 	Training Loss: 1.177458 	Validation Loss: 1.365616 	 time: 0.3
Epoch: 385 	Training Loss: 1.178445 	Validation Loss: 1.363089 	 time: 0.3
Epoch: 386 	Training Loss: 1.177490 	Validation Loss: 1.360970 	 time: 0.3
Epoch: 387 	Training Loss: 1.176412 	Validation Loss: 1.359560 	 time: 0.3
Epoch: 388 	Training Loss: 1.177328 	Validation Loss: 1.359763 	 time: 0.3
Epoch: 389 	Training Loss: 1.176566 	Validation Loss: 1.361326 	 time: 0.3
Epoch: 390 	Training Loss: 1.175835 	Validation Loss: 1.362693 	 time: 0.2
Epoch: 391 	Training Loss: 1.176116 	Validation Loss: 1.362518 	 time: 0.2
Epoch: 392 	Training Loss: 1.176025 	Validation Loss: 1.360287 	 time: 0.3
Epoch: 393 	Training Loss: 1.175096 	Validation Loss: 1.359199 	 time: 0.2
Epoch: 394 	Training Loss: 1.175539 	Validation Loss: 1.359258 	 time: 0.3
Epoch: 395 	Training Loss: 1.175132 	Validation Loss: 1.360215 	 time: 0.3
Epoch: 396 	Training Loss: 1.174603 	Validation Loss: 1.361398 	 time: 0.3
Epoch: 397 	Training Loss: 1.174816 	Validation Loss: 1.360659 	 time: 0.3
Epoch: 398 	Training Loss: 1.174543 	Validation Loss: 1.359656 	 time: 0.3
Epoch: 399 	Training Loss: 1.174097 	Validation Loss: 1.359396 	 time: 0.3
Epoch: 400 	Training Loss: 1.174297 	Validation Loss: 1.359716 	 time: 0.3
Epoch: 401 	Training Loss: 1.173926 	Validation Loss: 1.360195 	 time: 0.3
Epoch: 402 	Training Loss: 1.173807 	Validation Loss: 1.359859 	 time: 0.3
Epoch: 403 	Training Loss: 1.173705 	Validation Loss: 1.358441 	 time: 0.3
Epoch: 404 	Training Loss: 1.173463 	Validation Loss: 1.357401 	 time: 0.3
Epoch: 405 	Training Loss: 1.173327 	Validation Loss: 1.356963 	 time: 0.3
Epoch: 406 	Training Loss: 1.173207 	Validation Loss: 1.356936 	 time: 0.3
Epoch: 407 	Training Loss: 1.173005 	Validation Loss: 1.356857 	 time: 0.3
Epoch: 408 	Training Loss: 1.172896 	Validation Loss: 1.356048 	 time: 0.3
Epoch: 409 	Training Loss: 1.172644 	Validation Loss: 1.355752 	 time: 0.3
Epoch: 410 	Training Loss: 1.172541 	Validation Loss: 1.356239 	 time: 0.3
Epoch: 411 	Training Loss: 1.172266 	Validation Loss: 1.356700 	 time: 0.3
Epoch: 412 	Training Loss: 1.172147 	Validation Loss: 1.356682 	 time: 0.2
Epoch: 413 	Training Loss: 1.172030 	Validation Loss: 1.356179 	 time: 0.3
Epoch: 414 	Training Loss: 1.171718 	Validation Loss: 1.355969 	 time: 0.3
Epoch: 415 	Training Loss: 1.171585 	Validation Loss: 1.355998 	 time: 0.3
Epoch: 416 	Training Loss: 1.171353 	Validation Loss: 1.355961 	 time: 0.3
Epoch: 417 	Training Loss: 1.171254 	Validation Loss: 1.355465 	 time: 0.3
Epoch: 418 	Training Loss: 1.171106 	Validation Loss: 1.354939 	 time: 0.3
Epoch: 419 	Training Loss: 1.170971 	Validation Loss: 1.354539 	 time: 0.3
Validation loss decreased from 1.354860 to 1.354539. Model was saved
Epoch: 420 	Training Loss: 1.170841 	Validation Loss: 1.354396 	 time: 0.3
Validation loss decreased from 1.354539 to 1.354396. Model was saved
Epoch: 421 	Training Loss: 1.170702 	Validation Loss: 1.354203 	 time: 0.3
Validation loss decreased from 1.354396 to 1.354203. Model was saved
Epoch: 422 	Training Loss: 1.170594 	Validation Loss: 1.353686 	 time: 0.3
Validation loss decreased from 1.354203 to 1.353686. Model was saved
Epoch: 423 	Training Loss: 1.170439 	Validation Loss: 1.353389 	 time: 0.3
Validation loss decreased from 1.353686 to 1.353389. Model was saved
Epoch: 424 	Training Loss: 1.170344 	Validation Loss: 1.353536 	 time: 0.3
Epoch: 425 	Training Loss: 1.170190 	Validation Loss: 1.353812 	 time: 0.3
Epoch: 426 	Training Loss: 1.170084 	Validation Loss: 1.353927 	 time: 0.3
Epoch: 427 	Training Loss: 1.169971 	Validation Loss: 1.353930 	 time: 0.3
Epoch: 428 	Training Loss: 1.169864 	Validation Loss: 1.353887 	 time: 0.3
Epoch: 429 	Training Loss: 1.169763 	Validation Loss: 1.354007 	 time: 0.2
Epoch: 430 	Training Loss: 1.169656 	Validation Loss: 1.354111 	 time: 0.3
Epoch: 431 	Training Loss: 1.169551 	Validation Loss: 1.353927 	 time: 0.3
Epoch: 432 	Training Loss: 1.169431 	Validation Loss: 1.353706 	 time: 0.3
Epoch: 433 	Training Loss: 1.169320 	Validation Loss: 1.353655 	 time: 0.3
Epoch: 434 	Training Loss: 1.169210 	Validation Loss: 1.353706 	 time: 0.3
Epoch: 435 	Training Loss: 1.169119 	Validation Loss: 1.353850 	 time: 0.3
Epoch: 436 	Training Loss: 1.169018 	Validation Loss: 1.354028 	 time: 0.3
Epoch: 437 	Training Loss: 1.168938 	Validation Loss: 1.354212 	 time: 0.3
Epoch: 438 	Training Loss: 1.168841 	Validation Loss: 1.354478 	 time: 0.3
Epoch: 439 	Training Loss: 1.168744 	Validation Loss: 1.354478 	 time: 0.3
Epoch: 440 	Training Loss: 1.168638 	Validation Loss: 1.354382 	 time: 0.3
Epoch: 441 	Training Loss: 1.168520 	Validation Loss: 1.354493 	 time: 0.3
Epoch: 442 	Training Loss: 1.168412 	Validation Loss: 1.354574 	 time: 0.3
Epoch: 443 	Training Loss: 1.168317 	Validation Loss: 1.354555 	 time: 0.3
Epoch: 444 	Training Loss: 1.168225 	Validation Loss: 1.354432 	 time: 0.3
Epoch: 445 	Training Loss: 1.168123 	Validation Loss: 1.354222 	 time: 0.3
Epoch: 446 	Training Loss: 1.168026 	Validation Loss: 1.354132 	 time: 0.3
Epoch: 447 	Training Loss: 1.167916 	Validation Loss: 1.354038 	 time: 0.2
Epoch: 448 	Training Loss: 1.167798 	Validation Loss: 1.353812 	 time: 0.3
Epoch: 449 	Training Loss: 1.167691 	Validation Loss: 1.353598 	 time: 0.3
Epoch: 450 	Training Loss: 1.167600 	Validation Loss: 1.353477 	 time: 0.2
Epoch: 451 	Training Loss: 1.167505 	Validation Loss: 1.353408 	 time: 0.2
Epoch: 452 	Training Loss: 1.167413 	Validation Loss: 1.353276 	 time: 0.3
Validation loss decreased from 1.353389 to 1.353276. Model was saved
Epoch: 453 	Training Loss: 1.167312 	Validation Loss: 1.353072 	 time: 0.2
Validation loss decreased from 1.353276 to 1.353072. Model was saved
Epoch: 454 	Training Loss: 1.167215 	Validation Loss: 1.352952 	 time: 0.3
Validation loss decreased from 1.353072 to 1.352952. Model was saved
Epoch: 455 	Training Loss: 1.167117 	Validation Loss: 1.352888 	 time: 0.3
Validation loss decreased from 1.352952 to 1.352888. Model was saved
Epoch: 456 	Training Loss: 1.167024 	Validation Loss: 1.352773 	 time: 0.3
Validation loss decreased from 1.352888 to 1.352773. Model was saved
Epoch: 457 	Training Loss: 1.166921 	Validation Loss: 1.352629 	 time: 0.3
Validation loss decreased from 1.352773 to 1.352629. Model was saved
Epoch: 458 	Training Loss: 1.166816 	Validation Loss: 1.352484 	 time: 0.3
Validation loss decreased from 1.352629 to 1.352484. Model was saved
Epoch: 459 	Training Loss: 1.166725 	Validation Loss: 1.352332 	 time: 0.3
Validation loss decreased from 1.352484 to 1.352332. Model was saved
Epoch: 460 	Training Loss: 1.166634 	Validation Loss: 1.352113 	 time: 0.3
Validation loss decreased from 1.352332 to 1.352113. Model was saved
Epoch: 461 	Training Loss: 1.166540 	Validation Loss: 1.351936 	 time: 0.3
Validation loss decreased from 1.352113 to 1.351936. Model was saved
Epoch: 462 	Training Loss: 1.166452 	Validation Loss: 1.351923 	 time: 0.3
Validation loss decreased from 1.351936 to 1.351923. Model was saved
Epoch: 463 	Training Loss: 1.166374 	Validation Loss: 1.351950 	 time: 0.3
Epoch: 464 	Training Loss: 1.166304 	Validation Loss: 1.351907 	 time: 0.3
Validation loss decreased from 1.351923 to 1.351907. Model was saved
Epoch: 465 	Training Loss: 1.166234 	Validation Loss: 1.351818 	 time: 0.3
Validation loss decreased from 1.351907 to 1.351818. Model was saved
Epoch: 466 	Training Loss: 1.166165 	Validation Loss: 1.351741 	 time: 0.3
Validation loss decreased from 1.351818 to 1.351741. Model was saved
Epoch: 467 	Training Loss: 1.166095 	Validation Loss: 1.351704 	 time: 0.3
Validation loss decreased from 1.351741 to 1.351704. Model was saved
Epoch: 468 	Training Loss: 1.166025 	Validation Loss: 1.351610 	 time: 0.3
Validation loss decreased from 1.351704 to 1.351610. Model was saved
Epoch: 469 	Training Loss: 1.165954 	Validation Loss: 1.351408 	 time: 0.3
Validation loss decreased from 1.351610 to 1.351408. Model was saved
Epoch: 470 	Training Loss: 1.165882 	Validation Loss: 1.351135 	 time: 0.3
Validation loss decreased from 1.351408 to 1.351135. Model was saved
Epoch: 471 	Training Loss: 1.165806 	Validation Loss: 1.350750 	 time: 0.3
Validation loss decreased from 1.351135 to 1.350750. Model was saved
Epoch: 472 	Training Loss: 1.165725 	Validation Loss: 1.350253 	 time: 0.3
Validation loss decreased from 1.350750 to 1.350253. Model was saved
Epoch: 473 	Training Loss: 1.165639 	Validation Loss: 1.349848 	 time: 0.3
Validation loss decreased from 1.350253 to 1.349848. Model was saved
Epoch: 474 	Training Loss: 1.165555 	Validation Loss: 1.349643 	 time: 0.3
Validation loss decreased from 1.349848 to 1.349643. Model was saved
Epoch: 475 	Training Loss: 1.165473 	Validation Loss: 1.349544 	 time: 0.3
Validation loss decreased from 1.349643 to 1.349544. Model was saved
Epoch: 476 	Training Loss: 1.165387 	Validation Loss: 1.349451 	 time: 0.3
Validation loss decreased from 1.349544 to 1.349451. Model was saved
Epoch: 477 	Training Loss: 1.165300 	Validation Loss: 1.349365 	 time: 0.3
Validation loss decreased from 1.349451 to 1.349365. Model was saved
Epoch: 478 	Training Loss: 1.165213 	Validation Loss: 1.349279 	 time: 0.3
Validation loss decreased from 1.349365 to 1.349279. Model was saved
Epoch: 479 	Training Loss: 1.165123 	Validation Loss: 1.349182 	 time: 0.3
Validation loss decreased from 1.349279 to 1.349182. Model was saved
Epoch: 480 	Training Loss: 1.165031 	Validation Loss: 1.349090 	 time: 0.3
Validation loss decreased from 1.349182 to 1.349090. Model was saved
Epoch: 481 	Training Loss: 1.164952 	Validation Loss: 1.348987 	 time: 0.3
Validation loss decreased from 1.349090 to 1.348987. Model was saved
Epoch: 482 	Training Loss: 1.164884 	Validation Loss: 1.348894 	 time: 0.3
Validation loss decreased from 1.348987 to 1.348894. Model was saved
Epoch: 483 	Training Loss: 1.164810 	Validation Loss: 1.348844 	 time: 0.3
Validation loss decreased from 1.348894 to 1.348844. Model was saved
Epoch: 484 	Training Loss: 1.164723 	Validation Loss: 1.348779 	 time: 0.3
Validation loss decreased from 1.348844 to 1.348779. Model was saved
Epoch: 485 	Training Loss: 1.164643 	Validation Loss: 1.348597 	 time: 0.3
Validation loss decreased from 1.348779 to 1.348597. Model was saved
Epoch: 486 	Training Loss: 1.164549 	Validation Loss: 1.348383 	 time: 0.3
Validation loss decreased from 1.348597 to 1.348383. Model was saved
Epoch: 487 	Training Loss: 1.164474 	Validation Loss: 1.348243 	 time: 0.3
Validation loss decreased from 1.348383 to 1.348243. Model was saved
Epoch: 488 	Training Loss: 1.164404 	Validation Loss: 1.348049 	 time: 0.3
Validation loss decreased from 1.348243 to 1.348049. Model was saved
Epoch: 489 	Training Loss: 1.164329 	Validation Loss: 1.347851 	 time: 0.3
Validation loss decreased from 1.348049 to 1.347851. Model was saved
Epoch: 490 	Training Loss: 1.164243 	Validation Loss: 1.347685 	 time: 0.3
Validation loss decreased from 1.347851 to 1.347685. Model was saved
Epoch: 491 	Training Loss: 1.164148 	Validation Loss: 1.347445 	 time: 0.3
Validation loss decreased from 1.347685 to 1.347445. Model was saved
Epoch: 492 	Training Loss: 1.164056 	Validation Loss: 1.347184 	 time: 0.3
Validation loss decreased from 1.347445 to 1.347184. Model was saved
Epoch: 493 	Training Loss: 1.163973 	Validation Loss: 1.347026 	 time: 0.3
Validation loss decreased from 1.347184 to 1.347026. Model was saved
Epoch: 494 	Training Loss: 1.163882 	Validation Loss: 1.346907 	 time: 0.3
Validation loss decreased from 1.347026 to 1.346907. Model was saved
Epoch: 495 	Training Loss: 1.163734 	Validation Loss: 1.346788 	 time: 0.3
Validation loss decreased from 1.346907 to 1.346788. Model was saved
Epoch: 496 	Training Loss: 1.163583 	Validation Loss: 1.346635 	 time: 0.3
Validation loss decreased from 1.346788 to 1.346635. Model was saved
Epoch: 497 	Training Loss: 1.163496 	Validation Loss: 1.346205 	 time: 0.3
Validation loss decreased from 1.346635 to 1.346205. Model was saved
Epoch: 498 	Training Loss: 1.163405 	Validation Loss: 1.345842 	 time: 0.3
Validation loss decreased from 1.346205 to 1.345842. Model was saved
Epoch: 499 	Training Loss: 1.163321 	Validation Loss: 1.345778 	 time: 0.3
Validation loss decreased from 1.345842 to 1.345778. Model was saved
Epoch: 500 	Training Loss: 1.163225 	Validation Loss: 1.345661 	 time: 0.3
Validation loss decreased from 1.345778 to 1.345661. Model was saved
Epoch: 501 	Training Loss: 1.163059 	Validation Loss: 1.345585 	 time: 0.3
Validation loss decreased from 1.345661 to 1.345585. Model was saved
Epoch: 502 	Training Loss: 1.162953 	Validation Loss: 1.345424 	 time: 0.3
Validation loss decreased from 1.345585 to 1.345424. Model was saved
Epoch: 503 	Training Loss: 1.162881 	Validation Loss: 1.345476 	 time: 0.3
Epoch: 504 	Training Loss: 1.162798 	Validation Loss: 1.345285 	 time: 0.3
Validation loss decreased from 1.345424 to 1.345285. Model was saved
Epoch: 505 	Training Loss: 1.162711 	Validation Loss: 1.345217 	 time: 0.3
Validation loss decreased from 1.345285 to 1.345217. Model was saved
Epoch: 506 	Training Loss: 1.162632 	Validation Loss: 1.345176 	 time: 0.3
Validation loss decreased from 1.345217 to 1.345176. Model was saved
Epoch: 507 	Training Loss: 1.162553 	Validation Loss: 1.345050 	 time: 0.3
Validation loss decreased from 1.345176 to 1.345050. Model was saved
Epoch: 508 	Training Loss: 1.162455 	Validation Loss: 1.344991 	 time: 0.3
Validation loss decreased from 1.345050 to 1.344991. Model was saved
Epoch: 509 	Training Loss: 1.162335 	Validation Loss: 1.345241 	 time: 0.3
Epoch: 510 	Training Loss: 1.162226 	Validation Loss: 1.345513 	 time: 0.3
Epoch: 511 	Training Loss: 1.162142 	Validation Loss: 1.345812 	 time: 0.3
Epoch: 512 	Training Loss: 1.162066 	Validation Loss: 1.345972 	 time: 0.3
Epoch: 513 	Training Loss: 1.161990 	Validation Loss: 1.345953 	 time: 0.3
Epoch: 514 	Training Loss: 1.161921 	Validation Loss: 1.345936 	 time: 0.3
Epoch: 515 	Training Loss: 1.161859 	Validation Loss: 1.345926 	 time: 0.3
Epoch: 516 	Training Loss: 1.161794 	Validation Loss: 1.345869 	 time: 0.3
Epoch: 517 	Training Loss: 1.161724 	Validation Loss: 1.345715 	 time: 0.2
Epoch: 518 	Training Loss: 1.161646 	Validation Loss: 1.345642 	 time: 0.3
Epoch: 519 	Training Loss: 1.161555 	Validation Loss: 1.345480 	 time: 0.3
Epoch: 520 	Training Loss: 1.161451 	Validation Loss: 1.345521 	 time: 0.3
Epoch: 521 	Training Loss: 1.161366 	Validation Loss: 1.345505 	 time: 0.3
Epoch: 522 	Training Loss: 1.161301 	Validation Loss: 1.345420 	 time: 0.3
Epoch: 523 	Training Loss: 1.161239 	Validation Loss: 1.345398 	 time: 0.3
Epoch: 524 	Training Loss: 1.161181 	Validation Loss: 1.345449 	 time: 0.2
Epoch: 525 	Training Loss: 1.161122 	Validation Loss: 1.345417 	 time: 0.3
Epoch: 526 	Training Loss: 1.161065 	Validation Loss: 1.345532 	 time: 0.3
Epoch: 527 	Training Loss: 1.161009 	Validation Loss: 1.345580 	 time: 0.3
Epoch: 528 	Training Loss: 1.160952 	Validation Loss: 1.345587 	 time: 0.3
Epoch: 529 	Training Loss: 1.160893 	Validation Loss: 1.345628 	 time: 0.3
Epoch: 530 	Training Loss: 1.160835 	Validation Loss: 1.345539 	 time: 0.3
Epoch: 531 	Training Loss: 1.160778 	Validation Loss: 1.345387 	 time: 0.3
Epoch: 532 	Training Loss: 1.160724 	Validation Loss: 1.345322 	 time: 0.3
Epoch: 533 	Training Loss: 1.160672 	Validation Loss: 1.345245 	 time: 0.2
Epoch: 534 	Training Loss: 1.160621 	Validation Loss: 1.345244 	 time: 0.3
Epoch: 535 	Training Loss: 1.160572 	Validation Loss: 1.345311 	 time: 0.3
Epoch: 536 	Training Loss: 1.160522 	Validation Loss: 1.345336 	 time: 0.3
Epoch: 537 	Training Loss: 1.160473 	Validation Loss: 1.345359 	 time: 0.3
Epoch: 538 	Training Loss: 1.160424 	Validation Loss: 1.345404 	 time: 0.3
Epoch: 539 	Training Loss: 1.160377 	Validation Loss: 1.345389 	 time: 0.3
Epoch: 540 	Training Loss: 1.160330 	Validation Loss: 1.345371 	 time: 0.3
Epoch: 541 	Training Loss: 1.160283 	Validation Loss: 1.345349 	 time: 0.3
Epoch: 542 	Training Loss: 1.160236 	Validation Loss: 1.345244 	 time: 0.3
Epoch: 543 	Training Loss: 1.160189 	Validation Loss: 1.345147 	 time: 0.3
Epoch: 544 	Training Loss: 1.160140 	Validation Loss: 1.345037 	 time: 0.3
Epoch: 545 	Training Loss: 1.160089 	Validation Loss: 1.344945 	 time: 0.3
Validation loss decreased from 1.344991 to 1.344945. Model was saved
Epoch: 546 	Training Loss: 1.160035 	Validation Loss: 1.344863 	 time: 0.3
Validation loss decreased from 1.344945 to 1.344863. Model was saved
Epoch: 547 	Training Loss: 1.159977 	Validation Loss: 1.344834 	 time: 0.3
Validation loss decreased from 1.344863 to 1.344834. Model was saved
Epoch: 548 	Training Loss: 1.159919 	Validation Loss: 1.344747 	 time: 0.3
Validation loss decreased from 1.344834 to 1.344747. Model was saved
Epoch: 549 	Training Loss: 1.159862 	Validation Loss: 1.344727 	 time: 0.3
Validation loss decreased from 1.344747 to 1.344727. Model was saved
Epoch: 550 	Training Loss: 1.159805 	Validation Loss: 1.344659 	 time: 0.3
Validation loss decreased from 1.344727 to 1.344659. Model was saved
Epoch: 551 	Training Loss: 1.159745 	Validation Loss: 1.344693 	 time: 0.3
Epoch: 552 	Training Loss: 1.159684 	Validation Loss: 1.344646 	 time: 0.3
Validation loss decreased from 1.344659 to 1.344646. Model was saved
Epoch: 553 	Training Loss: 1.159624 	Validation Loss: 1.344727 	 time: 0.3
Epoch: 554 	Training Loss: 1.159569 	Validation Loss: 1.344635 	 time: 0.3
Validation loss decreased from 1.344646 to 1.344635. Model was saved
Epoch: 555 	Training Loss: 1.159514 	Validation Loss: 1.344687 	 time: 0.3
Epoch: 556 	Training Loss: 1.159462 	Validation Loss: 1.344571 	 time: 0.3
Validation loss decreased from 1.344635 to 1.344571. Model was saved
Epoch: 557 	Training Loss: 1.159403 	Validation Loss: 1.344611 	 time: 0.3
Epoch: 558 	Training Loss: 1.159347 	Validation Loss: 1.344454 	 time: 0.3
Validation loss decreased from 1.344571 to 1.344454. Model was saved
Epoch: 559 	Training Loss: 1.159273 	Validation Loss: 1.344501 	 time: 0.3
Epoch: 560 	Training Loss: 1.159208 	Validation Loss: 1.344316 	 time: 0.3
Validation loss decreased from 1.344454 to 1.344316. Model was saved
Epoch: 561 	Training Loss: 1.159130 	Validation Loss: 1.344356 	 time: 0.3
Epoch: 562 	Training Loss: 1.159057 	Validation Loss: 1.344166 	 time: 0.3
Validation loss decreased from 1.344316 to 1.344166. Model was saved
Epoch: 563 	Training Loss: 1.158978 	Validation Loss: 1.344214 	 time: 0.3
Epoch: 564 	Training Loss: 1.158911 	Validation Loss: 1.344099 	 time: 0.3
Validation loss decreased from 1.344166 to 1.344099. Model was saved
Epoch: 565 	Training Loss: 1.158851 	Validation Loss: 1.344192 	 time: 0.3
Epoch: 566 	Training Loss: 1.158794 	Validation Loss: 1.344207 	 time: 0.3
Epoch: 567 	Training Loss: 1.158734 	Validation Loss: 1.344334 	 time: 0.3
Epoch: 568 	Training Loss: 1.158663 	Validation Loss: 1.344426 	 time: 0.2
Epoch: 569 	Training Loss: 1.158569 	Validation Loss: 1.344508 	 time: 0.2
Epoch: 570 	Training Loss: 1.158466 	Validation Loss: 1.344603 	 time: 0.3
Epoch: 571 	Training Loss: 1.158403 	Validation Loss: 1.344674 	 time: 0.3
Epoch: 572 	Training Loss: 1.158355 	Validation Loss: 1.344810 	 time: 0.3
Epoch: 573 	Training Loss: 1.158303 	Validation Loss: 1.344903 	 time: 0.3
Epoch: 574 	Training Loss: 1.158249 	Validation Loss: 1.345182 	 time: 0.3
Epoch: 575 	Training Loss: 1.158193 	Validation Loss: 1.345458 	 time: 0.3
Epoch: 576 	Training Loss: 1.158140 	Validation Loss: 1.346110 	 time: 0.3
Epoch: 577 	Training Loss: 1.158109 	Validation Loss: 1.346313 	 time: 0.3
Epoch: 578 	Training Loss: 1.158088 	Validation Loss: 1.346765 	 time: 0.3
Epoch: 579 	Training Loss: 1.158085 	Validation Loss: 1.346518 	 time: 0.3
Epoch: 580 	Training Loss: 1.158057 	Validation Loss: 1.346946 	 time: 0.3
Epoch: 581 	Training Loss: 1.158079 	Validation Loss: 1.346459 	 time: 0.3
Epoch: 582 	Training Loss: 1.158010 	Validation Loss: 1.346621 	 time: 0.3
Epoch: 583 	Training Loss: 1.157970 	Validation Loss: 1.346015 	 time: 0.3
Epoch: 584 	Training Loss: 1.157843 	Validation Loss: 1.345946 	 time: 0.3
Epoch: 585 	Training Loss: 1.157748 	Validation Loss: 1.345564 	 time: 0.3
Epoch: 586 	Training Loss: 1.157668 	Validation Loss: 1.345429 	 time: 0.3
Epoch: 587 	Training Loss: 1.157620 	Validation Loss: 1.345371 	 time: 0.3
Epoch: 588 	Training Loss: 1.157593 	Validation Loss: 1.345182 	 time: 0.3
Epoch: 589 	Training Loss: 1.157577 	Validation Loss: 1.345458 	 time: 0.3
Epoch: 590 	Training Loss: 1.157575 	Validation Loss: 1.345257 	 time: 0.3
Epoch: 591 	Training Loss: 1.157555 	Validation Loss: 1.345624 	 time: 0.3
Epoch: 592 	Training Loss: 1.157557 	Validation Loss: 1.345393 	 time: 0.3
Epoch: 593 	Training Loss: 1.157515 	Validation Loss: 1.345754 	 time: 0.3
Epoch: 594 	Training Loss: 1.157529 	Validation Loss: 1.345432 	 time: 0.3
Epoch: 595 	Training Loss: 1.157449 	Validation Loss: 1.345756 	 time: 0.2
Epoch: 596 	Training Loss: 1.157422 	Validation Loss: 1.345331 	 time: 0.3
Epoch: 597 	Training Loss: 1.157298 	Validation Loss: 1.345521 	 time: 0.3
Epoch: 598 	Training Loss: 1.157207 	Validation Loss: 1.345261 	 time: 0.3
Epoch: 599 	Training Loss: 1.157126 	Validation Loss: 1.345258 	 time: 0.3
Epoch: 600 	Training Loss: 1.157072 	Validation Loss: 1.345250 	 time: 0.3
Epoch: 601 	Training Loss: 1.157038 	Validation Loss: 1.345152 	 time: 0.3
Epoch: 602 	Training Loss: 1.157016 	Validation Loss: 1.345477 	 time: 0.3
Epoch: 603 	Training Loss: 1.157003 	Validation Loss: 1.345329 	 time: 0.3
Epoch: 604 	Training Loss: 1.156987 	Validation Loss: 1.345876 	 time: 0.3
Epoch: 605 	Training Loss: 1.157002 	Validation Loss: 1.345551 	 time: 0.3
Epoch: 606 	Training Loss: 1.156960 	Validation Loss: 1.346066 	 time: 0.3
Epoch: 607 	Training Loss: 1.156943 	Validation Loss: 1.345709 	 time: 0.3
Epoch: 608 	Training Loss: 1.156841 	Validation Loss: 1.346193 	 time: 0.3
Epoch: 609 	Training Loss: 1.156766 	Validation Loss: 1.346021 	 time: 0.3
Epoch: 610 	Training Loss: 1.156654 	Validation Loss: 1.346511 	 time: 0.3
Epoch: 611 	Training Loss: 1.156573 	Validation Loss: 1.346462 	 time: 0.3
Epoch: 612 	Training Loss: 1.156508 	Validation Loss: 1.346598 	 time: 0.3
Epoch: 613 	Training Loss: 1.156459 	Validation Loss: 1.346580 	 time: 0.3
Epoch: 614 	Training Loss: 1.156418 	Validation Loss: 1.346627 	 time: 0.3
Epoch: 615 	Training Loss: 1.156386 	Validation Loss: 1.346688 	 time: 0.3
Epoch: 616 	Training Loss: 1.156358 	Validation Loss: 1.346685 	 time: 0.3
Epoch: 617 	Training Loss: 1.156331 	Validation Loss: 1.346711 	 time: 0.3
Epoch: 618 	Training Loss: 1.156302 	Validation Loss: 1.346615 	 time: 0.3
Epoch: 619 	Training Loss: 1.156272 	Validation Loss: 1.346575 	 time: 0.2
Epoch: 620 	Training Loss: 1.156246 	Validation Loss: 1.346470 	 time: 0.3
Epoch: 621 	Training Loss: 1.156222 	Validation Loss: 1.346367 	 time: 0.3
Epoch: 622 	Training Loss: 1.156214 	Validation Loss: 1.346283 	 time: 0.3
Epoch: 623 	Training Loss: 1.156209 	Validation Loss: 1.346225 	 time: 0.3
Epoch: 624 	Training Loss: 1.156245 	Validation Loss: 1.346293 	 time: 0.3
Epoch: 625 	Training Loss: 1.156251 	Validation Loss: 1.346331 	 time: 0.3
Epoch: 626 	Training Loss: 1.156334 	Validation Loss: 1.346423 	 time: 0.3
Epoch: 627 	Training Loss: 1.156283 	Validation Loss: 1.346298 	 time: 0.3
Epoch: 628 	Training Loss: 1.156319 	Validation Loss: 1.346237 	 time: 0.3
Epoch: 629 	Training Loss: 1.156163 	Validation Loss: 1.345784 	 time: 0.3
Epoch: 630 	Training Loss: 1.156040 	Validation Loss: 1.345560 	 time: 0.3
Epoch: 631 	Training Loss: 1.155877 	Validation Loss: 1.345133 	 time: 0.3
Epoch: 632 	Training Loss: 1.155797 	Validation Loss: 1.344863 	 time: 0.3
Epoch: 633 	Training Loss: 1.155773 	Validation Loss: 1.344888 	 time: 0.3
Epoch: 634 	Training Loss: 1.155784 	Validation Loss: 1.344782 	 time: 0.3
Epoch: 635 	Training Loss: 1.155833 	Validation Loss: 1.344933 	 time: 0.3
Epoch: 636 	Training Loss: 1.155872 	Validation Loss: 1.344940 	 time: 0.3
Epoch: 637 	Training Loss: 1.155992 	Validation Loss: 1.345088 	 time: 0.2
Epoch: 638 	Training Loss: 1.155988 	Validation Loss: 1.344893 	 time: 0.3
Epoch: 639 	Training Loss: 1.156076 	Validation Loss: 1.344505 	 time: 0.3
Epoch: 640 	Training Loss: 1.155855 	Validation Loss: 1.344143 	 time: 0.3
Epoch: 641 	Training Loss: 1.155652 	Validation Loss: 1.343857 	 time: 0.3
Validation loss decreased from 1.344099 to 1.343857. Model was saved
Epoch: 642 	Training Loss: 1.155466 	Validation Loss: 1.343833 	 time: 0.3
Validation loss decreased from 1.343857 to 1.343833. Model was saved
Epoch: 643 	Training Loss: 1.155472 	Validation Loss: 1.343921 	 time: 0.3
Epoch: 644 	Training Loss: 1.155599 	Validation Loss: 1.344036 	 time: 0.3
Epoch: 645 	Training Loss: 1.155701 	Validation Loss: 1.344781 	 time: 0.3
Epoch: 646 	Training Loss: 1.155975 	Validation Loss: 1.344499 	 time: 0.3
Epoch: 647 	Training Loss: 1.155859 	Validation Loss: 1.344394 	 time: 0.3
Epoch: 648 	Training Loss: 1.155654 	Validation Loss: 1.343858 	 time: 0.3
Epoch: 649 	Training Loss: 1.155267 	Validation Loss: 1.343555 	 time: 0.3
Validation loss decreased from 1.343833 to 1.343555. Model was saved
Epoch: 650 	Training Loss: 1.155512 	Validation Loss: 1.344685 	 time: 0.3
Epoch: 651 	Training Loss: 1.156271 	Validation Loss: 1.344493 	 time: 0.3
Epoch: 652 	Training Loss: 1.156101 	Validation Loss: 1.343238 	 time: 0.3
Validation loss decreased from 1.343555 to 1.343238. Model was saved
Epoch: 653 	Training Loss: 1.155910 	Validation Loss: 1.343696 	 time: 0.3
Epoch: 654 	Training Loss: 1.155450 	Validation Loss: 1.342787 	 time: 0.3
Validation loss decreased from 1.343238 to 1.342787. Model was saved
Epoch: 655 	Training Loss: 1.155436 	Validation Loss: 1.344049 	 time: 0.3
Epoch: 656 	Training Loss: 1.156155 	Validation Loss: 1.342744 	 time: 0.3
Validation loss decreased from 1.342787 to 1.342744. Model was saved
Epoch: 657 	Training Loss: 1.155704 	Validation Loss: 1.341527 	 time: 0.3
Validation loss decreased from 1.342744 to 1.341527. Model was saved
Epoch: 658 	Training Loss: 1.155211 	Validation Loss: 1.342930 	 time: 0.3
Epoch: 659 	Training Loss: 1.155144 	Validation Loss: 1.344245 	 time: 0.3
Epoch: 660 	Training Loss: 1.155312 	Validation Loss: 1.342305 	 time: 0.3
Epoch: 661 	Training Loss: 1.155343 	Validation Loss: 1.343038 	 time: 0.3
Epoch: 662 	Training Loss: 1.154839 	Validation Loss: 1.342896 	 time: 0.3
Epoch: 663 	Training Loss: 1.154950 	Validation Loss: 1.342407 	 time: 0.3
Epoch: 664 	Training Loss: 1.155453 	Validation Loss: 1.343122 	 time: 0.3
Epoch: 665 	Training Loss: 1.155061 	Validation Loss: 1.341811 	 time: 0.3
Epoch: 666 	Training Loss: 1.154633 	Validation Loss: 1.341036 	 time: 0.3
Validation loss decreased from 1.341527 to 1.341036. Model was saved
Epoch: 667 	Training Loss: 1.154620 	Validation Loss: 1.342521 	 time: 0.3
Epoch: 668 	Training Loss: 1.154672 	Validation Loss: 1.342400 	 time: 0.3
Epoch: 669 	Training Loss: 1.154642 	Validation Loss: 1.341817 	 time: 0.3
Epoch: 670 	Training Loss: 1.154294 	Validation Loss: 1.343387 	 time: 0.3
Epoch: 671 	Training Loss: 1.154395 	Validation Loss: 1.343752 	 time: 0.3
Epoch: 672 	Training Loss: 1.154643 	Validation Loss: 1.342533 	 time: 0.3
Epoch: 673 	Training Loss: 1.154249 	Validation Loss: 1.343032 	 time: 0.2
Epoch: 674 	Training Loss: 1.154004 	Validation Loss: 1.342732 	 time: 0.3
Epoch: 675 	Training Loss: 1.154117 	Validation Loss: 1.342135 	 time: 0.3
Epoch: 676 	Training Loss: 1.154031 	Validation Loss: 1.342610 	 time: 0.2
Epoch: 677 	Training Loss: 1.153881 	Validation Loss: 1.342710 	 time: 0.3
Epoch: 678 	Training Loss: 1.153840 	Validation Loss: 1.343095 	 time: 0.3
Epoch: 679 	Training Loss: 1.153890 	Validation Loss: 1.343538 	 time: 0.3
Epoch: 680 	Training Loss: 1.153824 	Validation Loss: 1.343260 	 time: 0.3
Epoch: 681 	Training Loss: 1.153714 	Validation Loss: 1.342764 	 time: 0.3
Epoch: 682 	Training Loss: 1.153711 	Validation Loss: 1.343197 	 time: 0.3
Epoch: 683 	Training Loss: 1.153702 	Validation Loss: 1.343164 	 time: 0.3
Epoch: 684 	Training Loss: 1.153656 	Validation Loss: 1.342891 	 time: 0.3
Epoch: 685 	Training Loss: 1.153610 	Validation Loss: 1.343539 	 time: 0.3
Epoch: 686 	Training Loss: 1.153574 	Validation Loss: 1.343493 	 time: 0.3
Epoch: 687 	Training Loss: 1.153549 	Validation Loss: 1.343096 	 time: 0.3
Epoch: 688 	Training Loss: 1.153531 	Validation Loss: 1.343437 	 time: 0.3
Epoch: 689 	Training Loss: 1.153488 	Validation Loss: 1.343168 	 time: 0.3
Epoch: 690 	Training Loss: 1.153457 	Validation Loss: 1.343059 	 time: 0.3
Epoch: 691 	Training Loss: 1.153441 	Validation Loss: 1.343650 	 time: 0.2
Epoch: 692 	Training Loss: 1.153419 	Validation Loss: 1.343408 	 time: 0.2
Epoch: 693 	Training Loss: 1.153376 	Validation Loss: 1.343345 	 time: 0.3
Epoch: 694 	Training Loss: 1.153349 	Validation Loss: 1.343680 	 time: 0.3
Epoch: 695 	Training Loss: 1.153337 	Validation Loss: 1.343524 	 time: 0.3
Epoch: 696 	Training Loss: 1.153305 	Validation Loss: 1.343726 	 time: 0.3
Epoch: 697 	Training Loss: 1.153272 	Validation Loss: 1.343943 	 time: 0.2
Epoch: 698 	Training Loss: 1.153249 	Validation Loss: 1.343671 	 time: 0.3
Epoch: 699 	Training Loss: 1.153228 	Validation Loss: 1.343747 	 time: 0.3
Epoch: 700 	Training Loss: 1.153203 	Validation Loss: 1.343816 	 time: 0.3
Epoch: 701 	Training Loss: 1.153178 	Validation Loss: 1.343633 	 time: 0.3
Epoch: 702 	Training Loss: 1.153144 	Validation Loss: 1.343781 	 time: 0.3
Epoch: 703 	Training Loss: 1.153113 	Validation Loss: 1.343917 	 time: 0.3
Epoch: 704 	Training Loss: 1.153084 	Validation Loss: 1.343838 	 time: 0.3
Epoch: 705 	Training Loss: 1.153052 	Validation Loss: 1.343838 	 time: 0.3
Epoch: 706 	Training Loss: 1.153026 	Validation Loss: 1.343813 	 time: 0.3
Epoch: 707 	Training Loss: 1.153005 	Validation Loss: 1.343637 	 time: 0.3
Epoch: 708 	Training Loss: 1.152984 	Validation Loss: 1.343687 	 time: 0.3
Epoch: 709 	Training Loss: 1.152953 	Validation Loss: 1.343811 	 time: 0.3
Epoch: 710 	Training Loss: 1.152903 	Validation Loss: 1.343793 	 time: 0.2
Epoch: 711 	Training Loss: 1.152810 	Validation Loss: 1.343562 	 time: 0.3
Epoch: 712 	Training Loss: 1.152787 	Validation Loss: 1.343612 	 time: 0.3
Epoch: 713 	Training Loss: 1.152778 	Validation Loss: 1.343668 	 time: 0.3
Epoch: 714 	Training Loss: 1.152739 	Validation Loss: 1.343775 	 time: 0.3
Epoch: 715 	Training Loss: 1.152702 	Validation Loss: 1.343863 	 time: 0.3
Epoch: 716 	Training Loss: 1.152675 	Validation Loss: 1.343612 	 time: 0.3
Epoch: 717 	Training Loss: 1.152642 	Validation Loss: 1.343291 	 time: 0.3
Epoch: 718 	Training Loss: 1.152597 	Validation Loss: 1.342670 	 time: 0.3
Epoch: 719 	Training Loss: 1.152535 	Validation Loss: 1.342475 	 time: 0.3
Epoch: 720 	Training Loss: 1.152503 	Validation Loss: 1.342646 	 time: 0.2
Epoch: 721 	Training Loss: 1.152481 	Validation Loss: 1.342673 	 time: 0.3
Epoch: 722 	Training Loss: 1.152461 	Validation Loss: 1.342715 	 time: 0.3
Epoch: 723 	Training Loss: 1.152439 	Validation Loss: 1.342690 	 time: 0.3
Epoch: 724 	Training Loss: 1.152421 	Validation Loss: 1.342522 	 time: 0.3
Epoch: 725 	Training Loss: 1.152403 	Validation Loss: 1.342406 	 time: 0.3
Epoch: 726 	Training Loss: 1.152386 	Validation Loss: 1.342293 	 time: 0.3
Epoch: 727 	Training Loss: 1.152365 	Validation Loss: 1.342286 	 time: 0.3
Epoch: 728 	Training Loss: 1.152343 	Validation Loss: 1.342212 	 time: 0.3
Epoch: 729 	Training Loss: 1.152321 	Validation Loss: 1.342021 	 time: 0.3
Epoch: 730 	Training Loss: 1.152298 	Validation Loss: 1.341932 	 time: 0.3
Epoch: 731 	Training Loss: 1.152277 	Validation Loss: 1.341956 	 time: 0.3
Epoch: 732 	Training Loss: 1.152245 	Validation Loss: 1.342045 	 time: 0.3
Epoch: 733 	Training Loss: 1.152200 	Validation Loss: 1.342080 	 time: 0.3
Epoch: 734 	Training Loss: 1.152150 	Validation Loss: 1.341871 	 time: 0.3
Epoch: 735 	Training Loss: 1.152115 	Validation Loss: 1.341826 	 time: 0.2
Epoch: 736 	Training Loss: 1.152077 	Validation Loss: 1.341901 	 time: 0.3
Epoch: 737 	Training Loss: 1.152036 	Validation Loss: 1.341808 	 time: 0.3
Epoch: 738 	Training Loss: 1.152001 	Validation Loss: 1.341803 	 time: 0.3
Epoch: 739 	Training Loss: 1.151971 	Validation Loss: 1.341852 	 time: 0.3
Epoch: 740 	Training Loss: 1.151932 	Validation Loss: 1.341817 	 time: 0.3
Epoch: 741 	Training Loss: 1.151892 	Validation Loss: 1.341794 	 time: 0.3
Epoch: 742 	Training Loss: 1.151848 	Validation Loss: 1.341771 	 time: 0.3
Epoch: 743 	Training Loss: 1.151755 	Validation Loss: 1.341657 	 time: 0.3
Epoch: 744 	Training Loss: 1.151629 	Validation Loss: 1.341722 	 time: 0.3
Epoch: 745 	Training Loss: 1.151590 	Validation Loss: 1.341420 	 time: 0.3
Epoch: 746 	Training Loss: 1.151541 	Validation Loss: 1.341260 	 time: 0.3
Epoch: 747 	Training Loss: 1.151513 	Validation Loss: 1.341281 	 time: 0.3
Epoch: 748 	Training Loss: 1.151482 	Validation Loss: 1.341034 	 time: 0.3
Validation loss decreased from 1.341036 to 1.341034. Model was saved
Epoch: 749 	Training Loss: 1.151444 	Validation Loss: 1.341117 	 time: 0.3
Epoch: 750 	Training Loss: 1.151412 	Validation Loss: 1.341210 	 time: 0.3
Epoch: 751 	Training Loss: 1.151385 	Validation Loss: 1.341090 	 time: 0.3
Epoch: 752 	Training Loss: 1.151355 	Validation Loss: 1.341301 	 time: 0.3
Epoch: 753 	Training Loss: 1.151326 	Validation Loss: 1.341594 	 time: 0.3
Epoch: 754 	Training Loss: 1.151305 	Validation Loss: 1.341643 	 time: 0.3
Epoch: 755 	Training Loss: 1.151283 	Validation Loss: 1.341868 	 time: 0.3
Epoch: 756 	Training Loss: 1.151260 	Validation Loss: 1.342039 	 time: 0.3
Epoch: 757 	Training Loss: 1.151240 	Validation Loss: 1.342060 	 time: 0.3
Epoch: 758 	Training Loss: 1.151222 	Validation Loss: 1.342189 	 time: 0.3
Epoch: 759 	Training Loss: 1.151201 	Validation Loss: 1.342181 	 time: 0.3
Epoch: 760 	Training Loss: 1.151181 	Validation Loss: 1.342109 	 time: 0.3
Epoch: 761 	Training Loss: 1.151163 	Validation Loss: 1.342140 	 time: 0.3
Epoch: 762 	Training Loss: 1.151143 	Validation Loss: 1.342061 	 time: 0.3
Epoch: 763 	Training Loss: 1.151123 	Validation Loss: 1.342062 	 time: 0.3
Epoch: 764 	Training Loss: 1.151104 	Validation Loss: 1.342171 	 time: 0.3
Epoch: 765 	Training Loss: 1.151086 	Validation Loss: 1.342210 	 time: 0.3
Epoch: 766 	Training Loss: 1.151067 	Validation Loss: 1.342347 	 time: 0.3
Epoch: 767 	Training Loss: 1.151048 	Validation Loss: 1.342493 	 time: 0.3
Epoch: 768 	Training Loss: 1.151029 	Validation Loss: 1.342482 	 time: 0.3
Epoch: 769 	Training Loss: 1.151009 	Validation Loss: 1.342558 	 time: 0.3
Epoch: 770 	Training Loss: 1.150989 	Validation Loss: 1.342638 	 time: 0.3
Epoch: 771 	Training Loss: 1.150970 	Validation Loss: 1.342589 	 time: 0.2
Epoch: 772 	Training Loss: 1.150953 	Validation Loss: 1.342607 	 time: 0.3
Epoch: 773 	Training Loss: 1.150936 	Validation Loss: 1.342614 	 time: 0.3
Epoch: 774 	Training Loss: 1.150920 	Validation Loss: 1.342575 	 time: 0.3
Epoch: 775 	Training Loss: 1.150905 	Validation Loss: 1.342564 	 time: 0.3
Epoch: 776 	Training Loss: 1.150890 	Validation Loss: 1.342509 	 time: 0.3
Epoch: 777 	Training Loss: 1.150875 	Validation Loss: 1.342486 	 time: 0.3
Epoch: 778 	Training Loss: 1.150861 	Validation Loss: 1.342482 	 time: 0.3
Epoch: 779 	Training Loss: 1.150846 	Validation Loss: 1.342443 	 time: 0.3
Epoch: 780 	Training Loss: 1.150833 	Validation Loss: 1.342472 	 time: 0.3
Epoch: 781 	Training Loss: 1.150819 	Validation Loss: 1.342518 	 time: 0.3
Epoch: 782 	Training Loss: 1.150805 	Validation Loss: 1.342557 	 time: 0.3
Epoch: 783 	Training Loss: 1.150792 	Validation Loss: 1.342652 	 time: 0.3
Epoch: 784 	Training Loss: 1.150777 	Validation Loss: 1.342711 	 time: 0.3
Epoch: 785 	Training Loss: 1.150764 	Validation Loss: 1.342739 	 time: 0.3
Epoch: 786 	Training Loss: 1.150748 	Validation Loss: 1.342795 	 time: 0.3
Epoch: 787 	Training Loss: 1.150727 	Validation Loss: 1.342811 	 time: 0.3
Epoch: 788 	Training Loss: 1.150692 	Validation Loss: 1.342824 	 time: 0.3
Epoch: 789 	Training Loss: 1.150674 	Validation Loss: 1.342838 	 time: 0.3
Epoch: 790 	Training Loss: 1.150661 	Validation Loss: 1.342811 	 time: 0.3
Epoch: 791 	Training Loss: 1.150648 	Validation Loss: 1.342796 	 time: 0.3
Epoch: 792 	Training Loss: 1.150627 	Validation Loss: 1.342780 	 time: 0.3
Epoch: 793 	Training Loss: 1.150605 	Validation Loss: 1.342810 	 time: 0.2
Epoch: 794 	Training Loss: 1.150594 	Validation Loss: 1.342839 	 time: 0.3
Epoch: 795 	Training Loss: 1.150574 	Validation Loss: 1.342820 	 time: 0.3
Epoch: 796 	Training Loss: 1.150544 	Validation Loss: 1.342773 	 time: 0.3
Epoch: 797 	Training Loss: 1.150494 	Validation Loss: 1.342705 	 time: 0.3
Epoch: 798 	Training Loss: 1.150475 	Validation Loss: 1.342661 	 time: 0.3
Epoch: 799 	Training Loss: 1.150467 	Validation Loss: 1.342673 	 time: 0.3
Epoch: 800 	Training Loss: 1.150456 	Validation Loss: 1.342654 	 time: 0.3
