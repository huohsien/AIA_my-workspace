{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make number of data for each class equal\n",
    "#\n",
    "from collections import Counter\n",
    "\n",
    "class_counter = Counter()\n",
    "\n",
    "class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print(class_counter)\n",
    "\n",
    "max_count = -np.Inf\n",
    "for i in range(number_of_class):\n",
    "    if class_counter['class_' + str(i)] > max_count:\n",
    "        max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "    num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "    num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "    for j in range(num_resample_batch):\n",
    "        add_df = train_classified[i]\n",
    "        train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "        train =  train.append(df_to_be_added)\n",
    "        \n",
    "\n",
    "    df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "    train =  train.append(df_to_be_added)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names =[i for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter[i] += 1\n",
    "\n",
    "class_counter.most_common(number_of_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appearedTimeOfDay</th>\n",
       "      <th>appearedHour</th>\n",
       "      <th>appearedMinute</th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>city</th>\n",
       "      <th>continent</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>...</th>\n",
       "      <th>cooc_142</th>\n",
       "      <th>cooc_143</th>\n",
       "      <th>cooc_144</th>\n",
       "      <th>cooc_145</th>\n",
       "      <th>cooc_146</th>\n",
       "      <th>cooc_147</th>\n",
       "      <th>cooc_148</th>\n",
       "      <th>cooc_149</th>\n",
       "      <th>cooc_150</th>\n",
       "      <th>cooc_151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evening</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>Los_Angeles</td>\n",
       "      <td>America</td>\n",
       "      <td>PartlyCloudy</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  appearedTimeOfDay  appearedHour  appearedMinute  terrainType  closeToWater  \\\n",
       "0           evening            19              10           13         False   \n",
       "1             night             5              19           13          True   \n",
       "2           evening            19              46            0          True   \n",
       "3           morning            11              10            0          True   \n",
       "4           evening            18              32           13          True   \n",
       "\n",
       "          city  continent       weather  temperature  windSpeed    ...     \\\n",
       "0      Bangkok       Asia         Clear         27.8       9.00    ...      \n",
       "1     New_York    America         Clear         26.1       8.70    ...      \n",
       "2     New_York    America         Clear         24.7      16.82    ...      \n",
       "3       Hobart  Australia         Clear         12.7      13.25    ...      \n",
       "4  Los_Angeles    America  PartlyCloudy         19.1       5.78    ...      \n",
       "\n",
       "   cooc_142 cooc_143  cooc_144  cooc_145  cooc_146  cooc_147  cooc_148  \\\n",
       "0     False    False     False     False     False     False     False   \n",
       "1     False    False     False     False     False     False     False   \n",
       "2     False    False     False     False     False     False     False   \n",
       "3     False    False     False     False     False     False     False   \n",
       "4     False    False     False     False     False     False     False   \n",
       "\n",
       "   cooc_149  cooc_150  cooc_151  \n",
       "0     False     False     False  \n",
       "1     False     False     False  \n",
       "2     False     False     False  \n",
       "3     False     False     False  \n",
       "4     False     False     False  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1008.96</td>\n",
       "      <td>6019.04440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1018.96</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>128.89505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1011.36</td>\n",
       "      <td>4188.39100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.990268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0         13.0           0.0         27.8       9.00   1008.96   \n",
       "1         13.0           1.0         26.1       8.70   1018.96   \n",
       "2          0.0           1.0         24.7      16.82   1023.22   \n",
       "3          0.0           1.0         12.7      13.25   1014.19   \n",
       "4         13.0           1.0         19.1       5.78   1011.36   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0          6019.04440    1.0       1.0       1.0    0.0          ...            \n",
       "1             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "2             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "3           128.89505    0.0       0.0       0.0    1.0          ...            \n",
       "4          4188.39100    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                             0                      1   \n",
       "1                             0                      0   \n",
       "2                             0                      1   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                        0                   0                0   \n",
       "1                        1                   0                0   \n",
       "2                        0                   0                0   \n",
       "3                        1                   0                0   \n",
       "4                        0                   0                0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                              0                                0   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              1                                0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0                 0                 0             -0.953717  \n",
       "1                 0                 0              0.984041  \n",
       "2                 0                 0             -0.894934  \n",
       "3                 0                 0              0.216440  \n",
       "4                 0                 0             -0.990268  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631868</td>\n",
       "      <td>0.160342</td>\n",
       "      <td>0.333774</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.154997</td>\n",
       "      <td>0.598044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.710624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217033</td>\n",
       "      <td>0.236059</td>\n",
       "      <td>0.471987</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.102975</td>\n",
       "      <td>0.397199</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0       0.8125           0.0     0.631868   0.160342  0.333774   \n",
       "1       0.8125           1.0     0.585165   0.154997  0.598044   \n",
       "2       0.0000           1.0     0.546703   0.299662  0.710624   \n",
       "3       0.0000           1.0     0.217033   0.236059  0.471987   \n",
       "4       0.8125           1.0     0.392857   0.102975  0.397199   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0            0.601904    1.0       1.0       1.0    0.0          ...            \n",
       "1            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "2            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "3            0.012890    0.0       0.0       0.0    1.0          ...            \n",
       "4            0.418839    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                           0.0                    1.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    1.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                      0.0                 0.0              0.0   \n",
       "1                      1.0                 0.0              0.0   \n",
       "2                      0.0                 0.0              0.0   \n",
       "3                      1.0                 0.0              0.0   \n",
       "4                      0.0                 0.0              0.0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            1.0                              0.0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0               0.0               0.0              0.023142  \n",
       "1               0.0               0.0              0.992020  \n",
       "2               0.0               0.0              0.052533  \n",
       "3               0.0               0.0              0.608220  \n",
       "4               0.0               0.0              0.004866  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7160 entries, 0 to 7159\n",
      "Columns: 297 entries, terrainType to appearedTimeDayCycle\n",
      "dtypes: float64(272), int64(25)\n",
      "memory usage: 16.3 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7160, 297)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1611.,    0.,  920.,    0., 1478.,    0.,  889.,    0.,  851.,\n",
       "        1411.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5011, 297), (2127, 297), (22, 297))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.01\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ratio = 0.98\n",
    "\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1127.,    0.,  644.,    0., 1034.,    0.,  622.,    0.,  596.,\n",
       "         988.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data per batch to load\n",
    "batch_size = 10000\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.796115 \tValidation Loss: 1.774409 \t time: 0.2\n",
      "Validation loss decreased from inf to 1.774409. Model was saved\n",
      "Epoch: 2 \tTraining Loss: 1.776063 \tValidation Loss: 1.762958 \t time: 0.2\n",
      "Validation loss decreased from 1.774409 to 1.762958. Model was saved\n",
      "Epoch: 3 \tTraining Loss: 1.763768 \tValidation Loss: 1.758254 \t time: 0.2\n",
      "Validation loss decreased from 1.762958 to 1.758254. Model was saved\n",
      "Epoch: 4 \tTraining Loss: 1.758981 \tValidation Loss: 1.756897 \t time: 0.2\n",
      "Validation loss decreased from 1.758254 to 1.756897. Model was saved\n",
      "Epoch: 5 \tTraining Loss: 1.758113 \tValidation Loss: 1.756801 \t time: 0.2\n",
      "Validation loss decreased from 1.756897 to 1.756801. Model was saved\n",
      "Epoch: 6 \tTraining Loss: 1.758768 \tValidation Loss: 1.757045 \t time: 0.2\n",
      "Epoch: 7 \tTraining Loss: 1.757309 \tValidation Loss: 1.757289 \t time: 0.2\n",
      "Epoch: 8 \tTraining Loss: 1.759075 \tValidation Loss: 1.757409 \t time: 0.2\n",
      "Epoch: 9 \tTraining Loss: 1.759082 \tValidation Loss: 1.757425 \t time: 0.2\n",
      "Epoch: 10 \tTraining Loss: 1.759243 \tValidation Loss: 1.757348 \t time: 0.2\n",
      "Epoch: 11 \tTraining Loss: 1.758719 \tValidation Loss: 1.757194 \t time: 0.2\n",
      "Epoch: 12 \tTraining Loss: 1.760349 \tValidation Loss: 1.756949 \t time: 0.2\n",
      "Epoch: 13 \tTraining Loss: 1.758129 \tValidation Loss: 1.756577 \t time: 0.2\n",
      "Validation loss decreased from 1.756801 to 1.756577. Model was saved\n",
      "Epoch: 14 \tTraining Loss: 1.757051 \tValidation Loss: 1.756041 \t time: 0.2\n",
      "Validation loss decreased from 1.756577 to 1.756041. Model was saved\n",
      "Epoch: 15 \tTraining Loss: 1.756593 \tValidation Loss: 1.755301 \t time: 0.2\n",
      "Validation loss decreased from 1.756041 to 1.755301. Model was saved\n",
      "Epoch: 16 \tTraining Loss: 1.756594 \tValidation Loss: 1.754380 \t time: 0.2\n",
      "Validation loss decreased from 1.755301 to 1.754380. Model was saved\n",
      "Epoch: 17 \tTraining Loss: 1.756486 \tValidation Loss: 1.753339 \t time: 0.2\n",
      "Validation loss decreased from 1.754380 to 1.753339. Model was saved\n",
      "Epoch: 18 \tTraining Loss: 1.754566 \tValidation Loss: 1.752181 \t time: 0.2\n",
      "Validation loss decreased from 1.753339 to 1.752181. Model was saved\n",
      "Epoch: 19 \tTraining Loss: 1.753859 \tValidation Loss: 1.750818 \t time: 0.2\n",
      "Validation loss decreased from 1.752181 to 1.750818. Model was saved\n",
      "Epoch: 20 \tTraining Loss: 1.752158 \tValidation Loss: 1.749129 \t time: 0.2\n",
      "Validation loss decreased from 1.750818 to 1.749129. Model was saved\n",
      "Epoch: 21 \tTraining Loss: 1.748931 \tValidation Loss: 1.747068 \t time: 0.2\n",
      "Validation loss decreased from 1.749129 to 1.747068. Model was saved\n",
      "Epoch: 22 \tTraining Loss: 1.747814 \tValidation Loss: 1.744666 \t time: 0.2\n",
      "Validation loss decreased from 1.747068 to 1.744666. Model was saved\n",
      "Epoch: 23 \tTraining Loss: 1.744303 \tValidation Loss: 1.742005 \t time: 0.2\n",
      "Validation loss decreased from 1.744666 to 1.742005. Model was saved\n",
      "Epoch: 24 \tTraining Loss: 1.741414 \tValidation Loss: 1.739142 \t time: 0.2\n",
      "Validation loss decreased from 1.742005 to 1.739142. Model was saved\n",
      "Epoch: 25 \tTraining Loss: 1.738867 \tValidation Loss: 1.736073 \t time: 0.2\n",
      "Validation loss decreased from 1.739142 to 1.736073. Model was saved\n",
      "Epoch: 26 \tTraining Loss: 1.737032 \tValidation Loss: 1.732754 \t time: 0.2\n",
      "Validation loss decreased from 1.736073 to 1.732754. Model was saved\n",
      "Epoch: 27 \tTraining Loss: 1.731752 \tValidation Loss: 1.729165 \t time: 0.2\n",
      "Validation loss decreased from 1.732754 to 1.729165. Model was saved\n",
      "Epoch: 28 \tTraining Loss: 1.728827 \tValidation Loss: 1.725336 \t time: 0.2\n",
      "Validation loss decreased from 1.729165 to 1.725336. Model was saved\n",
      "Epoch: 29 \tTraining Loss: 1.724686 \tValidation Loss: 1.721314 \t time: 0.2\n",
      "Validation loss decreased from 1.725336 to 1.721314. Model was saved\n",
      "Epoch: 30 \tTraining Loss: 1.720733 \tValidation Loss: 1.717110 \t time: 0.2\n",
      "Validation loss decreased from 1.721314 to 1.717110. Model was saved\n",
      "Epoch: 31 \tTraining Loss: 1.716862 \tValidation Loss: 1.712744 \t time: 0.2\n",
      "Validation loss decreased from 1.717110 to 1.712744. Model was saved\n",
      "Epoch: 32 \tTraining Loss: 1.710321 \tValidation Loss: 1.708232 \t time: 0.2\n",
      "Validation loss decreased from 1.712744 to 1.708232. Model was saved\n",
      "Epoch: 33 \tTraining Loss: 1.706526 \tValidation Loss: 1.703600 \t time: 0.3\n",
      "Validation loss decreased from 1.708232 to 1.703600. Model was saved\n",
      "Epoch: 34 \tTraining Loss: 1.701392 \tValidation Loss: 1.698828 \t time: 0.2\n",
      "Validation loss decreased from 1.703600 to 1.698828. Model was saved\n",
      "Epoch: 35 \tTraining Loss: 1.696699 \tValidation Loss: 1.693914 \t time: 0.2\n",
      "Validation loss decreased from 1.698828 to 1.693914. Model was saved\n",
      "Epoch: 36 \tTraining Loss: 1.692044 \tValidation Loss: 1.688825 \t time: 0.2\n",
      "Validation loss decreased from 1.693914 to 1.688825. Model was saved\n",
      "Epoch: 37 \tTraining Loss: 1.685595 \tValidation Loss: 1.683543 \t time: 0.2\n",
      "Validation loss decreased from 1.688825 to 1.683543. Model was saved\n",
      "Epoch: 38 \tTraining Loss: 1.678976 \tValidation Loss: 1.678010 \t time: 0.2\n",
      "Validation loss decreased from 1.683543 to 1.678010. Model was saved\n",
      "Epoch: 39 \tTraining Loss: 1.673667 \tValidation Loss: 1.672201 \t time: 0.2\n",
      "Validation loss decreased from 1.678010 to 1.672201. Model was saved\n",
      "Epoch: 40 \tTraining Loss: 1.669021 \tValidation Loss: 1.666069 \t time: 0.2\n",
      "Validation loss decreased from 1.672201 to 1.666069. Model was saved\n",
      "Epoch: 41 \tTraining Loss: 1.661747 \tValidation Loss: 1.659641 \t time: 0.2\n",
      "Validation loss decreased from 1.666069 to 1.659641. Model was saved\n",
      "Epoch: 42 \tTraining Loss: 1.653931 \tValidation Loss: 1.652951 \t time: 0.2\n",
      "Validation loss decreased from 1.659641 to 1.652951. Model was saved\n",
      "Epoch: 43 \tTraining Loss: 1.648299 \tValidation Loss: 1.646146 \t time: 0.2\n",
      "Validation loss decreased from 1.652951 to 1.646146. Model was saved\n",
      "Epoch: 44 \tTraining Loss: 1.640316 \tValidation Loss: 1.639296 \t time: 0.2\n",
      "Validation loss decreased from 1.646146 to 1.639296. Model was saved\n",
      "Epoch: 45 \tTraining Loss: 1.632359 \tValidation Loss: 1.632604 \t time: 0.2\n",
      "Validation loss decreased from 1.639296 to 1.632604. Model was saved\n",
      "Epoch: 46 \tTraining Loss: 1.626777 \tValidation Loss: 1.626247 \t time: 0.2\n",
      "Validation loss decreased from 1.632604 to 1.626247. Model was saved\n",
      "Epoch: 47 \tTraining Loss: 1.619433 \tValidation Loss: 1.620333 \t time: 0.2\n",
      "Validation loss decreased from 1.626247 to 1.620333. Model was saved\n",
      "Epoch: 48 \tTraining Loss: 1.613746 \tValidation Loss: 1.614703 \t time: 0.2\n",
      "Validation loss decreased from 1.620333 to 1.614703. Model was saved\n",
      "Epoch: 49 \tTraining Loss: 1.606381 \tValidation Loss: 1.609349 \t time: 0.2\n",
      "Validation loss decreased from 1.614703 to 1.609349. Model was saved\n",
      "Epoch: 50 \tTraining Loss: 1.602911 \tValidation Loss: 1.604380 \t time: 0.2\n",
      "Validation loss decreased from 1.609349 to 1.604380. Model was saved\n",
      "Epoch: 51 \tTraining Loss: 1.596845 \tValidation Loss: 1.599843 \t time: 0.2\n",
      "Validation loss decreased from 1.604380 to 1.599843. Model was saved\n",
      "Epoch: 52 \tTraining Loss: 1.591131 \tValidation Loss: 1.595218 \t time: 0.2\n",
      "Validation loss decreased from 1.599843 to 1.595218. Model was saved\n",
      "Epoch: 53 \tTraining Loss: 1.586893 \tValidation Loss: 1.591120 \t time: 0.2\n",
      "Validation loss decreased from 1.595218 to 1.591120. Model was saved\n",
      "Epoch: 54 \tTraining Loss: 1.582334 \tValidation Loss: 1.587209 \t time: 0.2\n",
      "Validation loss decreased from 1.591120 to 1.587209. Model was saved\n",
      "Epoch: 55 \tTraining Loss: 1.579461 \tValidation Loss: 1.583709 \t time: 0.2\n",
      "Validation loss decreased from 1.587209 to 1.583709. Model was saved\n",
      "Epoch: 56 \tTraining Loss: 1.569032 \tValidation Loss: 1.580823 \t time: 0.2\n",
      "Validation loss decreased from 1.583709 to 1.580823. Model was saved\n",
      "Epoch: 57 \tTraining Loss: 1.568247 \tValidation Loss: 1.577271 \t time: 0.2\n",
      "Validation loss decreased from 1.580823 to 1.577271. Model was saved\n",
      "Epoch: 58 \tTraining Loss: 1.566116 \tValidation Loss: 1.573493 \t time: 0.2\n",
      "Validation loss decreased from 1.577271 to 1.573493. Model was saved\n",
      "Epoch: 59 \tTraining Loss: 1.560017 \tValidation Loss: 1.570293 \t time: 0.2\n",
      "Validation loss decreased from 1.573493 to 1.570293. Model was saved\n",
      "Epoch: 60 \tTraining Loss: 1.557108 \tValidation Loss: 1.567087 \t time: 0.2\n",
      "Validation loss decreased from 1.570293 to 1.567087. Model was saved\n",
      "Epoch: 61 \tTraining Loss: 1.554570 \tValidation Loss: 1.564299 \t time: 0.2\n",
      "Validation loss decreased from 1.567087 to 1.564299. Model was saved\n",
      "Epoch: 62 \tTraining Loss: 1.550558 \tValidation Loss: 1.561698 \t time: 0.2\n",
      "Validation loss decreased from 1.564299 to 1.561698. Model was saved\n",
      "Epoch: 63 \tTraining Loss: 1.547873 \tValidation Loss: 1.558124 \t time: 0.2\n",
      "Validation loss decreased from 1.561698 to 1.558124. Model was saved\n",
      "Epoch: 64 \tTraining Loss: 1.541151 \tValidation Loss: 1.554873 \t time: 0.2\n",
      "Validation loss decreased from 1.558124 to 1.554873. Model was saved\n",
      "Epoch: 65 \tTraining Loss: 1.538207 \tValidation Loss: 1.551868 \t time: 0.2\n",
      "Validation loss decreased from 1.554873 to 1.551868. Model was saved\n",
      "Epoch: 66 \tTraining Loss: 1.535458 \tValidation Loss: 1.549140 \t time: 0.2\n",
      "Validation loss decreased from 1.551868 to 1.549140. Model was saved\n",
      "Epoch: 67 \tTraining Loss: 1.534535 \tValidation Loss: 1.546728 \t time: 0.2\n",
      "Validation loss decreased from 1.549140 to 1.546728. Model was saved\n",
      "Epoch: 68 \tTraining Loss: 1.531991 \tValidation Loss: 1.543795 \t time: 0.3\n",
      "Validation loss decreased from 1.546728 to 1.543795. Model was saved\n",
      "Epoch: 69 \tTraining Loss: 1.527645 \tValidation Loss: 1.540814 \t time: 0.2\n",
      "Validation loss decreased from 1.543795 to 1.540814. Model was saved\n",
      "Epoch: 70 \tTraining Loss: 1.525473 \tValidation Loss: 1.538223 \t time: 0.2\n",
      "Validation loss decreased from 1.540814 to 1.538223. Model was saved\n",
      "Epoch: 71 \tTraining Loss: 1.521374 \tValidation Loss: 1.535911 \t time: 0.2\n",
      "Validation loss decreased from 1.538223 to 1.535911. Model was saved\n",
      "Epoch: 72 \tTraining Loss: 1.519060 \tValidation Loss: 1.533804 \t time: 0.2\n",
      "Validation loss decreased from 1.535911 to 1.533804. Model was saved\n",
      "Epoch: 73 \tTraining Loss: 1.519064 \tValidation Loss: 1.531737 \t time: 0.2\n",
      "Validation loss decreased from 1.533804 to 1.531737. Model was saved\n",
      "Epoch: 74 \tTraining Loss: 1.515593 \tValidation Loss: 1.529753 \t time: 0.2\n",
      "Validation loss decreased from 1.531737 to 1.529753. Model was saved\n",
      "Epoch: 75 \tTraining Loss: 1.513324 \tValidation Loss: 1.527792 \t time: 0.2\n",
      "Validation loss decreased from 1.529753 to 1.527792. Model was saved\n",
      "Epoch: 76 \tTraining Loss: 1.511322 \tValidation Loss: 1.526228 \t time: 0.2\n",
      "Validation loss decreased from 1.527792 to 1.526228. Model was saved\n",
      "Epoch: 77 \tTraining Loss: 1.507486 \tValidation Loss: 1.524926 \t time: 0.2\n",
      "Validation loss decreased from 1.526228 to 1.524926. Model was saved\n",
      "Epoch: 78 \tTraining Loss: 1.505840 \tValidation Loss: 1.523706 \t time: 0.2\n",
      "Validation loss decreased from 1.524926 to 1.523706. Model was saved\n",
      "Epoch: 79 \tTraining Loss: 1.505836 \tValidation Loss: 1.522317 \t time: 0.2\n",
      "Validation loss decreased from 1.523706 to 1.522317. Model was saved\n",
      "Epoch: 80 \tTraining Loss: 1.504163 \tValidation Loss: 1.521000 \t time: 0.2\n",
      "Validation loss decreased from 1.522317 to 1.521000. Model was saved\n",
      "Epoch: 81 \tTraining Loss: 1.498631 \tValidation Loss: 1.519966 \t time: 0.2\n",
      "Validation loss decreased from 1.521000 to 1.519966. Model was saved\n",
      "Epoch: 82 \tTraining Loss: 1.498145 \tValidation Loss: 1.518758 \t time: 0.2\n",
      "Validation loss decreased from 1.519966 to 1.518758. Model was saved\n",
      "Epoch: 83 \tTraining Loss: 1.492249 \tValidation Loss: 1.517851 \t time: 0.2\n",
      "Validation loss decreased from 1.518758 to 1.517851. Model was saved\n",
      "Epoch: 84 \tTraining Loss: 1.499046 \tValidation Loss: 1.517300 \t time: 0.2\n",
      "Validation loss decreased from 1.517851 to 1.517300. Model was saved\n",
      "Epoch: 85 \tTraining Loss: 1.493331 \tValidation Loss: 1.516251 \t time: 0.2\n",
      "Validation loss decreased from 1.517300 to 1.516251. Model was saved\n",
      "Epoch: 86 \tTraining Loss: 1.495373 \tValidation Loss: 1.515290 \t time: 0.3\n",
      "Validation loss decreased from 1.516251 to 1.515290. Model was saved\n",
      "Epoch: 87 \tTraining Loss: 1.492134 \tValidation Loss: 1.514690 \t time: 0.2\n",
      "Validation loss decreased from 1.515290 to 1.514690. Model was saved\n",
      "Epoch: 88 \tTraining Loss: 1.489264 \tValidation Loss: 1.514201 \t time: 0.2\n",
      "Validation loss decreased from 1.514690 to 1.514201. Model was saved\n",
      "Epoch: 89 \tTraining Loss: 1.487726 \tValidation Loss: 1.513669 \t time: 0.2\n",
      "Validation loss decreased from 1.514201 to 1.513669. Model was saved\n",
      "Epoch: 90 \tTraining Loss: 1.486771 \tValidation Loss: 1.513038 \t time: 0.2\n",
      "Validation loss decreased from 1.513669 to 1.513038. Model was saved\n",
      "Epoch: 91 \tTraining Loss: 1.483870 \tValidation Loss: 1.512216 \t time: 0.2\n",
      "Validation loss decreased from 1.513038 to 1.512216. Model was saved\n",
      "Epoch: 92 \tTraining Loss: 1.484385 \tValidation Loss: 1.511578 \t time: 0.2\n",
      "Validation loss decreased from 1.512216 to 1.511578. Model was saved\n",
      "Epoch: 93 \tTraining Loss: 1.481994 \tValidation Loss: 1.511334 \t time: 0.2\n",
      "Validation loss decreased from 1.511578 to 1.511334. Model was saved\n",
      "Epoch: 94 \tTraining Loss: 1.483514 \tValidation Loss: 1.510746 \t time: 0.2\n",
      "Validation loss decreased from 1.511334 to 1.510746. Model was saved\n",
      "Epoch: 95 \tTraining Loss: 1.481075 \tValidation Loss: 1.510043 \t time: 0.2\n",
      "Validation loss decreased from 1.510746 to 1.510043. Model was saved\n",
      "Epoch: 96 \tTraining Loss: 1.481777 \tValidation Loss: 1.509385 \t time: 0.2\n",
      "Validation loss decreased from 1.510043 to 1.509385. Model was saved\n",
      "Epoch: 97 \tTraining Loss: 1.478944 \tValidation Loss: 1.508574 \t time: 0.2\n",
      "Validation loss decreased from 1.509385 to 1.508574. Model was saved\n",
      "Epoch: 98 \tTraining Loss: 1.480478 \tValidation Loss: 1.507924 \t time: 0.2\n",
      "Validation loss decreased from 1.508574 to 1.507924. Model was saved\n",
      "Epoch: 99 \tTraining Loss: 1.477691 \tValidation Loss: 1.507439 \t time: 0.2\n",
      "Validation loss decreased from 1.507924 to 1.507439. Model was saved\n",
      "Epoch: 100 \tTraining Loss: 1.474666 \tValidation Loss: 1.506721 \t time: 0.2\n",
      "Validation loss decreased from 1.507439 to 1.506721. Model was saved\n",
      "Epoch: 101 \tTraining Loss: 1.474252 \tValidation Loss: 1.506288 \t time: 0.2\n",
      "Validation loss decreased from 1.506721 to 1.506288. Model was saved\n",
      "Epoch: 102 \tTraining Loss: 1.471806 \tValidation Loss: 1.505873 \t time: 0.2\n",
      "Validation loss decreased from 1.506288 to 1.505873. Model was saved\n",
      "Epoch: 103 \tTraining Loss: 1.472332 \tValidation Loss: 1.505545 \t time: 0.2\n",
      "Validation loss decreased from 1.505873 to 1.505545. Model was saved\n",
      "Epoch: 104 \tTraining Loss: 1.470246 \tValidation Loss: 1.504983 \t time: 0.2\n",
      "Validation loss decreased from 1.505545 to 1.504983. Model was saved\n",
      "Epoch: 105 \tTraining Loss: 1.469443 \tValidation Loss: 1.504344 \t time: 0.2\n",
      "Validation loss decreased from 1.504983 to 1.504344. Model was saved\n",
      "Epoch: 106 \tTraining Loss: 1.470469 \tValidation Loss: 1.503976 \t time: 0.2\n",
      "Validation loss decreased from 1.504344 to 1.503976. Model was saved\n",
      "Epoch: 107 \tTraining Loss: 1.468571 \tValidation Loss: 1.503876 \t time: 0.2\n",
      "Validation loss decreased from 1.503976 to 1.503876. Model was saved\n",
      "Epoch: 108 \tTraining Loss: 1.467827 \tValidation Loss: 1.503412 \t time: 0.2\n",
      "Validation loss decreased from 1.503876 to 1.503412. Model was saved\n",
      "Epoch: 109 \tTraining Loss: 1.465311 \tValidation Loss: 1.502753 \t time: 0.2\n",
      "Validation loss decreased from 1.503412 to 1.502753. Model was saved\n",
      "Epoch: 110 \tTraining Loss: 1.466022 \tValidation Loss: 1.502265 \t time: 0.2\n",
      "Validation loss decreased from 1.502753 to 1.502265. Model was saved\n",
      "Epoch: 111 \tTraining Loss: 1.466530 \tValidation Loss: 1.502020 \t time: 0.2\n",
      "Validation loss decreased from 1.502265 to 1.502020. Model was saved\n",
      "Epoch: 112 \tTraining Loss: 1.464154 \tValidation Loss: 1.502025 \t time: 0.2\n",
      "Epoch: 113 \tTraining Loss: 1.464747 \tValidation Loss: 1.501996 \t time: 0.2\n",
      "Validation loss decreased from 1.502020 to 1.501996. Model was saved\n",
      "Epoch: 114 \tTraining Loss: 1.463485 \tValidation Loss: 1.501639 \t time: 0.2\n",
      "Validation loss decreased from 1.501996 to 1.501639. Model was saved\n",
      "Epoch: 115 \tTraining Loss: 1.467862 \tValidation Loss: 1.501142 \t time: 0.2\n",
      "Validation loss decreased from 1.501639 to 1.501142. Model was saved\n",
      "Epoch: 116 \tTraining Loss: 1.461552 \tValidation Loss: 1.500669 \t time: 0.2\n",
      "Validation loss decreased from 1.501142 to 1.500669. Model was saved\n",
      "Epoch: 117 \tTraining Loss: 1.459206 \tValidation Loss: 1.500217 \t time: 0.2\n",
      "Validation loss decreased from 1.500669 to 1.500217. Model was saved\n",
      "Epoch: 118 \tTraining Loss: 1.461224 \tValidation Loss: 1.500062 \t time: 0.2\n",
      "Validation loss decreased from 1.500217 to 1.500062. Model was saved\n",
      "Epoch: 119 \tTraining Loss: 1.460665 \tValidation Loss: 1.499868 \t time: 0.2\n",
      "Validation loss decreased from 1.500062 to 1.499868. Model was saved\n",
      "Epoch: 120 \tTraining Loss: 1.458175 \tValidation Loss: 1.499497 \t time: 0.2\n",
      "Validation loss decreased from 1.499868 to 1.499497. Model was saved\n",
      "Epoch: 121 \tTraining Loss: 1.458765 \tValidation Loss: 1.498942 \t time: 0.2\n",
      "Validation loss decreased from 1.499497 to 1.498942. Model was saved\n",
      "Epoch: 122 \tTraining Loss: 1.460303 \tValidation Loss: 1.498456 \t time: 0.2\n",
      "Validation loss decreased from 1.498942 to 1.498456. Model was saved\n",
      "Epoch: 123 \tTraining Loss: 1.456734 \tValidation Loss: 1.498147 \t time: 0.2\n",
      "Validation loss decreased from 1.498456 to 1.498147. Model was saved\n",
      "Epoch: 124 \tTraining Loss: 1.456630 \tValidation Loss: 1.498037 \t time: 0.2\n",
      "Validation loss decreased from 1.498147 to 1.498037. Model was saved\n",
      "Epoch: 125 \tTraining Loss: 1.457418 \tValidation Loss: 1.498146 \t time: 0.2\n",
      "Epoch: 126 \tTraining Loss: 1.457991 \tValidation Loss: 1.497958 \t time: 0.2\n",
      "Validation loss decreased from 1.498037 to 1.497958. Model was saved\n",
      "Epoch: 127 \tTraining Loss: 1.452247 \tValidation Loss: 1.497340 \t time: 0.2\n",
      "Validation loss decreased from 1.497958 to 1.497340. Model was saved\n",
      "Epoch: 128 \tTraining Loss: 1.454655 \tValidation Loss: 1.496819 \t time: 0.2\n",
      "Validation loss decreased from 1.497340 to 1.496819. Model was saved\n",
      "Epoch: 129 \tTraining Loss: 1.453079 \tValidation Loss: 1.496405 \t time: 0.2\n",
      "Validation loss decreased from 1.496819 to 1.496405. Model was saved\n",
      "Epoch: 130 \tTraining Loss: 1.451645 \tValidation Loss: 1.496249 \t time: 0.2\n",
      "Validation loss decreased from 1.496405 to 1.496249. Model was saved\n",
      "Epoch: 131 \tTraining Loss: 1.453243 \tValidation Loss: 1.496137 \t time: 0.2\n",
      "Validation loss decreased from 1.496249 to 1.496137. Model was saved\n",
      "Epoch: 132 \tTraining Loss: 1.455228 \tValidation Loss: 1.496049 \t time: 0.2\n",
      "Validation loss decreased from 1.496137 to 1.496049. Model was saved\n",
      "Epoch: 133 \tTraining Loss: 1.452121 \tValidation Loss: 1.495959 \t time: 0.2\n",
      "Validation loss decreased from 1.496049 to 1.495959. Model was saved\n",
      "Epoch: 134 \tTraining Loss: 1.450986 \tValidation Loss: 1.495660 \t time: 0.2\n",
      "Validation loss decreased from 1.495959 to 1.495660. Model was saved\n",
      "Epoch: 135 \tTraining Loss: 1.451392 \tValidation Loss: 1.495557 \t time: 0.2\n",
      "Validation loss decreased from 1.495660 to 1.495557. Model was saved\n",
      "Epoch: 136 \tTraining Loss: 1.450078 \tValidation Loss: 1.495492 \t time: 0.2\n",
      "Validation loss decreased from 1.495557 to 1.495492. Model was saved\n",
      "Epoch: 137 \tTraining Loss: 1.449084 \tValidation Loss: 1.495461 \t time: 0.2\n",
      "Validation loss decreased from 1.495492 to 1.495461. Model was saved\n",
      "Epoch: 138 \tTraining Loss: 1.448217 \tValidation Loss: 1.495544 \t time: 0.2\n",
      "Epoch: 139 \tTraining Loss: 1.448439 \tValidation Loss: 1.495377 \t time: 0.2\n",
      "Validation loss decreased from 1.495461 to 1.495377. Model was saved\n",
      "Epoch: 140 \tTraining Loss: 1.447415 \tValidation Loss: 1.494471 \t time: 0.2\n",
      "Validation loss decreased from 1.495377 to 1.494471. Model was saved\n",
      "Epoch: 141 \tTraining Loss: 1.447546 \tValidation Loss: 1.494062 \t time: 0.2\n",
      "Validation loss decreased from 1.494471 to 1.494062. Model was saved\n",
      "Epoch: 142 \tTraining Loss: 1.443879 \tValidation Loss: 1.493892 \t time: 0.2\n",
      "Validation loss decreased from 1.494062 to 1.493892. Model was saved\n",
      "Epoch: 143 \tTraining Loss: 1.445213 \tValidation Loss: 1.493883 \t time: 0.2\n",
      "Validation loss decreased from 1.493892 to 1.493883. Model was saved\n",
      "Epoch: 144 \tTraining Loss: 1.449339 \tValidation Loss: 1.494515 \t time: 0.2\n",
      "Epoch: 145 \tTraining Loss: 1.442760 \tValidation Loss: 1.494512 \t time: 0.2\n",
      "Epoch: 146 \tTraining Loss: 1.444875 \tValidation Loss: 1.493947 \t time: 0.2\n",
      "Epoch: 147 \tTraining Loss: 1.441052 \tValidation Loss: 1.493538 \t time: 0.2\n",
      "Validation loss decreased from 1.493883 to 1.493538. Model was saved\n",
      "Epoch: 148 \tTraining Loss: 1.443509 \tValidation Loss: 1.493139 \t time: 0.2\n",
      "Validation loss decreased from 1.493538 to 1.493139. Model was saved\n",
      "Epoch: 149 \tTraining Loss: 1.442097 \tValidation Loss: 1.492788 \t time: 0.2\n",
      "Validation loss decreased from 1.493139 to 1.492788. Model was saved\n",
      "Epoch: 150 \tTraining Loss: 1.440563 \tValidation Loss: 1.492824 \t time: 0.2\n",
      "Epoch: 151 \tTraining Loss: 1.442680 \tValidation Loss: 1.492959 \t time: 0.2\n",
      "Epoch: 152 \tTraining Loss: 1.441039 \tValidation Loss: 1.492669 \t time: 0.2\n",
      "Validation loss decreased from 1.492788 to 1.492669. Model was saved\n",
      "Epoch: 153 \tTraining Loss: 1.441516 \tValidation Loss: 1.492660 \t time: 0.2\n",
      "Validation loss decreased from 1.492669 to 1.492660. Model was saved\n",
      "Epoch: 154 \tTraining Loss: 1.438491 \tValidation Loss: 1.492561 \t time: 0.2\n",
      "Validation loss decreased from 1.492660 to 1.492561. Model was saved\n",
      "Epoch: 155 \tTraining Loss: 1.439829 \tValidation Loss: 1.492164 \t time: 0.2\n",
      "Validation loss decreased from 1.492561 to 1.492164. Model was saved\n",
      "Epoch: 156 \tTraining Loss: 1.437649 \tValidation Loss: 1.492019 \t time: 0.2\n",
      "Validation loss decreased from 1.492164 to 1.492019. Model was saved\n",
      "Epoch: 157 \tTraining Loss: 1.439321 \tValidation Loss: 1.491998 \t time: 0.2\n",
      "Validation loss decreased from 1.492019 to 1.491998. Model was saved\n",
      "Epoch: 158 \tTraining Loss: 1.441346 \tValidation Loss: 1.491402 \t time: 0.2\n",
      "Validation loss decreased from 1.491998 to 1.491402. Model was saved\n",
      "Epoch: 159 \tTraining Loss: 1.437058 \tValidation Loss: 1.490950 \t time: 0.2\n",
      "Validation loss decreased from 1.491402 to 1.490950. Model was saved\n",
      "Epoch: 160 \tTraining Loss: 1.436287 \tValidation Loss: 1.490956 \t time: 0.2\n",
      "Epoch: 161 \tTraining Loss: 1.435295 \tValidation Loss: 1.490597 \t time: 0.2\n",
      "Validation loss decreased from 1.490950 to 1.490597. Model was saved\n",
      "Epoch: 162 \tTraining Loss: 1.437817 \tValidation Loss: 1.490240 \t time: 0.2\n",
      "Validation loss decreased from 1.490597 to 1.490240. Model was saved\n",
      "Epoch: 163 \tTraining Loss: 1.436949 \tValidation Loss: 1.490082 \t time: 0.2\n",
      "Validation loss decreased from 1.490240 to 1.490082. Model was saved\n",
      "Epoch: 164 \tTraining Loss: 1.434631 \tValidation Loss: 1.489826 \t time: 0.2\n",
      "Validation loss decreased from 1.490082 to 1.489826. Model was saved\n",
      "Epoch: 165 \tTraining Loss: 1.436840 \tValidation Loss: 1.489551 \t time: 0.2\n",
      "Validation loss decreased from 1.489826 to 1.489551. Model was saved\n",
      "Epoch: 166 \tTraining Loss: 1.435697 \tValidation Loss: 1.489536 \t time: 0.2\n",
      "Validation loss decreased from 1.489551 to 1.489536. Model was saved\n",
      "Epoch: 167 \tTraining Loss: 1.431656 \tValidation Loss: 1.489355 \t time: 0.3\n",
      "Validation loss decreased from 1.489536 to 1.489355. Model was saved\n",
      "Epoch: 168 \tTraining Loss: 1.434232 \tValidation Loss: 1.489015 \t time: 0.2\n",
      "Validation loss decreased from 1.489355 to 1.489015. Model was saved\n",
      "Epoch: 169 \tTraining Loss: 1.434848 \tValidation Loss: 1.488855 \t time: 0.2\n",
      "Validation loss decreased from 1.489015 to 1.488855. Model was saved\n",
      "Epoch: 170 \tTraining Loss: 1.433976 \tValidation Loss: 1.489198 \t time: 0.2\n",
      "Epoch: 171 \tTraining Loss: 1.433833 \tValidation Loss: 1.489290 \t time: 0.2\n",
      "Epoch: 172 \tTraining Loss: 1.431965 \tValidation Loss: 1.488828 \t time: 0.2\n",
      "Validation loss decreased from 1.488855 to 1.488828. Model was saved\n",
      "Epoch: 173 \tTraining Loss: 1.431211 \tValidation Loss: 1.488416 \t time: 0.2\n",
      "Validation loss decreased from 1.488828 to 1.488416. Model was saved\n",
      "Epoch: 174 \tTraining Loss: 1.429432 \tValidation Loss: 1.488224 \t time: 0.2\n",
      "Validation loss decreased from 1.488416 to 1.488224. Model was saved\n",
      "Epoch: 175 \tTraining Loss: 1.430390 \tValidation Loss: 1.487965 \t time: 0.2\n",
      "Validation loss decreased from 1.488224 to 1.487965. Model was saved\n",
      "Epoch: 176 \tTraining Loss: 1.431382 \tValidation Loss: 1.487950 \t time: 0.2\n",
      "Validation loss decreased from 1.487965 to 1.487950. Model was saved\n",
      "Epoch: 177 \tTraining Loss: 1.434185 \tValidation Loss: 1.487967 \t time: 0.2\n",
      "Epoch: 178 \tTraining Loss: 1.427710 \tValidation Loss: 1.487987 \t time: 0.2\n",
      "Epoch: 179 \tTraining Loss: 1.431657 \tValidation Loss: 1.487557 \t time: 0.2\n",
      "Validation loss decreased from 1.487950 to 1.487557. Model was saved\n",
      "Epoch: 180 \tTraining Loss: 1.427813 \tValidation Loss: 1.487116 \t time: 0.2\n",
      "Validation loss decreased from 1.487557 to 1.487116. Model was saved\n",
      "Epoch: 181 \tTraining Loss: 1.430463 \tValidation Loss: 1.486960 \t time: 0.2\n",
      "Validation loss decreased from 1.487116 to 1.486960. Model was saved\n",
      "Epoch: 182 \tTraining Loss: 1.428519 \tValidation Loss: 1.486354 \t time: 0.2\n",
      "Validation loss decreased from 1.486960 to 1.486354. Model was saved\n",
      "Epoch: 183 \tTraining Loss: 1.427963 \tValidation Loss: 1.486030 \t time: 0.2\n",
      "Validation loss decreased from 1.486354 to 1.486030. Model was saved\n",
      "Epoch: 184 \tTraining Loss: 1.430087 \tValidation Loss: 1.486215 \t time: 0.2\n",
      "Epoch: 185 \tTraining Loss: 1.427089 \tValidation Loss: 1.485916 \t time: 0.2\n",
      "Validation loss decreased from 1.486030 to 1.485916. Model was saved\n",
      "Epoch: 186 \tTraining Loss: 1.427381 \tValidation Loss: 1.485512 \t time: 0.2\n",
      "Validation loss decreased from 1.485916 to 1.485512. Model was saved\n",
      "Epoch: 187 \tTraining Loss: 1.426296 \tValidation Loss: 1.485462 \t time: 0.2\n",
      "Validation loss decreased from 1.485512 to 1.485462. Model was saved\n",
      "Epoch: 188 \tTraining Loss: 1.427086 \tValidation Loss: 1.485390 \t time: 0.2\n",
      "Validation loss decreased from 1.485462 to 1.485390. Model was saved\n",
      "Epoch: 189 \tTraining Loss: 1.425413 \tValidation Loss: 1.485124 \t time: 0.2\n",
      "Validation loss decreased from 1.485390 to 1.485124. Model was saved\n",
      "Epoch: 190 \tTraining Loss: 1.424091 \tValidation Loss: 1.484977 \t time: 0.2\n",
      "Validation loss decreased from 1.485124 to 1.484977. Model was saved\n",
      "Epoch: 191 \tTraining Loss: 1.428640 \tValidation Loss: 1.484717 \t time: 0.2\n",
      "Validation loss decreased from 1.484977 to 1.484717. Model was saved\n",
      "Epoch: 192 \tTraining Loss: 1.422250 \tValidation Loss: 1.484405 \t time: 0.2\n",
      "Validation loss decreased from 1.484717 to 1.484405. Model was saved\n",
      "Epoch: 193 \tTraining Loss: 1.424184 \tValidation Loss: 1.484278 \t time: 0.2\n",
      "Validation loss decreased from 1.484405 to 1.484278. Model was saved\n",
      "Epoch: 194 \tTraining Loss: 1.422183 \tValidation Loss: 1.484373 \t time: 0.2\n",
      "Epoch: 195 \tTraining Loss: 1.422459 \tValidation Loss: 1.484278 \t time: 0.2\n",
      "Validation loss decreased from 1.484278 to 1.484278. Model was saved\n",
      "Epoch: 196 \tTraining Loss: 1.422342 \tValidation Loss: 1.484391 \t time: 0.2\n",
      "Epoch: 197 \tTraining Loss: 1.419684 \tValidation Loss: 1.484460 \t time: 0.2\n",
      "Epoch: 198 \tTraining Loss: 1.421621 \tValidation Loss: 1.484066 \t time: 0.2\n",
      "Validation loss decreased from 1.484278 to 1.484066. Model was saved\n",
      "Epoch: 199 \tTraining Loss: 1.419446 \tValidation Loss: 1.483633 \t time: 0.2\n",
      "Validation loss decreased from 1.484066 to 1.483633. Model was saved\n",
      "Epoch: 200 \tTraining Loss: 1.420953 \tValidation Loss: 1.483282 \t time: 0.2\n",
      "Validation loss decreased from 1.483633 to 1.483282. Model was saved\n",
      "Epoch: 201 \tTraining Loss: 1.421808 \tValidation Loss: 1.483042 \t time: 0.2\n",
      "Validation loss decreased from 1.483282 to 1.483042. Model was saved\n",
      "Epoch: 202 \tTraining Loss: 1.417405 \tValidation Loss: 1.483029 \t time: 0.2\n",
      "Validation loss decreased from 1.483042 to 1.483029. Model was saved\n",
      "Epoch: 203 \tTraining Loss: 1.418469 \tValidation Loss: 1.482926 \t time: 0.2\n",
      "Validation loss decreased from 1.483029 to 1.482926. Model was saved\n",
      "Epoch: 204 \tTraining Loss: 1.421272 \tValidation Loss: 1.482791 \t time: 0.2\n",
      "Validation loss decreased from 1.482926 to 1.482791. Model was saved\n",
      "Epoch: 205 \tTraining Loss: 1.418288 \tValidation Loss: 1.482523 \t time: 0.2\n",
      "Validation loss decreased from 1.482791 to 1.482523. Model was saved\n",
      "Epoch: 206 \tTraining Loss: 1.418185 \tValidation Loss: 1.482358 \t time: 0.2\n",
      "Validation loss decreased from 1.482523 to 1.482358. Model was saved\n",
      "Epoch: 207 \tTraining Loss: 1.414229 \tValidation Loss: 1.482383 \t time: 0.2\n",
      "Epoch: 208 \tTraining Loss: 1.417985 \tValidation Loss: 1.482542 \t time: 0.2\n",
      "Epoch: 209 \tTraining Loss: 1.416300 \tValidation Loss: 1.482442 \t time: 0.3\n",
      "Epoch: 210 \tTraining Loss: 1.416976 \tValidation Loss: 1.482247 \t time: 0.2\n",
      "Validation loss decreased from 1.482358 to 1.482247. Model was saved\n",
      "Epoch: 211 \tTraining Loss: 1.414973 \tValidation Loss: 1.482138 \t time: 0.2\n",
      "Validation loss decreased from 1.482247 to 1.482138. Model was saved\n",
      "Epoch: 212 \tTraining Loss: 1.412657 \tValidation Loss: 1.482300 \t time: 0.3\n",
      "Epoch: 213 \tTraining Loss: 1.415087 \tValidation Loss: 1.482503 \t time: 0.2\n",
      "Epoch: 214 \tTraining Loss: 1.414309 \tValidation Loss: 1.482405 \t time: 0.2\n",
      "Epoch: 215 \tTraining Loss: 1.414620 \tValidation Loss: 1.481940 \t time: 0.2\n",
      "Validation loss decreased from 1.482138 to 1.481940. Model was saved\n",
      "Epoch: 216 \tTraining Loss: 1.415914 \tValidation Loss: 1.481710 \t time: 0.2\n",
      "Validation loss decreased from 1.481940 to 1.481710. Model was saved\n",
      "Epoch: 217 \tTraining Loss: 1.413849 \tValidation Loss: 1.481589 \t time: 0.2\n",
      "Validation loss decreased from 1.481710 to 1.481589. Model was saved\n",
      "Epoch: 218 \tTraining Loss: 1.413739 \tValidation Loss: 1.481678 \t time: 0.2\n",
      "Epoch: 219 \tTraining Loss: 1.410950 \tValidation Loss: 1.481923 \t time: 0.2\n",
      "Epoch: 220 \tTraining Loss: 1.412348 \tValidation Loss: 1.482183 \t time: 0.2\n",
      "Epoch: 221 \tTraining Loss: 1.414269 \tValidation Loss: 1.482227 \t time: 0.2\n",
      "Epoch: 222 \tTraining Loss: 1.412601 \tValidation Loss: 1.481947 \t time: 0.2\n",
      "Epoch: 223 \tTraining Loss: 1.412069 \tValidation Loss: 1.481735 \t time: 0.2\n",
      "Epoch: 224 \tTraining Loss: 1.409678 \tValidation Loss: 1.481368 \t time: 0.2\n",
      "Validation loss decreased from 1.481589 to 1.481368. Model was saved\n",
      "Epoch: 225 \tTraining Loss: 1.409324 \tValidation Loss: 1.481153 \t time: 0.2\n",
      "Validation loss decreased from 1.481368 to 1.481153. Model was saved\n",
      "Epoch: 226 \tTraining Loss: 1.408113 \tValidation Loss: 1.481136 \t time: 0.2\n",
      "Validation loss decreased from 1.481153 to 1.481136. Model was saved\n",
      "Epoch: 227 \tTraining Loss: 1.408098 \tValidation Loss: 1.481263 \t time: 0.2\n",
      "Epoch: 228 \tTraining Loss: 1.408880 \tValidation Loss: 1.481502 \t time: 0.2\n",
      "Epoch: 229 \tTraining Loss: 1.410203 \tValidation Loss: 1.481530 \t time: 0.2\n",
      "Epoch: 230 \tTraining Loss: 1.407399 \tValidation Loss: 1.481457 \t time: 0.2\n",
      "Epoch: 231 \tTraining Loss: 1.407816 \tValidation Loss: 1.481020 \t time: 0.2\n",
      "Validation loss decreased from 1.481136 to 1.481020. Model was saved\n",
      "Epoch: 232 \tTraining Loss: 1.409001 \tValidation Loss: 1.480553 \t time: 0.2\n",
      "Validation loss decreased from 1.481020 to 1.480553. Model was saved\n",
      "Epoch: 233 \tTraining Loss: 1.412315 \tValidation Loss: 1.480321 \t time: 0.2\n",
      "Validation loss decreased from 1.480553 to 1.480321. Model was saved\n",
      "Epoch: 234 \tTraining Loss: 1.406509 \tValidation Loss: 1.480312 \t time: 0.2\n",
      "Validation loss decreased from 1.480321 to 1.480312. Model was saved\n",
      "Epoch: 235 \tTraining Loss: 1.405759 \tValidation Loss: 1.480390 \t time: 0.2\n",
      "Epoch: 236 \tTraining Loss: 1.406499 \tValidation Loss: 1.480582 \t time: 0.2\n",
      "Epoch: 237 \tTraining Loss: 1.405184 \tValidation Loss: 1.480722 \t time: 0.2\n",
      "Epoch: 238 \tTraining Loss: 1.404243 \tValidation Loss: 1.480619 \t time: 0.2\n",
      "Epoch: 239 \tTraining Loss: 1.404793 \tValidation Loss: 1.480481 \t time: 0.2\n",
      "Epoch: 240 \tTraining Loss: 1.402736 \tValidation Loss: 1.480241 \t time: 0.2\n",
      "Validation loss decreased from 1.480312 to 1.480241. Model was saved\n",
      "Epoch: 241 \tTraining Loss: 1.403767 \tValidation Loss: 1.479877 \t time: 0.2\n",
      "Validation loss decreased from 1.480241 to 1.479877. Model was saved\n",
      "Epoch: 242 \tTraining Loss: 1.399710 \tValidation Loss: 1.479753 \t time: 0.2\n",
      "Validation loss decreased from 1.479877 to 1.479753. Model was saved\n",
      "Epoch: 243 \tTraining Loss: 1.406312 \tValidation Loss: 1.479528 \t time: 0.2\n",
      "Validation loss decreased from 1.479753 to 1.479528. Model was saved\n",
      "Epoch: 244 \tTraining Loss: 1.404939 \tValidation Loss: 1.480010 \t time: 0.2\n",
      "Epoch: 245 \tTraining Loss: 1.403385 \tValidation Loss: 1.480345 \t time: 0.2\n",
      "Epoch: 246 \tTraining Loss: 1.402574 \tValidation Loss: 1.480152 \t time: 0.2\n",
      "Epoch: 247 \tTraining Loss: 1.402224 \tValidation Loss: 1.479369 \t time: 0.2\n",
      "Validation loss decreased from 1.479528 to 1.479369. Model was saved\n",
      "Epoch: 248 \tTraining Loss: 1.401519 \tValidation Loss: 1.478245 \t time: 0.2\n",
      "Validation loss decreased from 1.479369 to 1.478245. Model was saved\n",
      "Epoch: 249 \tTraining Loss: 1.403907 \tValidation Loss: 1.477584 \t time: 0.2\n",
      "Validation loss decreased from 1.478245 to 1.477584. Model was saved\n",
      "Epoch: 250 \tTraining Loss: 1.400573 \tValidation Loss: 1.477435 \t time: 0.2\n",
      "Validation loss decreased from 1.477584 to 1.477435. Model was saved\n",
      "Epoch: 251 \tTraining Loss: 1.403702 \tValidation Loss: 1.477541 \t time: 0.2\n",
      "Epoch: 252 \tTraining Loss: 1.398436 \tValidation Loss: 1.478173 \t time: 0.2\n",
      "Epoch: 253 \tTraining Loss: 1.400201 \tValidation Loss: 1.478524 \t time: 0.2\n",
      "Epoch: 254 \tTraining Loss: 1.400350 \tValidation Loss: 1.478382 \t time: 0.2\n",
      "Epoch: 255 \tTraining Loss: 1.401389 \tValidation Loss: 1.478149 \t time: 0.2\n",
      "Epoch: 256 \tTraining Loss: 1.399154 \tValidation Loss: 1.477789 \t time: 0.2\n",
      "Epoch: 257 \tTraining Loss: 1.400025 \tValidation Loss: 1.477309 \t time: 0.2\n",
      "Validation loss decreased from 1.477435 to 1.477309. Model was saved\n",
      "Epoch: 258 \tTraining Loss: 1.394014 \tValidation Loss: 1.476831 \t time: 0.2\n",
      "Validation loss decreased from 1.477309 to 1.476831. Model was saved\n",
      "Epoch: 259 \tTraining Loss: 1.398303 \tValidation Loss: 1.476505 \t time: 0.2\n",
      "Validation loss decreased from 1.476831 to 1.476505. Model was saved\n",
      "Epoch: 260 \tTraining Loss: 1.396421 \tValidation Loss: 1.476396 \t time: 0.2\n",
      "Validation loss decreased from 1.476505 to 1.476396. Model was saved\n",
      "Epoch: 261 \tTraining Loss: 1.396041 \tValidation Loss: 1.476061 \t time: 0.2\n",
      "Validation loss decreased from 1.476396 to 1.476061. Model was saved\n",
      "Epoch: 262 \tTraining Loss: 1.394276 \tValidation Loss: 1.475578 \t time: 0.2\n",
      "Validation loss decreased from 1.476061 to 1.475578. Model was saved\n",
      "Epoch: 263 \tTraining Loss: 1.395317 \tValidation Loss: 1.475104 \t time: 0.2\n",
      "Validation loss decreased from 1.475578 to 1.475104. Model was saved\n",
      "Epoch: 264 \tTraining Loss: 1.392051 \tValidation Loss: 1.474694 \t time: 0.2\n",
      "Validation loss decreased from 1.475104 to 1.474694. Model was saved\n",
      "Epoch: 265 \tTraining Loss: 1.394365 \tValidation Loss: 1.474465 \t time: 0.2\n",
      "Validation loss decreased from 1.474694 to 1.474465. Model was saved\n",
      "Epoch: 266 \tTraining Loss: 1.393536 \tValidation Loss: 1.473318 \t time: 0.2\n",
      "Validation loss decreased from 1.474465 to 1.473318. Model was saved\n",
      "Epoch: 267 \tTraining Loss: 1.392295 \tValidation Loss: 1.471906 \t time: 0.2\n",
      "Validation loss decreased from 1.473318 to 1.471906. Model was saved\n",
      "Epoch: 268 \tTraining Loss: 1.393360 \tValidation Loss: 1.470820 \t time: 0.2\n",
      "Validation loss decreased from 1.471906 to 1.470820. Model was saved\n",
      "Epoch: 269 \tTraining Loss: 1.389856 \tValidation Loss: 1.469871 \t time: 0.2\n",
      "Validation loss decreased from 1.470820 to 1.469871. Model was saved\n",
      "Epoch: 270 \tTraining Loss: 1.388983 \tValidation Loss: 1.469124 \t time: 0.2\n",
      "Validation loss decreased from 1.469871 to 1.469124. Model was saved\n",
      "Epoch: 271 \tTraining Loss: 1.388080 \tValidation Loss: 1.468540 \t time: 0.2\n",
      "Validation loss decreased from 1.469124 to 1.468540. Model was saved\n",
      "Epoch: 272 \tTraining Loss: 1.389403 \tValidation Loss: 1.468158 \t time: 0.2\n",
      "Validation loss decreased from 1.468540 to 1.468158. Model was saved\n",
      "Epoch: 273 \tTraining Loss: 1.387579 \tValidation Loss: 1.467447 \t time: 0.2\n",
      "Validation loss decreased from 1.468158 to 1.467447. Model was saved\n",
      "Epoch: 274 \tTraining Loss: 1.385338 \tValidation Loss: 1.466295 \t time: 0.2\n",
      "Validation loss decreased from 1.467447 to 1.466295. Model was saved\n",
      "Epoch: 275 \tTraining Loss: 1.388174 \tValidation Loss: 1.465088 \t time: 0.2\n",
      "Validation loss decreased from 1.466295 to 1.465088. Model was saved\n",
      "Epoch: 276 \tTraining Loss: 1.385805 \tValidation Loss: 1.464154 \t time: 0.2\n",
      "Validation loss decreased from 1.465088 to 1.464154. Model was saved\n",
      "Epoch: 277 \tTraining Loss: 1.381807 \tValidation Loss: 1.463355 \t time: 0.2\n",
      "Validation loss decreased from 1.464154 to 1.463355. Model was saved\n",
      "Epoch: 278 \tTraining Loss: 1.384434 \tValidation Loss: 1.462893 \t time: 0.2\n",
      "Validation loss decreased from 1.463355 to 1.462893. Model was saved\n",
      "Epoch: 279 \tTraining Loss: 1.381149 \tValidation Loss: 1.462627 \t time: 0.2\n",
      "Validation loss decreased from 1.462893 to 1.462627. Model was saved\n",
      "Epoch: 280 \tTraining Loss: 1.381289 \tValidation Loss: 1.462172 \t time: 0.3\n",
      "Validation loss decreased from 1.462627 to 1.462172. Model was saved\n",
      "Epoch: 281 \tTraining Loss: 1.381847 \tValidation Loss: 1.461911 \t time: 0.2\n",
      "Validation loss decreased from 1.462172 to 1.461911. Model was saved\n",
      "Epoch: 282 \tTraining Loss: 1.381146 \tValidation Loss: 1.461537 \t time: 0.2\n",
      "Validation loss decreased from 1.461911 to 1.461537. Model was saved\n",
      "Epoch: 283 \tTraining Loss: 1.379415 \tValidation Loss: 1.461327 \t time: 0.2\n",
      "Validation loss decreased from 1.461537 to 1.461327. Model was saved\n",
      "Epoch: 284 \tTraining Loss: 1.381835 \tValidation Loss: 1.461036 \t time: 0.2\n",
      "Validation loss decreased from 1.461327 to 1.461036. Model was saved\n",
      "Epoch: 285 \tTraining Loss: 1.375318 \tValidation Loss: 1.460713 \t time: 0.2\n",
      "Validation loss decreased from 1.461036 to 1.460713. Model was saved\n",
      "Epoch: 286 \tTraining Loss: 1.379891 \tValidation Loss: 1.460354 \t time: 0.2\n",
      "Validation loss decreased from 1.460713 to 1.460354. Model was saved\n",
      "Epoch: 287 \tTraining Loss: 1.376788 \tValidation Loss: 1.460422 \t time: 0.2\n",
      "Epoch: 288 \tTraining Loss: 1.380110 \tValidation Loss: 1.460564 \t time: 0.2\n",
      "Epoch: 289 \tTraining Loss: 1.377737 \tValidation Loss: 1.460279 \t time: 0.2\n",
      "Validation loss decreased from 1.460354 to 1.460279. Model was saved\n",
      "Epoch: 290 \tTraining Loss: 1.377244 \tValidation Loss: 1.459937 \t time: 0.2\n",
      "Validation loss decreased from 1.460279 to 1.459937. Model was saved\n",
      "Epoch: 291 \tTraining Loss: 1.375925 \tValidation Loss: 1.459556 \t time: 0.2\n",
      "Validation loss decreased from 1.459937 to 1.459556. Model was saved\n",
      "Epoch: 292 \tTraining Loss: 1.374793 \tValidation Loss: 1.459106 \t time: 0.2\n",
      "Validation loss decreased from 1.459556 to 1.459106. Model was saved\n",
      "Epoch: 293 \tTraining Loss: 1.374517 \tValidation Loss: 1.458681 \t time: 0.2\n",
      "Validation loss decreased from 1.459106 to 1.458681. Model was saved\n",
      "Epoch: 294 \tTraining Loss: 1.375670 \tValidation Loss: 1.458156 \t time: 0.2\n",
      "Validation loss decreased from 1.458681 to 1.458156. Model was saved\n",
      "Epoch: 295 \tTraining Loss: 1.370855 \tValidation Loss: 1.457619 \t time: 0.2\n",
      "Validation loss decreased from 1.458156 to 1.457619. Model was saved\n",
      "Epoch: 296 \tTraining Loss: 1.375520 \tValidation Loss: 1.457142 \t time: 0.2\n",
      "Validation loss decreased from 1.457619 to 1.457142. Model was saved\n",
      "Epoch: 297 \tTraining Loss: 1.372748 \tValidation Loss: 1.456774 \t time: 0.2\n",
      "Validation loss decreased from 1.457142 to 1.456774. Model was saved\n",
      "Epoch: 298 \tTraining Loss: 1.373152 \tValidation Loss: 1.456611 \t time: 0.2\n",
      "Validation loss decreased from 1.456774 to 1.456611. Model was saved\n",
      "Epoch: 299 \tTraining Loss: 1.373909 \tValidation Loss: 1.456638 \t time: 0.2\n",
      "Epoch: 300 \tTraining Loss: 1.373061 \tValidation Loss: 1.456691 \t time: 0.2\n",
      "Epoch: 301 \tTraining Loss: 1.369035 \tValidation Loss: 1.456775 \t time: 0.2\n",
      "Epoch: 302 \tTraining Loss: 1.371987 \tValidation Loss: 1.456572 \t time: 0.2\n",
      "Validation loss decreased from 1.456611 to 1.456572. Model was saved\n",
      "Epoch: 303 \tTraining Loss: 1.372478 \tValidation Loss: 1.456159 \t time: 0.2\n",
      "Validation loss decreased from 1.456572 to 1.456159. Model was saved\n",
      "Epoch: 304 \tTraining Loss: 1.369408 \tValidation Loss: 1.455737 \t time: 0.2\n",
      "Validation loss decreased from 1.456159 to 1.455737. Model was saved\n",
      "Epoch: 305 \tTraining Loss: 1.368366 \tValidation Loss: 1.455382 \t time: 0.2\n",
      "Validation loss decreased from 1.455737 to 1.455382. Model was saved\n",
      "Epoch: 306 \tTraining Loss: 1.370321 \tValidation Loss: 1.455175 \t time: 0.2\n",
      "Validation loss decreased from 1.455382 to 1.455175. Model was saved\n",
      "Epoch: 307 \tTraining Loss: 1.369791 \tValidation Loss: 1.455179 \t time: 0.2\n",
      "Epoch: 308 \tTraining Loss: 1.367179 \tValidation Loss: 1.455363 \t time: 0.2\n",
      "Epoch: 309 \tTraining Loss: 1.366505 \tValidation Loss: 1.455608 \t time: 0.2\n",
      "Epoch: 310 \tTraining Loss: 1.367985 \tValidation Loss: 1.455691 \t time: 0.2\n",
      "Epoch: 311 \tTraining Loss: 1.370356 \tValidation Loss: 1.455536 \t time: 0.2\n",
      "Epoch: 312 \tTraining Loss: 1.365355 \tValidation Loss: 1.455163 \t time: 0.2\n",
      "Validation loss decreased from 1.455175 to 1.455163. Model was saved\n",
      "Epoch: 313 \tTraining Loss: 1.364163 \tValidation Loss: 1.454808 \t time: 0.2\n",
      "Validation loss decreased from 1.455163 to 1.454808. Model was saved\n",
      "Epoch: 314 \tTraining Loss: 1.365835 \tValidation Loss: 1.454494 \t time: 0.2\n",
      "Validation loss decreased from 1.454808 to 1.454494. Model was saved\n",
      "Epoch: 315 \tTraining Loss: 1.364215 \tValidation Loss: 1.454329 \t time: 0.2\n",
      "Validation loss decreased from 1.454494 to 1.454329. Model was saved\n",
      "Epoch: 316 \tTraining Loss: 1.364582 \tValidation Loss: 1.454237 \t time: 0.2\n",
      "Validation loss decreased from 1.454329 to 1.454237. Model was saved\n",
      "Epoch: 317 \tTraining Loss: 1.361656 \tValidation Loss: 1.454360 \t time: 0.2\n",
      "Epoch: 318 \tTraining Loss: 1.366943 \tValidation Loss: 1.454432 \t time: 0.2\n",
      "Epoch: 319 \tTraining Loss: 1.365317 \tValidation Loss: 1.454331 \t time: 0.2\n",
      "Epoch: 320 \tTraining Loss: 1.361350 \tValidation Loss: 1.454104 \t time: 0.2\n",
      "Validation loss decreased from 1.454237 to 1.454104. Model was saved\n",
      "Epoch: 321 \tTraining Loss: 1.363754 \tValidation Loss: 1.453724 \t time: 0.2\n",
      "Validation loss decreased from 1.454104 to 1.453724. Model was saved\n",
      "Epoch: 322 \tTraining Loss: 1.360671 \tValidation Loss: 1.453390 \t time: 0.2\n",
      "Validation loss decreased from 1.453724 to 1.453390. Model was saved\n",
      "Epoch: 323 \tTraining Loss: 1.363726 \tValidation Loss: 1.453293 \t time: 0.2\n",
      "Validation loss decreased from 1.453390 to 1.453293. Model was saved\n",
      "Epoch: 324 \tTraining Loss: 1.365241 \tValidation Loss: 1.453359 \t time: 0.2\n",
      "Epoch: 325 \tTraining Loss: 1.360561 \tValidation Loss: 1.453733 \t time: 0.2\n",
      "Epoch: 326 \tTraining Loss: 1.362683 \tValidation Loss: 1.453861 \t time: 0.2\n",
      "Epoch: 327 \tTraining Loss: 1.359024 \tValidation Loss: 1.453971 \t time: 0.2\n",
      "Epoch: 328 \tTraining Loss: 1.359610 \tValidation Loss: 1.454066 \t time: 0.2\n",
      "Epoch: 329 \tTraining Loss: 1.361694 \tValidation Loss: 1.454038 \t time: 0.2\n",
      "Epoch: 330 \tTraining Loss: 1.361751 \tValidation Loss: 1.453912 \t time: 0.2\n",
      "Epoch: 331 \tTraining Loss: 1.361799 \tValidation Loss: 1.453717 \t time: 0.2\n",
      "Epoch: 332 \tTraining Loss: 1.359712 \tValidation Loss: 1.453656 \t time: 0.2\n",
      "Epoch: 333 \tTraining Loss: 1.358302 \tValidation Loss: 1.453437 \t time: 0.2\n",
      "Epoch: 334 \tTraining Loss: 1.356719 \tValidation Loss: 1.452981 \t time: 0.2\n",
      "Validation loss decreased from 1.453293 to 1.452981. Model was saved\n",
      "Epoch: 335 \tTraining Loss: 1.359807 \tValidation Loss: 1.452449 \t time: 0.2\n",
      "Validation loss decreased from 1.452981 to 1.452449. Model was saved\n",
      "Epoch: 336 \tTraining Loss: 1.357843 \tValidation Loss: 1.452254 \t time: 0.2\n",
      "Validation loss decreased from 1.452449 to 1.452254. Model was saved\n",
      "Epoch: 337 \tTraining Loss: 1.358724 \tValidation Loss: 1.452237 \t time: 0.2\n",
      "Validation loss decreased from 1.452254 to 1.452237. Model was saved\n",
      "Epoch: 338 \tTraining Loss: 1.356583 \tValidation Loss: 1.452438 \t time: 0.2\n",
      "Epoch: 339 \tTraining Loss: 1.357638 \tValidation Loss: 1.452569 \t time: 0.2\n",
      "Epoch: 340 \tTraining Loss: 1.355120 \tValidation Loss: 1.452801 \t time: 0.2\n",
      "Epoch: 341 \tTraining Loss: 1.354191 \tValidation Loss: 1.452774 \t time: 0.2\n",
      "Epoch: 342 \tTraining Loss: 1.354099 \tValidation Loss: 1.452728 \t time: 0.2\n",
      "Epoch: 343 \tTraining Loss: 1.355487 \tValidation Loss: 1.452850 \t time: 0.2\n",
      "Epoch: 344 \tTraining Loss: 1.355224 \tValidation Loss: 1.453067 \t time: 0.2\n",
      "Epoch: 345 \tTraining Loss: 1.355174 \tValidation Loss: 1.453259 \t time: 0.2\n",
      "Epoch: 346 \tTraining Loss: 1.353300 \tValidation Loss: 1.453188 \t time: 0.2\n",
      "Epoch: 347 \tTraining Loss: 1.356425 \tValidation Loss: 1.453239 \t time: 0.2\n",
      "Epoch: 348 \tTraining Loss: 1.353481 \tValidation Loss: 1.453251 \t time: 0.2\n",
      "Epoch: 349 \tTraining Loss: 1.355420 \tValidation Loss: 1.453263 \t time: 0.2\n",
      "Epoch: 350 \tTraining Loss: 1.356144 \tValidation Loss: 1.453423 \t time: 0.2\n",
      "Epoch: 351 \tTraining Loss: 1.354663 \tValidation Loss: 1.453534 \t time: 0.2\n",
      "Epoch: 352 \tTraining Loss: 1.352383 \tValidation Loss: 1.453495 \t time: 0.2\n",
      "Epoch: 353 \tTraining Loss: 1.354124 \tValidation Loss: 1.453194 \t time: 0.2\n",
      "Epoch: 354 \tTraining Loss: 1.353319 \tValidation Loss: 1.452806 \t time: 0.2\n",
      "Epoch: 355 \tTraining Loss: 1.349826 \tValidation Loss: 1.452496 \t time: 0.2\n",
      "Epoch: 356 \tTraining Loss: 1.353359 \tValidation Loss: 1.452381 \t time: 0.2\n",
      "Epoch: 357 \tTraining Loss: 1.350087 \tValidation Loss: 1.452635 \t time: 0.2\n",
      "Epoch: 358 \tTraining Loss: 1.350421 \tValidation Loss: 1.452933 \t time: 0.2\n",
      "Epoch: 359 \tTraining Loss: 1.348880 \tValidation Loss: 1.452908 \t time: 0.2\n",
      "Epoch: 360 \tTraining Loss: 1.349225 \tValidation Loss: 1.452895 \t time: 0.2\n",
      "Epoch: 361 \tTraining Loss: 1.348424 \tValidation Loss: 1.452878 \t time: 0.2\n",
      "Epoch: 362 \tTraining Loss: 1.349930 \tValidation Loss: 1.452893 \t time: 0.2\n",
      "Epoch: 363 \tTraining Loss: 1.349191 \tValidation Loss: 1.452833 \t time: 0.2\n",
      "Epoch: 364 \tTraining Loss: 1.353131 \tValidation Loss: 1.452637 \t time: 0.2\n",
      "Epoch: 365 \tTraining Loss: 1.351527 \tValidation Loss: 1.452348 \t time: 0.2\n",
      "Epoch: 366 \tTraining Loss: 1.351680 \tValidation Loss: 1.452313 \t time: 0.2\n",
      "Epoch: 367 \tTraining Loss: 1.349303 \tValidation Loss: 1.452296 \t time: 0.2\n",
      "Epoch: 368 \tTraining Loss: 1.348228 \tValidation Loss: 1.452176 \t time: 0.2\n",
      "Validation loss decreased from 1.452237 to 1.452176. Model was saved\n",
      "Epoch: 369 \tTraining Loss: 1.349561 \tValidation Loss: 1.452170 \t time: 0.2\n",
      "Validation loss decreased from 1.452176 to 1.452170. Model was saved\n",
      "Epoch: 370 \tTraining Loss: 1.345739 \tValidation Loss: 1.452152 \t time: 0.2\n",
      "Validation loss decreased from 1.452170 to 1.452152. Model was saved\n",
      "Epoch: 371 \tTraining Loss: 1.348142 \tValidation Loss: 1.452068 \t time: 0.2\n",
      "Validation loss decreased from 1.452152 to 1.452068. Model was saved\n",
      "Epoch: 372 \tTraining Loss: 1.346614 \tValidation Loss: 1.452095 \t time: 0.2\n",
      "Epoch: 373 \tTraining Loss: 1.347678 \tValidation Loss: 1.452251 \t time: 0.2\n",
      "Epoch: 374 \tTraining Loss: 1.345450 \tValidation Loss: 1.452533 \t time: 0.2\n",
      "Epoch: 375 \tTraining Loss: 1.346468 \tValidation Loss: 1.452372 \t time: 0.2\n",
      "Epoch: 376 \tTraining Loss: 1.346005 \tValidation Loss: 1.452088 \t time: 0.2\n",
      "Epoch: 377 \tTraining Loss: 1.346279 \tValidation Loss: 1.451750 \t time: 0.2\n",
      "Validation loss decreased from 1.452068 to 1.451750. Model was saved\n",
      "Epoch: 378 \tTraining Loss: 1.345771 \tValidation Loss: 1.451380 \t time: 0.2\n",
      "Validation loss decreased from 1.451750 to 1.451380. Model was saved\n",
      "Epoch: 379 \tTraining Loss: 1.345403 \tValidation Loss: 1.451267 \t time: 0.2\n",
      "Validation loss decreased from 1.451380 to 1.451267. Model was saved\n",
      "Epoch: 380 \tTraining Loss: 1.344904 \tValidation Loss: 1.451435 \t time: 0.2\n",
      "Epoch: 381 \tTraining Loss: 1.345726 \tValidation Loss: 1.451599 \t time: 0.2\n",
      "Epoch: 382 \tTraining Loss: 1.344116 \tValidation Loss: 1.451796 \t time: 0.2\n",
      "Epoch: 383 \tTraining Loss: 1.343050 \tValidation Loss: 1.451754 \t time: 0.2\n",
      "Epoch: 384 \tTraining Loss: 1.342349 \tValidation Loss: 1.451541 \t time: 0.2\n",
      "Epoch: 385 \tTraining Loss: 1.346030 \tValidation Loss: 1.451195 \t time: 0.2\n",
      "Validation loss decreased from 1.451267 to 1.451195. Model was saved\n",
      "Epoch: 386 \tTraining Loss: 1.343144 \tValidation Loss: 1.451018 \t time: 0.2\n",
      "Validation loss decreased from 1.451195 to 1.451018. Model was saved\n",
      "Epoch: 387 \tTraining Loss: 1.345473 \tValidation Loss: 1.451223 \t time: 0.2\n",
      "Epoch: 388 \tTraining Loss: 1.343827 \tValidation Loss: 1.451612 \t time: 0.2\n",
      "Epoch: 389 \tTraining Loss: 1.344682 \tValidation Loss: 1.452043 \t time: 0.2\n",
      "Epoch: 390 \tTraining Loss: 1.341939 \tValidation Loss: 1.452154 \t time: 0.2\n",
      "Epoch: 391 \tTraining Loss: 1.342327 \tValidation Loss: 1.452476 \t time: 0.2\n",
      "Epoch: 392 \tTraining Loss: 1.344650 \tValidation Loss: 1.452698 \t time: 0.2\n",
      "Epoch: 393 \tTraining Loss: 1.340887 \tValidation Loss: 1.452635 \t time: 0.3\n",
      "Epoch: 394 \tTraining Loss: 1.343927 \tValidation Loss: 1.452407 \t time: 0.2\n",
      "Epoch: 395 \tTraining Loss: 1.341420 \tValidation Loss: 1.452113 \t time: 0.2\n",
      "Epoch: 396 \tTraining Loss: 1.343562 \tValidation Loss: 1.451894 \t time: 0.3\n",
      "Epoch: 397 \tTraining Loss: 1.342488 \tValidation Loss: 1.451921 \t time: 0.2\n",
      "Epoch: 398 \tTraining Loss: 1.337122 \tValidation Loss: 1.452144 \t time: 0.2\n",
      "Epoch: 399 \tTraining Loss: 1.339107 \tValidation Loss: 1.452243 \t time: 0.2\n",
      "Epoch: 400 \tTraining Loss: 1.341374 \tValidation Loss: 1.452164 \t time: 0.2\n",
      "Epoch: 401 \tTraining Loss: 1.338938 \tValidation Loss: 1.451912 \t time: 0.2\n",
      "Epoch: 402 \tTraining Loss: 1.337772 \tValidation Loss: 1.451659 \t time: 0.2\n",
      "Epoch: 403 \tTraining Loss: 1.341227 \tValidation Loss: 1.451594 \t time: 0.2\n",
      "Epoch: 404 \tTraining Loss: 1.340065 \tValidation Loss: 1.451533 \t time: 0.2\n",
      "Epoch: 405 \tTraining Loss: 1.335671 \tValidation Loss: 1.451414 \t time: 0.2\n",
      "Epoch: 406 \tTraining Loss: 1.337814 \tValidation Loss: 1.451284 \t time: 0.2\n",
      "Epoch: 407 \tTraining Loss: 1.339318 \tValidation Loss: 1.451316 \t time: 0.2\n",
      "Epoch: 408 \tTraining Loss: 1.337901 \tValidation Loss: 1.451610 \t time: 0.2\n",
      "Epoch: 409 \tTraining Loss: 1.335837 \tValidation Loss: 1.451900 \t time: 0.2\n",
      "Epoch: 410 \tTraining Loss: 1.338428 \tValidation Loss: 1.452020 \t time: 0.2\n",
      "Epoch: 411 \tTraining Loss: 1.335644 \tValidation Loss: 1.451910 \t time: 0.2\n",
      "Epoch: 412 \tTraining Loss: 1.336259 \tValidation Loss: 1.451534 \t time: 0.2\n",
      "Epoch: 413 \tTraining Loss: 1.339019 \tValidation Loss: 1.451277 \t time: 0.2\n",
      "Epoch: 414 \tTraining Loss: 1.339777 \tValidation Loss: 1.451135 \t time: 0.2\n",
      "Epoch: 415 \tTraining Loss: 1.339360 \tValidation Loss: 1.451366 \t time: 0.2\n",
      "Epoch: 416 \tTraining Loss: 1.335764 \tValidation Loss: 1.451925 \t time: 0.2\n",
      "Epoch: 417 \tTraining Loss: 1.335820 \tValidation Loss: 1.452468 \t time: 0.2\n",
      "Epoch: 418 \tTraining Loss: 1.334895 \tValidation Loss: 1.452730 \t time: 0.2\n",
      "Epoch: 419 \tTraining Loss: 1.337867 \tValidation Loss: 1.452549 \t time: 0.2\n",
      "Epoch: 420 \tTraining Loss: 1.336155 \tValidation Loss: 1.452049 \t time: 0.2\n",
      "Epoch: 421 \tTraining Loss: 1.336302 \tValidation Loss: 1.451359 \t time: 0.2\n",
      "Epoch: 422 \tTraining Loss: 1.336112 \tValidation Loss: 1.450812 \t time: 0.2\n",
      "Validation loss decreased from 1.451018 to 1.450812. Model was saved\n",
      "Epoch: 423 \tTraining Loss: 1.335535 \tValidation Loss: 1.450660 \t time: 0.2\n",
      "Validation loss decreased from 1.450812 to 1.450660. Model was saved\n",
      "Epoch: 424 \tTraining Loss: 1.332419 \tValidation Loss: 1.450838 \t time: 0.2\n",
      "Epoch: 425 \tTraining Loss: 1.337400 \tValidation Loss: 1.451371 \t time: 0.2\n",
      "Epoch: 426 \tTraining Loss: 1.337250 \tValidation Loss: 1.451981 \t time: 0.2\n",
      "Epoch: 427 \tTraining Loss: 1.334662 \tValidation Loss: 1.452305 \t time: 0.2\n",
      "Epoch: 428 \tTraining Loss: 1.337275 \tValidation Loss: 1.452000 \t time: 0.2\n",
      "Epoch: 429 \tTraining Loss: 1.334117 \tValidation Loss: 1.451603 \t time: 0.2\n",
      "Epoch: 430 \tTraining Loss: 1.335759 \tValidation Loss: 1.451421 \t time: 0.2\n",
      "Epoch: 431 \tTraining Loss: 1.334527 \tValidation Loss: 1.451418 \t time: 0.2\n",
      "Epoch: 432 \tTraining Loss: 1.333149 \tValidation Loss: 1.451489 \t time: 0.2\n",
      "Epoch: 433 \tTraining Loss: 1.333238 \tValidation Loss: 1.451838 \t time: 0.2\n",
      "Epoch: 434 \tTraining Loss: 1.330844 \tValidation Loss: 1.452346 \t time: 0.2\n",
      "Epoch: 435 \tTraining Loss: 1.334962 \tValidation Loss: 1.452551 \t time: 0.2\n",
      "Epoch: 436 \tTraining Loss: 1.333437 \tValidation Loss: 1.452330 \t time: 0.2\n",
      "Epoch: 437 \tTraining Loss: 1.334684 \tValidation Loss: 1.451914 \t time: 0.2\n",
      "Epoch: 438 \tTraining Loss: 1.334540 \tValidation Loss: 1.451723 \t time: 0.2\n",
      "Epoch: 439 \tTraining Loss: 1.330373 \tValidation Loss: 1.451457 \t time: 0.2\n",
      "Epoch: 440 \tTraining Loss: 1.332471 \tValidation Loss: 1.451333 \t time: 0.2\n",
      "Epoch: 441 \tTraining Loss: 1.332046 \tValidation Loss: 1.451494 \t time: 0.2\n",
      "Epoch: 442 \tTraining Loss: 1.331442 \tValidation Loss: 1.451653 \t time: 0.2\n",
      "Epoch: 443 \tTraining Loss: 1.332058 \tValidation Loss: 1.451735 \t time: 0.2\n",
      "Epoch: 444 \tTraining Loss: 1.330202 \tValidation Loss: 1.451492 \t time: 0.2\n",
      "Epoch: 445 \tTraining Loss: 1.329069 \tValidation Loss: 1.451091 \t time: 0.2\n",
      "Epoch: 446 \tTraining Loss: 1.329237 \tValidation Loss: 1.450782 \t time: 0.2\n",
      "Epoch: 447 \tTraining Loss: 1.331452 \tValidation Loss: 1.450770 \t time: 0.2\n",
      "Epoch: 448 \tTraining Loss: 1.330135 \tValidation Loss: 1.451050 \t time: 0.2\n",
      "Epoch: 449 \tTraining Loss: 1.329129 \tValidation Loss: 1.451335 \t time: 0.2\n",
      "Epoch: 450 \tTraining Loss: 1.330565 \tValidation Loss: 1.451576 \t time: 0.2\n",
      "Epoch: 451 \tTraining Loss: 1.329567 \tValidation Loss: 1.451774 \t time: 0.2\n",
      "Epoch: 452 \tTraining Loss: 1.329370 \tValidation Loss: 1.451853 \t time: 0.2\n",
      "Epoch: 453 \tTraining Loss: 1.325373 \tValidation Loss: 1.451701 \t time: 0.2\n",
      "Epoch: 454 \tTraining Loss: 1.327332 \tValidation Loss: 1.451631 \t time: 0.3\n",
      "Epoch: 455 \tTraining Loss: 1.326058 \tValidation Loss: 1.451613 \t time: 0.2\n",
      "Epoch: 456 \tTraining Loss: 1.328597 \tValidation Loss: 1.451627 \t time: 0.2\n",
      "Epoch: 457 \tTraining Loss: 1.327849 \tValidation Loss: 1.451820 \t time: 0.2\n",
      "Epoch: 458 \tTraining Loss: 1.324960 \tValidation Loss: 1.452039 \t time: 0.2\n",
      "Epoch: 459 \tTraining Loss: 1.328046 \tValidation Loss: 1.452289 \t time: 0.2\n",
      "Epoch: 460 \tTraining Loss: 1.327948 \tValidation Loss: 1.452362 \t time: 0.2\n",
      "Epoch: 461 \tTraining Loss: 1.327174 \tValidation Loss: 1.452354 \t time: 0.2\n",
      "Epoch: 462 \tTraining Loss: 1.326624 \tValidation Loss: 1.452241 \t time: 0.2\n",
      "Epoch: 463 \tTraining Loss: 1.328624 \tValidation Loss: 1.452201 \t time: 0.2\n",
      "Epoch: 464 \tTraining Loss: 1.325570 \tValidation Loss: 1.452379 \t time: 0.2\n",
      "Epoch: 465 \tTraining Loss: 1.326573 \tValidation Loss: 1.452532 \t time: 0.2\n",
      "Epoch: 466 \tTraining Loss: 1.326015 \tValidation Loss: 1.452746 \t time: 0.2\n",
      "Epoch: 467 \tTraining Loss: 1.325342 \tValidation Loss: 1.452906 \t time: 0.2\n",
      "Epoch: 468 \tTraining Loss: 1.327310 \tValidation Loss: 1.452905 \t time: 0.2\n",
      "Epoch: 469 \tTraining Loss: 1.325448 \tValidation Loss: 1.452835 \t time: 0.2\n",
      "Epoch: 470 \tTraining Loss: 1.326303 \tValidation Loss: 1.452731 \t time: 0.2\n",
      "Epoch: 471 \tTraining Loss: 1.324011 \tValidation Loss: 1.452704 \t time: 0.2\n",
      "Epoch: 472 \tTraining Loss: 1.324291 \tValidation Loss: 1.452780 \t time: 0.2\n",
      "Epoch: 473 \tTraining Loss: 1.324384 \tValidation Loss: 1.452883 \t time: 0.2\n",
      "Epoch: 474 \tTraining Loss: 1.327070 \tValidation Loss: 1.452947 \t time: 0.2\n",
      "Epoch: 475 \tTraining Loss: 1.320756 \tValidation Loss: 1.452973 \t time: 0.2\n",
      "Epoch: 476 \tTraining Loss: 1.323582 \tValidation Loss: 1.452958 \t time: 0.2\n",
      "Epoch: 477 \tTraining Loss: 1.326199 \tValidation Loss: 1.452924 \t time: 0.2\n",
      "Epoch: 478 \tTraining Loss: 1.325565 \tValidation Loss: 1.452760 \t time: 0.2\n",
      "Epoch: 479 \tTraining Loss: 1.324222 \tValidation Loss: 1.452676 \t time: 0.2\n",
      "Epoch: 480 \tTraining Loss: 1.322805 \tValidation Loss: 1.452768 \t time: 0.2\n",
      "Epoch: 481 \tTraining Loss: 1.323588 \tValidation Loss: 1.452869 \t time: 0.2\n",
      "Epoch: 482 \tTraining Loss: 1.322031 \tValidation Loss: 1.453128 \t time: 0.2\n",
      "Epoch: 483 \tTraining Loss: 1.322366 \tValidation Loss: 1.453234 \t time: 0.2\n",
      "Epoch: 484 \tTraining Loss: 1.324135 \tValidation Loss: 1.453218 \t time: 0.2\n",
      "Epoch: 485 \tTraining Loss: 1.322788 \tValidation Loss: 1.453076 \t time: 0.2\n",
      "Epoch: 486 \tTraining Loss: 1.325044 \tValidation Loss: 1.453009 \t time: 0.2\n",
      "Epoch: 487 \tTraining Loss: 1.323763 \tValidation Loss: 1.452995 \t time: 0.2\n",
      "Epoch: 488 \tTraining Loss: 1.320122 \tValidation Loss: 1.453061 \t time: 0.2\n",
      "Epoch: 489 \tTraining Loss: 1.323009 \tValidation Loss: 1.453331 \t time: 0.2\n",
      "Epoch: 490 \tTraining Loss: 1.321353 \tValidation Loss: 1.453661 \t time: 0.2\n",
      "Epoch: 491 \tTraining Loss: 1.320782 \tValidation Loss: 1.453821 \t time: 0.2\n",
      "Epoch: 492 \tTraining Loss: 1.320302 \tValidation Loss: 1.453854 \t time: 0.2\n",
      "Epoch: 493 \tTraining Loss: 1.319807 \tValidation Loss: 1.453749 \t time: 0.2\n",
      "Epoch: 494 \tTraining Loss: 1.322023 \tValidation Loss: 1.453398 \t time: 0.2\n",
      "Epoch: 495 \tTraining Loss: 1.321423 \tValidation Loss: 1.453003 \t time: 0.2\n",
      "Epoch: 496 \tTraining Loss: 1.321712 \tValidation Loss: 1.452923 \t time: 0.2\n",
      "Epoch: 497 \tTraining Loss: 1.322107 \tValidation Loss: 1.453160 \t time: 0.2\n",
      "Epoch: 498 \tTraining Loss: 1.319017 \tValidation Loss: 1.453463 \t time: 0.2\n",
      "Epoch: 499 \tTraining Loss: 1.321481 \tValidation Loss: 1.453755 \t time: 0.2\n",
      "Epoch: 500 \tTraining Loss: 1.320793 \tValidation Loss: 1.453675 \t time: 0.2\n",
      "Epoch: 501 \tTraining Loss: 1.320548 \tValidation Loss: 1.453288 \t time: 0.2\n",
      "Epoch: 502 \tTraining Loss: 1.316225 \tValidation Loss: 1.452953 \t time: 0.2\n",
      "Epoch: 503 \tTraining Loss: 1.319647 \tValidation Loss: 1.452865 \t time: 0.2\n",
      "Epoch: 504 \tTraining Loss: 1.318379 \tValidation Loss: 1.453044 \t time: 0.2\n",
      "Epoch: 505 \tTraining Loss: 1.319576 \tValidation Loss: 1.453390 \t time: 0.3\n",
      "Epoch: 506 \tTraining Loss: 1.321048 \tValidation Loss: 1.453803 \t time: 0.2\n",
      "Epoch: 507 \tTraining Loss: 1.315666 \tValidation Loss: 1.453981 \t time: 0.2\n",
      "Epoch: 508 \tTraining Loss: 1.317867 \tValidation Loss: 1.453996 \t time: 0.2\n",
      "Epoch: 509 \tTraining Loss: 1.320764 \tValidation Loss: 1.453786 \t time: 0.2\n",
      "Epoch: 510 \tTraining Loss: 1.318025 \tValidation Loss: 1.453616 \t time: 0.2\n",
      "Epoch: 511 \tTraining Loss: 1.316968 \tValidation Loss: 1.453544 \t time: 0.2\n",
      "Epoch: 512 \tTraining Loss: 1.317306 \tValidation Loss: 1.453510 \t time: 0.2\n",
      "Epoch: 513 \tTraining Loss: 1.314061 \tValidation Loss: 1.453678 \t time: 0.2\n",
      "Epoch: 514 \tTraining Loss: 1.318366 \tValidation Loss: 1.453769 \t time: 0.2\n",
      "Epoch: 515 \tTraining Loss: 1.318802 \tValidation Loss: 1.453785 \t time: 0.2\n",
      "Epoch: 516 \tTraining Loss: 1.316994 \tValidation Loss: 1.453764 \t time: 0.2\n",
      "Epoch: 517 \tTraining Loss: 1.317662 \tValidation Loss: 1.453744 \t time: 0.2\n",
      "Epoch: 518 \tTraining Loss: 1.319455 \tValidation Loss: 1.453495 \t time: 0.2\n",
      "Epoch: 519 \tTraining Loss: 1.316935 \tValidation Loss: 1.453364 \t time: 0.2\n",
      "Epoch: 520 \tTraining Loss: 1.317787 \tValidation Loss: 1.453082 \t time: 0.2\n",
      "Epoch: 521 \tTraining Loss: 1.314674 \tValidation Loss: 1.452758 \t time: 0.2\n",
      "Epoch: 522 \tTraining Loss: 1.316698 \tValidation Loss: 1.452558 \t time: 0.2\n",
      "Epoch: 523 \tTraining Loss: 1.316220 \tValidation Loss: 1.452669 \t time: 0.2\n",
      "Epoch: 524 \tTraining Loss: 1.314126 \tValidation Loss: 1.452780 \t time: 0.2\n",
      "Epoch: 525 \tTraining Loss: 1.316944 \tValidation Loss: 1.452885 \t time: 0.2\n",
      "Epoch: 526 \tTraining Loss: 1.318940 \tValidation Loss: 1.452508 \t time: 0.2\n",
      "Epoch: 527 \tTraining Loss: 1.317765 \tValidation Loss: 1.451944 \t time: 0.2\n",
      "Epoch: 528 \tTraining Loss: 1.313025 \tValidation Loss: 1.451436 \t time: 0.2\n",
      "Epoch: 529 \tTraining Loss: 1.316771 \tValidation Loss: 1.451510 \t time: 0.2\n",
      "Epoch: 530 \tTraining Loss: 1.316165 \tValidation Loss: 1.451511 \t time: 0.2\n",
      "Epoch: 531 \tTraining Loss: 1.316480 \tValidation Loss: 1.451795 \t time: 0.2\n",
      "Epoch: 532 \tTraining Loss: 1.317830 \tValidation Loss: 1.452356 \t time: 0.2\n",
      "Epoch: 533 \tTraining Loss: 1.315974 \tValidation Loss: 1.452839 \t time: 0.3\n",
      "Epoch: 534 \tTraining Loss: 1.315852 \tValidation Loss: 1.453323 \t time: 0.2\n",
      "Epoch: 535 \tTraining Loss: 1.311984 \tValidation Loss: 1.453455 \t time: 0.2\n",
      "Epoch: 536 \tTraining Loss: 1.316377 \tValidation Loss: 1.453315 \t time: 0.2\n",
      "Epoch: 537 \tTraining Loss: 1.313161 \tValidation Loss: 1.453118 \t time: 0.2\n",
      "Epoch: 538 \tTraining Loss: 1.315848 \tValidation Loss: 1.452995 \t time: 0.2\n",
      "Epoch: 539 \tTraining Loss: 1.314755 \tValidation Loss: 1.453114 \t time: 0.2\n",
      "Epoch: 540 \tTraining Loss: 1.316161 \tValidation Loss: 1.453335 \t time: 0.2\n",
      "Epoch: 541 \tTraining Loss: 1.317818 \tValidation Loss: 1.453419 \t time: 0.2\n",
      "Epoch: 542 \tTraining Loss: 1.314248 \tValidation Loss: 1.453391 \t time: 0.2\n",
      "Epoch: 543 \tTraining Loss: 1.314843 \tValidation Loss: 1.453331 \t time: 0.2\n",
      "Epoch: 544 \tTraining Loss: 1.311383 \tValidation Loss: 1.453182 \t time: 0.2\n",
      "Epoch: 545 \tTraining Loss: 1.313557 \tValidation Loss: 1.453227 \t time: 0.2\n",
      "Epoch: 546 \tTraining Loss: 1.311078 \tValidation Loss: 1.453332 \t time: 0.2\n",
      "Epoch: 547 \tTraining Loss: 1.309153 \tValidation Loss: 1.453379 \t time: 0.2\n",
      "Epoch: 548 \tTraining Loss: 1.309724 \tValidation Loss: 1.453298 \t time: 0.2\n",
      "Epoch: 549 \tTraining Loss: 1.312397 \tValidation Loss: 1.453391 \t time: 0.2\n",
      "Epoch: 550 \tTraining Loss: 1.313532 \tValidation Loss: 1.453338 \t time: 0.2\n",
      "Epoch: 551 \tTraining Loss: 1.312185 \tValidation Loss: 1.452888 \t time: 0.2\n",
      "Epoch: 552 \tTraining Loss: 1.312050 \tValidation Loss: 1.452591 \t time: 0.2\n",
      "Epoch: 553 \tTraining Loss: 1.311492 \tValidation Loss: 1.452166 \t time: 0.2\n",
      "Epoch: 554 \tTraining Loss: 1.310468 \tValidation Loss: 1.451951 \t time: 0.2\n",
      "Epoch: 555 \tTraining Loss: 1.310925 \tValidation Loss: 1.452207 \t time: 0.2\n",
      "Epoch: 556 \tTraining Loss: 1.310144 \tValidation Loss: 1.452682 \t time: 0.2\n",
      "Epoch: 557 \tTraining Loss: 1.312486 \tValidation Loss: 1.453112 \t time: 0.2\n",
      "Epoch: 558 \tTraining Loss: 1.311593 \tValidation Loss: 1.453066 \t time: 0.2\n",
      "Epoch: 559 \tTraining Loss: 1.309107 \tValidation Loss: 1.452843 \t time: 0.2\n",
      "Epoch: 560 \tTraining Loss: 1.313207 \tValidation Loss: 1.452557 \t time: 0.2\n",
      "Epoch: 561 \tTraining Loss: 1.307994 \tValidation Loss: 1.452369 \t time: 0.2\n",
      "Epoch: 562 \tTraining Loss: 1.309165 \tValidation Loss: 1.452414 \t time: 0.2\n",
      "Epoch: 563 \tTraining Loss: 1.309342 \tValidation Loss: 1.452724 \t time: 0.2\n",
      "Epoch: 564 \tTraining Loss: 1.307825 \tValidation Loss: 1.453279 \t time: 0.2\n",
      "Epoch: 565 \tTraining Loss: 1.309826 \tValidation Loss: 1.453603 \t time: 0.2\n",
      "Epoch: 566 \tTraining Loss: 1.310427 \tValidation Loss: 1.453751 \t time: 0.2\n",
      "Epoch: 567 \tTraining Loss: 1.309404 \tValidation Loss: 1.453934 \t time: 0.2\n",
      "Epoch: 568 \tTraining Loss: 1.309541 \tValidation Loss: 1.454077 \t time: 0.2\n",
      "Epoch: 569 \tTraining Loss: 1.311207 \tValidation Loss: 1.454036 \t time: 0.2\n",
      "Epoch: 570 \tTraining Loss: 1.310258 \tValidation Loss: 1.453896 \t time: 0.2\n",
      "Epoch: 571 \tTraining Loss: 1.311175 \tValidation Loss: 1.453904 \t time: 0.2\n",
      "Epoch: 572 \tTraining Loss: 1.308206 \tValidation Loss: 1.454099 \t time: 0.2\n",
      "Epoch: 573 \tTraining Loss: 1.307584 \tValidation Loss: 1.454112 \t time: 0.2\n",
      "Epoch: 574 \tTraining Loss: 1.308783 \tValidation Loss: 1.454365 \t time: 0.2\n",
      "Epoch: 575 \tTraining Loss: 1.307180 \tValidation Loss: 1.454335 \t time: 0.2\n",
      "Epoch: 576 \tTraining Loss: 1.310495 \tValidation Loss: 1.454111 \t time: 0.2\n",
      "Epoch: 577 \tTraining Loss: 1.308503 \tValidation Loss: 1.453813 \t time: 0.2\n",
      "Epoch: 578 \tTraining Loss: 1.308876 \tValidation Loss: 1.453446 \t time: 0.2\n",
      "Epoch: 579 \tTraining Loss: 1.309946 \tValidation Loss: 1.452987 \t time: 0.2\n",
      "Epoch: 580 \tTraining Loss: 1.309399 \tValidation Loss: 1.452478 \t time: 0.2\n",
      "Epoch: 581 \tTraining Loss: 1.308288 \tValidation Loss: 1.452258 \t time: 0.2\n",
      "Epoch: 582 \tTraining Loss: 1.306430 \tValidation Loss: 1.452285 \t time: 0.2\n",
      "Epoch: 583 \tTraining Loss: 1.306686 \tValidation Loss: 1.452574 \t time: 0.2\n",
      "Epoch: 584 \tTraining Loss: 1.303314 \tValidation Loss: 1.452705 \t time: 0.2\n",
      "Epoch: 585 \tTraining Loss: 1.308050 \tValidation Loss: 1.452567 \t time: 0.2\n",
      "Epoch: 586 \tTraining Loss: 1.309242 \tValidation Loss: 1.452324 \t time: 0.2\n",
      "Epoch: 587 \tTraining Loss: 1.309023 \tValidation Loss: 1.452019 \t time: 0.2\n",
      "Epoch: 588 \tTraining Loss: 1.305989 \tValidation Loss: 1.452063 \t time: 0.3\n",
      "Epoch: 589 \tTraining Loss: 1.308671 \tValidation Loss: 1.452248 \t time: 0.2\n",
      "Epoch: 590 \tTraining Loss: 1.304083 \tValidation Loss: 1.452561 \t time: 0.2\n",
      "Epoch: 591 \tTraining Loss: 1.307171 \tValidation Loss: 1.452905 \t time: 0.2\n",
      "Epoch: 592 \tTraining Loss: 1.306290 \tValidation Loss: 1.453020 \t time: 0.2\n",
      "Epoch: 593 \tTraining Loss: 1.306190 \tValidation Loss: 1.452839 \t time: 0.2\n",
      "Epoch: 594 \tTraining Loss: 1.305413 \tValidation Loss: 1.452646 \t time: 0.2\n",
      "Epoch: 595 \tTraining Loss: 1.307200 \tValidation Loss: 1.452563 \t time: 0.2\n",
      "Epoch: 596 \tTraining Loss: 1.308082 \tValidation Loss: 1.452510 \t time: 0.2\n",
      "Epoch: 597 \tTraining Loss: 1.302804 \tValidation Loss: 1.453032 \t time: 0.2\n",
      "Epoch: 598 \tTraining Loss: 1.302027 \tValidation Loss: 1.453729 \t time: 0.2\n",
      "Epoch: 599 \tTraining Loss: 1.305514 \tValidation Loss: 1.453994 \t time: 0.2\n",
      "Epoch: 600 \tTraining Loss: 1.304913 \tValidation Loss: 1.453729 \t time: 0.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(600, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.432300\n",
      "\n",
      "\n",
      "Test Accuracy: 50% (11/22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 2, 0, 2, 5, 2, 5, 3, 5, 5, 2, 3, 2, 3, 0, 3, 5, 0, 2, 3, 2, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,l = next(iter(loaders['test']))\n",
    "if use_cuda:\n",
    "    i, l = i.cuda(), l.cuda()\n",
    "\n",
    "output = model(i)\n",
    "\n",
    "result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 0., 0., 0., 7., 0., 6., 0., 0., 6.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = result[:,0]\n",
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5., 0., 3., 0., 4., 0., 3., 0., 3., 4.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
