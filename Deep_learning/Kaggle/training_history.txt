Epoch: 1 	Training Loss: 1.793298 	Validation Loss: 1.806818 	 time: 0.3
Validation loss decreased from inf to 1.806818. Model was saved
Epoch: 2 	Training Loss: 1.806925 	Validation Loss: 1.797241 	 time: 0.3
Validation loss decreased from 1.806818 to 1.797241. Model was saved
Epoch: 3 	Training Loss: 1.797394 	Validation Loss: 1.792401 	 time: 0.3
Validation loss decreased from 1.797241 to 1.792401. Model was saved
Epoch: 4 	Training Loss: 1.792525 	Validation Loss: 1.788959 	 time: 0.3
Validation loss decreased from 1.792401 to 1.788959. Model was saved
Epoch: 5 	Training Loss: 1.789291 	Validation Loss: 1.784393 	 time: 0.3
Validation loss decreased from 1.788959 to 1.784393. Model was saved
Epoch: 6 	Training Loss: 1.785117 	Validation Loss: 1.779380 	 time: 0.3
Validation loss decreased from 1.784393 to 1.779380. Model was saved
Epoch: 7 	Training Loss: 1.780378 	Validation Loss: 1.774434 	 time: 0.3
Validation loss decreased from 1.779380 to 1.774434. Model was saved
Epoch: 8 	Training Loss: 1.775574 	Validation Loss: 1.768450 	 time: 0.3
Validation loss decreased from 1.774434 to 1.768450. Model was saved
Epoch: 9 	Training Loss: 1.769864 	Validation Loss: 1.760289 	 time: 0.3
Validation loss decreased from 1.768450 to 1.760289. Model was saved
Epoch: 10 	Training Loss: 1.762244 	Validation Loss: 1.749875 	 time: 0.3
Validation loss decreased from 1.760289 to 1.749875. Model was saved
Epoch: 11 	Training Loss: 1.752538 	Validation Loss: 1.738261 	 time: 0.3
Validation loss decreased from 1.749875 to 1.738261. Model was saved
Epoch: 12 	Training Loss: 1.741564 	Validation Loss: 1.726449 	 time: 0.3
Validation loss decreased from 1.738261 to 1.726449. Model was saved
Epoch: 13 	Training Loss: 1.730110 	Validation Loss: 1.715110 	 time: 0.3
Validation loss decreased from 1.726449 to 1.715110. Model was saved
Epoch: 14 	Training Loss: 1.718806 	Validation Loss: 1.704513 	 time: 0.3
Validation loss decreased from 1.715110 to 1.704513. Model was saved
Epoch: 15 	Training Loss: 1.707962 	Validation Loss: 1.694304 	 time: 0.3
Validation loss decreased from 1.704513 to 1.694304. Model was saved
Epoch: 16 	Training Loss: 1.696963 	Validation Loss: 1.684029 	 time: 0.3
Validation loss decreased from 1.694304 to 1.684029. Model was saved
Epoch: 17 	Training Loss: 1.685432 	Validation Loss: 1.673968 	 time: 0.3
Validation loss decreased from 1.684029 to 1.673968. Model was saved
Epoch: 18 	Training Loss: 1.673607 	Validation Loss: 1.664472 	 time: 0.3
Validation loss decreased from 1.673968 to 1.664472. Model was saved
Epoch: 19 	Training Loss: 1.661813 	Validation Loss: 1.654990 	 time: 0.3
Validation loss decreased from 1.664472 to 1.654990. Model was saved
Epoch: 20 	Training Loss: 1.649940 	Validation Loss: 1.645991 	 time: 0.3
Validation loss decreased from 1.654990 to 1.645991. Model was saved
Epoch: 21 	Training Loss: 1.638349 	Validation Loss: 1.638968 	 time: 0.3
Validation loss decreased from 1.645991 to 1.638968. Model was saved
Epoch: 22 	Training Loss: 1.627927 	Validation Loss: 1.633678 	 time: 0.3
Validation loss decreased from 1.638968 to 1.633678. Model was saved
Epoch: 23 	Training Loss: 1.618459 	Validation Loss: 1.629368 	 time: 0.3
Validation loss decreased from 1.633678 to 1.629368. Model was saved
Epoch: 24 	Training Loss: 1.609141 	Validation Loss: 1.625578 	 time: 0.3
Validation loss decreased from 1.629368 to 1.625578. Model was saved
Epoch: 25 	Training Loss: 1.600733 	Validation Loss: 1.621509 	 time: 0.3
Validation loss decreased from 1.625578 to 1.621509. Model was saved
Epoch: 26 	Training Loss: 1.592536 	Validation Loss: 1.617857 	 time: 0.3
Validation loss decreased from 1.621509 to 1.617857. Model was saved
Epoch: 27 	Training Loss: 1.584927 	Validation Loss: 1.613888 	 time: 0.3
Validation loss decreased from 1.617857 to 1.613888. Model was saved
Epoch: 28 	Training Loss: 1.577836 	Validation Loss: 1.609257 	 time: 0.3
Validation loss decreased from 1.613888 to 1.609257. Model was saved
Epoch: 29 	Training Loss: 1.570976 	Validation Loss: 1.604600 	 time: 0.3
Validation loss decreased from 1.609257 to 1.604600. Model was saved
Epoch: 30 	Training Loss: 1.564397 	Validation Loss: 1.600026 	 time: 0.3
Validation loss decreased from 1.604600 to 1.600026. Model was saved
Epoch: 31 	Training Loss: 1.557905 	Validation Loss: 1.595639 	 time: 0.3
Validation loss decreased from 1.600026 to 1.595639. Model was saved
Epoch: 32 	Training Loss: 1.551566 	Validation Loss: 1.591364 	 time: 0.3
Validation loss decreased from 1.595639 to 1.591364. Model was saved
Epoch: 33 	Training Loss: 1.545639 	Validation Loss: 1.586459 	 time: 0.3
Validation loss decreased from 1.591364 to 1.586459. Model was saved
Epoch: 34 	Training Loss: 1.539986 	Validation Loss: 1.581600 	 time: 0.3
Validation loss decreased from 1.586459 to 1.581600. Model was saved
Epoch: 35 	Training Loss: 1.534683 	Validation Loss: 1.576683 	 time: 0.3
Validation loss decreased from 1.581600 to 1.576683. Model was saved
Epoch: 36 	Training Loss: 1.529419 	Validation Loss: 1.571563 	 time: 0.3
Validation loss decreased from 1.576683 to 1.571563. Model was saved
Epoch: 37 	Training Loss: 1.524355 	Validation Loss: 1.566966 	 time: 0.3
Validation loss decreased from 1.571563 to 1.566966. Model was saved
Epoch: 38 	Training Loss: 1.519372 	Validation Loss: 1.562844 	 time: 0.3
Validation loss decreased from 1.566966 to 1.562844. Model was saved
Epoch: 39 	Training Loss: 1.514520 	Validation Loss: 1.558033 	 time: 0.3
Validation loss decreased from 1.562844 to 1.558033. Model was saved
Epoch: 40 	Training Loss: 1.509555 	Validation Loss: 1.553613 	 time: 0.3
Validation loss decreased from 1.558033 to 1.553613. Model was saved
Epoch: 41 	Training Loss: 1.504688 	Validation Loss: 1.550291 	 time: 0.3
Validation loss decreased from 1.553613 to 1.550291. Model was saved
Epoch: 42 	Training Loss: 1.499849 	Validation Loss: 1.547558 	 time: 0.3
Validation loss decreased from 1.550291 to 1.547558. Model was saved
Epoch: 43 	Training Loss: 1.495263 	Validation Loss: 1.545056 	 time: 0.3
Validation loss decreased from 1.547558 to 1.545056. Model was saved
Epoch: 44 	Training Loss: 1.490928 	Validation Loss: 1.542401 	 time: 0.3
Validation loss decreased from 1.545056 to 1.542401. Model was saved
Epoch: 45 	Training Loss: 1.486927 	Validation Loss: 1.539436 	 time: 0.3
Validation loss decreased from 1.542401 to 1.539436. Model was saved
Epoch: 46 	Training Loss: 1.483183 	Validation Loss: 1.536796 	 time: 0.3
Validation loss decreased from 1.539436 to 1.536796. Model was saved
Epoch: 47 	Training Loss: 1.479467 	Validation Loss: 1.534075 	 time: 0.3
Validation loss decreased from 1.536796 to 1.534075. Model was saved
Epoch: 48 	Training Loss: 1.475849 	Validation Loss: 1.530594 	 time: 0.3
Validation loss decreased from 1.534075 to 1.530594. Model was saved
Epoch: 49 	Training Loss: 1.472189 	Validation Loss: 1.527507 	 time: 0.3
Validation loss decreased from 1.530594 to 1.527507. Model was saved
Epoch: 50 	Training Loss: 1.468780 	Validation Loss: 1.525455 	 time: 0.3
Validation loss decreased from 1.527507 to 1.525455. Model was saved
Epoch: 51 	Training Loss: 1.465593 	Validation Loss: 1.524075 	 time: 0.3
Validation loss decreased from 1.525455 to 1.524075. Model was saved
Epoch: 52 	Training Loss: 1.462586 	Validation Loss: 1.523055 	 time: 0.3
Validation loss decreased from 1.524075 to 1.523055. Model was saved
Epoch: 53 	Training Loss: 1.459779 	Validation Loss: 1.522720 	 time: 0.3
Validation loss decreased from 1.523055 to 1.522720. Model was saved
Epoch: 54 	Training Loss: 1.457142 	Validation Loss: 1.522932 	 time: 0.3
Epoch: 55 	Training Loss: 1.454669 	Validation Loss: 1.522270 	 time: 0.3
Validation loss decreased from 1.522720 to 1.522270. Model was saved
Epoch: 56 	Training Loss: 1.452274 	Validation Loss: 1.521766 	 time: 0.3
Validation loss decreased from 1.522270 to 1.521766. Model was saved
Epoch: 57 	Training Loss: 1.450000 	Validation Loss: 1.521354 	 time: 0.3
Validation loss decreased from 1.521766 to 1.521354. Model was saved
Epoch: 58 	Training Loss: 1.447852 	Validation Loss: 1.519704 	 time: 0.3
Validation loss decreased from 1.521354 to 1.519704. Model was saved
Epoch: 59 	Training Loss: 1.445769 	Validation Loss: 1.518902 	 time: 0.3
Validation loss decreased from 1.519704 to 1.518902. Model was saved
Epoch: 60 	Training Loss: 1.443778 	Validation Loss: 1.517728 	 time: 0.3
Validation loss decreased from 1.518902 to 1.517728. Model was saved
Epoch: 61 	Training Loss: 1.441865 	Validation Loss: 1.517345 	 time: 0.3
Validation loss decreased from 1.517728 to 1.517345. Model was saved
Epoch: 62 	Training Loss: 1.440057 	Validation Loss: 1.516697 	 time: 0.3
Validation loss decreased from 1.517345 to 1.516697. Model was saved
Epoch: 63 	Training Loss: 1.438381 	Validation Loss: 1.516868 	 time: 0.3
Epoch: 64 	Training Loss: 1.436778 	Validation Loss: 1.516265 	 time: 0.3
Validation loss decreased from 1.516697 to 1.516265. Model was saved
Epoch: 65 	Training Loss: 1.435245 	Validation Loss: 1.516859 	 time: 0.3
Epoch: 66 	Training Loss: 1.433775 	Validation Loss: 1.515485 	 time: 0.3
Validation loss decreased from 1.516265 to 1.515485. Model was saved
Epoch: 67 	Training Loss: 1.432377 	Validation Loss: 1.516670 	 time: 0.3
Epoch: 68 	Training Loss: 1.430879 	Validation Loss: 1.515475 	 time: 0.3
Validation loss decreased from 1.515485 to 1.515475. Model was saved
Epoch: 69 	Training Loss: 1.429338 	Validation Loss: 1.514949 	 time: 0.3
Validation loss decreased from 1.515475 to 1.514949. Model was saved
Epoch: 70 	Training Loss: 1.427993 	Validation Loss: 1.515731 	 time: 0.3
Epoch: 71 	Training Loss: 1.426780 	Validation Loss: 1.513711 	 time: 0.3
Validation loss decreased from 1.514949 to 1.513711. Model was saved
Epoch: 72 	Training Loss: 1.425517 	Validation Loss: 1.514286 	 time: 0.3
Epoch: 73 	Training Loss: 1.424183 	Validation Loss: 1.513175 	 time: 0.3
Validation loss decreased from 1.513711 to 1.513175. Model was saved
Epoch: 74 	Training Loss: 1.422901 	Validation Loss: 1.512245 	 time: 0.3
Validation loss decreased from 1.513175 to 1.512245. Model was saved
Epoch: 75 	Training Loss: 1.421707 	Validation Loss: 1.512525 	 time: 0.3
Epoch: 76 	Training Loss: 1.420569 	Validation Loss: 1.510956 	 time: 0.3
Validation loss decreased from 1.512245 to 1.510956. Model was saved
Epoch: 77 	Training Loss: 1.419417 	Validation Loss: 1.511297 	 time: 0.3
Epoch: 78 	Training Loss: 1.418213 	Validation Loss: 1.510275 	 time: 0.3
Validation loss decreased from 1.510956 to 1.510275. Model was saved
Epoch: 79 	Training Loss: 1.417026 	Validation Loss: 1.510124 	 time: 0.3
Validation loss decreased from 1.510275 to 1.510124. Model was saved
Epoch: 80 	Training Loss: 1.415903 	Validation Loss: 1.510094 	 time: 0.3
Validation loss decreased from 1.510124 to 1.510094. Model was saved
Epoch: 81 	Training Loss: 1.414847 	Validation Loss: 1.509667 	 time: 0.3
Validation loss decreased from 1.510094 to 1.509667. Model was saved
Epoch: 82 	Training Loss: 1.413838 	Validation Loss: 1.510179 	 time: 0.3
Epoch: 83 	Training Loss: 1.412848 	Validation Loss: 1.509367 	 time: 0.3
Validation loss decreased from 1.509667 to 1.509367. Model was saved
Epoch: 84 	Training Loss: 1.411847 	Validation Loss: 1.509738 	 time: 0.3
Epoch: 85 	Training Loss: 1.410824 	Validation Loss: 1.508475 	 time: 0.3
Validation loss decreased from 1.509367 to 1.508475. Model was saved
Epoch: 86 	Training Loss: 1.409790 	Validation Loss: 1.508408 	 time: 0.3
Validation loss decreased from 1.508475 to 1.508408. Model was saved
Epoch: 87 	Training Loss: 1.408743 	Validation Loss: 1.506915 	 time: 0.3
Validation loss decreased from 1.508408 to 1.506915. Model was saved
Epoch: 88 	Training Loss: 1.407678 	Validation Loss: 1.506507 	 time: 0.3
Validation loss decreased from 1.506915 to 1.506507. Model was saved
Epoch: 89 	Training Loss: 1.406610 	Validation Loss: 1.505096 	 time: 0.3
Validation loss decreased from 1.506507 to 1.505096. Model was saved
Epoch: 90 	Training Loss: 1.405565 	Validation Loss: 1.504818 	 time: 0.3
Validation loss decreased from 1.505096 to 1.504818. Model was saved
Epoch: 91 	Training Loss: 1.404535 	Validation Loss: 1.503731 	 time: 0.3
Validation loss decreased from 1.504818 to 1.503731. Model was saved
Epoch: 92 	Training Loss: 1.403510 	Validation Loss: 1.503360 	 time: 0.3
Validation loss decreased from 1.503731 to 1.503360. Model was saved
Epoch: 93 	Training Loss: 1.402488 	Validation Loss: 1.502731 	 time: 0.3
Validation loss decreased from 1.503360 to 1.502731. Model was saved
Epoch: 94 	Training Loss: 1.401469 	Validation Loss: 1.501688 	 time: 0.3
Validation loss decreased from 1.502731 to 1.501688. Model was saved
Epoch: 95 	Training Loss: 1.400452 	Validation Loss: 1.501383 	 time: 0.3
Validation loss decreased from 1.501688 to 1.501383. Model was saved
Epoch: 96 	Training Loss: 1.399442 	Validation Loss: 1.499520 	 time: 0.3
Validation loss decreased from 1.501383 to 1.499520. Model was saved
Epoch: 97 	Training Loss: 1.398443 	Validation Loss: 1.499752 	 time: 0.3
Epoch: 98 	Training Loss: 1.397469 	Validation Loss: 1.497058 	 time: 0.3
Validation loss decreased from 1.499520 to 1.497058. Model was saved
Epoch: 99 	Training Loss: 1.396567 	Validation Loss: 1.498227 	 time: 0.3
Epoch: 100 	Training Loss: 1.395654 	Validation Loss: 1.495154 	 time: 0.3
Validation loss decreased from 1.497058 to 1.495154. Model was saved
Epoch: 101 	Training Loss: 1.394483 	Validation Loss: 1.494537 	 time: 0.3
Validation loss decreased from 1.495154 to 1.494537. Model was saved
Epoch: 102 	Training Loss: 1.393339 	Validation Loss: 1.494385 	 time: 0.3
Validation loss decreased from 1.494537 to 1.494385. Model was saved
Epoch: 103 	Training Loss: 1.392469 	Validation Loss: 1.491493 	 time: 0.3
Validation loss decreased from 1.494385 to 1.491493. Model was saved
Epoch: 104 	Training Loss: 1.391607 	Validation Loss: 1.492193 	 time: 0.3
Epoch: 105 	Training Loss: 1.390488 	Validation Loss: 1.490145 	 time: 0.3
Validation loss decreased from 1.491493 to 1.490145. Model was saved
Epoch: 106 	Training Loss: 1.389359 	Validation Loss: 1.488885 	 time: 0.3
Validation loss decreased from 1.490145 to 1.488885. Model was saved
Epoch: 107 	Training Loss: 1.388397 	Validation Loss: 1.489668 	 time: 0.3
Epoch: 108 	Training Loss: 1.387518 	Validation Loss: 1.486306 	 time: 0.3
Validation loss decreased from 1.488885 to 1.486306. Model was saved
Epoch: 109 	Training Loss: 1.386585 	Validation Loss: 1.488001 	 time: 0.3
Epoch: 110 	Training Loss: 1.385541 	Validation Loss: 1.484756 	 time: 0.3
Validation loss decreased from 1.486306 to 1.484756. Model was saved
Epoch: 111 	Training Loss: 1.384473 	Validation Loss: 1.485372 	 time: 0.3
Epoch: 112 	Training Loss: 1.383439 	Validation Loss: 1.484272 	 time: 0.3
Validation loss decreased from 1.484756 to 1.484272. Model was saved
Epoch: 113 	Training Loss: 1.382465 	Validation Loss: 1.482861 	 time: 0.3
Validation loss decreased from 1.484272 to 1.482861. Model was saved
Epoch: 114 	Training Loss: 1.381533 	Validation Loss: 1.483962 	 time: 0.3
Epoch: 115 	Training Loss: 1.380622 	Validation Loss: 1.480340 	 time: 0.3
Validation loss decreased from 1.482861 to 1.480340. Model was saved
Epoch: 116 	Training Loss: 1.379749 	Validation Loss: 1.483457 	 time: 0.3
Epoch: 117 	Training Loss: 1.378857 	Validation Loss: 1.478930 	 time: 0.3
Validation loss decreased from 1.480340 to 1.478930. Model was saved
Epoch: 118 	Training Loss: 1.377885 	Validation Loss: 1.481531 	 time: 0.3
Epoch: 119 	Training Loss: 1.376843 	Validation Loss: 1.479614 	 time: 0.3
Epoch: 120 	Training Loss: 1.375837 	Validation Loss: 1.479516 	 time: 0.3
Epoch: 121 	Training Loss: 1.374846 	Validation Loss: 1.479749 	 time: 0.3
Epoch: 122 	Training Loss: 1.373858 	Validation Loss: 1.478315 	 time: 0.3
Validation loss decreased from 1.478930 to 1.478315. Model was saved
Epoch: 123 	Training Loss: 1.372921 	Validation Loss: 1.478958 	 time: 0.3
Epoch: 124 	Training Loss: 1.372046 	Validation Loss: 1.477172 	 time: 0.3
Validation loss decreased from 1.478315 to 1.477172. Model was saved
Epoch: 125 	Training Loss: 1.371189 	Validation Loss: 1.479339 	 time: 0.3
Epoch: 126 	Training Loss: 1.370351 	Validation Loss: 1.474918 	 time: 0.3
Validation loss decreased from 1.477172 to 1.474918. Model was saved
Epoch: 127 	Training Loss: 1.369574 	Validation Loss: 1.480066 	 time: 0.3
Epoch: 128 	Training Loss: 1.368661 	Validation Loss: 1.474251 	 time: 0.3
Validation loss decreased from 1.474918 to 1.474251. Model was saved
Epoch: 129 	Training Loss: 1.367530 	Validation Loss: 1.475532 	 time: 0.3
Epoch: 130 	Training Loss: 1.366462 	Validation Loss: 1.477126 	 time: 0.3
Epoch: 131 	Training Loss: 1.365766 	Validation Loss: 1.471919 	 time: 0.3
Validation loss decreased from 1.474251 to 1.471919. Model was saved
Epoch: 132 	Training Loss: 1.365109 	Validation Loss: 1.476335 	 time: 0.3
Epoch: 133 	Training Loss: 1.364087 	Validation Loss: 1.472744 	 time: 0.3
Epoch: 134 	Training Loss: 1.363029 	Validation Loss: 1.472324 	 time: 0.3
Epoch: 135 	Training Loss: 1.362057 	Validation Loss: 1.473298 	 time: 0.3
Epoch: 136 	Training Loss: 1.361190 	Validation Loss: 1.470179 	 time: 0.3
Validation loss decreased from 1.471919 to 1.470179. Model was saved
Epoch: 137 	Training Loss: 1.360442 	Validation Loss: 1.472454 	 time: 0.3
Epoch: 138 	Training Loss: 1.359673 	Validation Loss: 1.468265 	 time: 0.3
Validation loss decreased from 1.470179 to 1.468265. Model was saved
Epoch: 139 	Training Loss: 1.358793 	Validation Loss: 1.471230 	 time: 0.3
Epoch: 140 	Training Loss: 1.357848 	Validation Loss: 1.466221 	 time: 0.3
Validation loss decreased from 1.468265 to 1.466221. Model was saved
Epoch: 141 	Training Loss: 1.356968 	Validation Loss: 1.469154 	 time: 0.3
Epoch: 142 	Training Loss: 1.356046 	Validation Loss: 1.464953 	 time: 0.3
Validation loss decreased from 1.466221 to 1.464953. Model was saved
Epoch: 143 	Training Loss: 1.355132 	Validation Loss: 1.466838 	 time: 0.3
Epoch: 144 	Training Loss: 1.354275 	Validation Loss: 1.463596 	 time: 0.3
Validation loss decreased from 1.464953 to 1.463596. Model was saved
Epoch: 145 	Training Loss: 1.353464 	Validation Loss: 1.465746 	 time: 0.3
Epoch: 146 	Training Loss: 1.352663 	Validation Loss: 1.461054 	 time: 0.3
Validation loss decreased from 1.463596 to 1.461054. Model was saved
Epoch: 147 	Training Loss: 1.352011 	Validation Loss: 1.466544 	 time: 0.3
Epoch: 148 	Training Loss: 1.351537 	Validation Loss: 1.459385 	 time: 0.3
Validation loss decreased from 1.461054 to 1.459385. Model was saved
Epoch: 149 	Training Loss: 1.350505 	Validation Loss: 1.461199 	 time: 0.3
Epoch: 150 	Training Loss: 1.349219 	Validation Loss: 1.462692 	 time: 0.3
Epoch: 151 	Training Loss: 1.348703 	Validation Loss: 1.457277 	 time: 0.3
Validation loss decreased from 1.459385 to 1.457277. Model was saved
Epoch: 152 	Training Loss: 1.348169 	Validation Loss: 1.460327 	 time: 0.3
Epoch: 153 	Training Loss: 1.347133 	Validation Loss: 1.458106 	 time: 0.3
Epoch: 154 	Training Loss: 1.346111 	Validation Loss: 1.455465 	 time: 0.3
Validation loss decreased from 1.457277 to 1.455465. Model was saved
Epoch: 155 	Training Loss: 1.345387 	Validation Loss: 1.457782 	 time: 0.3
Epoch: 156 	Training Loss: 1.344815 	Validation Loss: 1.454144 	 time: 0.3
Validation loss decreased from 1.455465 to 1.454144. Model was saved
Epoch: 157 	Training Loss: 1.343927 	Validation Loss: 1.454545 	 time: 0.3
Epoch: 158 	Training Loss: 1.342807 	Validation Loss: 1.453850 	 time: 0.3
Validation loss decreased from 1.454144 to 1.453850. Model was saved
Epoch: 159 	Training Loss: 1.342057 	Validation Loss: 1.452256 	 time: 0.3
Validation loss decreased from 1.453850 to 1.452256. Model was saved
Epoch: 160 	Training Loss: 1.341424 	Validation Loss: 1.454028 	 time: 0.3
Epoch: 161 	Training Loss: 1.340571 	Validation Loss: 1.450552 	 time: 0.3
Validation loss decreased from 1.452256 to 1.450552. Model was saved
Epoch: 162 	Training Loss: 1.339755 	Validation Loss: 1.453425 	 time: 0.3
Epoch: 163 	Training Loss: 1.338942 	Validation Loss: 1.450104 	 time: 0.3
Validation loss decreased from 1.450552 to 1.450104. Model was saved
Epoch: 164 	Training Loss: 1.338012 	Validation Loss: 1.450960 	 time: 0.3
Epoch: 165 	Training Loss: 1.337142 	Validation Loss: 1.450346 	 time: 0.3
Epoch: 166 	Training Loss: 1.336404 	Validation Loss: 1.448961 	 time: 0.3
Validation loss decreased from 1.450104 to 1.448961. Model was saved
Epoch: 167 	Training Loss: 1.335627 	Validation Loss: 1.449369 	 time: 0.3
Epoch: 168 	Training Loss: 1.334849 	Validation Loss: 1.447574 	 time: 0.3
Validation loss decreased from 1.448961 to 1.447574. Model was saved
Epoch: 169 	Training Loss: 1.334176 	Validation Loss: 1.448590 	 time: 0.3
Epoch: 170 	Training Loss: 1.333518 	Validation Loss: 1.445494 	 time: 0.3
Validation loss decreased from 1.447574 to 1.445494. Model was saved
Epoch: 171 	Training Loss: 1.332924 	Validation Loss: 1.449460 	 time: 0.3
Epoch: 172 	Training Loss: 1.332521 	Validation Loss: 1.443859 	 time: 0.3
Validation loss decreased from 1.445494 to 1.443859. Model was saved
Epoch: 173 	Training Loss: 1.332112 	Validation Loss: 1.447413 	 time: 0.3
Epoch: 174 	Training Loss: 1.330736 	Validation Loss: 1.445839 	 time: 0.3
Epoch: 175 	Training Loss: 1.329743 	Validation Loss: 1.443862 	 time: 0.3
Epoch: 176 	Training Loss: 1.329333 	Validation Loss: 1.447593 	 time: 0.3
Epoch: 177 	Training Loss: 1.328867 	Validation Loss: 1.443985 	 time: 0.3
Epoch: 178 	Training Loss: 1.328027 	Validation Loss: 1.444772 	 time: 0.3
Epoch: 179 	Training Loss: 1.326880 	Validation Loss: 1.445167 	 time: 0.3
Epoch: 180 	Training Loss: 1.326340 	Validation Loss: 1.442754 	 time: 0.3
Validation loss decreased from 1.443859 to 1.442754. Model was saved
Epoch: 181 	Training Loss: 1.325975 	Validation Loss: 1.445300 	 time: 0.3
Epoch: 182 	Training Loss: 1.325136 	Validation Loss: 1.442180 	 time: 0.3
Validation loss decreased from 1.442754 to 1.442180. Model was saved
Epoch: 183 	Training Loss: 1.324255 	Validation Loss: 1.442585 	 time: 0.3
Epoch: 184 	Training Loss: 1.323414 	Validation Loss: 1.442862 	 time: 0.3
Epoch: 185 	Training Loss: 1.322770 	Validation Loss: 1.440715 	 time: 0.3
Validation loss decreased from 1.442180 to 1.440715. Model was saved
Epoch: 186 	Training Loss: 1.322313 	Validation Loss: 1.442938 	 time: 0.3
Epoch: 187 	Training Loss: 1.321695 	Validation Loss: 1.439565 	 time: 0.3
Validation loss decreased from 1.440715 to 1.439565. Model was saved
Epoch: 188 	Training Loss: 1.320924 	Validation Loss: 1.441122 	 time: 0.3
Epoch: 189 	Training Loss: 1.320144 	Validation Loss: 1.439020 	 time: 0.3
Validation loss decreased from 1.439565 to 1.439020. Model was saved
Epoch: 190 	Training Loss: 1.319383 	Validation Loss: 1.438419 	 time: 0.3
Validation loss decreased from 1.439020 to 1.438419. Model was saved
Epoch: 191 	Training Loss: 1.318714 	Validation Loss: 1.439057 	 time: 0.3
Epoch: 192 	Training Loss: 1.318161 	Validation Loss: 1.436500 	 time: 0.3
Validation loss decreased from 1.438419 to 1.436500. Model was saved
Epoch: 193 	Training Loss: 1.317600 	Validation Loss: 1.438097 	 time: 0.3
Epoch: 194 	Training Loss: 1.317014 	Validation Loss: 1.434843 	 time: 0.3
Validation loss decreased from 1.436500 to 1.434843. Model was saved
Epoch: 195 	Training Loss: 1.316458 	Validation Loss: 1.436818 	 time: 0.3
Epoch: 196 	Training Loss: 1.315861 	Validation Loss: 1.433477 	 time: 0.3
Validation loss decreased from 1.434843 to 1.433477. Model was saved
Epoch: 197 	Training Loss: 1.315312 	Validation Loss: 1.436598 	 time: 0.3
Epoch: 198 	Training Loss: 1.314774 	Validation Loss: 1.432582 	 time: 0.3
Validation loss decreased from 1.433477 to 1.432582. Model was saved
Epoch: 199 	Training Loss: 1.314369 	Validation Loss: 1.435990 	 time: 0.3
Epoch: 200 	Training Loss: 1.313735 	Validation Loss: 1.431829 	 time: 0.3
Validation loss decreased from 1.432582 to 1.431829. Model was saved
Epoch: 201 	Training Loss: 1.312840 	Validation Loss: 1.433287 	 time: 0.3
Epoch: 202 	Training Loss: 1.311780 	Validation Loss: 1.432005 	 time: 0.3
Epoch: 203 	Training Loss: 1.310979 	Validation Loss: 1.431480 	 time: 0.3
Validation loss decreased from 1.431829 to 1.431480. Model was saved
Epoch: 204 	Training Loss: 1.310466 	Validation Loss: 1.433379 	 time: 0.3
Epoch: 205 	Training Loss: 1.310119 	Validation Loss: 1.430376 	 time: 0.3
Validation loss decreased from 1.431480 to 1.430376. Model was saved
Epoch: 206 	Training Loss: 1.309885 	Validation Loss: 1.434321 	 time: 0.3
Epoch: 207 	Training Loss: 1.309468 	Validation Loss: 1.429765 	 time: 0.3
Validation loss decreased from 1.430376 to 1.429765. Model was saved
Epoch: 208 	Training Loss: 1.308825 	Validation Loss: 1.431465 	 time: 0.3
Epoch: 209 	Training Loss: 1.307697 	Validation Loss: 1.429827 	 time: 0.3
Epoch: 210 	Training Loss: 1.306731 	Validation Loss: 1.429178 	 time: 0.3
Validation loss decreased from 1.429765 to 1.429178. Model was saved
Epoch: 211 	Training Loss: 1.306199 	Validation Loss: 1.430783 	 time: 0.3
Epoch: 212 	Training Loss: 1.305958 	Validation Loss: 1.428233 	 time: 0.3
Validation loss decreased from 1.429178 to 1.428233. Model was saved
Epoch: 213 	Training Loss: 1.305677 	Validation Loss: 1.430534 	 time: 0.3
Epoch: 214 	Training Loss: 1.304989 	Validation Loss: 1.426324 	 time: 0.3
Validation loss decreased from 1.428233 to 1.426324. Model was saved
Epoch: 215 	Training Loss: 1.304210 	Validation Loss: 1.427351 	 time: 0.3
Epoch: 216 	Training Loss: 1.303266 	Validation Loss: 1.425705 	 time: 0.3
Validation loss decreased from 1.426324 to 1.425705. Model was saved
Epoch: 217 	Training Loss: 1.302474 	Validation Loss: 1.424622 	 time: 0.3
Validation loss decreased from 1.425705 to 1.424622. Model was saved
Epoch: 218 	Training Loss: 1.301908 	Validation Loss: 1.425645 	 time: 0.3
Epoch: 219 	Training Loss: 1.301469 	Validation Loss: 1.423326 	 time: 0.3
Validation loss decreased from 1.424622 to 1.423326. Model was saved
Epoch: 220 	Training Loss: 1.301152 	Validation Loss: 1.425081 	 time: 0.3
Epoch: 221 	Training Loss: 1.300828 	Validation Loss: 1.421463 	 time: 0.3
Validation loss decreased from 1.423326 to 1.421463. Model was saved
Epoch: 222 	Training Loss: 1.300635 	Validation Loss: 1.423767 	 time: 0.3
Epoch: 223 	Training Loss: 1.299654 	Validation Loss: 1.419907 	 time: 0.3
Validation loss decreased from 1.421463 to 1.419907. Model was saved
Epoch: 224 	Training Loss: 1.298378 	Validation Loss: 1.419554 	 time: 0.3
Validation loss decreased from 1.419907 to 1.419554. Model was saved
Epoch: 225 	Training Loss: 1.297591 	Validation Loss: 1.421575 	 time: 0.3
Epoch: 226 	Training Loss: 1.297409 	Validation Loss: 1.418472 	 time: 0.3
Validation loss decreased from 1.419554 to 1.418472. Model was saved
Epoch: 227 	Training Loss: 1.297323 	Validation Loss: 1.420714 	 time: 0.3
Epoch: 228 	Training Loss: 1.296563 	Validation Loss: 1.416894 	 time: 0.3
Validation loss decreased from 1.418472 to 1.416894. Model was saved
Epoch: 229 	Training Loss: 1.295573 	Validation Loss: 1.417671 	 time: 0.3
Epoch: 230 	Training Loss: 1.294622 	Validation Loss: 1.417175 	 time: 0.3
Epoch: 231 	Training Loss: 1.294041 	Validation Loss: 1.415494 	 time: 0.3
Validation loss decreased from 1.416894 to 1.415494. Model was saved
Epoch: 232 	Training Loss: 1.293733 	Validation Loss: 1.417998 	 time: 0.3
Epoch: 233 	Training Loss: 1.293373 	Validation Loss: 1.414160 	 time: 0.3
Validation loss decreased from 1.415494 to 1.414160. Model was saved
Epoch: 234 	Training Loss: 1.292888 	Validation Loss: 1.416306 	 time: 0.3
Epoch: 235 	Training Loss: 1.292066 	Validation Loss: 1.413148 	 time: 0.3
Validation loss decreased from 1.414160 to 1.413148. Model was saved
Epoch: 236 	Training Loss: 1.291241 	Validation Loss: 1.413628 	 time: 0.3
Epoch: 237 	Training Loss: 1.290443 	Validation Loss: 1.412681 	 time: 0.3
Validation loss decreased from 1.413148 to 1.412681. Model was saved
Epoch: 238 	Training Loss: 1.289756 	Validation Loss: 1.411694 	 time: 0.3
Validation loss decreased from 1.412681 to 1.411694. Model was saved
Epoch: 239 	Training Loss: 1.289197 	Validation Loss: 1.412698 	 time: 0.3
Epoch: 240 	Training Loss: 1.288718 	Validation Loss: 1.410530 	 time: 0.3
Validation loss decreased from 1.411694 to 1.410530. Model was saved
Epoch: 241 	Training Loss: 1.288305 	Validation Loss: 1.413240 	 time: 0.3
Epoch: 242 	Training Loss: 1.287929 	Validation Loss: 1.409419 	 time: 0.3
Validation loss decreased from 1.410530 to 1.409419. Model was saved
Epoch: 243 	Training Loss: 1.287814 	Validation Loss: 1.413029 	 time: 0.3
Epoch: 244 	Training Loss: 1.287274 	Validation Loss: 1.408504 	 time: 0.3
Validation loss decreased from 1.409419 to 1.408504. Model was saved
Epoch: 245 	Training Loss: 1.286208 	Validation Loss: 1.409322 	 time: 0.3
Epoch: 246 	Training Loss: 1.284841 	Validation Loss: 1.409654 	 time: 0.3
Epoch: 247 	Training Loss: 1.284311 	Validation Loss: 1.407255 	 time: 0.3
Validation loss decreased from 1.408504 to 1.407255. Model was saved
Epoch: 248 	Training Loss: 1.284366 	Validation Loss: 1.410170 	 time: 0.3
Epoch: 249 	Training Loss: 1.284036 	Validation Loss: 1.406136 	 time: 0.3
Validation loss decreased from 1.407255 to 1.406136. Model was saved
Epoch: 250 	Training Loss: 1.283234 	Validation Loss: 1.407877 	 time: 0.3
Epoch: 251 	Training Loss: 1.282082 	Validation Loss: 1.406239 	 time: 0.3
Epoch: 252 	Training Loss: 1.281259 	Validation Loss: 1.405592 	 time: 0.3
Validation loss decreased from 1.406136 to 1.405592. Model was saved
Epoch: 253 	Training Loss: 1.280888 	Validation Loss: 1.408001 	 time: 0.3
Epoch: 254 	Training Loss: 1.280729 	Validation Loss: 1.404601 	 time: 0.3
Validation loss decreased from 1.405592 to 1.404601. Model was saved
Epoch: 255 	Training Loss: 1.280578 	Validation Loss: 1.408051 	 time: 0.3
Epoch: 256 	Training Loss: 1.280012 	Validation Loss: 1.404012 	 time: 0.3
Validation loss decreased from 1.404601 to 1.404012. Model was saved
Epoch: 257 	Training Loss: 1.279359 	Validation Loss: 1.406148 	 time: 0.3
Epoch: 258 	Training Loss: 1.278507 	Validation Loss: 1.403803 	 time: 0.3
Validation loss decreased from 1.404012 to 1.403803. Model was saved
Epoch: 259 	Training Loss: 1.277725 	Validation Loss: 1.403905 	 time: 0.3
Epoch: 260 	Training Loss: 1.277093 	Validation Loss: 1.404669 	 time: 0.3
Epoch: 261 	Training Loss: 1.276653 	Validation Loss: 1.403208 	 time: 0.3
Validation loss decreased from 1.403803 to 1.403208. Model was saved
Epoch: 262 	Training Loss: 1.276361 	Validation Loss: 1.405388 	 time: 0.3
Epoch: 263 	Training Loss: 1.276121 	Validation Loss: 1.402565 	 time: 0.3
Validation loss decreased from 1.403208 to 1.402565. Model was saved
Epoch: 264 	Training Loss: 1.276017 	Validation Loss: 1.406245 	 time: 0.3
Epoch: 265 	Training Loss: 1.275824 	Validation Loss: 1.401548 	 time: 0.3
Validation loss decreased from 1.402565 to 1.401548. Model was saved
Epoch: 266 	Training Loss: 1.275594 	Validation Loss: 1.405427 	 time: 0.3
Epoch: 267 	Training Loss: 1.274469 	Validation Loss: 1.401285 	 time: 0.3
Validation loss decreased from 1.401548 to 1.401285. Model was saved
Epoch: 268 	Training Loss: 1.273421 	Validation Loss: 1.401498 	 time: 0.3
Epoch: 269 	Training Loss: 1.272757 	Validation Loss: 1.402850 	 time: 0.3
Epoch: 270 	Training Loss: 1.272571 	Validation Loss: 1.400059 	 time: 0.3
Validation loss decreased from 1.401285 to 1.400059. Model was saved
Epoch: 271 	Training Loss: 1.272580 	Validation Loss: 1.402927 	 time: 0.3
Epoch: 272 	Training Loss: 1.272303 	Validation Loss: 1.399720 	 time: 0.3
Validation loss decreased from 1.400059 to 1.399720. Model was saved
Epoch: 273 	Training Loss: 1.271807 	Validation Loss: 1.401365 	 time: 0.3
Epoch: 274 	Training Loss: 1.271004 	Validation Loss: 1.399861 	 time: 0.3
Epoch: 275 	Training Loss: 1.270250 	Validation Loss: 1.399979 	 time: 0.3
Epoch: 276 	Training Loss: 1.269695 	Validation Loss: 1.400440 	 time: 0.3
Epoch: 277 	Training Loss: 1.269385 	Validation Loss: 1.399562 	 time: 0.3
Validation loss decreased from 1.399720 to 1.399562. Model was saved
Epoch: 278 	Training Loss: 1.269208 	Validation Loss: 1.400979 	 time: 0.3
Epoch: 279 	Training Loss: 1.269038 	Validation Loss: 1.399310 	 time: 0.3
Validation loss decreased from 1.399562 to 1.399310. Model was saved
Epoch: 280 	Training Loss: 1.268933 	Validation Loss: 1.402121 	 time: 0.3
Epoch: 281 	Training Loss: 1.268712 	Validation Loss: 1.398747 	 time: 0.3
Validation loss decreased from 1.399310 to 1.398747. Model was saved
Epoch: 282 	Training Loss: 1.268762 	Validation Loss: 1.401246 	 time: 0.3
Epoch: 283 	Training Loss: 1.267694 	Validation Loss: 1.398503 	 time: 0.3
Validation loss decreased from 1.398747 to 1.398503. Model was saved
Epoch: 284 	Training Loss: 1.266613 	Validation Loss: 1.398450 	 time: 0.3
Validation loss decreased from 1.398503 to 1.398450. Model was saved
Epoch: 285 	Training Loss: 1.265907 	Validation Loss: 1.399577 	 time: 0.3
Epoch: 286 	Training Loss: 1.265823 	Validation Loss: 1.398170 	 time: 0.3
Validation loss decreased from 1.398450 to 1.398170. Model was saved
Epoch: 287 	Training Loss: 1.265988 	Validation Loss: 1.399708 	 time: 0.3
Epoch: 288 	Training Loss: 1.265778 	Validation Loss: 1.398252 	 time: 0.3
Epoch: 289 	Training Loss: 1.265327 	Validation Loss: 1.398629 	 time: 0.3
Epoch: 290 	Training Loss: 1.264445 	Validation Loss: 1.397798 	 time: 0.3
Validation loss decreased from 1.398170 to 1.397798. Model was saved
Epoch: 291 	Training Loss: 1.263693 	Validation Loss: 1.397954 	 time: 0.3
Epoch: 292 	Training Loss: 1.263372 	Validation Loss: 1.397961 	 time: 0.3
Epoch: 293 	Training Loss: 1.263256 	Validation Loss: 1.397957 	 time: 0.3
Epoch: 294 	Training Loss: 1.263086 	Validation Loss: 1.399187 	 time: 0.3
Epoch: 295 	Training Loss: 1.262854 	Validation Loss: 1.397776 	 time: 0.3
Validation loss decreased from 1.397798 to 1.397776. Model was saved
Epoch: 296 	Training Loss: 1.262727 	Validation Loss: 1.399063 	 time: 0.3
Epoch: 297 	Training Loss: 1.262101 	Validation Loss: 1.397847 	 time: 0.3
Epoch: 298 	Training Loss: 1.261579 	Validation Loss: 1.397529 	 time: 0.3
Validation loss decreased from 1.397776 to 1.397529. Model was saved
Epoch: 299 	Training Loss: 1.261035 	Validation Loss: 1.397807 	 time: 0.3
Epoch: 300 	Training Loss: 1.260460 	Validation Loss: 1.397543 	 time: 0.3
Epoch: 301 	Training Loss: 1.260031 	Validation Loss: 1.397195 	 time: 0.3
Validation loss decreased from 1.397529 to 1.397195. Model was saved
Epoch: 302 	Training Loss: 1.259773 	Validation Loss: 1.397658 	 time: 0.3
Epoch: 303 	Training Loss: 1.259500 	Validation Loss: 1.397974 	 time: 0.3
Epoch: 304 	Training Loss: 1.259272 	Validation Loss: 1.397050 	 time: 0.3
Validation loss decreased from 1.397195 to 1.397050. Model was saved
Epoch: 305 	Training Loss: 1.259237 	Validation Loss: 1.398580 	 time: 0.3
Epoch: 306 	Training Loss: 1.259086 	Validation Loss: 1.397284 	 time: 0.3
Epoch: 307 	Training Loss: 1.259279 	Validation Loss: 1.398504 	 time: 0.3
Epoch: 308 	Training Loss: 1.259018 	Validation Loss: 1.396654 	 time: 0.3
Validation loss decreased from 1.397050 to 1.396654. Model was saved
Epoch: 309 	Training Loss: 1.258219 	Validation Loss: 1.396912 	 time: 0.3
Epoch: 310 	Training Loss: 1.256914 	Validation Loss: 1.396470 	 time: 0.3
Validation loss decreased from 1.396654 to 1.396470. Model was saved
Epoch: 311 	Training Loss: 1.256520 	Validation Loss: 1.396194 	 time: 0.3
Validation loss decreased from 1.396470 to 1.396194. Model was saved
Epoch: 312 	Training Loss: 1.256830 	Validation Loss: 1.397580 	 time: 0.3
Epoch: 313 	Training Loss: 1.256759 	Validation Loss: 1.395784 	 time: 0.3
Validation loss decreased from 1.396194 to 1.395784. Model was saved
Epoch: 314 	Training Loss: 1.256415 	Validation Loss: 1.396602 	 time: 0.3
Epoch: 315 	Training Loss: 1.255515 	Validation Loss: 1.394868 	 time: 0.3
Validation loss decreased from 1.395784 to 1.394868. Model was saved
Epoch: 316 	Training Loss: 1.254785 	Validation Loss: 1.395114 	 time: 0.3
Epoch: 317 	Training Loss: 1.254433 	Validation Loss: 1.395983 	 time: 0.3
Epoch: 318 	Training Loss: 1.254421 	Validation Loss: 1.395105 	 time: 0.3
Epoch: 319 	Training Loss: 1.254513 	Validation Loss: 1.396661 	 time: 0.3
Epoch: 320 	Training Loss: 1.254100 	Validation Loss: 1.395549 	 time: 0.3
Epoch: 321 	Training Loss: 1.253686 	Validation Loss: 1.395799 	 time: 0.3
Epoch: 322 	Training Loss: 1.253063 	Validation Loss: 1.395575 	 time: 0.3
Epoch: 323 	Training Loss: 1.252500 	Validation Loss: 1.395385 	 time: 0.3
Epoch: 324 	Training Loss: 1.252061 	Validation Loss: 1.395740 	 time: 0.3
Epoch: 325 	Training Loss: 1.251795 	Validation Loss: 1.395765 	 time: 0.3
Epoch: 326 	Training Loss: 1.251664 	Validation Loss: 1.396217 	 time: 0.3
Epoch: 327 	Training Loss: 1.251548 	Validation Loss: 1.396109 	 time: 0.3
Epoch: 328 	Training Loss: 1.251544 	Validation Loss: 1.396944 	 time: 0.3
Epoch: 329 	Training Loss: 1.251488 	Validation Loss: 1.396341 	 time: 0.3
Epoch: 330 	Training Loss: 1.251734 	Validation Loss: 1.396697 	 time: 0.3
Epoch: 331 	Training Loss: 1.251124 	Validation Loss: 1.395434 	 time: 0.3
Epoch: 332 	Training Loss: 1.250340 	Validation Loss: 1.394186 	 time: 0.3
Validation loss decreased from 1.394868 to 1.394186. Model was saved
Epoch: 333 	Training Loss: 1.249404 	Validation Loss: 1.394930 	 time: 0.3
Epoch: 334 	Training Loss: 1.248933 	Validation Loss: 1.394511 	 time: 0.3
Epoch: 335 	Training Loss: 1.248882 	Validation Loss: 1.394814 	 time: 0.3
Epoch: 336 	Training Loss: 1.248920 	Validation Loss: 1.395824 	 time: 0.3
Epoch: 337 	Training Loss: 1.248917 	Validation Loss: 1.394704 	 time: 0.3
Epoch: 338 	Training Loss: 1.248385 	Validation Loss: 1.395097 	 time: 0.3
Epoch: 339 	Training Loss: 1.247664 	Validation Loss: 1.395247 	 time: 0.3
Epoch: 340 	Training Loss: 1.247095 	Validation Loss: 1.394132 	 time: 0.3
Validation loss decreased from 1.394186 to 1.394132. Model was saved
Epoch: 341 	Training Loss: 1.246732 	Validation Loss: 1.394961 	 time: 0.3
Epoch: 342 	Training Loss: 1.246415 	Validation Loss: 1.395338 	 time: 0.3
Epoch: 343 	Training Loss: 1.246306 	Validation Loss: 1.395341 	 time: 0.3
Epoch: 344 	Training Loss: 1.246307 	Validation Loss: 1.395692 	 time: 0.3
Epoch: 345 	Training Loss: 1.246038 	Validation Loss: 1.396367 	 time: 0.3
Epoch: 346 	Training Loss: 1.245955 	Validation Loss: 1.394495 	 time: 0.3
Epoch: 347 	Training Loss: 1.245718 	Validation Loss: 1.396177 	 time: 0.3
Epoch: 348 	Training Loss: 1.245371 	Validation Loss: 1.394580 	 time: 0.3
Epoch: 349 	Training Loss: 1.244752 	Validation Loss: 1.393936 	 time: 0.3
Validation loss decreased from 1.394132 to 1.393936. Model was saved
Epoch: 350 	Training Loss: 1.244223 	Validation Loss: 1.393990 	 time: 0.3
Epoch: 351 	Training Loss: 1.243566 	Validation Loss: 1.393296 	 time: 0.3
Validation loss decreased from 1.393936 to 1.393296. Model was saved
Epoch: 352 	Training Loss: 1.243093 	Validation Loss: 1.393058 	 time: 0.3
Validation loss decreased from 1.393296 to 1.393058. Model was saved
Epoch: 353 	Training Loss: 1.242886 	Validation Loss: 1.393871 	 time: 0.3
Epoch: 354 	Training Loss: 1.242784 	Validation Loss: 1.393361 	 time: 0.3
Epoch: 355 	Training Loss: 1.242770 	Validation Loss: 1.392465 	 time: 0.3
Validation loss decreased from 1.393058 to 1.392465. Model was saved
Epoch: 356 	Training Loss: 1.242787 	Validation Loss: 1.393834 	 time: 0.3
Epoch: 357 	Training Loss: 1.243083 	Validation Loss: 1.391535 	 time: 0.3
Validation loss decreased from 1.392465 to 1.391535. Model was saved
Epoch: 358 	Training Loss: 1.242971 	Validation Loss: 1.392030 	 time: 0.3
Epoch: 359 	Training Loss: 1.242618 	Validation Loss: 1.391039 	 time: 0.3
Validation loss decreased from 1.391535 to 1.391039. Model was saved
Epoch: 360 	Training Loss: 1.241412 	Validation Loss: 1.389804 	 time: 0.3
Validation loss decreased from 1.391039 to 1.389804. Model was saved
Epoch: 361 	Training Loss: 1.240613 	Validation Loss: 1.390453 	 time: 0.3
Epoch: 362 	Training Loss: 1.240435 	Validation Loss: 1.390765 	 time: 0.3
Epoch: 363 	Training Loss: 1.240700 	Validation Loss: 1.391444 	 time: 0.3
Epoch: 364 	Training Loss: 1.241155 	Validation Loss: 1.391260 	 time: 0.3
Epoch: 365 	Training Loss: 1.240917 	Validation Loss: 1.390896 	 time: 0.3
Epoch: 366 	Training Loss: 1.240461 	Validation Loss: 1.389289 	 time: 0.3
Validation loss decreased from 1.389804 to 1.389289. Model was saved
Epoch: 367 	Training Loss: 1.239396 	Validation Loss: 1.389779 	 time: 0.3
Epoch: 368 	Training Loss: 1.238699 	Validation Loss: 1.389479 	 time: 0.3
Epoch: 369 	Training Loss: 1.238638 	Validation Loss: 1.389920 	 time: 0.3
Epoch: 370 	Training Loss: 1.238831 	Validation Loss: 1.390227 	 time: 0.3
Epoch: 371 	Training Loss: 1.238927 	Validation Loss: 1.389862 	 time: 0.3
Epoch: 372 	Training Loss: 1.238472 	Validation Loss: 1.389031 	 time: 0.3
Validation loss decreased from 1.389289 to 1.389031. Model was saved
Epoch: 373 	Training Loss: 1.237858 	Validation Loss: 1.389063 	 time: 0.3
Epoch: 374 	Training Loss: 1.237149 	Validation Loss: 1.388225 	 time: 0.3
Validation loss decreased from 1.389031 to 1.388225. Model was saved
Epoch: 375 	Training Loss: 1.236731 	Validation Loss: 1.388256 	 time: 0.3
Epoch: 376 	Training Loss: 1.236565 	Validation Loss: 1.388413 	 time: 0.3
Epoch: 377 	Training Loss: 1.236492 	Validation Loss: 1.388080 	 time: 0.3
Validation loss decreased from 1.388225 to 1.388080. Model was saved
Epoch: 378 	Training Loss: 1.236517 	Validation Loss: 1.388646 	 time: 0.3
Epoch: 379 	Training Loss: 1.236472 	Validation Loss: 1.388121 	 time: 0.3
Epoch: 380 	Training Loss: 1.236695 	Validation Loss: 1.388785 	 time: 0.3
Epoch: 381 	Training Loss: 1.236538 	Validation Loss: 1.387923 	 time: 0.3
Validation loss decreased from 1.388080 to 1.387923. Model was saved
Epoch: 382 	Training Loss: 1.236413 	Validation Loss: 1.386912 	 time: 0.3
Validation loss decreased from 1.387923 to 1.386912. Model was saved
Epoch: 383 	Training Loss: 1.235368 	Validation Loss: 1.386560 	 time: 0.3
Validation loss decreased from 1.386912 to 1.386560. Model was saved
Epoch: 384 	Training Loss: 1.234287 	Validation Loss: 1.386198 	 time: 0.3
Validation loss decreased from 1.386560 to 1.386198. Model was saved
Epoch: 385 	Training Loss: 1.233912 	Validation Loss: 1.386609 	 time: 0.3
Epoch: 386 	Training Loss: 1.234172 	Validation Loss: 1.386486 	 time: 0.3
Epoch: 387 	Training Loss: 1.234468 	Validation Loss: 1.387054 	 time: 0.3
Epoch: 388 	Training Loss: 1.234125 	Validation Loss: 1.385882 	 time: 0.3
Validation loss decreased from 1.386198 to 1.385882. Model was saved
Epoch: 389 	Training Loss: 1.233482 	Validation Loss: 1.385718 	 time: 0.3
Validation loss decreased from 1.385882 to 1.385718. Model was saved
Epoch: 390 	Training Loss: 1.232621 	Validation Loss: 1.385295 	 time: 0.3
Validation loss decreased from 1.385718 to 1.385295. Model was saved
Epoch: 391 	Training Loss: 1.232193 	Validation Loss: 1.384915 	 time: 0.3
Validation loss decreased from 1.385295 to 1.384915. Model was saved
Epoch: 392 	Training Loss: 1.232163 	Validation Loss: 1.385032 	 time: 0.3
Epoch: 393 	Training Loss: 1.232204 	Validation Loss: 1.384698 	 time: 0.3
Validation loss decreased from 1.384915 to 1.384698. Model was saved
Epoch: 394 	Training Loss: 1.232067 	Validation Loss: 1.385009 	 time: 0.3
Epoch: 395 	Training Loss: 1.231631 	Validation Loss: 1.383616 	 time: 0.3
Validation loss decreased from 1.384698 to 1.383616. Model was saved
Epoch: 396 	Training Loss: 1.231188 	Validation Loss: 1.384213 	 time: 0.3
Epoch: 397 	Training Loss: 1.230654 	Validation Loss: 1.383744 	 time: 0.3
Epoch: 398 	Training Loss: 1.230306 	Validation Loss: 1.383206 	 time: 0.3
Validation loss decreased from 1.383616 to 1.383206. Model was saved
Epoch: 399 	Training Loss: 1.230138 	Validation Loss: 1.383978 	 time: 0.3
Epoch: 400 	Training Loss: 1.230032 	Validation Loss: 1.382978 	 time: 0.3
Validation loss decreased from 1.383206 to 1.382978. Model was saved
Epoch: 401 	Training Loss: 1.229942 	Validation Loss: 1.383807 	 time: 0.3
Epoch: 402 	Training Loss: 1.229691 	Validation Loss: 1.382455 	 time: 0.3
Validation loss decreased from 1.382978 to 1.382455. Model was saved
Epoch: 403 	Training Loss: 1.229394 	Validation Loss: 1.383451 	 time: 0.3
Epoch: 404 	Training Loss: 1.228978 	Validation Loss: 1.382477 	 time: 0.3
Epoch: 405 	Training Loss: 1.228590 	Validation Loss: 1.382712 	 time: 0.3
Epoch: 406 	Training Loss: 1.228232 	Validation Loss: 1.382829 	 time: 0.3
Epoch: 407 	Training Loss: 1.227912 	Validation Loss: 1.382477 	 time: 0.3
Epoch: 408 	Training Loss: 1.227624 	Validation Loss: 1.382549 	 time: 0.3
Epoch: 409 	Training Loss: 1.227379 	Validation Loss: 1.382203 	 time: 0.3
Validation loss decreased from 1.382455 to 1.382203. Model was saved
Epoch: 410 	Training Loss: 1.227164 	Validation Loss: 1.382644 	 time: 0.3
Epoch: 411 	Training Loss: 1.226973 	Validation Loss: 1.381698 	 time: 0.3
Validation loss decreased from 1.382203 to 1.381698. Model was saved
Epoch: 412 	Training Loss: 1.226796 	Validation Loss: 1.382522 	 time: 0.3
Epoch: 413 	Training Loss: 1.226601 	Validation Loss: 1.381378 	 time: 0.3
Validation loss decreased from 1.381698 to 1.381378. Model was saved
Epoch: 414 	Training Loss: 1.226416 	Validation Loss: 1.382308 	 time: 0.3
Epoch: 415 	Training Loss: 1.226211 	Validation Loss: 1.380767 	 time: 0.3
Validation loss decreased from 1.381378 to 1.380767. Model was saved
Epoch: 416 	Training Loss: 1.226054 	Validation Loss: 1.382217 	 time: 0.3
Epoch: 417 	Training Loss: 1.225832 	Validation Loss: 1.380310 	 time: 0.3
Validation loss decreased from 1.380767 to 1.380310. Model was saved
Epoch: 418 	Training Loss: 1.225740 	Validation Loss: 1.381883 	 time: 0.3
Epoch: 419 	Training Loss: 1.225478 	Validation Loss: 1.379888 	 time: 0.3
Validation loss decreased from 1.380310 to 1.379888. Model was saved
Epoch: 420 	Training Loss: 1.225359 	Validation Loss: 1.381421 	 time: 0.3
Epoch: 421 	Training Loss: 1.225025 	Validation Loss: 1.378938 	 time: 0.3
Validation loss decreased from 1.379888 to 1.378938. Model was saved
Epoch: 422 	Training Loss: 1.224753 	Validation Loss: 1.380597 	 time: 0.3
Epoch: 423 	Training Loss: 1.224125 	Validation Loss: 1.378470 	 time: 0.3
Validation loss decreased from 1.378938 to 1.378470. Model was saved
Epoch: 424 	Training Loss: 1.223479 	Validation Loss: 1.379297 	 time: 0.3
Epoch: 425 	Training Loss: 1.222821 	Validation Loss: 1.378422 	 time: 0.3
Validation loss decreased from 1.378470 to 1.378422. Model was saved
Epoch: 426 	Training Loss: 1.222321 	Validation Loss: 1.378199 	 time: 0.3
Validation loss decreased from 1.378422 to 1.378199. Model was saved
Epoch: 427 	Training Loss: 1.221994 	Validation Loss: 1.378870 	 time: 0.3
Epoch: 428 	Training Loss: 1.221778 	Validation Loss: 1.377299 	 time: 0.3
Validation loss decreased from 1.378199 to 1.377299. Model was saved
Epoch: 429 	Training Loss: 1.221649 	Validation Loss: 1.379526 	 time: 0.3
Epoch: 430 	Training Loss: 1.221576 	Validation Loss: 1.376629 	 time: 0.3
Validation loss decreased from 1.377299 to 1.376629. Model was saved
Epoch: 431 	Training Loss: 1.221611 	Validation Loss: 1.379904 	 time: 0.3
Epoch: 432 	Training Loss: 1.221447 	Validation Loss: 1.376433 	 time: 0.2
Validation loss decreased from 1.376629 to 1.376433. Model was saved
Epoch: 433 	Training Loss: 1.221163 	Validation Loss: 1.379758 	 time: 0.3
Epoch: 434 	Training Loss: 1.220511 	Validation Loss: 1.376276 	 time: 0.3
Validation loss decreased from 1.376433 to 1.376276. Model was saved
Epoch: 435 	Training Loss: 1.219984 	Validation Loss: 1.378286 	 time: 0.3
Epoch: 436 	Training Loss: 1.219347 	Validation Loss: 1.376265 	 time: 0.3
Validation loss decreased from 1.376276 to 1.376265. Model was saved
Epoch: 437 	Training Loss: 1.218821 	Validation Loss: 1.376044 	 time: 0.3
Validation loss decreased from 1.376265 to 1.376044. Model was saved
Epoch: 438 	Training Loss: 1.218463 	Validation Loss: 1.377073 	 time: 0.3
Epoch: 439 	Training Loss: 1.218344 	Validation Loss: 1.374877 	 time: 0.3
Validation loss decreased from 1.376044 to 1.374877. Model was saved
Epoch: 440 	Training Loss: 1.218324 	Validation Loss: 1.377341 	 time: 0.3
Epoch: 441 	Training Loss: 1.218146 	Validation Loss: 1.374506 	 time: 0.3
Validation loss decreased from 1.374877 to 1.374506. Model was saved
Epoch: 442 	Training Loss: 1.217870 	Validation Loss: 1.376738 	 time: 0.3
Epoch: 443 	Training Loss: 1.217455 	Validation Loss: 1.374685 	 time: 0.3
Epoch: 444 	Training Loss: 1.217070 	Validation Loss: 1.375625 	 time: 0.3
Epoch: 445 	Training Loss: 1.216732 	Validation Loss: 1.375471 	 time: 0.3
Epoch: 446 	Training Loss: 1.216428 	Validation Loss: 1.374777 	 time: 0.3
Epoch: 447 	Training Loss: 1.216171 	Validation Loss: 1.376105 	 time: 0.3
Epoch: 448 	Training Loss: 1.215970 	Validation Loss: 1.374555 	 time: 0.3
Epoch: 449 	Training Loss: 1.215808 	Validation Loss: 1.376597 	 time: 0.3
Epoch: 450 	Training Loss: 1.215633 	Validation Loss: 1.374723 	 time: 0.3
Epoch: 451 	Training Loss: 1.215408 	Validation Loss: 1.377071 	 time: 0.3
Epoch: 452 	Training Loss: 1.215144 	Validation Loss: 1.374684 	 time: 0.3
Epoch: 453 	Training Loss: 1.214872 	Validation Loss: 1.376662 	 time: 0.3
Epoch: 454 	Training Loss: 1.214591 	Validation Loss: 1.374487 	 time: 0.3
Validation loss decreased from 1.374506 to 1.374487. Model was saved
Epoch: 455 	Training Loss: 1.214322 	Validation Loss: 1.375816 	 time: 0.3
Epoch: 456 	Training Loss: 1.214042 	Validation Loss: 1.374113 	 time: 0.3
Validation loss decreased from 1.374487 to 1.374113. Model was saved
Epoch: 457 	Training Loss: 1.213772 	Validation Loss: 1.374986 	 time: 0.3
Epoch: 458 	Training Loss: 1.213515 	Validation Loss: 1.374001 	 time: 0.3
Validation loss decreased from 1.374113 to 1.374001. Model was saved
Epoch: 459 	Training Loss: 1.213279 	Validation Loss: 1.374545 	 time: 0.3
Epoch: 460 	Training Loss: 1.213068 	Validation Loss: 1.374121 	 time: 0.3
Epoch: 461 	Training Loss: 1.212868 	Validation Loss: 1.374751 	 time: 0.3
Epoch: 462 	Training Loss: 1.212686 	Validation Loss: 1.374177 	 time: 0.3
Epoch: 463 	Training Loss: 1.212519 	Validation Loss: 1.375623 	 time: 0.3
Epoch: 464 	Training Loss: 1.212405 	Validation Loss: 1.373806 	 time: 0.3
Validation loss decreased from 1.374001 to 1.373806. Model was saved
Epoch: 465 	Training Loss: 1.212352 	Validation Loss: 1.377149 	 time: 0.3
Epoch: 466 	Training Loss: 1.212431 	Validation Loss: 1.372985 	 time: 0.3
Validation loss decreased from 1.373806 to 1.372985. Model was saved
Epoch: 467 	Training Loss: 1.212640 	Validation Loss: 1.379574 	 time: 0.3
Epoch: 468 	Training Loss: 1.212897 	Validation Loss: 1.372369 	 time: 0.3
Validation loss decreased from 1.372985 to 1.372369. Model was saved
Epoch: 469 	Training Loss: 1.212977 	Validation Loss: 1.379630 	 time: 0.3
Epoch: 470 	Training Loss: 1.212218 	Validation Loss: 1.374097 	 time: 0.3
Epoch: 471 	Training Loss: 1.211307 	Validation Loss: 1.374838 	 time: 0.3
Epoch: 472 	Training Loss: 1.210731 	Validation Loss: 1.378452 	 time: 0.3
Epoch: 473 	Training Loss: 1.211069 	Validation Loss: 1.373373 	 time: 0.3
Epoch: 474 	Training Loss: 1.211411 	Validation Loss: 1.379090 	 time: 0.3
Epoch: 475 	Training Loss: 1.210814 	Validation Loss: 1.374138 	 time: 0.3
Epoch: 476 	Training Loss: 1.210004 	Validation Loss: 1.375214 	 time: 0.3
Epoch: 477 	Training Loss: 1.209727 	Validation Loss: 1.379098 	 time: 0.2
Epoch: 478 	Training Loss: 1.209980 	Validation Loss: 1.373511 	 time: 0.3
Epoch: 479 	Training Loss: 1.210006 	Validation Loss: 1.377664 	 time: 0.3
Epoch: 480 	Training Loss: 1.209494 	Validation Loss: 1.375507 	 time: 0.3
Epoch: 481 	Training Loss: 1.209089 	Validation Loss: 1.375016 	 time: 0.3
Epoch: 482 	Training Loss: 1.209003 	Validation Loss: 1.377269 	 time: 0.3
Epoch: 483 	Training Loss: 1.208941 	Validation Loss: 1.373242 	 time: 0.3
Epoch: 484 	Training Loss: 1.208799 	Validation Loss: 1.376529 	 time: 0.3
Epoch: 485 	Training Loss: 1.208541 	Validation Loss: 1.375486 	 time: 0.3
Epoch: 486 	Training Loss: 1.208204 	Validation Loss: 1.374951 	 time: 0.3
Epoch: 487 	Training Loss: 1.207982 	Validation Loss: 1.376809 	 time: 0.3
Epoch: 488 	Training Loss: 1.207941 	Validation Loss: 1.374423 	 time: 0.3
Epoch: 489 	Training Loss: 1.207840 	Validation Loss: 1.376830 	 time: 0.3
Epoch: 490 	Training Loss: 1.207549 	Validation Loss: 1.375650 	 time: 0.3
Epoch: 491 	Training Loss: 1.207229 	Validation Loss: 1.375556 	 time: 0.3
Epoch: 492 	Training Loss: 1.207068 	Validation Loss: 1.376878 	 time: 0.3
Epoch: 493 	Training Loss: 1.206980 	Validation Loss: 1.375460 	 time: 0.3
Epoch: 494 	Training Loss: 1.206807 	Validation Loss: 1.378087 	 time: 0.3
Epoch: 495 	Training Loss: 1.206607 	Validation Loss: 1.376594 	 time: 0.3
Epoch: 496 	Training Loss: 1.206433 	Validation Loss: 1.377278 	 time: 0.3
Epoch: 497 	Training Loss: 1.206279 	Validation Loss: 1.378220 	 time: 0.3
Epoch: 498 	Training Loss: 1.206141 	Validation Loss: 1.377123 	 time: 0.3
Epoch: 499 	Training Loss: 1.206026 	Validation Loss: 1.379350 	 time: 0.3
Epoch: 500 	Training Loss: 1.205903 	Validation Loss: 1.377756 	 time: 0.3
Epoch: 501 	Training Loss: 1.205743 	Validation Loss: 1.378664 	 time: 0.3
Epoch: 502 	Training Loss: 1.205587 	Validation Loss: 1.379187 	 time: 0.3
Epoch: 503 	Training Loss: 1.205488 	Validation Loss: 1.378107 	 time: 0.3
Epoch: 504 	Training Loss: 1.205408 	Validation Loss: 1.379330 	 time: 0.3
Epoch: 505 	Training Loss: 1.205292 	Validation Loss: 1.377778 	 time: 0.3
Epoch: 506 	Training Loss: 1.205161 	Validation Loss: 1.378393 	 time: 0.3
Epoch: 507 	Training Loss: 1.205043 	Validation Loss: 1.378270 	 time: 0.3
Epoch: 508 	Training Loss: 1.204929 	Validation Loss: 1.377245 	 time: 0.3
Epoch: 509 	Training Loss: 1.204812 	Validation Loss: 1.377881 	 time: 0.3
Epoch: 510 	Training Loss: 1.204701 	Validation Loss: 1.376759 	 time: 0.3
Epoch: 511 	Training Loss: 1.204581 	Validation Loss: 1.377239 	 time: 0.3
Epoch: 512 	Training Loss: 1.204445 	Validation Loss: 1.376547 	 time: 0.3
Epoch: 513 	Training Loss: 1.204308 	Validation Loss: 1.376027 	 time: 0.3
Epoch: 514 	Training Loss: 1.204192 	Validation Loss: 1.376118 	 time: 0.3
Epoch: 515 	Training Loss: 1.204086 	Validation Loss: 1.375106 	 time: 0.3
Epoch: 516 	Training Loss: 1.203970 	Validation Loss: 1.375481 	 time: 0.3
Epoch: 517 	Training Loss: 1.203846 	Validation Loss: 1.374459 	 time: 0.3
Epoch: 518 	Training Loss: 1.203717 	Validation Loss: 1.374508 	 time: 0.3
Epoch: 519 	Training Loss: 1.203590 	Validation Loss: 1.374542 	 time: 0.3
Epoch: 520 	Training Loss: 1.203474 	Validation Loss: 1.373862 	 time: 0.3
Epoch: 521 	Training Loss: 1.203368 	Validation Loss: 1.374163 	 time: 0.3
Epoch: 522 	Training Loss: 1.203262 	Validation Loss: 1.372956 	 time: 0.3
Epoch: 523 	Training Loss: 1.203148 	Validation Loss: 1.373057 	 time: 0.3
Epoch: 524 	Training Loss: 1.203030 	Validation Loss: 1.372503 	 time: 0.3
Epoch: 525 	Training Loss: 1.202915 	Validation Loss: 1.371941 	 time: 0.3
Validation loss decreased from 1.372369 to 1.371941. Model was saved
Epoch: 526 	Training Loss: 1.202805 	Validation Loss: 1.371834 	 time: 0.3
Validation loss decreased from 1.371941 to 1.371834. Model was saved
Epoch: 527 	Training Loss: 1.202698 	Validation Loss: 1.371221 	 time: 0.3
Validation loss decreased from 1.371834 to 1.371221. Model was saved
Epoch: 528 	Training Loss: 1.202591 	Validation Loss: 1.371598 	 time: 0.3
Epoch: 529 	Training Loss: 1.202480 	Validation Loss: 1.371148 	 time: 0.3
Validation loss decreased from 1.371221 to 1.371148. Model was saved
Epoch: 530 	Training Loss: 1.202361 	Validation Loss: 1.371368 	 time: 0.3
Epoch: 531 	Training Loss: 1.202239 	Validation Loss: 1.371351 	 time: 0.3
Epoch: 532 	Training Loss: 1.202125 	Validation Loss: 1.371603 	 time: 0.3
Epoch: 533 	Training Loss: 1.202019 	Validation Loss: 1.371940 	 time: 0.3
Epoch: 534 	Training Loss: 1.201914 	Validation Loss: 1.371781 	 time: 0.3
Epoch: 535 	Training Loss: 1.201806 	Validation Loss: 1.372106 	 time: 0.3
Epoch: 536 	Training Loss: 1.201693 	Validation Loss: 1.371784 	 time: 0.3
Epoch: 537 	Training Loss: 1.201573 	Validation Loss: 1.371945 	 time: 0.3
Epoch: 538 	Training Loss: 1.201446 	Validation Loss: 1.371492 	 time: 0.3
Epoch: 539 	Training Loss: 1.201316 	Validation Loss: 1.371393 	 time: 0.3
Epoch: 540 	Training Loss: 1.201184 	Validation Loss: 1.371269 	 time: 0.3
Epoch: 541 	Training Loss: 1.201049 	Validation Loss: 1.371172 	 time: 0.3
Epoch: 542 	Training Loss: 1.200916 	Validation Loss: 1.371165 	 time: 0.3
Epoch: 543 	Training Loss: 1.200799 	Validation Loss: 1.370861 	 time: 0.3
Validation loss decreased from 1.371148 to 1.370861. Model was saved
Epoch: 544 	Training Loss: 1.200696 	Validation Loss: 1.370927 	 time: 0.3
Epoch: 545 	Training Loss: 1.200599 	Validation Loss: 1.370722 	 time: 0.3
Validation loss decreased from 1.370861 to 1.370722. Model was saved
Epoch: 546 	Training Loss: 1.200504 	Validation Loss: 1.370902 	 time: 0.3
Epoch: 547 	Training Loss: 1.200410 	Validation Loss: 1.370644 	 time: 0.3
Validation loss decreased from 1.370722 to 1.370644. Model was saved
Epoch: 548 	Training Loss: 1.200318 	Validation Loss: 1.370868 	 time: 0.3
Epoch: 549 	Training Loss: 1.200225 	Validation Loss: 1.370606 	 time: 0.3
Validation loss decreased from 1.370644 to 1.370606. Model was saved
Epoch: 550 	Training Loss: 1.200130 	Validation Loss: 1.370714 	 time: 0.3
Epoch: 551 	Training Loss: 1.200034 	Validation Loss: 1.370388 	 time: 0.3
Validation loss decreased from 1.370606 to 1.370388. Model was saved
Epoch: 552 	Training Loss: 1.199940 	Validation Loss: 1.370462 	 time: 0.3
Epoch: 553 	Training Loss: 1.199845 	Validation Loss: 1.370345 	 time: 0.3
Validation loss decreased from 1.370388 to 1.370345. Model was saved
Epoch: 554 	Training Loss: 1.199747 	Validation Loss: 1.370428 	 time: 0.3
Epoch: 555 	Training Loss: 1.199645 	Validation Loss: 1.370304 	 time: 0.2
Validation loss decreased from 1.370345 to 1.370304. Model was saved
Epoch: 556 	Training Loss: 1.199543 	Validation Loss: 1.370329 	 time: 0.3
Epoch: 557 	Training Loss: 1.199447 	Validation Loss: 1.370272 	 time: 0.3
Validation loss decreased from 1.370304 to 1.370272. Model was saved
Epoch: 558 	Training Loss: 1.199356 	Validation Loss: 1.370309 	 time: 0.3
Epoch: 559 	Training Loss: 1.199269 	Validation Loss: 1.370319 	 time: 0.3
Epoch: 560 	Training Loss: 1.199182 	Validation Loss: 1.370276 	 time: 0.3
Epoch: 561 	Training Loss: 1.199094 	Validation Loss: 1.370364 	 time: 0.3
Epoch: 562 	Training Loss: 1.199006 	Validation Loss: 1.370322 	 time: 0.3
Epoch: 563 	Training Loss: 1.198918 	Validation Loss: 1.370422 	 time: 0.3
Epoch: 564 	Training Loss: 1.198828 	Validation Loss: 1.370312 	 time: 0.3
Epoch: 565 	Training Loss: 1.198736 	Validation Loss: 1.370278 	 time: 0.3
Epoch: 566 	Training Loss: 1.198641 	Validation Loss: 1.369976 	 time: 0.3
Validation loss decreased from 1.370272 to 1.369976. Model was saved
Epoch: 567 	Training Loss: 1.198541 	Validation Loss: 1.369723 	 time: 0.3
Validation loss decreased from 1.369976 to 1.369723. Model was saved
Epoch: 568 	Training Loss: 1.198435 	Validation Loss: 1.369111 	 time: 0.3
Validation loss decreased from 1.369723 to 1.369111. Model was saved
Epoch: 569 	Training Loss: 1.198326 	Validation Loss: 1.368755 	 time: 0.3
Validation loss decreased from 1.369111 to 1.368755. Model was saved
Epoch: 570 	Training Loss: 1.198220 	Validation Loss: 1.368073 	 time: 0.3
Validation loss decreased from 1.368755 to 1.368073. Model was saved
Epoch: 571 	Training Loss: 1.198120 	Validation Loss: 1.368007 	 time: 0.3
Validation loss decreased from 1.368073 to 1.368007. Model was saved
Epoch: 572 	Training Loss: 1.198025 	Validation Loss: 1.367427 	 time: 0.3
Validation loss decreased from 1.368007 to 1.367427. Model was saved
Epoch: 573 	Training Loss: 1.197931 	Validation Loss: 1.367685 	 time: 0.3
Epoch: 574 	Training Loss: 1.197838 	Validation Loss: 1.367050 	 time: 0.3
Validation loss decreased from 1.367427 to 1.367050. Model was saved
Epoch: 575 	Training Loss: 1.197748 	Validation Loss: 1.367689 	 time: 0.2
Epoch: 576 	Training Loss: 1.197666 	Validation Loss: 1.366783 	 time: 0.3
Validation loss decreased from 1.367050 to 1.366783. Model was saved
Epoch: 577 	Training Loss: 1.197598 	Validation Loss: 1.367993 	 time: 0.3
Epoch: 578 	Training Loss: 1.197557 	Validation Loss: 1.366416 	 time: 0.3
Validation loss decreased from 1.366783 to 1.366416. Model was saved
Epoch: 579 	Training Loss: 1.197546 	Validation Loss: 1.368713 	 time: 0.3
Epoch: 580 	Training Loss: 1.197604 	Validation Loss: 1.365811 	 time: 0.2
Validation loss decreased from 1.366416 to 1.365811. Model was saved
Epoch: 581 	Training Loss: 1.197744 	Validation Loss: 1.370273 	 time: 0.3
Epoch: 582 	Training Loss: 1.198064 	Validation Loss: 1.364787 	 time: 0.3
Validation loss decreased from 1.365811 to 1.364787. Model was saved
Epoch: 583 	Training Loss: 1.198380 	Validation Loss: 1.372000 	 time: 0.3
Epoch: 584 	Training Loss: 1.198441 	Validation Loss: 1.363706 	 time: 0.3
Validation loss decreased from 1.364787 to 1.363706. Model was saved
Epoch: 585 	Training Loss: 1.198046 	Validation Loss: 1.369142 	 time: 0.3
Epoch: 586 	Training Loss: 1.197284 	Validation Loss: 1.366520 	 time: 0.3
Epoch: 587 	Training Loss: 1.196871 	Validation Loss: 1.364870 	 time: 0.3
Epoch: 588 	Training Loss: 1.197060 	Validation Loss: 1.369838 	 time: 0.3
Epoch: 589 	Training Loss: 1.197381 	Validation Loss: 1.363415 	 time: 0.3
Validation loss decreased from 1.363706 to 1.363415. Model was saved
Epoch: 590 	Training Loss: 1.197285 	Validation Loss: 1.367568 	 time: 0.3
Epoch: 591 	Training Loss: 1.196714 	Validation Loss: 1.365844 	 time: 0.3
Epoch: 592 	Training Loss: 1.196433 	Validation Loss: 1.363323 	 time: 0.3
Validation loss decreased from 1.363415 to 1.363323. Model was saved
Epoch: 593 	Training Loss: 1.196628 	Validation Loss: 1.367538 	 time: 0.2
Epoch: 594 	Training Loss: 1.196605 	Validation Loss: 1.362908 	 time: 0.3
Validation loss decreased from 1.363323 to 1.362908. Model was saved
Epoch: 595 	Training Loss: 1.196295 	Validation Loss: 1.364194 	 time: 0.3
Epoch: 596 	Training Loss: 1.196068 	Validation Loss: 1.365421 	 time: 0.3
Epoch: 597 	Training Loss: 1.196061 	Validation Loss: 1.361649 	 time: 0.3
Validation loss decreased from 1.362908 to 1.361649. Model was saved
Epoch: 598 	Training Loss: 1.196083 	Validation Loss: 1.364758 	 time: 0.3
Epoch: 599 	Training Loss: 1.196023 	Validation Loss: 1.362906 	 time: 0.3
Epoch: 600 	Training Loss: 1.195897 	Validation Loss: 1.363350 	 time: 0.3
Epoch: 601 	Training Loss: 1.195736 	Validation Loss: 1.364480 	 time: 0.3
Epoch: 602 	Training Loss: 1.195635 	Validation Loss: 1.363271 	 time: 0.3
Epoch: 603 	Training Loss: 1.195669 	Validation Loss: 1.364932 	 time: 0.3
Epoch: 604 	Training Loss: 1.195665 	Validation Loss: 1.364207 	 time: 0.3
Epoch: 605 	Training Loss: 1.195504 	Validation Loss: 1.364410 	 time: 0.3
Epoch: 606 	Training Loss: 1.195359 	Validation Loss: 1.364595 	 time: 0.3
Epoch: 607 	Training Loss: 1.195350 	Validation Loss: 1.364034 	 time: 0.3
Epoch: 608 	Training Loss: 1.195342 	Validation Loss: 1.365005 	 time: 0.3
Epoch: 609 	Training Loss: 1.195245 	Validation Loss: 1.364034 	 time: 0.3
Epoch: 610 	Training Loss: 1.195123 	Validation Loss: 1.364644 	 time: 0.3
Epoch: 611 	Training Loss: 1.195075 	Validation Loss: 1.364676 	 time: 0.3
Epoch: 612 	Training Loss: 1.195047 	Validation Loss: 1.363916 	 time: 0.3
Epoch: 613 	Training Loss: 1.194975 	Validation Loss: 1.365042 	 time: 0.3
Epoch: 614 	Training Loss: 1.194892 	Validation Loss: 1.364114 	 time: 0.3
Epoch: 615 	Training Loss: 1.194832 	Validation Loss: 1.364363 	 time: 0.3
Epoch: 616 	Training Loss: 1.194774 	Validation Loss: 1.364669 	 time: 0.3
Epoch: 617 	Training Loss: 1.194708 	Validation Loss: 1.363779 	 time: 0.3
Epoch: 618 	Training Loss: 1.194644 	Validation Loss: 1.364491 	 time: 0.3
Epoch: 619 	Training Loss: 1.194585 	Validation Loss: 1.363697 	 time: 0.3
Epoch: 620 	Training Loss: 1.194517 	Validation Loss: 1.363281 	 time: 0.3
Epoch: 621 	Training Loss: 1.194437 	Validation Loss: 1.363730 	 time: 0.3
Epoch: 622 	Training Loss: 1.194358 	Validation Loss: 1.362808 	 time: 0.3
Epoch: 623 	Training Loss: 1.194273 	Validation Loss: 1.363097 	 time: 0.3
Epoch: 624 	Training Loss: 1.194178 	Validation Loss: 1.362849 	 time: 0.3
Epoch: 625 	Training Loss: 1.194095 	Validation Loss: 1.362526 	 time: 0.3
Epoch: 626 	Training Loss: 1.194036 	Validation Loss: 1.363098 	 time: 0.3
Epoch: 627 	Training Loss: 1.193987 	Validation Loss: 1.362284 	 time: 0.3
Epoch: 628 	Training Loss: 1.193925 	Validation Loss: 1.362328 	 time: 0.3
Epoch: 629 	Training Loss: 1.193847 	Validation Loss: 1.362003 	 time: 0.3
Epoch: 630 	Training Loss: 1.193769 	Validation Loss: 1.361208 	 time: 0.3
Validation loss decreased from 1.361649 to 1.361208. Model was saved
Epoch: 631 	Training Loss: 1.193689 	Validation Loss: 1.361253 	 time: 0.3
Epoch: 632 	Training Loss: 1.193589 	Validation Loss: 1.360430 	 time: 0.3
Validation loss decreased from 1.361208 to 1.360430. Model was saved
Epoch: 633 	Training Loss: 1.193478 	Validation Loss: 1.360267 	 time: 0.3
Validation loss decreased from 1.360430 to 1.360267. Model was saved
Epoch: 634 	Training Loss: 1.193391 	Validation Loss: 1.360272 	 time: 0.3
Epoch: 635 	Training Loss: 1.193317 	Validation Loss: 1.359550 	 time: 0.3
Validation loss decreased from 1.360267 to 1.359550. Model was saved
Epoch: 636 	Training Loss: 1.193220 	Validation Loss: 1.359419 	 time: 0.3
Validation loss decreased from 1.359550 to 1.359419. Model was saved
Epoch: 637 	Training Loss: 1.193141 	Validation Loss: 1.358856 	 time: 0.3
Validation loss decreased from 1.359419 to 1.358856. Model was saved
Epoch: 638 	Training Loss: 1.193084 	Validation Loss: 1.358563 	 time: 0.3
Validation loss decreased from 1.358856 to 1.358563. Model was saved
Epoch: 639 	Training Loss: 1.193019 	Validation Loss: 1.358302 	 time: 0.3
Validation loss decreased from 1.358563 to 1.358302. Model was saved
Epoch: 640 	Training Loss: 1.192944 	Validation Loss: 1.357839 	 time: 0.3
Validation loss decreased from 1.358302 to 1.357839. Model was saved
Epoch: 641 	Training Loss: 1.192867 	Validation Loss: 1.357843 	 time: 0.3
Epoch: 642 	Training Loss: 1.192795 	Validation Loss: 1.357826 	 time: 0.3
Validation loss decreased from 1.357839 to 1.357826. Model was saved
Epoch: 643 	Training Loss: 1.192725 	Validation Loss: 1.358037 	 time: 0.3
Epoch: 644 	Training Loss: 1.192654 	Validation Loss: 1.358440 	 time: 0.3
Epoch: 645 	Training Loss: 1.192583 	Validation Loss: 1.358835 	 time: 0.3
Epoch: 646 	Training Loss: 1.192513 	Validation Loss: 1.359128 	 time: 0.3
Epoch: 647 	Training Loss: 1.192443 	Validation Loss: 1.359156 	 time: 0.3
Epoch: 648 	Training Loss: 1.192370 	Validation Loss: 1.359039 	 time: 0.3
Epoch: 649 	Training Loss: 1.192302 	Validation Loss: 1.358685 	 time: 0.3
Epoch: 650 	Training Loss: 1.192241 	Validation Loss: 1.358451 	 time: 0.3
Epoch: 651 	Training Loss: 1.192182 	Validation Loss: 1.358181 	 time: 0.3
Epoch: 652 	Training Loss: 1.192122 	Validation Loss: 1.358002 	 time: 0.3
Epoch: 653 	Training Loss: 1.192059 	Validation Loss: 1.358099 	 time: 0.3
Epoch: 654 	Training Loss: 1.191992 	Validation Loss: 1.358014 	 time: 0.3
Epoch: 655 	Training Loss: 1.191923 	Validation Loss: 1.358174 	 time: 0.3
Epoch: 656 	Training Loss: 1.191857 	Validation Loss: 1.358208 	 time: 0.3
Epoch: 657 	Training Loss: 1.191790 	Validation Loss: 1.358011 	 time: 0.3
Epoch: 658 	Training Loss: 1.191723 	Validation Loss: 1.357976 	 time: 0.3
Epoch: 659 	Training Loss: 1.191660 	Validation Loss: 1.357800 	 time: 0.3
Validation loss decreased from 1.357826 to 1.357800. Model was saved
Epoch: 660 	Training Loss: 1.191597 	Validation Loss: 1.357865 	 time: 0.3
Epoch: 661 	Training Loss: 1.191537 	Validation Loss: 1.357858 	 time: 0.3
Epoch: 662 	Training Loss: 1.191483 	Validation Loss: 1.357669 	 time: 0.3
Validation loss decreased from 1.357800 to 1.357669. Model was saved
Epoch: 663 	Training Loss: 1.191429 	Validation Loss: 1.357682 	 time: 0.3
Epoch: 664 	Training Loss: 1.191374 	Validation Loss: 1.357641 	 time: 0.3
Validation loss decreased from 1.357669 to 1.357641. Model was saved
Epoch: 665 	Training Loss: 1.191315 	Validation Loss: 1.357643 	 time: 0.3
Epoch: 666 	Training Loss: 1.191255 	Validation Loss: 1.357561 	 time: 0.3
Validation loss decreased from 1.357641 to 1.357561. Model was saved
Epoch: 667 	Training Loss: 1.191196 	Validation Loss: 1.357463 	 time: 0.3
Validation loss decreased from 1.357561 to 1.357463. Model was saved
Epoch: 668 	Training Loss: 1.191139 	Validation Loss: 1.357482 	 time: 0.3
Epoch: 669 	Training Loss: 1.191086 	Validation Loss: 1.357474 	 time: 0.3
Epoch: 670 	Training Loss: 1.191034 	Validation Loss: 1.357308 	 time: 0.3
Validation loss decreased from 1.357463 to 1.357308. Model was saved
Epoch: 671 	Training Loss: 1.190980 	Validation Loss: 1.357114 	 time: 0.3
Validation loss decreased from 1.357308 to 1.357114. Model was saved
Epoch: 672 	Training Loss: 1.190924 	Validation Loss: 1.357036 	 time: 0.3
Validation loss decreased from 1.357114 to 1.357036. Model was saved
Epoch: 673 	Training Loss: 1.190862 	Validation Loss: 1.356942 	 time: 0.3
Validation loss decreased from 1.357036 to 1.356942. Model was saved
Epoch: 674 	Training Loss: 1.190790 	Validation Loss: 1.356899 	 time: 0.3
Validation loss decreased from 1.356942 to 1.356899. Model was saved
Epoch: 675 	Training Loss: 1.190713 	Validation Loss: 1.356834 	 time: 0.3
Validation loss decreased from 1.356899 to 1.356834. Model was saved
Epoch: 676 	Training Loss: 1.190643 	Validation Loss: 1.356931 	 time: 0.3
Epoch: 677 	Training Loss: 1.190589 	Validation Loss: 1.357236 	 time: 0.3
Epoch: 678 	Training Loss: 1.190543 	Validation Loss: 1.357497 	 time: 0.3
Epoch: 679 	Training Loss: 1.190500 	Validation Loss: 1.357783 	 time: 0.3
Epoch: 680 	Training Loss: 1.190455 	Validation Loss: 1.357957 	 time: 0.3
Epoch: 681 	Training Loss: 1.190410 	Validation Loss: 1.358115 	 time: 0.3
Epoch: 682 	Training Loss: 1.190363 	Validation Loss: 1.358203 	 time: 0.3
Epoch: 683 	Training Loss: 1.190314 	Validation Loss: 1.358103 	 time: 0.3
Epoch: 684 	Training Loss: 1.190267 	Validation Loss: 1.358004 	 time: 0.3
Epoch: 685 	Training Loss: 1.190222 	Validation Loss: 1.357845 	 time: 0.3
Epoch: 686 	Training Loss: 1.190179 	Validation Loss: 1.357687 	 time: 0.3
Epoch: 687 	Training Loss: 1.190137 	Validation Loss: 1.357482 	 time: 0.3
Epoch: 688 	Training Loss: 1.190095 	Validation Loss: 1.357258 	 time: 0.3
Epoch: 689 	Training Loss: 1.190052 	Validation Loss: 1.357098 	 time: 0.3
Epoch: 690 	Training Loss: 1.190008 	Validation Loss: 1.356955 	 time: 0.3
Epoch: 691 	Training Loss: 1.189964 	Validation Loss: 1.356815 	 time: 0.2
Validation loss decreased from 1.356834 to 1.356815. Model was saved
Epoch: 692 	Training Loss: 1.189920 	Validation Loss: 1.356668 	 time: 0.3
Validation loss decreased from 1.356815 to 1.356668. Model was saved
Epoch: 693 	Training Loss: 1.189874 	Validation Loss: 1.356569 	 time: 0.3
Validation loss decreased from 1.356668 to 1.356569. Model was saved
Epoch: 694 	Training Loss: 1.189828 	Validation Loss: 1.356475 	 time: 0.3
Validation loss decreased from 1.356569 to 1.356475. Model was saved
Epoch: 695 	Training Loss: 1.189781 	Validation Loss: 1.356408 	 time: 0.3
Validation loss decreased from 1.356475 to 1.356408. Model was saved
Epoch: 696 	Training Loss: 1.189737 	Validation Loss: 1.356338 	 time: 0.3
Validation loss decreased from 1.356408 to 1.356338. Model was saved
Epoch: 697 	Training Loss: 1.189697 	Validation Loss: 1.356304 	 time: 0.3
Validation loss decreased from 1.356338 to 1.356304. Model was saved
Epoch: 698 	Training Loss: 1.189662 	Validation Loss: 1.356328 	 time: 0.3
Epoch: 699 	Training Loss: 1.189628 	Validation Loss: 1.356318 	 time: 0.3
Epoch: 700 	Training Loss: 1.189595 	Validation Loss: 1.356320 	 time: 0.3
Epoch: 701 	Training Loss: 1.189563 	Validation Loss: 1.356317 	 time: 0.3
Epoch: 702 	Training Loss: 1.189531 	Validation Loss: 1.356353 	 time: 0.3
Epoch: 703 	Training Loss: 1.189500 	Validation Loss: 1.356427 	 time: 0.3
Epoch: 704 	Training Loss: 1.189468 	Validation Loss: 1.356481 	 time: 0.3
Epoch: 705 	Training Loss: 1.189437 	Validation Loss: 1.356551 	 time: 0.3
Epoch: 706 	Training Loss: 1.189405 	Validation Loss: 1.356620 	 time: 0.2
Epoch: 707 	Training Loss: 1.189373 	Validation Loss: 1.356690 	 time: 0.3
Epoch: 708 	Training Loss: 1.189340 	Validation Loss: 1.356744 	 time: 0.3
Epoch: 709 	Training Loss: 1.189307 	Validation Loss: 1.356785 	 time: 0.2
Epoch: 710 	Training Loss: 1.189273 	Validation Loss: 1.356827 	 time: 0.3
Epoch: 711 	Training Loss: 1.189239 	Validation Loss: 1.356852 	 time: 0.3
Epoch: 712 	Training Loss: 1.189203 	Validation Loss: 1.356822 	 time: 0.3
Epoch: 713 	Training Loss: 1.189165 	Validation Loss: 1.356703 	 time: 0.3
Epoch: 714 	Training Loss: 1.189122 	Validation Loss: 1.356508 	 time: 0.3
Epoch: 715 	Training Loss: 1.189070 	Validation Loss: 1.356226 	 time: 0.3
Validation loss decreased from 1.356304 to 1.356226. Model was saved
Epoch: 716 	Training Loss: 1.189013 	Validation Loss: 1.355921 	 time: 0.3
Validation loss decreased from 1.356226 to 1.355921. Model was saved
Epoch: 717 	Training Loss: 1.188969 	Validation Loss: 1.355611 	 time: 0.3
Validation loss decreased from 1.355921 to 1.355611. Model was saved
Epoch: 718 	Training Loss: 1.188933 	Validation Loss: 1.355457 	 time: 0.3
Validation loss decreased from 1.355611 to 1.355457. Model was saved
Epoch: 719 	Training Loss: 1.188897 	Validation Loss: 1.355344 	 time: 0.3
Validation loss decreased from 1.355457 to 1.355344. Model was saved
Epoch: 720 	Training Loss: 1.188860 	Validation Loss: 1.355258 	 time: 0.3
Validation loss decreased from 1.355344 to 1.355258. Model was saved
Epoch: 721 	Training Loss: 1.188821 	Validation Loss: 1.355195 	 time: 0.3
Validation loss decreased from 1.355258 to 1.355195. Model was saved
Epoch: 722 	Training Loss: 1.188779 	Validation Loss: 1.355178 	 time: 0.3
Validation loss decreased from 1.355195 to 1.355178. Model was saved
Epoch: 723 	Training Loss: 1.188734 	Validation Loss: 1.355325 	 time: 0.3
Epoch: 724 	Training Loss: 1.188687 	Validation Loss: 1.355427 	 time: 0.3
Epoch: 725 	Training Loss: 1.188640 	Validation Loss: 1.355588 	 time: 0.3
Epoch: 726 	Training Loss: 1.188594 	Validation Loss: 1.355710 	 time: 0.3
Epoch: 727 	Training Loss: 1.188550 	Validation Loss: 1.355841 	 time: 0.2
Epoch: 728 	Training Loss: 1.188505 	Validation Loss: 1.355905 	 time: 0.2
Epoch: 729 	Training Loss: 1.188459 	Validation Loss: 1.355871 	 time: 0.3
Epoch: 730 	Training Loss: 1.188409 	Validation Loss: 1.355842 	 time: 0.3
Epoch: 731 	Training Loss: 1.188352 	Validation Loss: 1.355832 	 time: 0.3
Epoch: 732 	Training Loss: 1.188289 	Validation Loss: 1.355874 	 time: 0.3
Epoch: 733 	Training Loss: 1.188220 	Validation Loss: 1.355876 	 time: 0.3
Epoch: 734 	Training Loss: 1.188152 	Validation Loss: 1.355944 	 time: 0.3
Epoch: 735 	Training Loss: 1.188090 	Validation Loss: 1.355979 	 time: 0.3
Epoch: 736 	Training Loss: 1.188035 	Validation Loss: 1.356072 	 time: 0.3
Epoch: 737 	Training Loss: 1.187986 	Validation Loss: 1.356098 	 time: 0.3
Epoch: 738 	Training Loss: 1.187938 	Validation Loss: 1.356215 	 time: 0.3
Epoch: 739 	Training Loss: 1.187892 	Validation Loss: 1.356313 	 time: 0.3
Epoch: 740 	Training Loss: 1.187847 	Validation Loss: 1.356470 	 time: 0.3
Epoch: 741 	Training Loss: 1.187802 	Validation Loss: 1.356439 	 time: 0.3
Epoch: 742 	Training Loss: 1.187757 	Validation Loss: 1.356415 	 time: 0.3
Epoch: 743 	Training Loss: 1.187709 	Validation Loss: 1.356217 	 time: 0.3
Epoch: 744 	Training Loss: 1.187656 	Validation Loss: 1.356120 	 time: 0.3
Epoch: 745 	Training Loss: 1.187592 	Validation Loss: 1.355830 	 time: 0.3
Epoch: 746 	Training Loss: 1.187516 	Validation Loss: 1.355716 	 time: 0.3
Epoch: 747 	Training Loss: 1.187438 	Validation Loss: 1.355416 	 time: 0.3
Epoch: 748 	Training Loss: 1.187365 	Validation Loss: 1.355411 	 time: 0.3
Epoch: 749 	Training Loss: 1.187291 	Validation Loss: 1.355263 	 time: 0.3
Epoch: 750 	Training Loss: 1.187213 	Validation Loss: 1.355361 	 time: 0.3
Epoch: 751 	Training Loss: 1.187130 	Validation Loss: 1.355239 	 time: 0.3
Epoch: 752 	Training Loss: 1.187038 	Validation Loss: 1.355479 	 time: 0.3
Epoch: 753 	Training Loss: 1.186941 	Validation Loss: 1.355315 	 time: 0.3
Epoch: 754 	Training Loss: 1.186853 	Validation Loss: 1.355661 	 time: 0.3
Epoch: 755 	Training Loss: 1.186787 	Validation Loss: 1.355383 	 time: 0.3
Epoch: 756 	Training Loss: 1.186738 	Validation Loss: 1.355968 	 time: 0.3
Epoch: 757 	Training Loss: 1.186698 	Validation Loss: 1.355240 	 time: 0.3
Epoch: 758 	Training Loss: 1.186661 	Validation Loss: 1.356109 	 time: 0.3
Epoch: 759 	Training Loss: 1.186629 	Validation Loss: 1.354633 	 time: 0.3
Validation loss decreased from 1.355178 to 1.354633. Model was saved
Epoch: 760 	Training Loss: 1.186609 	Validation Loss: 1.356616 	 time: 0.3
Epoch: 761 	Training Loss: 1.186607 	Validation Loss: 1.354396 	 time: 0.3
Validation loss decreased from 1.354633 to 1.354396. Model was saved
Epoch: 762 	Training Loss: 1.186648 	Validation Loss: 1.358025 	 time: 0.3
Epoch: 763 	Training Loss: 1.186749 	Validation Loss: 1.354125 	 time: 0.3
Validation loss decreased from 1.354396 to 1.354125. Model was saved
Epoch: 764 	Training Loss: 1.187096 	Validation Loss: 1.361110 	 time: 0.3
Epoch: 765 	Training Loss: 1.187923 	Validation Loss: 1.353136 	 time: 0.3
Validation loss decreased from 1.354125 to 1.353136. Model was saved
Epoch: 766 	Training Loss: 1.188554 	Validation Loss: 1.360696 	 time: 0.3
Epoch: 767 	Training Loss: 1.186801 	Validation Loss: 1.359002 	 time: 0.3
Epoch: 768 	Training Loss: 1.186802 	Validation Loss: 1.354164 	 time: 0.3
Epoch: 769 	Training Loss: 1.187425 	Validation Loss: 1.359731 	 time: 0.3
Epoch: 770 	Training Loss: 1.186111 	Validation Loss: 1.361945 	 time: 0.3
Epoch: 771 	Training Loss: 1.186884 	Validation Loss: 1.356359 	 time: 0.3
Epoch: 772 	Training Loss: 1.186816 	Validation Loss: 1.360391 	 time: 0.3
Epoch: 773 	Training Loss: 1.186064 	Validation Loss: 1.360701 	 time: 0.3
Epoch: 774 	Training Loss: 1.186676 	Validation Loss: 1.356241 	 time: 0.3
Epoch: 775 	Training Loss: 1.186212 	Validation Loss: 1.360034 	 time: 0.3
Epoch: 776 	Training Loss: 1.186180 	Validation Loss: 1.360346 	 time: 0.3
Epoch: 777 	Training Loss: 1.186270 	Validation Loss: 1.356295 	 time: 0.2
Epoch: 778 	Training Loss: 1.185894 	Validation Loss: 1.359216 	 time: 0.3
Epoch: 779 	Training Loss: 1.186109 	Validation Loss: 1.360816 	 time: 0.3
Epoch: 780 	Training Loss: 1.185816 	Validation Loss: 1.357983 	 time: 0.3
Epoch: 781 	Training Loss: 1.185862 	Validation Loss: 1.359636 	 time: 0.3
Epoch: 782 	Training Loss: 1.185804 	Validation Loss: 1.360133 	 time: 0.2
Epoch: 783 	Training Loss: 1.185619 	Validation Loss: 1.357304 	 time: 0.3
Epoch: 784 	Training Loss: 1.185758 	Validation Loss: 1.358521 	 time: 0.3
Epoch: 785 	Training Loss: 1.185481 	Validation Loss: 1.361359 	 time: 0.2
Epoch: 786 	Training Loss: 1.185654 	Validation Loss: 1.357099 	 time: 0.3
Epoch: 787 	Training Loss: 1.185524 	Validation Loss: 1.357522 	 time: 0.3
Epoch: 788 	Training Loss: 1.185412 	Validation Loss: 1.361350 	 time: 0.3
Epoch: 789 	Training Loss: 1.185518 	Validation Loss: 1.358431 	 time: 0.3
Epoch: 790 	Training Loss: 1.185301 	Validation Loss: 1.358342 	 time: 0.3
Epoch: 791 	Training Loss: 1.185367 	Validation Loss: 1.360116 	 time: 0.3
Epoch: 792 	Training Loss: 1.185267 	Validation Loss: 1.358182 	 time: 0.3
Epoch: 793 	Training Loss: 1.185242 	Validation Loss: 1.357982 	 time: 0.3
Epoch: 794 	Training Loss: 1.185215 	Validation Loss: 1.359514 	 time: 0.3
Epoch: 795 	Training Loss: 1.185125 	Validation Loss: 1.358899 	 time: 0.3
Epoch: 796 	Training Loss: 1.185156 	Validation Loss: 1.358130 	 time: 0.3
Epoch: 797 	Training Loss: 1.185035 	Validation Loss: 1.358619 	 time: 0.3
Epoch: 798 	Training Loss: 1.185062 	Validation Loss: 1.358704 	 time: 0.3
Epoch: 799 	Training Loss: 1.185009 	Validation Loss: 1.359136 	 time: 0.3
Epoch: 800 	Training Loss: 1.184961 	Validation Loss: 1.358626 	 time: 0.3
Epoch: 801 	Training Loss: 1.184967 	Validation Loss: 1.357821 	 time: 0.3
Epoch: 802 	Training Loss: 1.184893 	Validation Loss: 1.358805 	 time: 0.3
Epoch: 803 	Training Loss: 1.184898 	Validation Loss: 1.358864 	 time: 0.3
Epoch: 804 	Training Loss: 1.184843 	Validation Loss: 1.358121 	 time: 0.3
Epoch: 805 	Training Loss: 1.184825 	Validation Loss: 1.359300 	 time: 0.3
Epoch: 806 	Training Loss: 1.184794 	Validation Loss: 1.359581 	 time: 0.3
Epoch: 807 	Training Loss: 1.184755 	Validation Loss: 1.358701 	 time: 0.3
Epoch: 808 	Training Loss: 1.184747 	Validation Loss: 1.360061 	 time: 0.3
Epoch: 809 	Training Loss: 1.184695 	Validation Loss: 1.361190 	 time: 0.3
Epoch: 810 	Training Loss: 1.184691 	Validation Loss: 1.359934 	 time: 0.3
Epoch: 811 	Training Loss: 1.184657 	Validation Loss: 1.360500 	 time: 0.3
Epoch: 812 	Training Loss: 1.184630 	Validation Loss: 1.361702 	 time: 0.3
Epoch: 813 	Training Loss: 1.184611 	Validation Loss: 1.361040 	 time: 0.3
Epoch: 814 	Training Loss: 1.184574 	Validation Loss: 1.361114 	 time: 0.3
Epoch: 815 	Training Loss: 1.184557 	Validation Loss: 1.361748 	 time: 0.3
Epoch: 816 	Training Loss: 1.184519 	Validation Loss: 1.361617 	 time: 0.3
Epoch: 817 	Training Loss: 1.184497 	Validation Loss: 1.361723 	 time: 0.3
Epoch: 818 	Training Loss: 1.184463 	Validation Loss: 1.361984 	 time: 0.3
Epoch: 819 	Training Loss: 1.184433 	Validation Loss: 1.362047 	 time: 0.3
Epoch: 820 	Training Loss: 1.184410 	Validation Loss: 1.362082 	 time: 0.3
Epoch: 821 	Training Loss: 1.184376 	Validation Loss: 1.361822 	 time: 0.3
Epoch: 822 	Training Loss: 1.184353 	Validation Loss: 1.361950 	 time: 0.3
Epoch: 823 	Training Loss: 1.184318 	Validation Loss: 1.362406 	 time: 0.3
Epoch: 824 	Training Loss: 1.184283 	Validation Loss: 1.361988 	 time: 0.3
Epoch: 825 	Training Loss: 1.184244 	Validation Loss: 1.361948 	 time: 0.3
Epoch: 826 	Training Loss: 1.184203 	Validation Loss: 1.362620 	 time: 0.3
Epoch: 827 	Training Loss: 1.184173 	Validation Loss: 1.362430 	 time: 0.3
Epoch: 828 	Training Loss: 1.184141 	Validation Loss: 1.362306 	 time: 0.3
Epoch: 829 	Training Loss: 1.184115 	Validation Loss: 1.362940 	 time: 0.3
Epoch: 830 	Training Loss: 1.184082 	Validation Loss: 1.363032 	 time: 0.3
Epoch: 831 	Training Loss: 1.184046 	Validation Loss: 1.363039 	 time: 0.3
Epoch: 832 	Training Loss: 1.184004 	Validation Loss: 1.363709 	 time: 0.3
Epoch: 833 	Training Loss: 1.183953 	Validation Loss: 1.364161 	 time: 0.3
Epoch: 834 	Training Loss: 1.183902 	Validation Loss: 1.364365 	 time: 0.3
Epoch: 835 	Training Loss: 1.183853 	Validation Loss: 1.364774 	 time: 0.3
Epoch: 836 	Training Loss: 1.183815 	Validation Loss: 1.364920 	 time: 0.3
Epoch: 837 	Training Loss: 1.183787 	Validation Loss: 1.364935 	 time: 0.3
Epoch: 838 	Training Loss: 1.183759 	Validation Loss: 1.364886 	 time: 0.3
Epoch: 839 	Training Loss: 1.183726 	Validation Loss: 1.364794 	 time: 0.3
Epoch: 840 	Training Loss: 1.183688 	Validation Loss: 1.364915 	 time: 0.3
Epoch: 841 	Training Loss: 1.183646 	Validation Loss: 1.364931 	 time: 0.3
Epoch: 842 	Training Loss: 1.183595 	Validation Loss: 1.364898 	 time: 0.3
Epoch: 843 	Training Loss: 1.183538 	Validation Loss: 1.365151 	 time: 0.3
Epoch: 844 	Training Loss: 1.183488 	Validation Loss: 1.365121 	 time: 0.3
Epoch: 845 	Training Loss: 1.183443 	Validation Loss: 1.364936 	 time: 0.3
Epoch: 846 	Training Loss: 1.183389 	Validation Loss: 1.365233 	 time: 0.3
Epoch: 847 	Training Loss: 1.183312 	Validation Loss: 1.365426 	 time: 0.3
Epoch: 848 	Training Loss: 1.183241 	Validation Loss: 1.365335 	 time: 0.3
Epoch: 849 	Training Loss: 1.183201 	Validation Loss: 1.365780 	 time: 0.3
Epoch: 850 	Training Loss: 1.183172 	Validation Loss: 1.366009 	 time: 0.3
Epoch: 851 	Training Loss: 1.183144 	Validation Loss: 1.365853 	 time: 0.3
Epoch: 852 	Training Loss: 1.183115 	Validation Loss: 1.365810 	 time: 0.3
Epoch: 853 	Training Loss: 1.183087 	Validation Loss: 1.365424 	 time: 0.3
Epoch: 854 	Training Loss: 1.183059 	Validation Loss: 1.365042 	 time: 0.3
Epoch: 855 	Training Loss: 1.183032 	Validation Loss: 1.364904 	 time: 0.3
Epoch: 856 	Training Loss: 1.183009 	Validation Loss: 1.364719 	 time: 0.3
Epoch: 857 	Training Loss: 1.182986 	Validation Loss: 1.364730 	 time: 0.3
Epoch: 858 	Training Loss: 1.182964 	Validation Loss: 1.364772 	 time: 0.3
Epoch: 859 	Training Loss: 1.182942 	Validation Loss: 1.364634 	 time: 0.3
Epoch: 860 	Training Loss: 1.182918 	Validation Loss: 1.364685 	 time: 0.3
Epoch: 861 	Training Loss: 1.182896 	Validation Loss: 1.364672 	 time: 0.3
Epoch: 862 	Training Loss: 1.182872 	Validation Loss: 1.364490 	 time: 0.3
Epoch: 863 	Training Loss: 1.182846 	Validation Loss: 1.364563 	 time: 0.3
Epoch: 864 	Training Loss: 1.182820 	Validation Loss: 1.364620 	 time: 0.3
Epoch: 865 	Training Loss: 1.182794 	Validation Loss: 1.364556 	 time: 0.3
Epoch: 866 	Training Loss: 1.182768 	Validation Loss: 1.364699 	 time: 0.3
Epoch: 867 	Training Loss: 1.182743 	Validation Loss: 1.364787 	 time: 0.3
Epoch: 868 	Training Loss: 1.182719 	Validation Loss: 1.364723 	 time: 0.3
Epoch: 869 	Training Loss: 1.182696 	Validation Loss: 1.364760 	 time: 0.3
Epoch: 870 	Training Loss: 1.182674 	Validation Loss: 1.364710 	 time: 0.3
Epoch: 871 	Training Loss: 1.182651 	Validation Loss: 1.364552 	 time: 0.3
Epoch: 872 	Training Loss: 1.182628 	Validation Loss: 1.364436 	 time: 0.3
Epoch: 873 	Training Loss: 1.182606 	Validation Loss: 1.364281 	 time: 0.3
Epoch: 874 	Training Loss: 1.182583 	Validation Loss: 1.364178 	 time: 0.3
Epoch: 875 	Training Loss: 1.182561 	Validation Loss: 1.364146 	 time: 0.3
Epoch: 876 	Training Loss: 1.182538 	Validation Loss: 1.364063 	 time: 0.3
Epoch: 877 	Training Loss: 1.182516 	Validation Loss: 1.364039 	 time: 0.3
Epoch: 878 	Training Loss: 1.182493 	Validation Loss: 1.364012 	 time: 0.3
Epoch: 879 	Training Loss: 1.182470 	Validation Loss: 1.363888 	 time: 0.3
Epoch: 880 	Training Loss: 1.182445 	Validation Loss: 1.363843 	 time: 0.3
Epoch: 881 	Training Loss: 1.182419 	Validation Loss: 1.363821 	 time: 0.2
Epoch: 882 	Training Loss: 1.182389 	Validation Loss: 1.363745 	 time: 0.3
Epoch: 883 	Training Loss: 1.182356 	Validation Loss: 1.363770 	 time: 0.3
Epoch: 884 	Training Loss: 1.182315 	Validation Loss: 1.363786 	 time: 0.3
Epoch: 885 	Training Loss: 1.182268 	Validation Loss: 1.363639 	 time: 0.3
Epoch: 886 	Training Loss: 1.182227 	Validation Loss: 1.363486 	 time: 0.3
Epoch: 887 	Training Loss: 1.182193 	Validation Loss: 1.363340 	 time: 0.3
Epoch: 888 	Training Loss: 1.182165 	Validation Loss: 1.363115 	 time: 0.3
Epoch: 889 	Training Loss: 1.182136 	Validation Loss: 1.362939 	 time: 0.3
Epoch: 890 	Training Loss: 1.182106 	Validation Loss: 1.362814 	 time: 0.3
Epoch: 891 	Training Loss: 1.182077 	Validation Loss: 1.362721 	 time: 0.3
Epoch: 892 	Training Loss: 1.182048 	Validation Loss: 1.362706 	 time: 0.3
Epoch: 893 	Training Loss: 1.182019 	Validation Loss: 1.362719 	 time: 0.3
Epoch: 894 	Training Loss: 1.181988 	Validation Loss: 1.362775 	 time: 0.3
Epoch: 895 	Training Loss: 1.181950 	Validation Loss: 1.362847 	 time: 0.3
Epoch: 896 	Training Loss: 1.181903 	Validation Loss: 1.362802 	 time: 0.3
Epoch: 897 	Training Loss: 1.181865 	Validation Loss: 1.362677 	 time: 0.3
Epoch: 898 	Training Loss: 1.181844 	Validation Loss: 1.362577 	 time: 0.3
Epoch: 899 	Training Loss: 1.181823 	Validation Loss: 1.362458 	 time: 0.3
Epoch: 900 	Training Loss: 1.181791 	Validation Loss: 1.362424 	 time: 0.3
Epoch: 901 	Training Loss: 1.181758 	Validation Loss: 1.362544 	 time: 0.3
Epoch: 902 	Training Loss: 1.181728 	Validation Loss: 1.362741 	 time: 0.3
Epoch: 903 	Training Loss: 1.181700 	Validation Loss: 1.362984 	 time: 0.3
Epoch: 904 	Training Loss: 1.181676 	Validation Loss: 1.363183 	 time: 0.3
Epoch: 905 	Training Loss: 1.181650 	Validation Loss: 1.363267 	 time: 0.3
Epoch: 906 	Training Loss: 1.181623 	Validation Loss: 1.363284 	 time: 0.3
Epoch: 907 	Training Loss: 1.181594 	Validation Loss: 1.363267 	 time: 0.3
Epoch: 908 	Training Loss: 1.181562 	Validation Loss: 1.363294 	 time: 0.3
Epoch: 909 	Training Loss: 1.181525 	Validation Loss: 1.363386 	 time: 0.3
Epoch: 910 	Training Loss: 1.181480 	Validation Loss: 1.363451 	 time: 0.3
Epoch: 911 	Training Loss: 1.181441 	Validation Loss: 1.363553 	 time: 0.3
Epoch: 912 	Training Loss: 1.181412 	Validation Loss: 1.363714 	 time: 0.3
Epoch: 913 	Training Loss: 1.181387 	Validation Loss: 1.363756 	 time: 0.3
Epoch: 914 	Training Loss: 1.181358 	Validation Loss: 1.363807 	 time: 0.3
Epoch: 915 	Training Loss: 1.181331 	Validation Loss: 1.363938 	 time: 0.3
Epoch: 916 	Training Loss: 1.181301 	Validation Loss: 1.364085 	 time: 0.3
Epoch: 917 	Training Loss: 1.181270 	Validation Loss: 1.364279 	 time: 0.3
Epoch: 918 	Training Loss: 1.181237 	Validation Loss: 1.364458 	 time: 0.3
Epoch: 919 	Training Loss: 1.181200 	Validation Loss: 1.364541 	 time: 0.2
Epoch: 920 	Training Loss: 1.181162 	Validation Loss: 1.364500 	 time: 0.3
Epoch: 921 	Training Loss: 1.181125 	Validation Loss: 1.364363 	 time: 0.3
Epoch: 922 	Training Loss: 1.181086 	Validation Loss: 1.364215 	 time: 0.3
Epoch: 923 	Training Loss: 1.181044 	Validation Loss: 1.363991 	 time: 0.3
Epoch: 924 	Training Loss: 1.181008 	Validation Loss: 1.363747 	 time: 0.3
Epoch: 925 	Training Loss: 1.180976 	Validation Loss: 1.363664 	 time: 0.3
Epoch: 926 	Training Loss: 1.180941 	Validation Loss: 1.363563 	 time: 0.3
Epoch: 927 	Training Loss: 1.180895 	Validation Loss: 1.363416 	 time: 0.3
Epoch: 928 	Training Loss: 1.180842 	Validation Loss: 1.363317 	 time: 0.3
Epoch: 929 	Training Loss: 1.180795 	Validation Loss: 1.363202 	 time: 0.3
Epoch: 930 	Training Loss: 1.180760 	Validation Loss: 1.363214 	 time: 0.3
Epoch: 931 	Training Loss: 1.180727 	Validation Loss: 1.363342 	 time: 0.3
Epoch: 932 	Training Loss: 1.180686 	Validation Loss: 1.363470 	 time: 0.3
Epoch: 933 	Training Loss: 1.180635 	Validation Loss: 1.363564 	 time: 0.3
Epoch: 934 	Training Loss: 1.180578 	Validation Loss: 1.363572 	 time: 0.3
Epoch: 935 	Training Loss: 1.180532 	Validation Loss: 1.363434 	 time: 0.3
Epoch: 936 	Training Loss: 1.180497 	Validation Loss: 1.363163 	 time: 0.3
Epoch: 937 	Training Loss: 1.180465 	Validation Loss: 1.362840 	 time: 0.3
Epoch: 938 	Training Loss: 1.180434 	Validation Loss: 1.362525 	 time: 0.3
Epoch: 939 	Training Loss: 1.180402 	Validation Loss: 1.362274 	 time: 0.3
Epoch: 940 	Training Loss: 1.180372 	Validation Loss: 1.362125 	 time: 0.3
Epoch: 941 	Training Loss: 1.180341 	Validation Loss: 1.362086 	 time: 0.3
Epoch: 942 	Training Loss: 1.180310 	Validation Loss: 1.362076 	 time: 0.3
Epoch: 943 	Training Loss: 1.180279 	Validation Loss: 1.362086 	 time: 0.3
Epoch: 944 	Training Loss: 1.180248 	Validation Loss: 1.362170 	 time: 0.3
Epoch: 945 	Training Loss: 1.180219 	Validation Loss: 1.362219 	 time: 0.3
Epoch: 946 	Training Loss: 1.180191 	Validation Loss: 1.362186 	 time: 0.3
Epoch: 947 	Training Loss: 1.180165 	Validation Loss: 1.362133 	 time: 0.3
Epoch: 948 	Training Loss: 1.180140 	Validation Loss: 1.362022 	 time: 0.3
Epoch: 949 	Training Loss: 1.180115 	Validation Loss: 1.361867 	 time: 0.3
Epoch: 950 	Training Loss: 1.180090 	Validation Loss: 1.361746 	 time: 0.3
Epoch: 951 	Training Loss: 1.180065 	Validation Loss: 1.361659 	 time: 0.3
Epoch: 952 	Training Loss: 1.180036 	Validation Loss: 1.361641 	 time: 0.3
Epoch: 953 	Training Loss: 1.180003 	Validation Loss: 1.361721 	 time: 0.3
Epoch: 954 	Training Loss: 1.179965 	Validation Loss: 1.361799 	 time: 0.3
Epoch: 955 	Training Loss: 1.179923 	Validation Loss: 1.361809 	 time: 0.3
Epoch: 956 	Training Loss: 1.179880 	Validation Loss: 1.362075 	 time: 0.3
Epoch: 957 	Training Loss: 1.179835 	Validation Loss: 1.362401 	 time: 0.3
Epoch: 958 	Training Loss: 1.179790 	Validation Loss: 1.362713 	 time: 0.3
Epoch: 959 	Training Loss: 1.179746 	Validation Loss: 1.362992 	 time: 0.3
Epoch: 960 	Training Loss: 1.179708 	Validation Loss: 1.362897 	 time: 0.3
Epoch: 961 	Training Loss: 1.179672 	Validation Loss: 1.362516 	 time: 0.3
Epoch: 962 	Training Loss: 1.179633 	Validation Loss: 1.361836 	 time: 0.3
Epoch: 963 	Training Loss: 1.179595 	Validation Loss: 1.361050 	 time: 0.3
Epoch: 964 	Training Loss: 1.179564 	Validation Loss: 1.360647 	 time: 0.3
Epoch: 965 	Training Loss: 1.179535 	Validation Loss: 1.360595 	 time: 0.2
Epoch: 966 	Training Loss: 1.179506 	Validation Loss: 1.360853 	 time: 0.3
Epoch: 967 	Training Loss: 1.179475 	Validation Loss: 1.361167 	 time: 0.3
Epoch: 968 	Training Loss: 1.179443 	Validation Loss: 1.361328 	 time: 0.3
Epoch: 969 	Training Loss: 1.179415 	Validation Loss: 1.361494 	 time: 0.3
Epoch: 970 	Training Loss: 1.179393 	Validation Loss: 1.361569 	 time: 0.3
Epoch: 971 	Training Loss: 1.179372 	Validation Loss: 1.361645 	 time: 0.3
Epoch: 972 	Training Loss: 1.179351 	Validation Loss: 1.361823 	 time: 0.3
Epoch: 973 	Training Loss: 1.179331 	Validation Loss: 1.361910 	 time: 0.3
Epoch: 974 	Training Loss: 1.179311 	Validation Loss: 1.362012 	 time: 0.3
Epoch: 975 	Training Loss: 1.179292 	Validation Loss: 1.362153 	 time: 0.3
Epoch: 976 	Training Loss: 1.179273 	Validation Loss: 1.362237 	 time: 0.3
Epoch: 977 	Training Loss: 1.179255 	Validation Loss: 1.362384 	 time: 0.3
Epoch: 978 	Training Loss: 1.179237 	Validation Loss: 1.362572 	 time: 0.2
Epoch: 979 	Training Loss: 1.179218 	Validation Loss: 1.362753 	 time: 0.3
Epoch: 980 	Training Loss: 1.179200 	Validation Loss: 1.362915 	 time: 0.3
Epoch: 981 	Training Loss: 1.179182 	Validation Loss: 1.362956 	 time: 0.3
Epoch: 982 	Training Loss: 1.179162 	Validation Loss: 1.362908 	 time: 0.2
Epoch: 983 	Training Loss: 1.179143 	Validation Loss: 1.362788 	 time: 0.3
Epoch: 984 	Training Loss: 1.179124 	Validation Loss: 1.362602 	 time: 0.2
Epoch: 985 	Training Loss: 1.179104 	Validation Loss: 1.362431 	 time: 0.3
Epoch: 986 	Training Loss: 1.179082 	Validation Loss: 1.362234 	 time: 0.2
Epoch: 987 	Training Loss: 1.179056 	Validation Loss: 1.362037 	 time: 0.3
Epoch: 988 	Training Loss: 1.179025 	Validation Loss: 1.361895 	 time: 0.3
Epoch: 989 	Training Loss: 1.178990 	Validation Loss: 1.361761 	 time: 0.3
Epoch: 990 	Training Loss: 1.178958 	Validation Loss: 1.361619 	 time: 0.3
Epoch: 991 	Training Loss: 1.178932 	Validation Loss: 1.361291 	 time: 0.3
Epoch: 992 	Training Loss: 1.178905 	Validation Loss: 1.360461 	 time: 0.3
Epoch: 993 	Training Loss: 1.178868 	Validation Loss: 1.359048 	 time: 0.3
Epoch: 994 	Training Loss: 1.178818 	Validation Loss: 1.358061 	 time: 0.3
Epoch: 995 	Training Loss: 1.178774 	Validation Loss: 1.357865 	 time: 0.3
Epoch: 996 	Training Loss: 1.178747 	Validation Loss: 1.357834 	 time: 0.3
Epoch: 997 	Training Loss: 1.178729 	Validation Loss: 1.357669 	 time: 0.3
Epoch: 998 	Training Loss: 1.178713 	Validation Loss: 1.357628 	 time: 0.3
Epoch: 999 	Training Loss: 1.178697 	Validation Loss: 1.357647 	 time: 0.3
Epoch: 1000 	Training Loss: 1.178680 	Validation Loss: 1.357603 	 time: 0.3
Epoch: 1001 	Training Loss: 1.178663 	Validation Loss: 1.357592 	 time: 0.3
Epoch: 1002 	Training Loss: 1.178645 	Validation Loss: 1.357493 	 time: 0.3
Epoch: 1003 	Training Loss: 1.178625 	Validation Loss: 1.357424 	 time: 0.3
Epoch: 1004 	Training Loss: 1.178604 	Validation Loss: 1.357366 	 time: 0.3
Epoch: 1005 	Training Loss: 1.178582 	Validation Loss: 1.357182 	 time: 0.2
Epoch: 1006 	Training Loss: 1.178561 	Validation Loss: 1.357064 	 time: 0.3
Epoch: 1007 	Training Loss: 1.178542 	Validation Loss: 1.357020 	 time: 0.3
Epoch: 1008 	Training Loss: 1.178523 	Validation Loss: 1.357016 	 time: 0.3
Epoch: 1009 	Training Loss: 1.178503 	Validation Loss: 1.357041 	 time: 0.3
Epoch: 1010 	Training Loss: 1.178484 	Validation Loss: 1.356979 	 time: 0.3
Epoch: 1011 	Training Loss: 1.178465 	Validation Loss: 1.356946 	 time: 0.3
Epoch: 1012 	Training Loss: 1.178446 	Validation Loss: 1.356986 	 time: 0.3
Epoch: 1013 	Training Loss: 1.178428 	Validation Loss: 1.357012 	 time: 0.3
Epoch: 1014 	Training Loss: 1.178409 	Validation Loss: 1.357055 	 time: 0.3
Epoch: 1015 	Training Loss: 1.178390 	Validation Loss: 1.357074 	 time: 0.3
Epoch: 1016 	Training Loss: 1.178370 	Validation Loss: 1.357090 	 time: 0.3
Epoch: 1017 	Training Loss: 1.178349 	Validation Loss: 1.357134 	 time: 0.3
Epoch: 1018 	Training Loss: 1.178329 	Validation Loss: 1.357089 	 time: 0.3
Epoch: 1019 	Training Loss: 1.178311 	Validation Loss: 1.356998 	 time: 0.3
Epoch: 1020 	Training Loss: 1.178293 	Validation Loss: 1.356935 	 time: 0.3
Epoch: 1021 	Training Loss: 1.178272 	Validation Loss: 1.356912 	 time: 0.3
Epoch: 1022 	Training Loss: 1.178247 	Validation Loss: 1.356959 	 time: 0.3
Epoch: 1023 	Training Loss: 1.178217 	Validation Loss: 1.356996 	 time: 0.3
Epoch: 1024 	Training Loss: 1.178190 	Validation Loss: 1.356974 	 time: 0.3
Epoch: 1025 	Training Loss: 1.178169 	Validation Loss: 1.357028 	 time: 0.3
Epoch: 1026 	Training Loss: 1.178142 	Validation Loss: 1.357108 	 time: 0.3
Epoch: 1027 	Training Loss: 1.178106 	Validation Loss: 1.357188 	 time: 0.3
Epoch: 1028 	Training Loss: 1.178061 	Validation Loss: 1.357226 	 time: 0.3
Epoch: 1029 	Training Loss: 1.178023 	Validation Loss: 1.357212 	 time: 0.3
Epoch: 1030 	Training Loss: 1.177998 	Validation Loss: 1.357237 	 time: 0.3
Epoch: 1031 	Training Loss: 1.177980 	Validation Loss: 1.357236 	 time: 0.3
Epoch: 1032 	Training Loss: 1.177967 	Validation Loss: 1.357170 	 time: 0.3
Epoch: 1033 	Training Loss: 1.177954 	Validation Loss: 1.357078 	 time: 0.3
Epoch: 1034 	Training Loss: 1.177942 	Validation Loss: 1.356975 	 time: 0.3
Epoch: 1035 	Training Loss: 1.177930 	Validation Loss: 1.356951 	 time: 0.3
Epoch: 1036 	Training Loss: 1.177917 	Validation Loss: 1.356963 	 time: 0.3
Epoch: 1037 	Training Loss: 1.177902 	Validation Loss: 1.356938 	 time: 0.3
Epoch: 1038 	Training Loss: 1.177887 	Validation Loss: 1.356964 	 time: 0.3
Epoch: 1039 	Training Loss: 1.177871 	Validation Loss: 1.357051 	 time: 0.3
Epoch: 1040 	Training Loss: 1.177855 	Validation Loss: 1.357141 	 time: 0.3
Epoch: 1041 	Training Loss: 1.177837 	Validation Loss: 1.357179 	 time: 0.3
Epoch: 1042 	Training Loss: 1.177815 	Validation Loss: 1.357145 	 time: 0.3
Epoch: 1043 	Training Loss: 1.177785 	Validation Loss: 1.357140 	 time: 0.3
Epoch: 1044 	Training Loss: 1.177751 	Validation Loss: 1.357273 	 time: 0.3
Epoch: 1045 	Training Loss: 1.177726 	Validation Loss: 1.357536 	 time: 0.3
Epoch: 1046 	Training Loss: 1.177712 	Validation Loss: 1.357801 	 time: 0.3
Epoch: 1047 	Training Loss: 1.177697 	Validation Loss: 1.357970 	 time: 0.3
Epoch: 1048 	Training Loss: 1.177677 	Validation Loss: 1.358084 	 time: 0.3
Epoch: 1049 	Training Loss: 1.177653 	Validation Loss: 1.358180 	 time: 0.3
Epoch: 1050 	Training Loss: 1.177632 	Validation Loss: 1.358132 	 time: 0.3
Epoch: 1051 	Training Loss: 1.177614 	Validation Loss: 1.357917 	 time: 0.3
Epoch: 1052 	Training Loss: 1.177597 	Validation Loss: 1.357711 	 time: 0.3
Epoch: 1053 	Training Loss: 1.177581 	Validation Loss: 1.357632 	 time: 0.3
Epoch: 1054 	Training Loss: 1.177564 	Validation Loss: 1.357660 	 time: 0.3
Epoch: 1055 	Training Loss: 1.177548 	Validation Loss: 1.357696 	 time: 0.3
Epoch: 1056 	Training Loss: 1.177532 	Validation Loss: 1.357688 	 time: 0.3
Epoch: 1057 	Training Loss: 1.177516 	Validation Loss: 1.357661 	 time: 0.3
Epoch: 1058 	Training Loss: 1.177501 	Validation Loss: 1.357623 	 time: 0.3
Epoch: 1059 	Training Loss: 1.177486 	Validation Loss: 1.357566 	 time: 0.3
Epoch: 1060 	Training Loss: 1.177471 	Validation Loss: 1.357494 	 time: 0.3
Epoch: 1061 	Training Loss: 1.177456 	Validation Loss: 1.357463 	 time: 0.3
Epoch: 1062 	Training Loss: 1.177439 	Validation Loss: 1.357498 	 time: 0.3
Epoch: 1063 	Training Loss: 1.177421 	Validation Loss: 1.357511 	 time: 0.3
Epoch: 1064 	Training Loss: 1.177401 	Validation Loss: 1.357405 	 time: 0.3
Epoch: 1065 	Training Loss: 1.177379 	Validation Loss: 1.357107 	 time: 0.3
Epoch: 1066 	Training Loss: 1.177354 	Validation Loss: 1.356647 	 time: 0.3
Epoch: 1067 	Training Loss: 1.177326 	Validation Loss: 1.356205 	 time: 0.3
Epoch: 1068 	Training Loss: 1.177297 	Validation Loss: 1.355946 	 time: 0.2
Epoch: 1069 	Training Loss: 1.177270 	Validation Loss: 1.355940 	 time: 0.3
Epoch: 1070 	Training Loss: 1.177247 	Validation Loss: 1.356164 	 time: 0.3
Epoch: 1071 	Training Loss: 1.177228 	Validation Loss: 1.356431 	 time: 0.3
Epoch: 1072 	Training Loss: 1.177210 	Validation Loss: 1.356623 	 time: 0.3
Epoch: 1073 	Training Loss: 1.177193 	Validation Loss: 1.356641 	 time: 0.3
Epoch: 1074 	Training Loss: 1.177175 	Validation Loss: 1.356538 	 time: 0.3
Epoch: 1075 	Training Loss: 1.177157 	Validation Loss: 1.356428 	 time: 0.3
Epoch: 1076 	Training Loss: 1.177140 	Validation Loss: 1.356310 	 time: 0.3
Epoch: 1077 	Training Loss: 1.177125 	Validation Loss: 1.356180 	 time: 0.3
Epoch: 1078 	Training Loss: 1.177110 	Validation Loss: 1.356052 	 time: 0.3
Epoch: 1079 	Training Loss: 1.177093 	Validation Loss: 1.355960 	 time: 0.3
Epoch: 1080 	Training Loss: 1.177078 	Validation Loss: 1.355863 	 time: 0.3
Epoch: 1081 	Training Loss: 1.177062 	Validation Loss: 1.355711 	 time: 0.3
Epoch: 1082 	Training Loss: 1.177047 	Validation Loss: 1.355532 	 time: 0.3
Epoch: 1083 	Training Loss: 1.177032 	Validation Loss: 1.355346 	 time: 0.3
Epoch: 1084 	Training Loss: 1.177018 	Validation Loss: 1.355229 	 time: 0.3
Epoch: 1085 	Training Loss: 1.177004 	Validation Loss: 1.355231 	 time: 0.3
Epoch: 1086 	Training Loss: 1.176991 	Validation Loss: 1.355325 	 time: 0.3
Epoch: 1087 	Training Loss: 1.176979 	Validation Loss: 1.355509 	 time: 0.3
Epoch: 1088 	Training Loss: 1.176967 	Validation Loss: 1.355718 	 time: 0.3
Epoch: 1089 	Training Loss: 1.176954 	Validation Loss: 1.355871 	 time: 0.3
Epoch: 1090 	Training Loss: 1.176942 	Validation Loss: 1.355943 	 time: 0.3
Epoch: 1091 	Training Loss: 1.176930 	Validation Loss: 1.355978 	 time: 0.3
Epoch: 1092 	Training Loss: 1.176919 	Validation Loss: 1.356039 	 time: 0.3
Epoch: 1093 	Training Loss: 1.176907 	Validation Loss: 1.356124 	 time: 0.3
Epoch: 1094 	Training Loss: 1.176895 	Validation Loss: 1.356217 	 time: 0.3
Epoch: 1095 	Training Loss: 1.176884 	Validation Loss: 1.356281 	 time: 0.3
Epoch: 1096 	Training Loss: 1.176872 	Validation Loss: 1.356290 	 time: 0.3
Epoch: 1097 	Training Loss: 1.176859 	Validation Loss: 1.356283 	 time: 0.3
Epoch: 1098 	Training Loss: 1.176845 	Validation Loss: 1.356277 	 time: 0.3
Epoch: 1099 	Training Loss: 1.176828 	Validation Loss: 1.356288 	 time: 0.3
Epoch: 1100 	Training Loss: 1.176806 	Validation Loss: 1.356320 	 time: 0.3
Epoch: 1101 	Training Loss: 1.176778 	Validation Loss: 1.356337 	 time: 0.3
Epoch: 1102 	Training Loss: 1.176742 	Validation Loss: 1.356325 	 time: 0.2
Epoch: 1103 	Training Loss: 1.176708 	Validation Loss: 1.356351 	 time: 0.3
Epoch: 1104 	Training Loss: 1.176678 	Validation Loss: 1.356381 	 time: 0.3
Epoch: 1105 	Training Loss: 1.176655 	Validation Loss: 1.356357 	 time: 0.3
Epoch: 1106 	Training Loss: 1.176638 	Validation Loss: 1.356313 	 time: 0.3
Epoch: 1107 	Training Loss: 1.176620 	Validation Loss: 1.356248 	 time: 0.3
Epoch: 1108 	Training Loss: 1.176602 	Validation Loss: 1.356219 	 time: 0.3
Epoch: 1109 	Training Loss: 1.176583 	Validation Loss: 1.356216 	 time: 0.3
Epoch: 1110 	Training Loss: 1.176564 	Validation Loss: 1.356181 	 time: 0.3
Epoch: 1111 	Training Loss: 1.176544 	Validation Loss: 1.356139 	 time: 0.3
Epoch: 1112 	Training Loss: 1.176522 	Validation Loss: 1.356064 	 time: 0.2
Epoch: 1113 	Training Loss: 1.176497 	Validation Loss: 1.355873 	 time: 0.3
Epoch: 1114 	Training Loss: 1.176473 	Validation Loss: 1.355535 	 time: 0.3
Epoch: 1115 	Training Loss: 1.176451 	Validation Loss: 1.355141 	 time: 0.3
Epoch: 1116 	Training Loss: 1.176429 	Validation Loss: 1.354835 	 time: 0.3
Epoch: 1117 	Training Loss: 1.176408 	Validation Loss: 1.354754 	 time: 0.3
Epoch: 1118 	Training Loss: 1.176388 	Validation Loss: 1.354811 	 time: 0.3
Epoch: 1119 	Training Loss: 1.176368 	Validation Loss: 1.354827 	 time: 0.3
Epoch: 1120 	Training Loss: 1.176338 	Validation Loss: 1.354637 	 time: 0.3
Epoch: 1121 	Training Loss: 1.176296 	Validation Loss: 1.354122 	 time: 0.3
Epoch: 1122 	Training Loss: 1.176268 	Validation Loss: 1.353766 	 time: 0.3
Epoch: 1123 	Training Loss: 1.176253 	Validation Loss: 1.353734 	 time: 0.3
Epoch: 1124 	Training Loss: 1.176237 	Validation Loss: 1.353817 	 time: 0.3
Epoch: 1125 	Training Loss: 1.176219 	Validation Loss: 1.354308 	 time: 0.3
Epoch: 1126 	Training Loss: 1.176199 	Validation Loss: 1.354609 	 time: 0.3
Epoch: 1127 	Training Loss: 1.176179 	Validation Loss: 1.354632 	 time: 0.3
Epoch: 1128 	Training Loss: 1.176160 	Validation Loss: 1.354216 	 time: 0.3
Epoch: 1129 	Training Loss: 1.176141 	Validation Loss: 1.353748 	 time: 0.3
Epoch: 1130 	Training Loss: 1.176121 	Validation Loss: 1.353452 	 time: 0.3
Epoch: 1131 	Training Loss: 1.176099 	Validation Loss: 1.353215 	 time: 0.3
Epoch: 1132 	Training Loss: 1.176077 	Validation Loss: 1.353174 	 time: 0.3
Epoch: 1133 	Training Loss: 1.176061 	Validation Loss: 1.352729 	 time: 0.3
Validation loss decreased from 1.353136 to 1.352729. Model was saved
Epoch: 1134 	Training Loss: 1.176047 	Validation Loss: 1.352468 	 time: 0.3
Validation loss decreased from 1.352729 to 1.352468. Model was saved
Epoch: 1135 	Training Loss: 1.176034 	Validation Loss: 1.352463 	 time: 0.3
Validation loss decreased from 1.352468 to 1.352463. Model was saved
Epoch: 1136 	Training Loss: 1.176022 	Validation Loss: 1.352708 	 time: 0.3
Epoch: 1137 	Training Loss: 1.176010 	Validation Loss: 1.353192 	 time: 0.3
Epoch: 1138 	Training Loss: 1.175998 	Validation Loss: 1.353564 	 time: 0.3
Epoch: 1139 	Training Loss: 1.175987 	Validation Loss: 1.353612 	 time: 0.3
Epoch: 1140 	Training Loss: 1.175976 	Validation Loss: 1.353285 	 time: 0.3
Epoch: 1141 	Training Loss: 1.175965 	Validation Loss: 1.352851 	 time: 0.3
Epoch: 1142 	Training Loss: 1.175954 	Validation Loss: 1.352609 	 time: 0.3
Epoch: 1143 	Training Loss: 1.175944 	Validation Loss: 1.352596 	 time: 0.3
Epoch: 1144 	Training Loss: 1.175933 	Validation Loss: 1.352746 	 time: 0.3
Epoch: 1145 	Training Loss: 1.175923 	Validation Loss: 1.352814 	 time: 0.3
Epoch: 1146 	Training Loss: 1.175913 	Validation Loss: 1.352800 	 time: 0.3
Epoch: 1147 	Training Loss: 1.175902 	Validation Loss: 1.352736 	 time: 0.2
Epoch: 1148 	Training Loss: 1.175890 	Validation Loss: 1.352596 	 time: 0.3
Epoch: 1149 	Training Loss: 1.175877 	Validation Loss: 1.352562 	 time: 0.3
Epoch: 1150 	Training Loss: 1.175858 	Validation Loss: 1.352696 	 time: 0.3
Epoch: 1151 	Training Loss: 1.175822 	Validation Loss: 1.352871 	 time: 0.3
Epoch: 1152 	Training Loss: 1.175794 	Validation Loss: 1.352432 	 time: 0.3
Validation loss decreased from 1.352463 to 1.352432. Model was saved
Epoch: 1153 	Training Loss: 1.175789 	Validation Loss: 1.353466 	 time: 0.3
Epoch: 1154 	Training Loss: 1.175760 	Validation Loss: 1.353628 	 time: 0.3
Epoch: 1155 	Training Loss: 1.175738 	Validation Loss: 1.353467 	 time: 0.3
Epoch: 1156 	Training Loss: 1.175720 	Validation Loss: 1.352614 	 time: 0.3
Epoch: 1157 	Training Loss: 1.175702 	Validation Loss: 1.351953 	 time: 0.2
Validation loss decreased from 1.352432 to 1.351953. Model was saved
Epoch: 1158 	Training Loss: 1.175693 	Validation Loss: 1.352043 	 time: 0.3
Epoch: 1159 	Training Loss: 1.175677 	Validation Loss: 1.352234 	 time: 0.3
Epoch: 1160 	Training Loss: 1.175654 	Validation Loss: 1.353370 	 time: 0.2
Epoch: 1161 	Training Loss: 1.175630 	Validation Loss: 1.353151 	 time: 0.2
Epoch: 1162 	Training Loss: 1.175599 	Validation Loss: 1.352725 	 time: 0.3
Epoch: 1163 	Training Loss: 1.175563 	Validation Loss: 1.352385 	 time: 0.2
Epoch: 1164 	Training Loss: 1.175539 	Validation Loss: 1.351928 	 time: 0.2
Validation loss decreased from 1.351953 to 1.351928. Model was saved
Epoch: 1165 	Training Loss: 1.175522 	Validation Loss: 1.352382 	 time: 0.2
Epoch: 1166 	Training Loss: 1.175508 	Validation Loss: 1.352824 	 time: 0.3
Epoch: 1167 	Training Loss: 1.175494 	Validation Loss: 1.353338 	 time: 0.3
Epoch: 1168 	Training Loss: 1.175478 	Validation Loss: 1.353393 	 time: 0.3
Epoch: 1169 	Training Loss: 1.175464 	Validation Loss: 1.353117 	 time: 0.3
Epoch: 1170 	Training Loss: 1.175448 	Validation Loss: 1.352746 	 time: 0.3
Epoch: 1171 	Training Loss: 1.175431 	Validation Loss: 1.352445 	 time: 0.3
Epoch: 1172 	Training Loss: 1.175413 	Validation Loss: 1.352836 	 time: 0.2
Epoch: 1173 	Training Loss: 1.175396 	Validation Loss: 1.352831 	 time: 0.3
Epoch: 1174 	Training Loss: 1.175379 	Validation Loss: 1.352850 	 time: 0.3
Epoch: 1175 	Training Loss: 1.175361 	Validation Loss: 1.352842 	 time: 0.3
Epoch: 1176 	Training Loss: 1.175343 	Validation Loss: 1.352414 	 time: 0.3
Epoch: 1177 	Training Loss: 1.175323 	Validation Loss: 1.352443 	 time: 0.3
Epoch: 1178 	Training Loss: 1.175304 	Validation Loss: 1.352406 	 time: 0.3
Epoch: 1179 	Training Loss: 1.175285 	Validation Loss: 1.352600 	 time: 0.3
Epoch: 1180 	Training Loss: 1.175265 	Validation Loss: 1.352944 	 time: 0.3
Epoch: 1181 	Training Loss: 1.175242 	Validation Loss: 1.353274 	 time: 0.3
Epoch: 1182 	Training Loss: 1.175210 	Validation Loss: 1.353704 	 time: 0.3
Epoch: 1183 	Training Loss: 1.175164 	Validation Loss: 1.353990 	 time: 0.2
Epoch: 1184 	Training Loss: 1.175113 	Validation Loss: 1.354547 	 time: 0.3
Epoch: 1185 	Training Loss: 1.175073 	Validation Loss: 1.354605 	 time: 0.3
Epoch: 1186 	Training Loss: 1.175043 	Validation Loss: 1.354443 	 time: 0.2
Epoch: 1187 	Training Loss: 1.175022 	Validation Loss: 1.354548 	 time: 0.3
Epoch: 1188 	Training Loss: 1.175003 	Validation Loss: 1.354451 	 time: 0.3
Epoch: 1189 	Training Loss: 1.174981 	Validation Loss: 1.354811 	 time: 0.3
Epoch: 1190 	Training Loss: 1.174958 	Validation Loss: 1.354746 	 time: 0.3
Epoch: 1191 	Training Loss: 1.174933 	Validation Loss: 1.354751 	 time: 0.3
Epoch: 1192 	Training Loss: 1.174904 	Validation Loss: 1.354616 	 time: 0.3
Epoch: 1193 	Training Loss: 1.174875 	Validation Loss: 1.354555 	 time: 0.3
Epoch: 1194 	Training Loss: 1.174857 	Validation Loss: 1.354338 	 time: 0.3
Epoch: 1195 	Training Loss: 1.174845 	Validation Loss: 1.354263 	 time: 0.3
Epoch: 1196 	Training Loss: 1.174831 	Validation Loss: 1.354445 	 time: 0.3
Epoch: 1197 	Training Loss: 1.174816 	Validation Loss: 1.354329 	 time: 0.3
Epoch: 1198 	Training Loss: 1.174802 	Validation Loss: 1.354242 	 time: 0.3
Epoch: 1199 	Training Loss: 1.174789 	Validation Loss: 1.354096 	 time: 0.3
Epoch: 1200 	Training Loss: 1.174777 	Validation Loss: 1.354061 	 time: 0.3
Epoch: 1201 	Training Loss: 1.174765 	Validation Loss: 1.354020 	 time: 0.3
Epoch: 1202 	Training Loss: 1.174752 	Validation Loss: 1.353987 	 time: 0.3
Epoch: 1203 	Training Loss: 1.174740 	Validation Loss: 1.354017 	 time: 0.3
Epoch: 1204 	Training Loss: 1.174730 	Validation Loss: 1.354048 	 time: 0.3
Epoch: 1205 	Training Loss: 1.174719 	Validation Loss: 1.354140 	 time: 0.3
Epoch: 1206 	Training Loss: 1.174707 	Validation Loss: 1.353907 	 time: 0.3
Epoch: 1207 	Training Loss: 1.174693 	Validation Loss: 1.353718 	 time: 0.3
Epoch: 1208 	Training Loss: 1.174675 	Validation Loss: 1.353654 	 time: 0.3
Epoch: 1209 	Training Loss: 1.174647 	Validation Loss: 1.353610 	 time: 0.3
Epoch: 1210 	Training Loss: 1.174605 	Validation Loss: 1.353659 	 time: 0.3
Epoch: 1211 	Training Loss: 1.174568 	Validation Loss: 1.353571 	 time: 0.3
Epoch: 1212 	Training Loss: 1.174551 	Validation Loss: 1.353334 	 time: 0.3
Epoch: 1213 	Training Loss: 1.174540 	Validation Loss: 1.353391 	 time: 0.2
Epoch: 1214 	Training Loss: 1.174528 	Validation Loss: 1.353348 	 time: 0.3
Epoch: 1215 	Training Loss: 1.174513 	Validation Loss: 1.353256 	 time: 0.3
Epoch: 1216 	Training Loss: 1.174488 	Validation Loss: 1.353191 	 time: 0.3
Epoch: 1217 	Training Loss: 1.174460 	Validation Loss: 1.353345 	 time: 0.3
Epoch: 1218 	Training Loss: 1.174433 	Validation Loss: 1.353311 	 time: 0.3
Epoch: 1219 	Training Loss: 1.174414 	Validation Loss: 1.353013 	 time: 0.3
Epoch: 1220 	Training Loss: 1.174397 	Validation Loss: 1.352970 	 time: 0.3
Epoch: 1221 	Training Loss: 1.174383 	Validation Loss: 1.352878 	 time: 0.3
Epoch: 1222 	Training Loss: 1.174370 	Validation Loss: 1.352936 	 time: 0.3
Epoch: 1223 	Training Loss: 1.174357 	Validation Loss: 1.352810 	 time: 0.3
Epoch: 1224 	Training Loss: 1.174343 	Validation Loss: 1.352577 	 time: 0.3
Epoch: 1225 	Training Loss: 1.174322 	Validation Loss: 1.352535 	 time: 0.3
Epoch: 1226 	Training Loss: 1.174288 	Validation Loss: 1.352272 	 time: 0.3
Epoch: 1227 	Training Loss: 1.174264 	Validation Loss: 1.351743 	 time: 0.3
Validation loss decreased from 1.351928 to 1.351743. Model was saved
Epoch: 1228 	Training Loss: 1.174248 	Validation Loss: 1.352399 	 time: 0.3
Epoch: 1229 	Training Loss: 1.174220 	Validation Loss: 1.352134 	 time: 0.3
Epoch: 1230 	Training Loss: 1.174190 	Validation Loss: 1.352604 	 time: 0.3
Epoch: 1231 	Training Loss: 1.174164 	Validation Loss: 1.351988 	 time: 0.3
Epoch: 1232 	Training Loss: 1.174125 	Validation Loss: 1.351980 	 time: 0.3
Epoch: 1233 	Training Loss: 1.174089 	Validation Loss: 1.351956 	 time: 0.3
Epoch: 1234 	Training Loss: 1.174068 	Validation Loss: 1.352151 	 time: 0.3
Epoch: 1235 	Training Loss: 1.174055 	Validation Loss: 1.352457 	 time: 0.3
Epoch: 1236 	Training Loss: 1.174044 	Validation Loss: 1.351892 	 time: 0.3
Epoch: 1237 	Training Loss: 1.174031 	Validation Loss: 1.352116 	 time: 0.3
Epoch: 1238 	Training Loss: 1.174019 	Validation Loss: 1.351934 	 time: 0.3
Epoch: 1239 	Training Loss: 1.174006 	Validation Loss: 1.351801 	 time: 0.3
Epoch: 1240 	Training Loss: 1.173995 	Validation Loss: 1.351618 	 time: 0.3
Validation loss decreased from 1.351743 to 1.351618. Model was saved
Epoch: 1241 	Training Loss: 1.173980 	Validation Loss: 1.351380 	 time: 0.3
Validation loss decreased from 1.351618 to 1.351380. Model was saved
Epoch: 1242 	Training Loss: 1.173963 	Validation Loss: 1.351467 	 time: 0.3
Epoch: 1243 	Training Loss: 1.173941 	Validation Loss: 1.351271 	 time: 0.2
Validation loss decreased from 1.351380 to 1.351271. Model was saved
Epoch: 1244 	Training Loss: 1.173917 	Validation Loss: 1.351293 	 time: 0.3
Epoch: 1245 	Training Loss: 1.173893 	Validation Loss: 1.350951 	 time: 0.3
Validation loss decreased from 1.351271 to 1.350951. Model was saved
Epoch: 1246 	Training Loss: 1.173875 	Validation Loss: 1.350967 	 time: 0.3
Epoch: 1247 	Training Loss: 1.173859 	Validation Loss: 1.350855 	 time: 0.2
Validation loss decreased from 1.350951 to 1.350855. Model was saved
Epoch: 1248 	Training Loss: 1.173841 	Validation Loss: 1.350643 	 time: 0.3
Validation loss decreased from 1.350855 to 1.350643. Model was saved
Epoch: 1249 	Training Loss: 1.173824 	Validation Loss: 1.350629 	 time: 0.3
Validation loss decreased from 1.350643 to 1.350629. Model was saved
Epoch: 1250 	Training Loss: 1.173809 	Validation Loss: 1.350493 	 time: 0.3
Validation loss decreased from 1.350629 to 1.350493. Model was saved
Epoch: 1251 	Training Loss: 1.173796 	Validation Loss: 1.350400 	 time: 0.3
Validation loss decreased from 1.350493 to 1.350400. Model was saved
Epoch: 1252 	Training Loss: 1.173784 	Validation Loss: 1.350069 	 time: 0.3
Validation loss decreased from 1.350400 to 1.350069. Model was saved
Epoch: 1253 	Training Loss: 1.173773 	Validation Loss: 1.349914 	 time: 0.3
Validation loss decreased from 1.350069 to 1.349914. Model was saved
Epoch: 1254 	Training Loss: 1.173761 	Validation Loss: 1.349795 	 time: 0.3
Validation loss decreased from 1.349914 to 1.349795. Model was saved
Epoch: 1255 	Training Loss: 1.173749 	Validation Loss: 1.349891 	 time: 0.3
Epoch: 1256 	Training Loss: 1.173737 	Validation Loss: 1.349999 	 time: 0.3
Epoch: 1257 	Training Loss: 1.173726 	Validation Loss: 1.349937 	 time: 0.3
Epoch: 1258 	Training Loss: 1.173713 	Validation Loss: 1.350052 	 time: 0.3
Epoch: 1259 	Training Loss: 1.173701 	Validation Loss: 1.350063 	 time: 0.3
Epoch: 1260 	Training Loss: 1.173686 	Validation Loss: 1.350193 	 time: 0.3
Epoch: 1261 	Training Loss: 1.173669 	Validation Loss: 1.350256 	 time: 0.3
Epoch: 1262 	Training Loss: 1.173649 	Validation Loss: 1.350241 	 time: 0.3
Epoch: 1263 	Training Loss: 1.173633 	Validation Loss: 1.350129 	 time: 0.3
Epoch: 1264 	Training Loss: 1.173621 	Validation Loss: 1.350045 	 time: 0.3
Epoch: 1265 	Training Loss: 1.173608 	Validation Loss: 1.350130 	 time: 0.3
Epoch: 1266 	Training Loss: 1.173591 	Validation Loss: 1.350224 	 time: 0.3
Epoch: 1267 	Training Loss: 1.173570 	Validation Loss: 1.350507 	 time: 0.3
Epoch: 1268 	Training Loss: 1.173547 	Validation Loss: 1.350769 	 time: 0.3
Epoch: 1269 	Training Loss: 1.173525 	Validation Loss: 1.351046 	 time: 0.3
Epoch: 1270 	Training Loss: 1.173507 	Validation Loss: 1.351204 	 time: 0.3
Epoch: 1271 	Training Loss: 1.173488 	Validation Loss: 1.351107 	 time: 0.3
Epoch: 1272 	Training Loss: 1.173469 	Validation Loss: 1.350994 	 time: 0.3
Epoch: 1273 	Training Loss: 1.173453 	Validation Loss: 1.350887 	 time: 0.3
Epoch: 1274 	Training Loss: 1.173441 	Validation Loss: 1.350948 	 time: 0.3
Epoch: 1275 	Training Loss: 1.173429 	Validation Loss: 1.350958 	 time: 0.3
Epoch: 1276 	Training Loss: 1.173419 	Validation Loss: 1.350930 	 time: 0.3
Epoch: 1277 	Training Loss: 1.173408 	Validation Loss: 1.350726 	 time: 0.3
Epoch: 1278 	Training Loss: 1.173397 	Validation Loss: 1.350605 	 time: 0.3
Epoch: 1279 	Training Loss: 1.173385 	Validation Loss: 1.350512 	 time: 0.3
Epoch: 1280 	Training Loss: 1.173373 	Validation Loss: 1.350420 	 time: 0.3
Epoch: 1281 	Training Loss: 1.173361 	Validation Loss: 1.350398 	 time: 0.3
Epoch: 1282 	Training Loss: 1.173348 	Validation Loss: 1.350436 	 time: 0.3
Epoch: 1283 	Training Loss: 1.173336 	Validation Loss: 1.350561 	 time: 0.3
Epoch: 1284 	Training Loss: 1.173325 	Validation Loss: 1.350602 	 time: 0.3
Epoch: 1285 	Training Loss: 1.173313 	Validation Loss: 1.350619 	 time: 0.3
Epoch: 1286 	Training Loss: 1.173302 	Validation Loss: 1.350618 	 time: 0.3
Epoch: 1287 	Training Loss: 1.173291 	Validation Loss: 1.350717 	 time: 0.3
Epoch: 1288 	Training Loss: 1.173279 	Validation Loss: 1.350776 	 time: 0.3
Epoch: 1289 	Training Loss: 1.173267 	Validation Loss: 1.350826 	 time: 0.3
Epoch: 1290 	Training Loss: 1.173255 	Validation Loss: 1.350848 	 time: 0.3
Epoch: 1291 	Training Loss: 1.173243 	Validation Loss: 1.350838 	 time: 0.3
Epoch: 1292 	Training Loss: 1.173230 	Validation Loss: 1.350835 	 time: 0.3
Epoch: 1293 	Training Loss: 1.173217 	Validation Loss: 1.350853 	 time: 0.3
Epoch: 1294 	Training Loss: 1.173205 	Validation Loss: 1.350936 	 time: 0.3
Epoch: 1295 	Training Loss: 1.173194 	Validation Loss: 1.350996 	 time: 0.3
Epoch: 1296 	Training Loss: 1.173183 	Validation Loss: 1.351021 	 time: 0.3
Epoch: 1297 	Training Loss: 1.173173 	Validation Loss: 1.350965 	 time: 0.3
Epoch: 1298 	Training Loss: 1.173163 	Validation Loss: 1.350920 	 time: 0.3
Epoch: 1299 	Training Loss: 1.173153 	Validation Loss: 1.350828 	 time: 0.3
Epoch: 1300 	Training Loss: 1.173144 	Validation Loss: 1.350733 	 time: 0.3
Epoch: 1301 	Training Loss: 1.173134 	Validation Loss: 1.350647 	 time: 0.3
Epoch: 1302 	Training Loss: 1.173125 	Validation Loss: 1.350604 	 time: 0.3
Epoch: 1303 	Training Loss: 1.173115 	Validation Loss: 1.350567 	 time: 0.3
Epoch: 1304 	Training Loss: 1.173105 	Validation Loss: 1.350505 	 time: 0.3
Epoch: 1305 	Training Loss: 1.173095 	Validation Loss: 1.350423 	 time: 0.3
Epoch: 1306 	Training Loss: 1.173085 	Validation Loss: 1.350306 	 time: 0.3
Epoch: 1307 	Training Loss: 1.173074 	Validation Loss: 1.350165 	 time: 0.3
