Epoch: 1 	Training Loss: 1.794104 	Validation Loss: 1.807814 	 time: 0.3
Validation loss decreased from inf to 1.807814. Model was saved
Epoch: 2 	Training Loss: 1.805804 	Validation Loss: 1.795871 	 time: 0.3
Validation loss decreased from 1.807814 to 1.795871. Model was saved
Epoch: 3 	Training Loss: 1.794681 	Validation Loss: 1.788756 	 time: 0.3
Validation loss decreased from 1.795871 to 1.788756. Model was saved
Epoch: 4 	Training Loss: 1.788024 	Validation Loss: 1.784543 	 time: 0.3
Validation loss decreased from 1.788756 to 1.784543. Model was saved
Epoch: 5 	Training Loss: 1.782485 	Validation Loss: 1.778727 	 time: 0.3
Validation loss decreased from 1.784543 to 1.778727. Model was saved
Epoch: 6 	Training Loss: 1.772996 	Validation Loss: 1.770580 	 time: 0.2
Validation loss decreased from 1.778727 to 1.770580. Model was saved
Epoch: 7 	Training Loss: 1.758244 	Validation Loss: 1.760905 	 time: 0.3
Validation loss decreased from 1.770580 to 1.760905. Model was saved
Epoch: 8 	Training Loss: 1.738700 	Validation Loss: 1.749807 	 time: 0.3
Validation loss decreased from 1.760905 to 1.749807. Model was saved
Epoch: 9 	Training Loss: 1.716071 	Validation Loss: 1.737355 	 time: 0.3
Validation loss decreased from 1.749807 to 1.737355. Model was saved
Epoch: 10 	Training Loss: 1.692808 	Validation Loss: 1.724422 	 time: 0.3
Validation loss decreased from 1.737355 to 1.724422. Model was saved
Epoch: 11 	Training Loss: 1.670692 	Validation Loss: 1.710298 	 time: 0.3
Validation loss decreased from 1.724422 to 1.710298. Model was saved
Epoch: 12 	Training Loss: 1.650154 	Validation Loss: 1.695636 	 time: 0.4
Validation loss decreased from 1.710298 to 1.695636. Model was saved
Epoch: 13 	Training Loss: 1.631257 	Validation Loss: 1.681865 	 time: 0.3
Validation loss decreased from 1.695636 to 1.681865. Model was saved
Epoch: 14 	Training Loss: 1.614045 	Validation Loss: 1.674182 	 time: 0.3
Validation loss decreased from 1.681865 to 1.674182. Model was saved
Epoch: 15 	Training Loss: 1.598041 	Validation Loss: 1.658438 	 time: 0.3
Validation loss decreased from 1.674182 to 1.658438. Model was saved
Epoch: 16 	Training Loss: 1.583158 	Validation Loss: 1.653806 	 time: 0.3
Validation loss decreased from 1.658438 to 1.653806. Model was saved
Epoch: 17 	Training Loss: 1.568367 	Validation Loss: 1.630989 	 time: 0.3
Validation loss decreased from 1.653806 to 1.630989. Model was saved
Epoch: 18 	Training Loss: 1.554159 	Validation Loss: 1.620598 	 time: 0.3
Validation loss decreased from 1.630989 to 1.620598. Model was saved
Epoch: 19 	Training Loss: 1.543769 	Validation Loss: 1.615288 	 time: 0.2
Validation loss decreased from 1.620598 to 1.615288. Model was saved
Epoch: 20 	Training Loss: 1.536032 	Validation Loss: 1.605590 	 time: 0.2
Validation loss decreased from 1.615288 to 1.605590. Model was saved
Epoch: 21 	Training Loss: 1.528878 	Validation Loss: 1.604464 	 time: 0.3
Validation loss decreased from 1.605590 to 1.604464. Model was saved
Epoch: 22 	Training Loss: 1.522006 	Validation Loss: 1.603926 	 time: 0.2
Validation loss decreased from 1.604464 to 1.603926. Model was saved
Epoch: 23 	Training Loss: 1.515997 	Validation Loss: 1.596753 	 time: 0.3
Validation loss decreased from 1.603926 to 1.596753. Model was saved
Epoch: 24 	Training Loss: 1.510195 	Validation Loss: 1.596616 	 time: 0.3
Validation loss decreased from 1.596753 to 1.596616. Model was saved
Epoch: 25 	Training Loss: 1.504889 	Validation Loss: 1.588018 	 time: 0.2
Validation loss decreased from 1.596616 to 1.588018. Model was saved
Epoch: 26 	Training Loss: 1.500170 	Validation Loss: 1.584463 	 time: 0.2
Validation loss decreased from 1.588018 to 1.584463. Model was saved
Epoch: 27 	Training Loss: 1.495350 	Validation Loss: 1.580299 	 time: 0.3
Validation loss decreased from 1.584463 to 1.580299. Model was saved
Epoch: 28 	Training Loss: 1.491336 	Validation Loss: 1.573734 	 time: 0.3
Validation loss decreased from 1.580299 to 1.573734. Model was saved
Epoch: 29 	Training Loss: 1.487475 	Validation Loss: 1.569875 	 time: 0.3
Validation loss decreased from 1.573734 to 1.569875. Model was saved
Epoch: 30 	Training Loss: 1.483168 	Validation Loss: 1.566397 	 time: 0.3
Validation loss decreased from 1.569875 to 1.566397. Model was saved
Epoch: 31 	Training Loss: 1.479615 	Validation Loss: 1.561228 	 time: 0.3
Validation loss decreased from 1.566397 to 1.561228. Model was saved
Epoch: 32 	Training Loss: 1.476390 	Validation Loss: 1.559011 	 time: 0.3
Validation loss decreased from 1.561228 to 1.559011. Model was saved
Epoch: 33 	Training Loss: 1.473106 	Validation Loss: 1.553406 	 time: 0.3
Validation loss decreased from 1.559011 to 1.553406. Model was saved
Epoch: 34 	Training Loss: 1.470091 	Validation Loss: 1.549858 	 time: 0.3
Validation loss decreased from 1.553406 to 1.549858. Model was saved
Epoch: 35 	Training Loss: 1.467323 	Validation Loss: 1.542349 	 time: 0.3
Validation loss decreased from 1.549858 to 1.542349. Model was saved
Epoch: 36 	Training Loss: 1.464902 	Validation Loss: 1.545497 	 time: 0.4
Epoch: 37 	Training Loss: 1.462841 	Validation Loss: 1.534396 	 time: 0.3
Validation loss decreased from 1.542349 to 1.534396. Model was saved
Epoch: 38 	Training Loss: 1.461414 	Validation Loss: 1.544363 	 time: 0.5
Epoch: 39 	Training Loss: 1.459037 	Validation Loss: 1.532577 	 time: 0.3
Validation loss decreased from 1.534396 to 1.532577. Model was saved
Epoch: 40 	Training Loss: 1.455909 	Validation Loss: 1.536559 	 time: 0.3
Epoch: 41 	Training Loss: 1.453446 	Validation Loss: 1.542370 	 time: 0.2
Epoch: 42 	Training Loss: 1.451974 	Validation Loss: 1.535781 	 time: 0.2
Epoch: 43 	Training Loss: 1.450218 	Validation Loss: 1.547571 	 time: 0.3
Epoch: 44 	Training Loss: 1.447421 	Validation Loss: 1.541895 	 time: 0.3
Epoch: 45 	Training Loss: 1.446088 	Validation Loss: 1.547464 	 time: 0.2
Epoch: 46 	Training Loss: 1.444748 	Validation Loss: 1.545165 	 time: 0.3
Epoch: 47 	Training Loss: 1.441633 	Validation Loss: 1.541444 	 time: 0.2
Epoch: 48 	Training Loss: 1.440045 	Validation Loss: 1.544989 	 time: 0.3
Epoch: 49 	Training Loss: 1.439400 	Validation Loss: 1.539131 	 time: 0.3
Epoch: 50 	Training Loss: 1.437017 	Validation Loss: 1.540629 	 time: 0.2
Epoch: 51 	Training Loss: 1.435064 	Validation Loss: 1.538131 	 time: 0.2
Epoch: 52 	Training Loss: 1.434295 	Validation Loss: 1.541146 	 time: 0.3
Epoch: 53 	Training Loss: 1.432548 	Validation Loss: 1.531736 	 time: 0.2
Validation loss decreased from 1.532577 to 1.531736. Model was saved
Epoch: 54 	Training Loss: 1.431079 	Validation Loss: 1.549196 	 time: 0.3
Epoch: 55 	Training Loss: 1.431562 	Validation Loss: 1.530942 	 time: 0.2
Validation loss decreased from 1.531736 to 1.530942. Model was saved
Epoch: 56 	Training Loss: 1.431227 	Validation Loss: 1.547081 	 time: 0.3
Epoch: 57 	Training Loss: 1.427406 	Validation Loss: 1.539963 	 time: 0.2
Epoch: 58 	Training Loss: 1.424008 	Validation Loss: 1.533411 	 time: 0.3
Epoch: 59 	Training Loss: 1.423312 	Validation Loss: 1.545390 	 time: 0.2
Epoch: 60 	Training Loss: 1.422257 	Validation Loss: 1.536913 	 time: 0.3
Epoch: 61 	Training Loss: 1.418960 	Validation Loss: 1.533851 	 time: 0.3
Epoch: 62 	Training Loss: 1.417256 	Validation Loss: 1.542385 	 time: 0.3
Epoch: 63 	Training Loss: 1.417564 	Validation Loss: 1.533421 	 time: 0.2
Epoch: 64 	Training Loss: 1.414462 	Validation Loss: 1.533703 	 time: 0.2
Epoch: 65 	Training Loss: 1.412152 	Validation Loss: 1.540444 	 time: 0.3
Epoch: 66 	Training Loss: 1.412623 	Validation Loss: 1.532023 	 time: 0.2
Epoch: 67 	Training Loss: 1.410086 	Validation Loss: 1.535663 	 time: 0.2
Epoch: 68 	Training Loss: 1.407769 	Validation Loss: 1.537584 	 time: 0.3
Epoch: 69 	Training Loss: 1.407616 	Validation Loss: 1.530385 	 time: 0.2
Validation loss decreased from 1.530942 to 1.530385. Model was saved
Epoch: 70 	Training Loss: 1.405511 	Validation Loss: 1.536393 	 time: 0.2
Epoch: 71 	Training Loss: 1.404006 	Validation Loss: 1.532593 	 time: 0.3
Epoch: 72 	Training Loss: 1.403106 	Validation Loss: 1.529457 	 time: 0.2
Validation loss decreased from 1.530385 to 1.529457. Model was saved
Epoch: 73 	Training Loss: 1.400763 	Validation Loss: 1.533106 	 time: 0.3
Epoch: 74 	Training Loss: 1.399717 	Validation Loss: 1.529398 	 time: 0.3
Validation loss decreased from 1.529457 to 1.529398. Model was saved
Epoch: 75 	Training Loss: 1.398839 	Validation Loss: 1.531592 	 time: 0.3
Epoch: 76 	Training Loss: 1.396618 	Validation Loss: 1.528777 	 time: 0.3
Validation loss decreased from 1.529398 to 1.528777. Model was saved
Epoch: 77 	Training Loss: 1.395173 	Validation Loss: 1.529022 	 time: 0.3
Epoch: 78 	Training Loss: 1.394492 	Validation Loss: 1.527717 	 time: 0.2
Validation loss decreased from 1.528777 to 1.527717. Model was saved
Epoch: 79 	Training Loss: 1.392760 	Validation Loss: 1.523926 	 time: 0.3
Validation loss decreased from 1.527717 to 1.523926. Model was saved
Epoch: 80 	Training Loss: 1.390952 	Validation Loss: 1.523556 	 time: 0.3
Validation loss decreased from 1.523926 to 1.523556. Model was saved
Epoch: 81 	Training Loss: 1.390257 	Validation Loss: 1.520443 	 time: 0.3
Validation loss decreased from 1.523556 to 1.520443. Model was saved
Epoch: 82 	Training Loss: 1.389282 	Validation Loss: 1.523270 	 time: 0.3
Epoch: 83 	Training Loss: 1.387621 	Validation Loss: 1.511146 	 time: 0.3
Validation loss decreased from 1.520443 to 1.511146. Model was saved
Epoch: 84 	Training Loss: 1.387326 	Validation Loss: 1.532269 	 time: 0.3
Epoch: 85 	Training Loss: 1.388916 	Validation Loss: 1.504977 	 time: 0.3
Validation loss decreased from 1.511146 to 1.504977. Model was saved
Epoch: 86 	Training Loss: 1.389825 	Validation Loss: 1.531223 	 time: 0.3
Epoch: 87 	Training Loss: 1.387820 	Validation Loss: 1.515223 	 time: 0.3
Epoch: 88 	Training Loss: 1.383042 	Validation Loss: 1.508465 	 time: 0.4
Epoch: 89 	Training Loss: 1.382127 	Validation Loss: 1.526217 	 time: 0.4
Epoch: 90 	Training Loss: 1.383915 	Validation Loss: 1.514310 	 time: 0.3
Epoch: 91 	Training Loss: 1.379707 	Validation Loss: 1.507694 	 time: 0.4
Epoch: 92 	Training Loss: 1.378718 	Validation Loss: 1.522116 	 time: 0.3
Epoch: 93 	Training Loss: 1.380067 	Validation Loss: 1.513263 	 time: 0.3
Epoch: 94 	Training Loss: 1.375007 	Validation Loss: 1.507112 	 time: 0.3
Epoch: 95 	Training Loss: 1.375783 	Validation Loss: 1.519967 	 time: 0.3
Epoch: 96 	Training Loss: 1.375126 	Validation Loss: 1.510714 	 time: 0.3
Epoch: 97 	Training Loss: 1.371116 	Validation Loss: 1.507624 	 time: 0.2
Epoch: 98 	Training Loss: 1.371952 	Validation Loss: 1.518203 	 time: 0.3
Epoch: 99 	Training Loss: 1.370486 	Validation Loss: 1.507700 	 time: 0.2
Epoch: 100 	Training Loss: 1.369086 	Validation Loss: 1.511205 	 time: 0.3
Epoch: 101 	Training Loss: 1.367787 	Validation Loss: 1.512060 	 time: 0.3
Epoch: 102 	Training Loss: 1.365489 	Validation Loss: 1.507567 	 time: 0.3
Epoch: 103 	Training Loss: 1.365848 	Validation Loss: 1.513551 	 time: 0.2
Epoch: 104 	Training Loss: 1.364726 	Validation Loss: 1.507072 	 time: 0.3
Epoch: 105 	Training Loss: 1.361932 	Validation Loss: 1.512094 	 time: 0.3
Epoch: 106 	Training Loss: 1.361680 	Validation Loss: 1.506075 	 time: 0.2
Epoch: 107 	Training Loss: 1.360686 	Validation Loss: 1.508031 	 time: 0.3
Epoch: 108 	Training Loss: 1.357519 	Validation Loss: 1.508987 	 time: 0.3
Epoch: 109 	Training Loss: 1.357638 	Validation Loss: 1.502489 	 time: 0.3
Validation loss decreased from 1.504977 to 1.502489. Model was saved
Epoch: 110 	Training Loss: 1.356944 	Validation Loss: 1.505158 	 time: 0.3
Epoch: 111 	Training Loss: 1.353426 	Validation Loss: 1.503954 	 time: 0.4
Epoch: 112 	Training Loss: 1.354136 	Validation Loss: 1.503207 	 time: 0.3
Epoch: 113 	Training Loss: 1.353503 	Validation Loss: 1.496131 	 time: 0.2
Validation loss decreased from 1.502489 to 1.496131. Model was saved
Epoch: 114 	Training Loss: 1.349911 	Validation Loss: 1.510092 	 time: 0.3
Epoch: 115 	Training Loss: 1.352998 	Validation Loss: 1.488488 	 time: 0.3
Validation loss decreased from 1.496131 to 1.488488. Model was saved
Epoch: 116 	Training Loss: 1.352770 	Validation Loss: 1.504253 	 time: 0.3
Epoch: 117 	Training Loss: 1.350274 	Validation Loss: 1.498706 	 time: 0.2
Epoch: 118 	Training Loss: 1.344795 	Validation Loss: 1.490430 	 time: 0.2
Epoch: 119 	Training Loss: 1.340955 	Validation Loss: 1.499842 	 time: 0.3
Epoch: 120 	Training Loss: 1.343969 	Validation Loss: 1.490558 	 time: 0.2
Epoch: 121 	Training Loss: 1.335876 	Validation Loss: 1.488592 	 time: 0.2
Epoch: 122 	Training Loss: 1.337637 	Validation Loss: 1.496306 	 time: 0.3
Epoch: 123 	Training Loss: 1.336875 	Validation Loss: 1.486504 	 time: 0.3
Validation loss decreased from 1.488488 to 1.486504. Model was saved
Epoch: 124 	Training Loss: 1.332181 	Validation Loss: 1.483081 	 time: 0.3
Validation loss decreased from 1.486504 to 1.483081. Model was saved
Epoch: 125 	Training Loss: 1.331642 	Validation Loss: 1.489984 	 time: 0.3
Epoch: 126 	Training Loss: 1.330752 	Validation Loss: 1.481970 	 time: 0.2
Validation loss decreased from 1.483081 to 1.481970. Model was saved
Epoch: 127 	Training Loss: 1.329722 	Validation Loss: 1.479095 	 time: 0.3
Validation loss decreased from 1.481970 to 1.479095. Model was saved
Epoch: 128 	Training Loss: 1.324529 	Validation Loss: 1.482352 	 time: 0.3
Epoch: 129 	Training Loss: 1.328542 	Validation Loss: 1.472540 	 time: 0.3
Validation loss decreased from 1.479095 to 1.472540. Model was saved
Epoch: 130 	Training Loss: 1.322788 	Validation Loss: 1.476058 	 time: 0.3
Epoch: 131 	Training Loss: 1.323041 	Validation Loss: 1.472547 	 time: 0.3
Epoch: 132 	Training Loss: 1.319733 	Validation Loss: 1.464974 	 time: 0.4
Validation loss decreased from 1.472540 to 1.464974. Model was saved
Epoch: 133 	Training Loss: 1.321419 	Validation Loss: 1.466798 	 time: 0.3
Epoch: 134 	Training Loss: 1.316813 	Validation Loss: 1.466776 	 time: 0.4
Epoch: 135 	Training Loss: 1.317513 	Validation Loss: 1.460509 	 time: 0.3
Validation loss decreased from 1.464974 to 1.460509. Model was saved
Epoch: 136 	Training Loss: 1.314856 	Validation Loss: 1.461216 	 time: 0.5
Epoch: 137 	Training Loss: 1.315296 	Validation Loss: 1.459199 	 time: 0.3
Validation loss decreased from 1.460509 to 1.459199. Model was saved
Epoch: 138 	Training Loss: 1.312485 	Validation Loss: 1.458345 	 time: 0.4
Validation loss decreased from 1.459199 to 1.458345. Model was saved
Epoch: 139 	Training Loss: 1.312294 	Validation Loss: 1.455983 	 time: 0.3
Validation loss decreased from 1.458345 to 1.455983. Model was saved
Epoch: 140 	Training Loss: 1.310577 	Validation Loss: 1.452530 	 time: 0.4
Validation loss decreased from 1.455983 to 1.452530. Model was saved
Epoch: 141 	Training Loss: 1.309946 	Validation Loss: 1.452756 	 time: 0.3
Epoch: 142 	Training Loss: 1.308499 	Validation Loss: 1.450877 	 time: 0.3
Validation loss decreased from 1.452530 to 1.450877. Model was saved
Epoch: 143 	Training Loss: 1.307362 	Validation Loss: 1.448065 	 time: 0.3
Validation loss decreased from 1.450877 to 1.448065. Model was saved
Epoch: 144 	Training Loss: 1.306477 	Validation Loss: 1.448432 	 time: 0.2
Epoch: 145 	Training Loss: 1.305111 	Validation Loss: 1.447902 	 time: 0.3
Validation loss decreased from 1.448065 to 1.447902. Model was saved
Epoch: 146 	Training Loss: 1.304562 	Validation Loss: 1.447551 	 time: 0.3
Validation loss decreased from 1.447902 to 1.447551. Model was saved
Epoch: 147 	Training Loss: 1.302714 	Validation Loss: 1.446578 	 time: 0.3
Validation loss decreased from 1.447551 to 1.446578. Model was saved
Epoch: 148 	Training Loss: 1.302379 	Validation Loss: 1.446083 	 time: 0.3
Validation loss decreased from 1.446578 to 1.446083. Model was saved
Epoch: 149 	Training Loss: 1.300700 	Validation Loss: 1.448355 	 time: 0.3
Epoch: 150 	Training Loss: 1.300504 	Validation Loss: 1.444160 	 time: 0.2
Validation loss decreased from 1.446083 to 1.444160. Model was saved
Epoch: 151 	Training Loss: 1.299133 	Validation Loss: 1.446298 	 time: 0.3
Epoch: 152 	Training Loss: 1.298662 	Validation Loss: 1.442932 	 time: 0.2
Validation loss decreased from 1.444160 to 1.442932. Model was saved
Epoch: 153 	Training Loss: 1.298230 	Validation Loss: 1.447009 	 time: 0.2
Epoch: 154 	Training Loss: 1.297958 	Validation Loss: 1.438644 	 time: 0.3
Validation loss decreased from 1.442932 to 1.438644. Model was saved
Epoch: 155 	Training Loss: 1.298112 	Validation Loss: 1.449507 	 time: 0.3
Epoch: 156 	Training Loss: 1.298670 	Validation Loss: 1.439868 	 time: 0.3
Epoch: 157 	Training Loss: 1.299874 	Validation Loss: 1.446153 	 time: 0.2
Epoch: 158 	Training Loss: 1.295229 	Validation Loss: 1.439157 	 time: 0.3
Epoch: 159 	Training Loss: 1.292519 	Validation Loss: 1.434847 	 time: 0.2
Validation loss decreased from 1.438644 to 1.434847. Model was saved
Epoch: 160 	Training Loss: 1.292783 	Validation Loss: 1.444291 	 time: 0.3
Epoch: 161 	Training Loss: 1.294398 	Validation Loss: 1.431813 	 time: 0.2
Validation loss decreased from 1.434847 to 1.431813. Model was saved
Epoch: 162 	Training Loss: 1.291986 	Validation Loss: 1.436679 	 time: 0.3
Epoch: 163 	Training Loss: 1.289279 	Validation Loss: 1.435150 	 time: 0.2
Epoch: 164 	Training Loss: 1.288135 	Validation Loss: 1.430792 	 time: 0.2
Validation loss decreased from 1.431813 to 1.430792. Model was saved
Epoch: 165 	Training Loss: 1.288133 	Validation Loss: 1.434443 	 time: 0.3
Epoch: 166 	Training Loss: 1.287611 	Validation Loss: 1.427201 	 time: 0.2
Validation loss decreased from 1.430792 to 1.427201. Model was saved
Epoch: 167 	Training Loss: 1.286827 	Validation Loss: 1.432399 	 time: 0.3
Epoch: 168 	Training Loss: 1.285946 	Validation Loss: 1.426228 	 time: 0.2
Validation loss decreased from 1.427201 to 1.426228. Model was saved
Epoch: 169 	Training Loss: 1.284248 	Validation Loss: 1.428503 	 time: 0.3
Epoch: 170 	Training Loss: 1.283260 	Validation Loss: 1.424055 	 time: 0.3
Validation loss decreased from 1.426228 to 1.424055. Model was saved
Epoch: 171 	Training Loss: 1.281806 	Validation Loss: 1.423939 	 time: 0.3
Validation loss decreased from 1.424055 to 1.423939. Model was saved
Epoch: 172 	Training Loss: 1.280816 	Validation Loss: 1.419723 	 time: 0.2
Validation loss decreased from 1.423939 to 1.419723. Model was saved
Epoch: 173 	Training Loss: 1.279859 	Validation Loss: 1.420745 	 time: 0.2
Epoch: 174 	Training Loss: 1.278852 	Validation Loss: 1.415831 	 time: 0.2
Validation loss decreased from 1.419723 to 1.415831. Model was saved
Epoch: 175 	Training Loss: 1.278494 	Validation Loss: 1.422363 	 time: 0.2
Epoch: 176 	Training Loss: 1.278533 	Validation Loss: 1.412004 	 time: 0.2
Validation loss decreased from 1.415831 to 1.412004. Model was saved
Epoch: 177 	Training Loss: 1.282272 	Validation Loss: 1.436645 	 time: 0.3
Epoch: 178 	Training Loss: 1.290124 	Validation Loss: 1.416021 	 time: 0.2
Epoch: 179 	Training Loss: 1.296998 	Validation Loss: 1.420843 	 time: 0.2
Epoch: 180 	Training Loss: 1.277279 	Validation Loss: 1.436412 	 time: 0.2
Epoch: 181 	Training Loss: 1.291028 	Validation Loss: 1.418704 	 time: 0.3
Epoch: 182 	Training Loss: 1.297045 	Validation Loss: 1.423917 	 time: 0.3
Epoch: 183 	Training Loss: 1.286044 	Validation Loss: 1.430438 	 time: 0.2
Epoch: 184 	Training Loss: 1.285523 	Validation Loss: 1.420083 	 time: 0.3
Epoch: 185 	Training Loss: 1.278615 	Validation Loss: 1.408355 	 time: 0.3
Validation loss decreased from 1.412004 to 1.408355. Model was saved
Epoch: 186 	Training Loss: 1.283738 	Validation Loss: 1.422253 	 time: 0.3
Epoch: 187 	Training Loss: 1.278501 	Validation Loss: 1.423639 	 time: 0.3
Epoch: 188 	Training Loss: 1.279724 	Validation Loss: 1.411097 	 time: 0.3
Epoch: 189 	Training Loss: 1.272871 	Validation Loss: 1.400994 	 time: 0.2
Validation loss decreased from 1.408355 to 1.400994. Model was saved
Epoch: 190 	Training Loss: 1.278563 	Validation Loss: 1.409656 	 time: 0.3
Epoch: 191 	Training Loss: 1.272087 	Validation Loss: 1.416780 	 time: 0.3
Epoch: 192 	Training Loss: 1.273713 	Validation Loss: 1.406045 	 time: 0.3
Epoch: 193 	Training Loss: 1.270243 	Validation Loss: 1.395272 	 time: 0.3
Validation loss decreased from 1.400994 to 1.395272. Model was saved
Epoch: 194 	Training Loss: 1.272631 	Validation Loss: 1.405730 	 time: 0.3
Epoch: 195 	Training Loss: 1.268451 	Validation Loss: 1.405837 	 time: 0.2
Epoch: 196 	Training Loss: 1.268766 	Validation Loss: 1.401610 	 time: 0.3
Epoch: 197 	Training Loss: 1.266789 	Validation Loss: 1.399413 	 time: 0.2
Epoch: 198 	Training Loss: 1.266218 	Validation Loss: 1.398745 	 time: 0.2
Epoch: 199 	Training Loss: 1.265132 	Validation Loss: 1.398623 	 time: 0.3
Epoch: 200 	Training Loss: 1.263515 	Validation Loss: 1.401254 	 time: 0.3
Epoch: 201 	Training Loss: 1.264937 	Validation Loss: 1.400445 	 time: 0.2
Epoch: 202 	Training Loss: 1.261778 	Validation Loss: 1.399592 	 time: 0.3
Epoch: 203 	Training Loss: 1.262018 	Validation Loss: 1.396960 	 time: 0.2
Epoch: 204 	Training Loss: 1.261681 	Validation Loss: 1.399034 	 time: 0.2
Epoch: 205 	Training Loss: 1.259557 	Validation Loss: 1.402142 	 time: 0.3
Epoch: 206 	Training Loss: 1.260712 	Validation Loss: 1.399798 	 time: 0.3
Epoch: 207 	Training Loss: 1.258278 	Validation Loss: 1.398402 	 time: 0.2
Epoch: 208 	Training Loss: 1.258645 	Validation Loss: 1.398521 	 time: 0.3
Epoch: 209 	Training Loss: 1.257730 	Validation Loss: 1.396909 	 time: 0.2
Epoch: 210 	Training Loss: 1.256404 	Validation Loss: 1.395389 	 time: 0.2
Epoch: 211 	Training Loss: 1.257020 	Validation Loss: 1.392725 	 time: 0.3
Validation loss decreased from 1.395272 to 1.392725. Model was saved
Epoch: 212 	Training Loss: 1.255383 	Validation Loss: 1.390387 	 time: 0.3
Validation loss decreased from 1.392725 to 1.390387. Model was saved
Epoch: 213 	Training Loss: 1.255473 	Validation Loss: 1.391221 	 time: 0.2
Epoch: 214 	Training Loss: 1.254565 	Validation Loss: 1.392348 	 time: 0.3
Epoch: 215 	Training Loss: 1.254094 	Validation Loss: 1.389580 	 time: 0.2
Validation loss decreased from 1.390387 to 1.389580. Model was saved
Epoch: 216 	Training Loss: 1.253794 	Validation Loss: 1.385475 	 time: 0.2
Validation loss decreased from 1.389580 to 1.385475. Model was saved
Epoch: 217 	Training Loss: 1.252854 	Validation Loss: 1.384843 	 time: 0.3
Validation loss decreased from 1.385475 to 1.384843. Model was saved
Epoch: 218 	Training Loss: 1.252830 	Validation Loss: 1.382538 	 time: 0.2
Validation loss decreased from 1.384843 to 1.382538. Model was saved
Epoch: 219 	Training Loss: 1.252024 	Validation Loss: 1.380270 	 time: 0.2
Validation loss decreased from 1.382538 to 1.380270. Model was saved
Epoch: 220 	Training Loss: 1.251659 	Validation Loss: 1.379280 	 time: 0.2
Validation loss decreased from 1.380270 to 1.379280. Model was saved
Epoch: 221 	Training Loss: 1.251347 	Validation Loss: 1.378633 	 time: 0.3
Validation loss decreased from 1.379280 to 1.378633. Model was saved
Epoch: 222 	Training Loss: 1.250633 	Validation Loss: 1.379135 	 time: 0.2
Epoch: 223 	Training Loss: 1.250426 	Validation Loss: 1.377343 	 time: 0.2
Validation loss decreased from 1.378633 to 1.377343. Model was saved
Epoch: 224 	Training Loss: 1.249695 	Validation Loss: 1.375047 	 time: 0.3
Validation loss decreased from 1.377343 to 1.375047. Model was saved
Epoch: 225 	Training Loss: 1.249515 	Validation Loss: 1.374979 	 time: 0.2
Validation loss decreased from 1.375047 to 1.374979. Model was saved
Epoch: 226 	Training Loss: 1.248856 	Validation Loss: 1.375894 	 time: 0.3
Epoch: 227 	Training Loss: 1.248554 	Validation Loss: 1.375489 	 time: 0.3
Epoch: 228 	Training Loss: 1.248074 	Validation Loss: 1.374915 	 time: 0.3
Validation loss decreased from 1.374979 to 1.374915. Model was saved
Epoch: 229 	Training Loss: 1.247588 	Validation Loss: 1.374727 	 time: 0.3
Validation loss decreased from 1.374915 to 1.374727. Model was saved
Epoch: 230 	Training Loss: 1.247257 	Validation Loss: 1.375150 	 time: 0.3
Epoch: 231 	Training Loss: 1.246743 	Validation Loss: 1.375615 	 time: 0.2
Epoch: 232 	Training Loss: 1.246486 	Validation Loss: 1.374751 	 time: 0.2
Epoch: 233 	Training Loss: 1.246023 	Validation Loss: 1.375128 	 time: 0.3
Epoch: 234 	Training Loss: 1.245748 	Validation Loss: 1.375953 	 time: 0.2
Epoch: 235 	Training Loss: 1.245333 	Validation Loss: 1.376240 	 time: 0.2
Epoch: 236 	Training Loss: 1.245077 	Validation Loss: 1.375711 	 time: 0.3
Epoch: 237 	Training Loss: 1.244673 	Validation Loss: 1.375496 	 time: 0.2
Epoch: 238 	Training Loss: 1.244364 	Validation Loss: 1.375695 	 time: 0.3
Epoch: 239 	Training Loss: 1.244006 	Validation Loss: 1.375937 	 time: 0.3
Epoch: 240 	Training Loss: 1.243634 	Validation Loss: 1.375823 	 time: 0.2
Epoch: 241 	Training Loss: 1.243272 	Validation Loss: 1.375751 	 time: 0.2
Epoch: 242 	Training Loss: 1.242916 	Validation Loss: 1.375647 	 time: 0.3
Epoch: 243 	Training Loss: 1.242583 	Validation Loss: 1.374967 	 time: 0.2
Epoch: 244 	Training Loss: 1.242221 	Validation Loss: 1.374596 	 time: 0.2
Validation loss decreased from 1.374727 to 1.374596. Model was saved
Epoch: 245 	Training Loss: 1.241922 	Validation Loss: 1.374430 	 time: 0.3
Validation loss decreased from 1.374596 to 1.374430. Model was saved
Epoch: 246 	Training Loss: 1.241590 	Validation Loss: 1.374970 	 time: 0.3
Epoch: 247 	Training Loss: 1.241313 	Validation Loss: 1.375421 	 time: 0.2
Epoch: 248 	Training Loss: 1.240994 	Validation Loss: 1.375674 	 time: 0.3
Epoch: 249 	Training Loss: 1.240724 	Validation Loss: 1.375596 	 time: 0.3
Epoch: 250 	Training Loss: 1.240418 	Validation Loss: 1.375549 	 time: 0.3
Epoch: 251 	Training Loss: 1.240159 	Validation Loss: 1.375774 	 time: 0.2
Epoch: 252 	Training Loss: 1.239852 	Validation Loss: 1.375975 	 time: 0.3
Epoch: 253 	Training Loss: 1.239581 	Validation Loss: 1.376370 	 time: 0.2
Epoch: 254 	Training Loss: 1.239298 	Validation Loss: 1.376634 	 time: 0.2
Epoch: 255 	Training Loss: 1.239043 	Validation Loss: 1.376768 	 time: 0.3
Epoch: 256 	Training Loss: 1.238763 	Validation Loss: 1.377007 	 time: 0.2
Epoch: 257 	Training Loss: 1.238521 	Validation Loss: 1.377365 	 time: 0.2
Epoch: 258 	Training Loss: 1.238265 	Validation Loss: 1.377757 	 time: 0.2
Epoch: 259 	Training Loss: 1.238023 	Validation Loss: 1.377923 	 time: 0.3
Epoch: 260 	Training Loss: 1.237768 	Validation Loss: 1.378149 	 time: 0.2
Epoch: 261 	Training Loss: 1.237519 	Validation Loss: 1.378269 	 time: 0.3
Epoch: 262 	Training Loss: 1.237265 	Validation Loss: 1.378693 	 time: 0.2
Epoch: 263 	Training Loss: 1.237027 	Validation Loss: 1.378969 	 time: 0.3
Epoch: 264 	Training Loss: 1.236785 	Validation Loss: 1.379923 	 time: 0.3
Epoch: 265 	Training Loss: 1.236556 	Validation Loss: 1.379913 	 time: 0.3
Epoch: 266 	Training Loss: 1.236333 	Validation Loss: 1.381248 	 time: 0.2
Epoch: 267 	Training Loss: 1.236130 	Validation Loss: 1.379737 	 time: 0.3
Epoch: 268 	Training Loss: 1.235986 	Validation Loss: 1.383179 	 time: 0.3
Epoch: 269 	Training Loss: 1.236082 	Validation Loss: 1.378879 	 time: 0.3
Epoch: 270 	Training Loss: 1.237023 	Validation Loss: 1.391676 	 time: 0.3
Epoch: 271 	Training Loss: 1.240394 	Validation Loss: 1.379990 	 time: 0.3
Epoch: 272 	Training Loss: 1.252565 	Validation Loss: 1.417745 	 time: 0.3
Epoch: 273 	Training Loss: 1.262857 	Validation Loss: 1.379327 	 time: 0.3
Epoch: 274 	Training Loss: 1.253799 	Validation Loss: 1.373584 	 time: 0.3
Validation loss decreased from 1.374430 to 1.373584. Model was saved
Epoch: 275 	Training Loss: 1.246681 	Validation Loss: 1.394847 	 time: 0.3
Epoch: 276 	Training Loss: 1.252851 	Validation Loss: 1.391466 	 time: 0.3
Epoch: 277 	Training Loss: 1.245080 	Validation Loss: 1.389578 	 time: 0.2
Epoch: 278 	Training Loss: 1.248353 	Validation Loss: 1.378572 	 time: 0.3
Epoch: 279 	Training Loss: 1.241482 	Validation Loss: 1.403698 	 time: 0.3
Epoch: 280 	Training Loss: 1.248925 	Validation Loss: 1.388122 	 time: 0.3
Epoch: 281 	Training Loss: 1.240281 	Validation Loss: 1.389423 	 time: 0.3
Epoch: 282 	Training Loss: 1.244924 	Validation Loss: 1.388010 	 time: 0.3
Epoch: 283 	Training Loss: 1.238929 	Validation Loss: 1.392333 	 time: 0.2
Epoch: 284 	Training Loss: 1.244128 	Validation Loss: 1.384171 	 time: 0.2
Epoch: 285 	Training Loss: 1.239177 	Validation Loss: 1.394763 	 time: 0.3
Epoch: 286 	Training Loss: 1.237515 	Validation Loss: 1.404534 	 time: 0.3
Epoch: 287 	Training Loss: 1.239645 	Validation Loss: 1.390797 	 time: 0.2
Epoch: 288 	Training Loss: 1.235325 	Validation Loss: 1.385892 	 time: 0.3
Epoch: 289 	Training Loss: 1.238452 	Validation Loss: 1.396789 	 time: 0.3
Epoch: 290 	Training Loss: 1.235237 	Validation Loss: 1.395298 	 time: 0.2
Epoch: 291 	Training Loss: 1.236384 	Validation Loss: 1.383182 	 time: 0.3
Epoch: 292 	Training Loss: 1.235166 	Validation Loss: 1.379679 	 time: 0.3
Epoch: 293 	Training Loss: 1.234309 	Validation Loss: 1.388081 	 time: 0.3
Epoch: 294 	Training Loss: 1.234915 	Validation Loss: 1.389933 	 time: 0.3
Epoch: 295 	Training Loss: 1.232278 	Validation Loss: 1.396444 	 time: 0.3
Epoch: 296 	Training Loss: 1.234660 	Validation Loss: 1.397179 	 time: 0.3
Epoch: 297 	Training Loss: 1.232094 	Validation Loss: 1.392536 	 time: 0.3
Epoch: 298 	Training Loss: 1.232309 	Validation Loss: 1.390568 	 time: 0.3
Epoch: 299 	Training Loss: 1.231915 	Validation Loss: 1.395928 	 time: 0.2
Epoch: 300 	Training Loss: 1.230864 	Validation Loss: 1.398240 	 time: 0.3
Epoch: 301 	Training Loss: 1.231337 	Validation Loss: 1.390931 	 time: 0.3
Epoch: 302 	Training Loss: 1.230241 	Validation Loss: 1.388487 	 time: 0.3
Epoch: 303 	Training Loss: 1.230420 	Validation Loss: 1.391925 	 time: 0.3
Epoch: 304 	Training Loss: 1.229649 	Validation Loss: 1.391861 	 time: 0.3
Epoch: 305 	Training Loss: 1.229418 	Validation Loss: 1.392297 	 time: 0.2
Epoch: 306 	Training Loss: 1.229389 	Validation Loss: 1.393873 	 time: 0.2
Epoch: 307 	Training Loss: 1.228454 	Validation Loss: 1.393830 	 time: 0.3
Epoch: 308 	Training Loss: 1.228843 	Validation Loss: 1.391972 	 time: 0.2
Epoch: 309 	Training Loss: 1.228161 	Validation Loss: 1.393429 	 time: 0.2
Epoch: 310 	Training Loss: 1.227989 	Validation Loss: 1.392345 	 time: 0.2
Epoch: 311 	Training Loss: 1.227897 	Validation Loss: 1.388510 	 time: 0.2
Epoch: 312 	Training Loss: 1.227547 	Validation Loss: 1.389102 	 time: 0.2
Epoch: 313 	Training Loss: 1.227350 	Validation Loss: 1.391096 	 time: 0.3
Epoch: 314 	Training Loss: 1.226977 	Validation Loss: 1.390186 	 time: 0.2
Epoch: 315 	Training Loss: 1.227050 	Validation Loss: 1.388919 	 time: 0.3
Epoch: 316 	Training Loss: 1.226593 	Validation Loss: 1.388296 	 time: 0.3
Epoch: 317 	Training Loss: 1.226619 	Validation Loss: 1.387548 	 time: 0.3
Epoch: 318 	Training Loss: 1.226198 	Validation Loss: 1.390290 	 time: 0.3
Epoch: 319 	Training Loss: 1.225958 	Validation Loss: 1.392417 	 time: 0.3
Epoch: 320 	Training Loss: 1.225949 	Validation Loss: 1.390761 	 time: 0.3
Epoch: 321 	Training Loss: 1.225609 	Validation Loss: 1.390904 	 time: 0.3
Epoch: 322 	Training Loss: 1.225481 	Validation Loss: 1.392436 	 time: 0.3
Epoch: 323 	Training Loss: 1.225195 	Validation Loss: 1.392371 	 time: 0.3
Epoch: 324 	Training Loss: 1.225046 	Validation Loss: 1.392488 	 time: 0.3
Epoch: 325 	Training Loss: 1.224802 	Validation Loss: 1.391837 	 time: 0.3
Epoch: 326 	Training Loss: 1.224669 	Validation Loss: 1.389734 	 time: 0.3
Epoch: 327 	Training Loss: 1.224450 	Validation Loss: 1.390466 	 time: 0.3
Epoch: 328 	Training Loss: 1.224241 	Validation Loss: 1.390765 	 time: 0.3
Epoch: 329 	Training Loss: 1.224111 	Validation Loss: 1.389742 	 time: 0.3
Epoch: 330 	Training Loss: 1.223934 	Validation Loss: 1.390436 	 time: 0.3
Epoch: 331 	Training Loss: 1.223776 	Validation Loss: 1.390763 	 time: 0.2
Epoch: 332 	Training Loss: 1.223489 	Validation Loss: 1.390614 	 time: 0.2
Epoch: 333 	Training Loss: 1.223348 	Validation Loss: 1.390810 	 time: 0.2
Epoch: 334 	Training Loss: 1.223177 	Validation Loss: 1.389595 	 time: 0.3
Epoch: 335 	Training Loss: 1.223020 	Validation Loss: 1.389516 	 time: 0.2
Epoch: 336 	Training Loss: 1.222867 	Validation Loss: 1.390281 	 time: 0.3
Epoch: 337 	Training Loss: 1.222719 	Validation Loss: 1.389436 	 time: 0.3
Epoch: 338 	Training Loss: 1.222535 	Validation Loss: 1.389079 	 time: 0.3
Epoch: 339 	Training Loss: 1.222349 	Validation Loss: 1.389397 	 time: 0.3
Epoch: 340 	Training Loss: 1.222176 	Validation Loss: 1.389367 	 time: 0.3
Epoch: 341 	Training Loss: 1.222000 	Validation Loss: 1.389795 	 time: 0.3
Epoch: 342 	Training Loss: 1.221831 	Validation Loss: 1.388816 	 time: 0.3
Epoch: 343 	Training Loss: 1.221657 	Validation Loss: 1.388051 	 time: 0.3
Epoch: 344 	Training Loss: 1.221490 	Validation Loss: 1.388792 	 time: 0.3
Epoch: 345 	Training Loss: 1.221282 	Validation Loss: 1.388676 	 time: 0.2
Epoch: 346 	Training Loss: 1.221079 	Validation Loss: 1.388537 	 time: 0.3
Epoch: 347 	Training Loss: 1.220864 	Validation Loss: 1.388418 	 time: 0.3
Epoch: 348 	Training Loss: 1.220687 	Validation Loss: 1.388382 	 time: 0.2
Epoch: 349 	Training Loss: 1.220510 	Validation Loss: 1.389372 	 time: 0.2
Epoch: 350 	Training Loss: 1.220331 	Validation Loss: 1.389305 	 time: 0.2
Epoch: 351 	Training Loss: 1.220161 	Validation Loss: 1.389010 	 time: 0.3
Epoch: 352 	Training Loss: 1.220005 	Validation Loss: 1.389426 	 time: 0.3
Epoch: 353 	Training Loss: 1.219856 	Validation Loss: 1.389547 	 time: 0.3
Epoch: 354 	Training Loss: 1.219708 	Validation Loss: 1.390238 	 time: 0.3
Epoch: 355 	Training Loss: 1.219558 	Validation Loss: 1.390739 	 time: 0.2
Epoch: 356 	Training Loss: 1.219406 	Validation Loss: 1.391461 	 time: 0.3
Epoch: 357 	Training Loss: 1.219243 	Validation Loss: 1.392633 	 time: 0.3
Epoch: 358 	Training Loss: 1.219092 	Validation Loss: 1.393200 	 time: 0.3
Epoch: 359 	Training Loss: 1.218950 	Validation Loss: 1.394088 	 time: 0.2
Epoch: 360 	Training Loss: 1.218805 	Validation Loss: 1.394349 	 time: 0.3
Epoch: 361 	Training Loss: 1.218659 	Validation Loss: 1.394348 	 time: 0.3
Epoch: 362 	Training Loss: 1.218514 	Validation Loss: 1.394468 	 time: 0.3
Epoch: 363 	Training Loss: 1.218370 	Validation Loss: 1.394438 	 time: 0.2
Epoch: 364 	Training Loss: 1.218232 	Validation Loss: 1.394617 	 time: 0.2
Epoch: 365 	Training Loss: 1.218101 	Validation Loss: 1.394577 	 time: 0.3
Epoch: 366 	Training Loss: 1.217982 	Validation Loss: 1.394692 	 time: 0.2
Epoch: 367 	Training Loss: 1.217864 	Validation Loss: 1.394604 	 time: 0.2
Epoch: 368 	Training Loss: 1.217739 	Validation Loss: 1.394515 	 time: 0.2
Epoch: 369 	Training Loss: 1.217615 	Validation Loss: 1.394687 	 time: 0.3
Epoch: 370 	Training Loss: 1.217501 	Validation Loss: 1.394544 	 time: 0.3
Epoch: 371 	Training Loss: 1.217391 	Validation Loss: 1.394521 	 time: 0.3
Epoch: 372 	Training Loss: 1.217282 	Validation Loss: 1.394456 	 time: 0.2
Epoch: 373 	Training Loss: 1.217173 	Validation Loss: 1.394400 	 time: 0.2
Epoch: 374 	Training Loss: 1.217060 	Validation Loss: 1.394265 	 time: 0.3
Epoch: 375 	Training Loss: 1.216945 	Validation Loss: 1.394186 	 time: 0.3
Epoch: 376 	Training Loss: 1.216820 	Validation Loss: 1.393920 	 time: 0.3
Epoch: 377 	Training Loss: 1.216697 	Validation Loss: 1.393580 	 time: 0.3
Epoch: 378 	Training Loss: 1.216580 	Validation Loss: 1.393352 	 time: 0.3
Epoch: 379 	Training Loss: 1.216460 	Validation Loss: 1.393131 	 time: 0.3
Epoch: 380 	Training Loss: 1.216336 	Validation Loss: 1.393050 	 time: 0.3
Epoch: 381 	Training Loss: 1.216213 	Validation Loss: 1.393062 	 time: 0.2
Epoch: 382 	Training Loss: 1.216094 	Validation Loss: 1.392945 	 time: 0.4
Epoch: 383 	Training Loss: 1.215980 	Validation Loss: 1.392920 	 time: 0.3
Epoch: 384 	Training Loss: 1.215860 	Validation Loss: 1.392960 	 time: 0.2
Epoch: 385 	Training Loss: 1.215728 	Validation Loss: 1.392605 	 time: 0.2
Epoch: 386 	Training Loss: 1.215602 	Validation Loss: 1.392757 	 time: 0.2
Epoch: 387 	Training Loss: 1.215473 	Validation Loss: 1.392617 	 time: 0.3
Epoch: 388 	Training Loss: 1.215337 	Validation Loss: 1.392718 	 time: 0.3
Epoch: 389 	Training Loss: 1.215193 	Validation Loss: 1.392818 	 time: 0.3
Epoch: 390 	Training Loss: 1.215049 	Validation Loss: 1.392833 	 time: 0.3
Epoch: 391 	Training Loss: 1.214916 	Validation Loss: 1.392906 	 time: 0.3
Epoch: 392 	Training Loss: 1.214785 	Validation Loss: 1.392787 	 time: 0.3
Epoch: 393 	Training Loss: 1.214649 	Validation Loss: 1.393200 	 time: 0.3
Epoch: 394 	Training Loss: 1.214519 	Validation Loss: 1.392983 	 time: 0.3
Epoch: 395 	Training Loss: 1.214419 	Validation Loss: 1.393728 	 time: 0.2
Epoch: 396 	Training Loss: 1.214350 	Validation Loss: 1.393495 	 time: 0.3
Epoch: 397 	Training Loss: 1.214323 	Validation Loss: 1.394489 	 time: 0.3
Epoch: 398 	Training Loss: 1.214333 	Validation Loss: 1.394045 	 time: 0.3
Epoch: 399 	Training Loss: 1.214430 	Validation Loss: 1.395764 	 time: 0.3
Epoch: 400 	Training Loss: 1.214573 	Validation Loss: 1.394006 	 time: 0.3
Epoch: 401 	Training Loss: 1.214958 	Validation Loss: 1.397217 	 time: 0.3
Epoch: 402 	Training Loss: 1.215357 	Validation Loss: 1.393706 	 time: 0.3
Epoch: 403 	Training Loss: 1.216301 	Validation Loss: 1.399519 	 time: 0.5
Epoch: 404 	Training Loss: 1.217174 	Validation Loss: 1.392355 	 time: 0.3
Epoch: 405 	Training Loss: 1.218948 	Validation Loss: 1.401906 	 time: 0.3
Epoch: 406 	Training Loss: 1.218537 	Validation Loss: 1.392223 	 time: 0.3
Epoch: 407 	Training Loss: 1.216176 	Validation Loss: 1.394778 	 time: 0.3
Epoch: 408 	Training Loss: 1.214033 	Validation Loss: 1.402714 	 time: 0.3
Epoch: 409 	Training Loss: 1.216458 	Validation Loss: 1.395156 	 time: 0.7
Epoch: 410 	Training Loss: 1.215919 	Validation Loss: 1.398232 	 time: 0.3
Epoch: 411 	Training Loss: 1.213457 	Validation Loss: 1.402764 	 time: 0.3
Epoch: 412 	Training Loss: 1.215381 	Validation Loss: 1.396500 	 time: 0.3
Epoch: 413 	Training Loss: 1.216989 	Validation Loss: 1.404124 	 time: 0.3
Epoch: 414 	Training Loss: 1.214887 	Validation Loss: 1.400676 	 time: 0.3
Epoch: 415 	Training Loss: 1.213219 	Validation Loss: 1.398163 	 time: 0.3
Epoch: 416 	Training Loss: 1.214749 	Validation Loss: 1.400706 	 time: 0.3
Epoch: 417 	Training Loss: 1.213278 	Validation Loss: 1.401923 	 time: 0.3
Epoch: 418 	Training Loss: 1.212948 	Validation Loss: 1.398953 	 time: 0.3
Epoch: 419 	Training Loss: 1.213632 	Validation Loss: 1.400893 	 time: 0.3
Epoch: 420 	Training Loss: 1.212287 	Validation Loss: 1.402180 	 time: 0.3
Epoch: 421 	Training Loss: 1.212968 	Validation Loss: 1.395507 	 time: 0.3
Epoch: 422 	Training Loss: 1.213351 	Validation Loss: 1.402995 	 time: 0.2
Epoch: 423 	Training Loss: 1.212312 	Validation Loss: 1.401542 	 time: 0.3
Epoch: 424 	Training Loss: 1.212058 	Validation Loss: 1.397690 	 time: 0.3
Epoch: 425 	Training Loss: 1.212560 	Validation Loss: 1.401444 	 time: 0.3
Epoch: 426 	Training Loss: 1.211761 	Validation Loss: 1.404641 	 time: 0.2
Epoch: 427 	Training Loss: 1.211639 	Validation Loss: 1.400924 	 time: 0.2
Epoch: 428 	Training Loss: 1.211854 	Validation Loss: 1.403351 	 time: 0.2
Epoch: 429 	Training Loss: 1.211251 	Validation Loss: 1.403316 	 time: 0.3
Epoch: 430 	Training Loss: 1.211313 	Validation Loss: 1.399798 	 time: 0.3
Epoch: 431 	Training Loss: 1.211469 	Validation Loss: 1.404927 	 time: 0.3
Epoch: 432 	Training Loss: 1.211148 	Validation Loss: 1.402750 	 time: 0.2
Epoch: 433 	Training Loss: 1.210796 	Validation Loss: 1.400152 	 time: 0.3
Epoch: 434 	Training Loss: 1.211061 	Validation Loss: 1.404300 	 time: 0.3
Epoch: 435 	Training Loss: 1.210866 	Validation Loss: 1.404051 	 time: 0.2
Epoch: 436 	Training Loss: 1.210579 	Validation Loss: 1.404610 	 time: 0.2
Epoch: 437 	Training Loss: 1.210541 	Validation Loss: 1.406039 	 time: 0.2
Epoch: 438 	Training Loss: 1.210534 	Validation Loss: 1.403493 	 time: 0.3
Epoch: 439 	Training Loss: 1.210383 	Validation Loss: 1.404607 	 time: 0.3
Epoch: 440 	Training Loss: 1.210118 	Validation Loss: 1.406346 	 time: 0.3
Epoch: 441 	Training Loss: 1.210173 	Validation Loss: 1.402359 	 time: 0.3
Epoch: 442 	Training Loss: 1.210116 	Validation Loss: 1.403966 	 time: 0.3
Epoch: 443 	Training Loss: 1.209860 	Validation Loss: 1.404616 	 time: 0.3
Epoch: 444 	Training Loss: 1.209625 	Validation Loss: 1.404771 	 time: 0.3
Epoch: 445 	Training Loss: 1.209592 	Validation Loss: 1.407632 	 time: 0.3
Epoch: 446 	Training Loss: 1.209468 	Validation Loss: 1.406886 	 time: 0.3
Epoch: 447 	Training Loss: 1.209264 	Validation Loss: 1.407639 	 time: 0.3
Epoch: 448 	Training Loss: 1.209135 	Validation Loss: 1.408796 	 time: 0.3
Epoch: 449 	Training Loss: 1.209081 	Validation Loss: 1.406624 	 time: 0.2
Epoch: 450 	Training Loss: 1.208996 	Validation Loss: 1.407763 	 time: 0.2
Epoch: 451 	Training Loss: 1.208843 	Validation Loss: 1.405962 	 time: 0.3
Epoch: 452 	Training Loss: 1.208694 	Validation Loss: 1.407011 	 time: 0.3
Epoch: 453 	Training Loss: 1.208549 	Validation Loss: 1.408111 	 time: 0.3
Epoch: 454 	Training Loss: 1.208484 	Validation Loss: 1.407516 	 time: 0.3
Epoch: 455 	Training Loss: 1.208390 	Validation Loss: 1.408271 	 time: 0.3
Epoch: 456 	Training Loss: 1.208273 	Validation Loss: 1.407726 	 time: 0.3
Epoch: 457 	Training Loss: 1.208118 	Validation Loss: 1.407677 	 time: 0.3
Epoch: 458 	Training Loss: 1.207971 	Validation Loss: 1.407539 	 time: 0.3
Epoch: 459 	Training Loss: 1.207861 	Validation Loss: 1.406606 	 time: 0.3
Epoch: 460 	Training Loss: 1.207734 	Validation Loss: 1.407155 	 time: 0.3
Epoch: 461 	Training Loss: 1.207591 	Validation Loss: 1.405751 	 time: 0.3
Epoch: 462 	Training Loss: 1.207491 	Validation Loss: 1.405913 	 time: 0.3
Epoch: 463 	Training Loss: 1.207348 	Validation Loss: 1.405163 	 time: 0.3
Epoch: 464 	Training Loss: 1.207232 	Validation Loss: 1.404020 	 time: 0.3
Epoch: 465 	Training Loss: 1.207082 	Validation Loss: 1.405116 	 time: 0.3
Epoch: 466 	Training Loss: 1.206871 	Validation Loss: 1.403310 	 time: 0.3
Epoch: 467 	Training Loss: 1.206746 	Validation Loss: 1.403701 	 time: 0.3
Epoch: 468 	Training Loss: 1.206617 	Validation Loss: 1.402315 	 time: 0.3
Epoch: 469 	Training Loss: 1.206489 	Validation Loss: 1.402466 	 time: 0.3
Epoch: 470 	Training Loss: 1.206394 	Validation Loss: 1.402247 	 time: 0.2
Epoch: 471 	Training Loss: 1.206318 	Validation Loss: 1.401195 	 time: 0.2
Epoch: 472 	Training Loss: 1.206246 	Validation Loss: 1.401987 	 time: 0.3
Epoch: 473 	Training Loss: 1.206163 	Validation Loss: 1.400979 	 time: 0.3
Epoch: 474 	Training Loss: 1.206066 	Validation Loss: 1.401801 	 time: 0.3
Epoch: 475 	Training Loss: 1.205972 	Validation Loss: 1.401012 	 time: 0.3
Epoch: 476 	Training Loss: 1.205880 	Validation Loss: 1.401199 	 time: 0.2
Epoch: 477 	Training Loss: 1.205787 	Validation Loss: 1.400963 	 time: 0.3
Epoch: 478 	Training Loss: 1.205690 	Validation Loss: 1.400365 	 time: 0.3
Epoch: 479 	Training Loss: 1.205584 	Validation Loss: 1.400532 	 time: 0.3
Epoch: 480 	Training Loss: 1.205464 	Validation Loss: 1.399946 	 time: 0.2
Epoch: 481 	Training Loss: 1.205339 	Validation Loss: 1.400724 	 time: 0.3
Epoch: 482 	Training Loss: 1.205211 	Validation Loss: 1.400294 	 time: 0.3
Epoch: 483 	Training Loss: 1.205093 	Validation Loss: 1.400858 	 time: 0.3
Epoch: 484 	Training Loss: 1.205005 	Validation Loss: 1.400692 	 time: 0.3
Epoch: 485 	Training Loss: 1.204907 	Validation Loss: 1.401472 	 time: 0.2
Epoch: 486 	Training Loss: 1.204787 	Validation Loss: 1.401045 	 time: 0.3
Epoch: 487 	Training Loss: 1.204635 	Validation Loss: 1.401943 	 time: 0.3
Epoch: 488 	Training Loss: 1.204486 	Validation Loss: 1.400259 	 time: 0.3
Epoch: 489 	Training Loss: 1.204467 	Validation Loss: 1.403250 	 time: 0.3
Epoch: 490 	Training Loss: 1.204826 	Validation Loss: 1.395968 	 time: 0.3
Epoch: 491 	Training Loss: 1.207462 	Validation Loss: 1.419619 	 time: 0.3
Epoch: 492 	Training Loss: 1.219300 	Validation Loss: 1.428266 	 time: 0.3
Epoch: 493 	Training Loss: 1.304223 	Validation Loss: 1.387017 	 time: 0.3
Epoch: 494 	Training Loss: 1.223028 	Validation Loss: 1.529113 	 time: 0.2
Epoch: 495 	Training Loss: 1.343836 	Validation Loss: 1.401086 	 time: 0.3
Epoch: 496 	Training Loss: 1.262488 	Validation Loss: 1.414896 	 time: 0.3
Epoch: 497 	Training Loss: 1.309507 	Validation Loss: 1.402458 	 time: 0.3
Epoch: 498 	Training Loss: 1.282710 	Validation Loss: 1.427394 	 time: 0.3
Epoch: 499 	Training Loss: 1.257598 	Validation Loss: 1.481535 	 time: 0.3
Epoch: 500 	Training Loss: 1.278172 	Validation Loss: 1.461313 	 time: 0.3
Epoch: 501 	Training Loss: 1.267238 	Validation Loss: 1.435628 	 time: 0.3
Epoch: 502 	Training Loss: 1.242684 	Validation Loss: 1.416836 	 time: 0.2
Epoch: 503 	Training Loss: 1.253063 	Validation Loss: 1.411216 	 time: 0.2
Epoch: 504 	Training Loss: 1.261093 	Validation Loss: 1.406078 	 time: 0.3
Epoch: 505 	Training Loss: 1.237041 	Validation Loss: 1.416811 	 time: 0.3
Epoch: 506 	Training Loss: 1.237155 	Validation Loss: 1.427749 	 time: 0.3
Epoch: 507 	Training Loss: 1.245110 	Validation Loss: 1.418329 	 time: 0.2
Epoch: 508 	Training Loss: 1.229098 	Validation Loss: 1.396327 	 time: 0.3
Epoch: 509 	Training Loss: 1.227599 	Validation Loss: 1.391072 	 time: 0.3
Epoch: 510 	Training Loss: 1.231517 	Validation Loss: 1.396438 	 time: 0.3
Epoch: 511 	Training Loss: 1.223033 	Validation Loss: 1.407327 	 time: 0.3
Epoch: 512 	Training Loss: 1.220123 	Validation Loss: 1.411833 	 time: 0.2
Epoch: 513 	Training Loss: 1.221333 	Validation Loss: 1.403708 	 time: 0.3
Epoch: 514 	Training Loss: 1.218008 	Validation Loss: 1.398866 	 time: 0.3
Epoch: 515 	Training Loss: 1.215381 	Validation Loss: 1.390836 	 time: 0.3
Epoch: 516 	Training Loss: 1.215858 	Validation Loss: 1.384349 	 time: 0.2
Epoch: 517 	Training Loss: 1.212048 	Validation Loss: 1.390877 	 time: 0.2
Epoch: 518 	Training Loss: 1.212045 	Validation Loss: 1.394060 	 time: 0.3
Epoch: 519 	Training Loss: 1.210964 	Validation Loss: 1.390613 	 time: 0.4
Epoch: 520 	Training Loss: 1.208873 	Validation Loss: 1.391975 	 time: 0.3
Epoch: 521 	Training Loss: 1.208553 	Validation Loss: 1.397985 	 time: 0.3
Epoch: 522 	Training Loss: 1.206173 	Validation Loss: 1.400731 	 time: 0.3
Epoch: 523 	Training Loss: 1.206840 	Validation Loss: 1.396778 	 time: 0.3
Epoch: 524 	Training Loss: 1.205492 	Validation Loss: 1.399320 	 time: 0.3
Epoch: 525 	Training Loss: 1.204999 	Validation Loss: 1.405736 	 time: 0.3
Epoch: 526 	Training Loss: 1.204802 	Validation Loss: 1.403098 	 time: 0.3
Epoch: 527 	Training Loss: 1.203817 	Validation Loss: 1.397979 	 time: 0.3
Epoch: 528 	Training Loss: 1.204007 	Validation Loss: 1.396865 	 time: 0.3
Epoch: 529 	Training Loss: 1.202995 	Validation Loss: 1.396915 	 time: 0.3
Epoch: 530 	Training Loss: 1.202612 	Validation Loss: 1.393388 	 time: 0.3
Epoch: 531 	Training Loss: 1.202259 	Validation Loss: 1.391951 	 time: 0.3
Epoch: 532 	Training Loss: 1.201979 	Validation Loss: 1.392880 	 time: 0.3
Epoch: 533 	Training Loss: 1.201658 	Validation Loss: 1.394728 	 time: 0.3
Epoch: 534 	Training Loss: 1.201377 	Validation Loss: 1.395793 	 time: 0.3
Epoch: 535 	Training Loss: 1.200949 	Validation Loss: 1.396211 	 time: 0.3
Epoch: 536 	Training Loss: 1.200657 	Validation Loss: 1.394784 	 time: 0.3
Epoch: 537 	Training Loss: 1.200420 	Validation Loss: 1.390046 	 time: 0.3
Epoch: 538 	Training Loss: 1.200220 	Validation Loss: 1.388537 	 time: 0.3
Epoch: 539 	Training Loss: 1.199908 	Validation Loss: 1.391459 	 time: 0.3
Epoch: 540 	Training Loss: 1.199618 	Validation Loss: 1.392687 	 time: 0.3
Epoch: 541 	Training Loss: 1.199553 	Validation Loss: 1.390415 	 time: 0.3
Epoch: 542 	Training Loss: 1.199315 	Validation Loss: 1.388999 	 time: 0.4
Epoch: 543 	Training Loss: 1.199171 	Validation Loss: 1.391506 	 time: 0.3
Epoch: 544 	Training Loss: 1.198898 	Validation Loss: 1.393440 	 time: 0.3
Epoch: 545 	Training Loss: 1.198811 	Validation Loss: 1.392758 	 time: 0.3
Epoch: 546 	Training Loss: 1.198621 	Validation Loss: 1.393929 	 time: 0.2
Epoch: 547 	Training Loss: 1.198351 	Validation Loss: 1.396018 	 time: 0.2
Epoch: 548 	Training Loss: 1.198253 	Validation Loss: 1.396174 	 time: 0.3
Epoch: 549 	Training Loss: 1.198061 	Validation Loss: 1.395761 	 time: 0.3
Epoch: 550 	Training Loss: 1.197907 	Validation Loss: 1.395507 	 time: 0.2
Epoch: 551 	Training Loss: 1.197681 	Validation Loss: 1.394907 	 time: 0.2
Epoch: 552 	Training Loss: 1.197560 	Validation Loss: 1.393956 	 time: 0.2
Epoch: 553 	Training Loss: 1.197423 	Validation Loss: 1.393987 	 time: 0.3
Epoch: 554 	Training Loss: 1.197241 	Validation Loss: 1.394295 	 time: 0.3
Epoch: 555 	Training Loss: 1.197110 	Validation Loss: 1.393536 	 time: 0.3
Epoch: 556 	Training Loss: 1.196978 	Validation Loss: 1.392429 	 time: 0.3
Epoch: 557 	Training Loss: 1.196859 	Validation Loss: 1.391678 	 time: 0.3
Epoch: 558 	Training Loss: 1.196702 	Validation Loss: 1.391242 	 time: 0.3
Epoch: 559 	Training Loss: 1.196555 	Validation Loss: 1.390798 	 time: 0.3
Epoch: 560 	Training Loss: 1.196413 	Validation Loss: 1.390541 	 time: 0.3
Epoch: 561 	Training Loss: 1.196251 	Validation Loss: 1.390401 	 time: 0.3
Epoch: 562 	Training Loss: 1.196092 	Validation Loss: 1.390044 	 time: 0.3
Epoch: 563 	Training Loss: 1.195952 	Validation Loss: 1.389498 	 time: 0.3
Epoch: 564 	Training Loss: 1.195840 	Validation Loss: 1.388327 	 time: 0.3
Epoch: 565 	Training Loss: 1.195722 	Validation Loss: 1.387086 	 time: 0.2
Epoch: 566 	Training Loss: 1.195609 	Validation Loss: 1.386419 	 time: 0.3
Epoch: 567 	Training Loss: 1.195522 	Validation Loss: 1.386340 	 time: 0.2
Epoch: 568 	Training Loss: 1.195424 	Validation Loss: 1.386608 	 time: 0.3
Epoch: 569 	Training Loss: 1.195329 	Validation Loss: 1.387556 	 time: 0.3
Epoch: 570 	Training Loss: 1.195247 	Validation Loss: 1.389090 	 time: 0.3
Epoch: 571 	Training Loss: 1.195174 	Validation Loss: 1.389711 	 time: 0.3
Epoch: 572 	Training Loss: 1.195086 	Validation Loss: 1.389165 	 time: 0.3
Epoch: 573 	Training Loss: 1.194960 	Validation Loss: 1.388678 	 time: 0.2
Epoch: 574 	Training Loss: 1.194796 	Validation Loss: 1.388087 	 time: 0.2
Epoch: 575 	Training Loss: 1.194696 	Validation Loss: 1.387361 	 time: 0.3
Epoch: 576 	Training Loss: 1.194623 	Validation Loss: 1.387179 	 time: 0.3
Epoch: 577 	Training Loss: 1.194538 	Validation Loss: 1.387639 	 time: 0.3
Epoch: 578 	Training Loss: 1.194443 	Validation Loss: 1.388004 	 time: 0.3
Epoch: 579 	Training Loss: 1.194329 	Validation Loss: 1.388151 	 time: 0.3
Epoch: 580 	Training Loss: 1.194208 	Validation Loss: 1.388531 	 time: 0.3
Epoch: 581 	Training Loss: 1.194105 	Validation Loss: 1.389168 	 time: 0.3
Epoch: 582 	Training Loss: 1.193991 	Validation Loss: 1.389953 	 time: 0.3
Epoch: 583 	Training Loss: 1.193855 	Validation Loss: 1.390706 	 time: 0.2
Epoch: 584 	Training Loss: 1.193738 	Validation Loss: 1.390769 	 time: 0.3
Epoch: 585 	Training Loss: 1.193659 	Validation Loss: 1.390973 	 time: 0.3
Epoch: 586 	Training Loss: 1.193588 	Validation Loss: 1.391153 	 time: 0.3
Epoch: 587 	Training Loss: 1.193522 	Validation Loss: 1.390627 	 time: 0.3
Epoch: 588 	Training Loss: 1.193457 	Validation Loss: 1.389674 	 time: 0.3
Epoch: 589 	Training Loss: 1.193383 	Validation Loss: 1.388921 	 time: 0.5
Epoch: 590 	Training Loss: 1.193304 	Validation Loss: 1.388263 	 time: 0.3
Epoch: 591 	Training Loss: 1.193225 	Validation Loss: 1.387586 	 time: 0.3
Epoch: 592 	Training Loss: 1.193142 	Validation Loss: 1.387176 	 time: 0.4
Epoch: 593 	Training Loss: 1.193066 	Validation Loss: 1.386881 	 time: 0.3
Epoch: 594 	Training Loss: 1.193002 	Validation Loss: 1.386394 	 time: 0.3
Epoch: 595 	Training Loss: 1.192945 	Validation Loss: 1.386002 	 time: 0.3
Epoch: 596 	Training Loss: 1.192885 	Validation Loss: 1.385943 	 time: 0.3
Epoch: 597 	Training Loss: 1.192821 	Validation Loss: 1.385941 	 time: 0.3
Epoch: 598 	Training Loss: 1.192753 	Validation Loss: 1.385824 	 time: 0.2
Epoch: 599 	Training Loss: 1.192681 	Validation Loss: 1.385869 	 time: 0.3
Epoch: 600 	Training Loss: 1.192614 	Validation Loss: 1.386212 	 time: 0.3
Epoch: 601 	Training Loss: 1.192552 	Validation Loss: 1.386585 	 time: 0.3
Epoch: 602 	Training Loss: 1.192496 	Validation Loss: 1.386753 	 time: 0.2
Epoch: 603 	Training Loss: 1.192440 	Validation Loss: 1.386780 	 time: 0.3
Epoch: 604 	Training Loss: 1.192381 	Validation Loss: 1.386711 	 time: 0.3
Epoch: 605 	Training Loss: 1.192322 	Validation Loss: 1.386470 	 time: 0.3
Epoch: 606 	Training Loss: 1.192266 	Validation Loss: 1.386235 	 time: 0.2
Epoch: 607 	Training Loss: 1.192219 	Validation Loss: 1.386103 	 time: 0.2
Epoch: 608 	Training Loss: 1.192176 	Validation Loss: 1.385980 	 time: 0.3
Epoch: 609 	Training Loss: 1.192129 	Validation Loss: 1.386014 	 time: 0.3
Epoch: 610 	Training Loss: 1.192073 	Validation Loss: 1.386338 	 time: 0.3
Epoch: 611 	Training Loss: 1.192013 	Validation Loss: 1.386701 	 time: 0.2
Epoch: 612 	Training Loss: 1.191956 	Validation Loss: 1.386840 	 time: 0.3
Epoch: 613 	Training Loss: 1.191904 	Validation Loss: 1.386889 	 time: 0.3
Epoch: 614 	Training Loss: 1.191856 	Validation Loss: 1.387022 	 time: 0.3
Epoch: 615 	Training Loss: 1.191813 	Validation Loss: 1.387189 	 time: 0.2
Epoch: 616 	Training Loss: 1.191772 	Validation Loss: 1.387385 	 time: 0.2
Epoch: 617 	Training Loss: 1.191731 	Validation Loss: 1.387660 	 time: 0.3
Epoch: 618 	Training Loss: 1.191690 	Validation Loss: 1.387978 	 time: 0.3
Epoch: 619 	Training Loss: 1.191649 	Validation Loss: 1.388301 	 time: 0.3
Epoch: 620 	Training Loss: 1.191607 	Validation Loss: 1.388663 	 time: 0.2
Epoch: 621 	Training Loss: 1.191564 	Validation Loss: 1.389052 	 time: 0.3
Epoch: 622 	Training Loss: 1.191519 	Validation Loss: 1.389345 	 time: 0.3
Epoch: 623 	Training Loss: 1.191471 	Validation Loss: 1.389525 	 time: 0.3
Epoch: 624 	Training Loss: 1.191418 	Validation Loss: 1.389750 	 time: 0.2
Epoch: 625 	Training Loss: 1.191362 	Validation Loss: 1.390106 	 time: 0.2
Epoch: 626 	Training Loss: 1.191307 	Validation Loss: 1.390504 	 time: 0.3
Epoch: 627 	Training Loss: 1.191256 	Validation Loss: 1.390865 	 time: 0.3
Epoch: 628 	Training Loss: 1.191207 	Validation Loss: 1.391212 	 time: 0.3
Epoch: 629 	Training Loss: 1.191159 	Validation Loss: 1.391579 	 time: 0.2
Epoch: 630 	Training Loss: 1.191111 	Validation Loss: 1.391922 	 time: 0.3
Epoch: 631 	Training Loss: 1.191065 	Validation Loss: 1.392211 	 time: 0.3
Epoch: 632 	Training Loss: 1.191019 	Validation Loss: 1.392462 	 time: 0.3
Epoch: 633 	Training Loss: 1.190971 	Validation Loss: 1.392676 	 time: 0.3
Epoch: 634 	Training Loss: 1.190920 	Validation Loss: 1.392924 	 time: 0.3
Epoch: 635 	Training Loss: 1.190863 	Validation Loss: 1.393727 	 time: 0.3
Epoch: 636 	Training Loss: 1.190798 	Validation Loss: 1.396153 	 time: 0.3
Epoch: 637 	Training Loss: 1.190755 	Validation Loss: 1.397712 	 time: 0.3
Epoch: 638 	Training Loss: 1.190714 	Validation Loss: 1.397419 	 time: 0.4
Epoch: 639 	Training Loss: 1.190643 	Validation Loss: 1.395586 	 time: 0.3
Epoch: 640 	Training Loss: 1.190560 	Validation Loss: 1.393520 	 time: 0.3
Epoch: 641 	Training Loss: 1.190495 	Validation Loss: 1.392758 	 time: 0.3
Epoch: 642 	Training Loss: 1.190444 	Validation Loss: 1.392815 	 time: 0.3
Epoch: 643 	Training Loss: 1.190392 	Validation Loss: 1.393281 	 time: 0.3
Epoch: 644 	Training Loss: 1.190337 	Validation Loss: 1.394331 	 time: 0.3
Epoch: 645 	Training Loss: 1.190282 	Validation Loss: 1.395430 	 time: 0.3
Epoch: 646 	Training Loss: 1.190224 	Validation Loss: 1.395669 	 time: 0.3
Epoch: 647 	Training Loss: 1.190161 	Validation Loss: 1.395328 	 time: 0.3
Epoch: 648 	Training Loss: 1.190107 	Validation Loss: 1.395123 	 time: 0.3
Epoch: 649 	Training Loss: 1.190064 	Validation Loss: 1.395154 	 time: 0.3
Epoch: 650 	Training Loss: 1.190022 	Validation Loss: 1.395297 	 time: 0.2
Epoch: 651 	Training Loss: 1.189978 	Validation Loss: 1.395802 	 time: 0.2
Epoch: 652 	Training Loss: 1.189936 	Validation Loss: 1.396478 	 time: 0.3
Epoch: 653 	Training Loss: 1.189895 	Validation Loss: 1.396682 	 time: 0.3
Epoch: 654 	Training Loss: 1.189854 	Validation Loss: 1.396449 	 time: 0.3
Epoch: 655 	Training Loss: 1.189814 	Validation Loss: 1.396241 	 time: 0.3
Epoch: 656 	Training Loss: 1.189772 	Validation Loss: 1.396044 	 time: 0.3
Epoch: 657 	Training Loss: 1.189713 	Validation Loss: 1.396012 	 time: 0.2
Epoch: 658 	Training Loss: 1.189597 	Validation Loss: 1.396137 	 time: 0.2
Epoch: 659 	Training Loss: 1.189522 	Validation Loss: 1.395521 	 time: 0.2
Epoch: 660 	Training Loss: 1.189493 	Validation Loss: 1.395168 	 time: 0.2
Epoch: 661 	Training Loss: 1.189465 	Validation Loss: 1.395238 	 time: 0.3
Epoch: 662 	Training Loss: 1.189431 	Validation Loss: 1.395014 	 time: 0.3
Epoch: 663 	Training Loss: 1.189394 	Validation Loss: 1.394641 	 time: 0.3
Epoch: 664 	Training Loss: 1.189355 	Validation Loss: 1.394701 	 time: 0.2
Epoch: 665 	Training Loss: 1.189319 	Validation Loss: 1.394907 	 time: 0.2
Epoch: 666 	Training Loss: 1.189284 	Validation Loss: 1.394764 	 time: 0.3
Epoch: 667 	Training Loss: 1.189250 	Validation Loss: 1.394403 	 time: 0.3
Epoch: 668 	Training Loss: 1.189218 	Validation Loss: 1.394159 	 time: 0.2
Epoch: 669 	Training Loss: 1.189185 	Validation Loss: 1.394091 	 time: 0.2
Epoch: 670 	Training Loss: 1.189151 	Validation Loss: 1.394103 	 time: 0.3
Epoch: 671 	Training Loss: 1.189115 	Validation Loss: 1.394176 	 time: 0.3
Epoch: 672 	Training Loss: 1.189075 	Validation Loss: 1.394380 	 time: 0.3
Epoch: 673 	Training Loss: 1.189029 	Validation Loss: 1.394760 	 time: 0.3
Epoch: 674 	Training Loss: 1.188982 	Validation Loss: 1.395131 	 time: 0.3
Epoch: 675 	Training Loss: 1.188939 	Validation Loss: 1.395443 	 time: 0.3
Epoch: 676 	Training Loss: 1.188890 	Validation Loss: 1.395849 	 time: 0.3
Epoch: 677 	Training Loss: 1.188821 	Validation Loss: 1.396261 	 time: 0.3
Epoch: 678 	Training Loss: 1.188759 	Validation Loss: 1.396512 	 time: 0.3
Epoch: 679 	Training Loss: 1.188721 	Validation Loss: 1.396706 	 time: 0.3
Epoch: 680 	Training Loss: 1.188696 	Validation Loss: 1.397022 	 time: 0.3
Epoch: 681 	Training Loss: 1.188674 	Validation Loss: 1.397408 	 time: 0.5
Epoch: 682 	Training Loss: 1.188653 	Validation Loss: 1.397701 	 time: 0.3
Epoch: 683 	Training Loss: 1.188629 	Validation Loss: 1.397911 	 time: 0.3
Epoch: 684 	Training Loss: 1.188600 	Validation Loss: 1.398152 	 time: 0.3
Epoch: 685 	Training Loss: 1.188561 	Validation Loss: 1.398438 	 time: 0.3
Epoch: 686 	Training Loss: 1.188506 	Validation Loss: 1.398654 	 time: 0.3
Epoch: 687 	Training Loss: 1.188463 	Validation Loss: 1.398740 	 time: 0.3
Epoch: 688 	Training Loss: 1.188431 	Validation Loss: 1.398743 	 time: 0.3
Epoch: 689 	Training Loss: 1.188397 	Validation Loss: 1.398748 	 time: 0.3
Epoch: 690 	Training Loss: 1.188359 	Validation Loss: 1.398890 	 time: 0.3
Epoch: 691 	Training Loss: 1.188320 	Validation Loss: 1.399176 	 time: 0.3
Epoch: 692 	Training Loss: 1.188284 	Validation Loss: 1.399422 	 time: 0.3
Epoch: 693 	Training Loss: 1.188251 	Validation Loss: 1.399586 	 time: 0.3
Epoch: 694 	Training Loss: 1.188221 	Validation Loss: 1.399743 	 time: 0.3
Epoch: 695 	Training Loss: 1.188190 	Validation Loss: 1.399824 	 time: 0.3
Epoch: 696 	Training Loss: 1.188157 	Validation Loss: 1.399762 	 time: 0.3
Epoch: 697 	Training Loss: 1.188125 	Validation Loss: 1.399649 	 time: 0.3
Epoch: 698 	Training Loss: 1.188096 	Validation Loss: 1.399605 	 time: 0.2
Epoch: 699 	Training Loss: 1.188068 	Validation Loss: 1.399634 	 time: 0.3
Epoch: 700 	Training Loss: 1.188042 	Validation Loss: 1.399633 	 time: 0.3
Epoch: 701 	Training Loss: 1.188016 	Validation Loss: 1.399571 	 time: 0.3
Epoch: 702 	Training Loss: 1.187991 	Validation Loss: 1.399562 	 time: 0.3
Epoch: 703 	Training Loss: 1.187967 	Validation Loss: 1.399643 	 time: 0.2
Epoch: 704 	Training Loss: 1.187939 	Validation Loss: 1.399659 	 time: 0.2
Epoch: 705 	Training Loss: 1.187902 	Validation Loss: 1.399522 	 time: 0.2
Epoch: 706 	Training Loss: 1.187845 	Validation Loss: 1.399309 	 time: 0.3
Epoch: 707 	Training Loss: 1.187794 	Validation Loss: 1.399101 	 time: 0.3
Epoch: 708 	Training Loss: 1.187736 	Validation Loss: 1.398899 	 time: 0.3
Epoch: 709 	Training Loss: 1.187682 	Validation Loss: 1.398794 	 time: 0.2
Epoch: 710 	Training Loss: 1.187650 	Validation Loss: 1.398806 	 time: 0.3
Epoch: 711 	Training Loss: 1.187621 	Validation Loss: 1.398660 	 time: 0.3
Epoch: 712 	Training Loss: 1.187592 	Validation Loss: 1.398454 	 time: 0.3
Epoch: 713 	Training Loss: 1.187566 	Validation Loss: 1.398397 	 time: 0.2
Epoch: 714 	Training Loss: 1.187539 	Validation Loss: 1.398235 	 time: 0.2
Epoch: 715 	Training Loss: 1.187513 	Validation Loss: 1.397862 	 time: 0.3
Epoch: 716 	Training Loss: 1.187484 	Validation Loss: 1.397509 	 time: 0.3
Epoch: 717 	Training Loss: 1.187449 	Validation Loss: 1.397204 	 time: 0.2
Epoch: 718 	Training Loss: 1.187398 	Validation Loss: 1.396732 	 time: 0.2
Epoch: 719 	Training Loss: 1.187308 	Validation Loss: 1.396373 	 time: 0.3
Epoch: 720 	Training Loss: 1.187229 	Validation Loss: 1.396661 	 time: 0.3
Epoch: 721 	Training Loss: 1.187185 	Validation Loss: 1.397095 	 time: 0.3
Epoch: 722 	Training Loss: 1.187146 	Validation Loss: 1.396912 	 time: 0.3
Epoch: 723 	Training Loss: 1.187098 	Validation Loss: 1.396268 	 time: 0.2
Epoch: 724 	Training Loss: 1.187049 	Validation Loss: 1.395519 	 time: 0.3
Epoch: 725 	Training Loss: 1.187002 	Validation Loss: 1.394982 	 time: 0.3
Epoch: 726 	Training Loss: 1.186960 	Validation Loss: 1.394701 	 time: 0.3
Epoch: 727 	Training Loss: 1.186922 	Validation Loss: 1.394535 	 time: 0.4
Epoch: 728 	Training Loss: 1.186887 	Validation Loss: 1.394377 	 time: 0.3
Epoch: 729 	Training Loss: 1.186852 	Validation Loss: 1.394188 	 time: 0.3
Epoch: 730 	Training Loss: 1.186815 	Validation Loss: 1.393993 	 time: 0.3
Epoch: 731 	Training Loss: 1.186773 	Validation Loss: 1.393875 	 time: 0.3
Epoch: 732 	Training Loss: 1.186730 	Validation Loss: 1.393981 	 time: 0.3
Epoch: 733 	Training Loss: 1.186694 	Validation Loss: 1.394325 	 time: 0.3
Epoch: 734 	Training Loss: 1.186661 	Validation Loss: 1.394624 	 time: 0.4
Epoch: 735 	Training Loss: 1.186626 	Validation Loss: 1.394690 	 time: 0.3
Epoch: 736 	Training Loss: 1.186585 	Validation Loss: 1.394627 	 time: 0.3
Epoch: 737 	Training Loss: 1.186539 	Validation Loss: 1.394579 	 time: 0.3
Epoch: 738 	Training Loss: 1.186495 	Validation Loss: 1.394541 	 time: 0.2
Epoch: 739 	Training Loss: 1.186463 	Validation Loss: 1.394585 	 time: 0.2
Epoch: 740 	Training Loss: 1.186435 	Validation Loss: 1.394794 	 time: 0.3
Epoch: 741 	Training Loss: 1.186403 	Validation Loss: 1.395010 	 time: 0.3
Epoch: 742 	Training Loss: 1.186365 	Validation Loss: 1.395123 	 time: 0.2
Epoch: 743 	Training Loss: 1.186325 	Validation Loss: 1.395150 	 time: 0.2
Epoch: 744 	Training Loss: 1.186295 	Validation Loss: 1.394899 	 time: 0.3
Epoch: 745 	Training Loss: 1.186268 	Validation Loss: 1.394261 	 time: 0.3
Epoch: 746 	Training Loss: 1.186241 	Validation Loss: 1.393564 	 time: 0.2
Epoch: 747 	Training Loss: 1.186213 	Validation Loss: 1.393124 	 time: 0.2
Epoch: 748 	Training Loss: 1.186178 	Validation Loss: 1.392905 	 time: 0.2
Epoch: 749 	Training Loss: 1.186132 	Validation Loss: 1.392946 	 time: 0.3
Epoch: 750 	Training Loss: 1.186091 	Validation Loss: 1.393219 	 time: 0.3
Epoch: 751 	Training Loss: 1.186059 	Validation Loss: 1.393305 	 time: 0.3
Epoch: 752 	Training Loss: 1.186029 	Validation Loss: 1.392994 	 time: 0.2
Epoch: 753 	Training Loss: 1.186000 	Validation Loss: 1.392599 	 time: 0.3
Epoch: 754 	Training Loss: 1.185971 	Validation Loss: 1.392387 	 time: 0.3
Epoch: 755 	Training Loss: 1.185945 	Validation Loss: 1.392228 	 time: 0.3
Epoch: 756 	Training Loss: 1.185922 	Validation Loss: 1.392072 	 time: 0.3
Epoch: 757 	Training Loss: 1.185901 	Validation Loss: 1.392014 	 time: 0.2
Epoch: 758 	Training Loss: 1.185882 	Validation Loss: 1.391980 	 time: 0.3
Epoch: 759 	Training Loss: 1.185862 	Validation Loss: 1.391834 	 time: 0.3
Epoch: 760 	Training Loss: 1.185842 	Validation Loss: 1.391653 	 time: 0.3
Epoch: 761 	Training Loss: 1.185824 	Validation Loss: 1.391591 	 time: 0.3
Epoch: 762 	Training Loss: 1.185807 	Validation Loss: 1.391645 	 time: 0.3
Epoch: 763 	Training Loss: 1.185788 	Validation Loss: 1.391763 	 time: 0.3
Epoch: 764 	Training Loss: 1.185769 	Validation Loss: 1.391904 	 time: 0.3
Epoch: 765 	Training Loss: 1.185751 	Validation Loss: 1.391975 	 time: 0.3
Epoch: 766 	Training Loss: 1.185733 	Validation Loss: 1.391940 	 time: 0.3
Epoch: 767 	Training Loss: 1.185717 	Validation Loss: 1.391909 	 time: 0.3
Epoch: 768 	Training Loss: 1.185699 	Validation Loss: 1.391985 	 time: 0.3
Epoch: 769 	Training Loss: 1.185678 	Validation Loss: 1.392109 	 time: 0.3
Epoch: 770 	Training Loss: 1.185637 	Validation Loss: 1.392234 	 time: 0.3
Epoch: 771 	Training Loss: 1.185611 	Validation Loss: 1.392418 	 time: 0.3
Epoch: 772 	Training Loss: 1.185597 	Validation Loss: 1.392472 	 time: 0.3
Epoch: 773 	Training Loss: 1.185585 	Validation Loss: 1.392380 	 time: 0.3
Epoch: 774 	Training Loss: 1.185572 	Validation Loss: 1.392344 	 time: 0.3
Epoch: 775 	Training Loss: 1.185559 	Validation Loss: 1.392390 	 time: 0.3
Epoch: 776 	Training Loss: 1.185545 	Validation Loss: 1.392343 	 time: 0.3
Epoch: 777 	Training Loss: 1.185532 	Validation Loss: 1.392250 	 time: 0.4
Epoch: 778 	Training Loss: 1.185517 	Validation Loss: 1.392270 	 time: 0.3
Epoch: 779 	Training Loss: 1.185501 	Validation Loss: 1.392327 	 time: 0.3
Epoch: 780 	Training Loss: 1.185483 	Validation Loss: 1.392296 	 time: 0.3
Epoch: 781 	Training Loss: 1.185460 	Validation Loss: 1.392195 	 time: 0.3
Epoch: 782 	Training Loss: 1.185431 	Validation Loss: 1.392047 	 time: 0.3
Epoch: 783 	Training Loss: 1.185394 	Validation Loss: 1.391766 	 time: 0.4
Epoch: 784 	Training Loss: 1.185352 	Validation Loss: 1.391414 	 time: 0.3
Epoch: 785 	Training Loss: 1.185310 	Validation Loss: 1.391300 	 time: 0.3
Epoch: 786 	Training Loss: 1.185276 	Validation Loss: 1.391436 	 time: 0.9
Epoch: 787 	Training Loss: 1.185251 	Validation Loss: 1.391481 	 time: 0.3
Epoch: 788 	Training Loss: 1.185230 	Validation Loss: 1.391324 	 time: 0.4
Epoch: 789 	Training Loss: 1.185205 	Validation Loss: 1.391093 	 time: 0.3
Epoch: 790 	Training Loss: 1.185174 	Validation Loss: 1.390816 	 time: 0.3
Epoch: 791 	Training Loss: 1.185136 	Validation Loss: 1.390520 	 time: 0.2
Epoch: 792 	Training Loss: 1.185096 	Validation Loss: 1.390379 	 time: 0.3
Epoch: 793 	Training Loss: 1.185058 	Validation Loss: 1.390497 	 time: 0.3
Epoch: 794 	Training Loss: 1.185022 	Validation Loss: 1.390722 	 time: 0.3
Epoch: 795 	Training Loss: 1.184989 	Validation Loss: 1.390829 	 time: 0.3
Epoch: 796 	Training Loss: 1.184960 	Validation Loss: 1.390787 	 time: 0.2
Epoch: 797 	Training Loss: 1.184940 	Validation Loss: 1.390658 	 time: 0.3
Epoch: 798 	Training Loss: 1.184926 	Validation Loss: 1.390454 	 time: 0.3
Epoch: 799 	Training Loss: 1.184911 	Validation Loss: 1.390278 	 time: 0.3
Epoch: 800 	Training Loss: 1.184892 	Validation Loss: 1.390258 	 time: 0.3
Epoch: 801 	Training Loss: 1.184868 	Validation Loss: 1.390294 	 time: 0.3
Epoch: 802 	Training Loss: 1.184831 	Validation Loss: 1.390245 	 time: 0.3
Epoch: 803 	Training Loss: 1.184798 	Validation Loss: 1.390193 	 time: 0.3
Epoch: 804 	Training Loss: 1.184770 	Validation Loss: 1.390055 	 time: 0.3
Epoch: 805 	Training Loss: 1.184737 	Validation Loss: 1.389810 	 time: 0.3
Epoch: 806 	Training Loss: 1.184712 	Validation Loss: 1.389827 	 time: 0.3
Epoch: 807 	Training Loss: 1.184683 	Validation Loss: 1.389581 	 time: 0.3
Epoch: 808 	Training Loss: 1.184650 	Validation Loss: 1.388868 	 time: 0.3
Epoch: 809 	Training Loss: 1.184628 	Validation Loss: 1.388467 	 time: 0.3
Epoch: 810 	Training Loss: 1.184598 	Validation Loss: 1.388380 	 time: 0.2
Epoch: 811 	Training Loss: 1.184571 	Validation Loss: 1.387929 	 time: 0.3
Epoch: 812 	Training Loss: 1.184545 	Validation Loss: 1.387415 	 time: 0.3
Epoch: 813 	Training Loss: 1.184515 	Validation Loss: 1.387297 	 time: 0.4
Epoch: 814 	Training Loss: 1.184487 	Validation Loss: 1.387217 	 time: 0.2
Epoch: 815 	Training Loss: 1.184461 	Validation Loss: 1.387009 	 time: 0.3
Epoch: 816 	Training Loss: 1.184435 	Validation Loss: 1.386872 	 time: 0.3
Epoch: 817 	Training Loss: 1.184412 	Validation Loss: 1.386771 	 time: 0.3
Epoch: 818 	Training Loss: 1.184386 	Validation Loss: 1.386599 	 time: 0.3
Epoch: 819 	Training Loss: 1.184362 	Validation Loss: 1.386446 	 time: 0.3
Epoch: 820 	Training Loss: 1.184342 	Validation Loss: 1.386568 	 time: 0.3
Epoch: 821 	Training Loss: 1.184322 	Validation Loss: 1.386850 	 time: 0.3
Epoch: 822 	Training Loss: 1.184300 	Validation Loss: 1.387058 	 time: 0.3
Epoch: 823 	Training Loss: 1.184270 	Validation Loss: 1.387452 	 time: 0.2
Epoch: 824 	Training Loss: 1.184205 	Validation Loss: 1.387892 	 time: 0.3
Epoch: 825 	Training Loss: 1.184187 	Validation Loss: 1.388209 	 time: 0.2
Epoch: 826 	Training Loss: 1.184176 	Validation Loss: 1.388602 	 time: 0.2
Epoch: 827 	Training Loss: 1.184161 	Validation Loss: 1.388979 	 time: 0.3
Epoch: 828 	Training Loss: 1.184139 	Validation Loss: 1.389190 	 time: 0.2
Epoch: 829 	Training Loss: 1.184122 	Validation Loss: 1.389334 	 time: 0.3
Epoch: 830 	Training Loss: 1.184106 	Validation Loss: 1.389420 	 time: 0.3
Epoch: 831 	Training Loss: 1.184089 	Validation Loss: 1.389500 	 time: 0.3
Epoch: 832 	Training Loss: 1.184074 	Validation Loss: 1.389595 	 time: 0.2
Epoch: 833 	Training Loss: 1.184059 	Validation Loss: 1.389656 	 time: 0.3
Epoch: 834 	Training Loss: 1.184046 	Validation Loss: 1.389694 	 time: 0.3
Epoch: 835 	Training Loss: 1.184031 	Validation Loss: 1.389638 	 time: 0.3
Epoch: 836 	Training Loss: 1.184017 	Validation Loss: 1.389581 	 time: 0.3
Epoch: 837 	Training Loss: 1.184001 	Validation Loss: 1.389552 	 time: 0.3
Epoch: 838 	Training Loss: 1.183980 	Validation Loss: 1.389476 	 time: 0.3
Epoch: 839 	Training Loss: 1.183953 	Validation Loss: 1.389363 	 time: 0.3
Epoch: 840 	Training Loss: 1.183926 	Validation Loss: 1.389185 	 time: 0.3
Epoch: 841 	Training Loss: 1.183895 	Validation Loss: 1.388925 	 time: 0.3
Epoch: 842 	Training Loss: 1.183852 	Validation Loss: 1.388711 	 time: 0.2
Epoch: 843 	Training Loss: 1.183796 	Validation Loss: 1.388544 	 time: 0.3
Epoch: 844 	Training Loss: 1.183732 	Validation Loss: 1.388283 	 time: 0.3
Epoch: 845 	Training Loss: 1.183667 	Validation Loss: 1.387964 	 time: 0.3
Epoch: 846 	Training Loss: 1.183636 	Validation Loss: 1.387716 	 time: 0.3
Epoch: 847 	Training Loss: 1.183618 	Validation Loss: 1.387488 	 time: 0.3
Epoch: 848 	Training Loss: 1.183605 	Validation Loss: 1.387207 	 time: 0.2
Epoch: 849 	Training Loss: 1.183590 	Validation Loss: 1.387023 	 time: 0.2
Epoch: 850 	Training Loss: 1.183575 	Validation Loss: 1.387041 	 time: 0.3
Epoch: 851 	Training Loss: 1.183558 	Validation Loss: 1.387140 	 time: 0.2
Epoch: 852 	Training Loss: 1.183542 	Validation Loss: 1.387210 	 time: 0.3
Epoch: 853 	Training Loss: 1.183527 	Validation Loss: 1.387292 	 time: 0.2
Epoch: 854 	Training Loss: 1.183512 	Validation Loss: 1.387408 	 time: 0.3
Epoch: 855 	Training Loss: 1.183495 	Validation Loss: 1.387488 	 time: 0.3
Epoch: 856 	Training Loss: 1.183474 	Validation Loss: 1.387474 	 time: 0.3
Epoch: 857 	Training Loss: 1.183443 	Validation Loss: 1.387380 	 time: 0.3
Epoch: 858 	Training Loss: 1.183416 	Validation Loss: 1.387298 	 time: 0.3
Epoch: 859 	Training Loss: 1.183394 	Validation Loss: 1.387303 	 time: 0.3
Epoch: 860 	Training Loss: 1.183365 	Validation Loss: 1.387358 	 time: 0.3
Epoch: 861 	Training Loss: 1.183316 	Validation Loss: 1.387462 	 time: 0.3
Epoch: 862 	Training Loss: 1.183278 	Validation Loss: 1.387895 	 time: 0.2
Epoch: 863 	Training Loss: 1.183268 	Validation Loss: 1.388448 	 time: 0.2
Epoch: 864 	Training Loss: 1.183256 	Validation Loss: 1.388801 	 time: 0.3
Epoch: 865 	Training Loss: 1.183221 	Validation Loss: 1.388908 	 time: 0.3
Epoch: 866 	Training Loss: 1.183196 	Validation Loss: 1.388967 	 time: 0.3
Epoch: 867 	Training Loss: 1.183181 	Validation Loss: 1.389153 	 time: 0.3
Epoch: 868 	Training Loss: 1.183170 	Validation Loss: 1.389320 	 time: 0.3
Epoch: 869 	Training Loss: 1.183156 	Validation Loss: 1.389281 	 time: 0.3
Epoch: 870 	Training Loss: 1.183138 	Validation Loss: 1.389111 	 time: 0.3
Epoch: 871 	Training Loss: 1.183117 	Validation Loss: 1.389000 	 time: 0.2
Epoch: 872 	Training Loss: 1.183095 	Validation Loss: 1.389024 	 time: 0.2
Epoch: 873 	Training Loss: 1.183075 	Validation Loss: 1.389047 	 time: 0.3
Epoch: 874 	Training Loss: 1.183056 	Validation Loss: 1.389007 	 time: 0.3
Epoch: 875 	Training Loss: 1.183038 	Validation Loss: 1.389047 	 time: 0.3
Epoch: 876 	Training Loss: 1.183019 	Validation Loss: 1.389214 	 time: 0.2
Epoch: 877 	Training Loss: 1.182999 	Validation Loss: 1.389325 	 time: 0.2
Epoch: 878 	Training Loss: 1.182979 	Validation Loss: 1.389247 	 time: 0.3
Epoch: 879 	Training Loss: 1.182960 	Validation Loss: 1.389085 	 time: 0.3
Epoch: 880 	Training Loss: 1.182941 	Validation Loss: 1.389012 	 time: 0.3
Epoch: 881 	Training Loss: 1.182920 	Validation Loss: 1.389069 	 time: 0.4
Epoch: 882 	Training Loss: 1.182896 	Validation Loss: 1.389076 	 time: 0.3
Epoch: 883 	Training Loss: 1.182874 	Validation Loss: 1.388958 	 time: 0.3
Epoch: 884 	Training Loss: 1.182854 	Validation Loss: 1.389012 	 time: 0.3
Epoch: 885 	Training Loss: 1.182836 	Validation Loss: 1.389143 	 time: 0.3
Epoch: 886 	Training Loss: 1.182818 	Validation Loss: 1.389164 	 time: 0.3
Epoch: 887 	Training Loss: 1.182798 	Validation Loss: 1.389148 	 time: 0.3
Epoch: 888 	Training Loss: 1.182770 	Validation Loss: 1.389154 	 time: 0.3
Epoch: 889 	Training Loss: 1.182746 	Validation Loss: 1.389177 	 time: 0.3
Epoch: 890 	Training Loss: 1.182735 	Validation Loss: 1.389289 	 time: 0.3
Epoch: 891 	Training Loss: 1.182719 	Validation Loss: 1.389406 	 time: 0.3
Epoch: 892 	Training Loss: 1.182709 	Validation Loss: 1.389214 	 time: 0.3
Epoch: 893 	Training Loss: 1.182704 	Validation Loss: 1.388699 	 time: 0.2
Epoch: 894 	Training Loss: 1.182693 	Validation Loss: 1.388242 	 time: 0.3
Epoch: 895 	Training Loss: 1.182682 	Validation Loss: 1.388109 	 time: 0.3
Epoch: 896 	Training Loss: 1.182673 	Validation Loss: 1.388184 	 time: 0.3
Epoch: 897 	Training Loss: 1.182659 	Validation Loss: 1.388318 	 time: 0.3
Epoch: 898 	Training Loss: 1.182644 	Validation Loss: 1.388447 	 time: 0.2
Epoch: 899 	Training Loss: 1.182628 	Validation Loss: 1.388509 	 time: 0.3
Epoch: 900 	Training Loss: 1.182615 	Validation Loss: 1.388500 	 time: 0.3
Epoch: 901 	Training Loss: 1.182600 	Validation Loss: 1.388400 	 time: 0.3
Epoch: 902 	Training Loss: 1.182586 	Validation Loss: 1.388224 	 time: 0.2
Epoch: 903 	Training Loss: 1.182573 	Validation Loss: 1.388081 	 time: 0.3
Epoch: 904 	Training Loss: 1.182561 	Validation Loss: 1.388034 	 time: 0.3
Epoch: 905 	Training Loss: 1.182543 	Validation Loss: 1.388039 	 time: 0.3
Epoch: 906 	Training Loss: 1.182521 	Validation Loss: 1.388025 	 time: 0.3
Epoch: 907 	Training Loss: 1.182497 	Validation Loss: 1.387832 	 time: 0.3
Epoch: 908 	Training Loss: 1.182480 	Validation Loss: 1.387563 	 time: 0.3
Epoch: 909 	Training Loss: 1.182480 	Validation Loss: 1.387530 	 time: 0.3
Epoch: 910 	Training Loss: 1.182464 	Validation Loss: 1.387603 	 time: 0.2
Epoch: 911 	Training Loss: 1.182446 	Validation Loss: 1.387494 	 time: 0.2
Epoch: 912 	Training Loss: 1.182430 	Validation Loss: 1.387297 	 time: 0.3
Epoch: 913 	Training Loss: 1.182411 	Validation Loss: 1.387138 	 time: 0.3
Epoch: 914 	Training Loss: 1.182390 	Validation Loss: 1.386984 	 time: 0.3
Epoch: 915 	Training Loss: 1.182373 	Validation Loss: 1.386801 	 time: 0.2
Epoch: 916 	Training Loss: 1.182362 	Validation Loss: 1.386642 	 time: 0.2
Epoch: 917 	Training Loss: 1.182353 	Validation Loss: 1.386570 	 time: 0.3
Epoch: 918 	Training Loss: 1.182344 	Validation Loss: 1.386541 	 time: 0.3
Epoch: 919 	Training Loss: 1.182332 	Validation Loss: 1.386542 	 time: 0.3
Epoch: 920 	Training Loss: 1.182314 	Validation Loss: 1.386622 	 time: 0.3
Epoch: 921 	Training Loss: 1.182292 	Validation Loss: 1.386653 	 time: 0.3
Epoch: 922 	Training Loss: 1.182279 	Validation Loss: 1.386583 	 time: 0.3
Epoch: 923 	Training Loss: 1.182267 	Validation Loss: 1.386735 	 time: 0.3
Epoch: 924 	Training Loss: 1.182241 	Validation Loss: 1.387102 	 time: 0.3
Epoch: 925 	Training Loss: 1.182201 	Validation Loss: 1.387383 	 time: 0.2
Epoch: 926 	Training Loss: 1.182109 	Validation Loss: 1.387663 	 time: 0.2
Epoch: 927 	Training Loss: 1.182056 	Validation Loss: 1.387554 	 time: 0.3
Epoch: 928 	Training Loss: 1.182054 	Validation Loss: 1.387915 	 time: 0.4
Epoch: 929 	Training Loss: 1.182050 	Validation Loss: 1.388251 	 time: 0.3
Epoch: 930 	Training Loss: 1.182036 	Validation Loss: 1.388350 	 time: 0.3
Epoch: 931 	Training Loss: 1.182028 	Validation Loss: 1.388088 	 time: 0.3
Epoch: 932 	Training Loss: 1.182012 	Validation Loss: 1.387341 	 time: 0.3
Epoch: 933 	Training Loss: 1.181996 	Validation Loss: 1.386793 	 time: 0.3
Epoch: 934 	Training Loss: 1.181981 	Validation Loss: 1.386598 	 time: 0.3
Epoch: 935 	Training Loss: 1.181966 	Validation Loss: 1.386205 	 time: 0.3
Epoch: 936 	Training Loss: 1.181952 	Validation Loss: 1.385853 	 time: 0.2
Epoch: 937 	Training Loss: 1.181936 	Validation Loss: 1.385691 	 time: 0.3
Epoch: 938 	Training Loss: 1.181923 	Validation Loss: 1.385871 	 time: 0.3
Epoch: 939 	Training Loss: 1.181901 	Validation Loss: 1.386355 	 time: 0.3
Epoch: 940 	Training Loss: 1.181878 	Validation Loss: 1.386467 	 time: 0.3
Epoch: 941 	Training Loss: 1.181854 	Validation Loss: 1.386532 	 time: 0.3
Epoch: 942 	Training Loss: 1.181833 	Validation Loss: 1.386975 	 time: 0.3
Epoch: 943 	Training Loss: 1.181814 	Validation Loss: 1.387293 	 time: 0.3
Epoch: 944 	Training Loss: 1.181797 	Validation Loss: 1.387504 	 time: 0.3
Epoch: 945 	Training Loss: 1.181783 	Validation Loss: 1.387688 	 time: 0.3
Epoch: 946 	Training Loss: 1.181769 	Validation Loss: 1.387561 	 time: 0.3
Epoch: 947 	Training Loss: 1.181754 	Validation Loss: 1.387355 	 time: 0.3
Epoch: 948 	Training Loss: 1.181742 	Validation Loss: 1.387245 	 time: 0.3
Epoch: 949 	Training Loss: 1.181730 	Validation Loss: 1.387145 	 time: 0.3
Epoch: 950 	Training Loss: 1.181707 	Validation Loss: 1.387085 	 time: 0.3
Epoch: 951 	Training Loss: 1.181655 	Validation Loss: 1.386828 	 time: 0.3
Epoch: 952 	Training Loss: 1.181637 	Validation Loss: 1.386557 	 time: 0.3
Epoch: 953 	Training Loss: 1.181626 	Validation Loss: 1.386639 	 time: 0.3
Epoch: 954 	Training Loss: 1.181611 	Validation Loss: 1.386756 	 time: 0.3
Epoch: 955 	Training Loss: 1.181601 	Validation Loss: 1.386767 	 time: 0.3
Epoch: 956 	Training Loss: 1.181591 	Validation Loss: 1.386816 	 time: 0.3
Epoch: 957 	Training Loss: 1.181579 	Validation Loss: 1.386907 	 time: 0.2
Epoch: 958 	Training Loss: 1.181569 	Validation Loss: 1.387133 	 time: 0.2
Epoch: 959 	Training Loss: 1.181560 	Validation Loss: 1.387291 	 time: 0.3
Epoch: 960 	Training Loss: 1.181551 	Validation Loss: 1.387245 	 time: 0.3
Epoch: 961 	Training Loss: 1.181541 	Validation Loss: 1.387291 	 time: 0.3
Epoch: 962 	Training Loss: 1.181530 	Validation Loss: 1.387397 	 time: 0.3
Epoch: 963 	Training Loss: 1.181519 	Validation Loss: 1.387460 	 time: 0.3
Epoch: 964 	Training Loss: 1.181506 	Validation Loss: 1.387704 	 time: 0.3
Epoch: 965 	Training Loss: 1.181494 	Validation Loss: 1.387985 	 time: 0.3
Epoch: 966 	Training Loss: 1.181483 	Validation Loss: 1.388108 	 time: 0.2
Epoch: 967 	Training Loss: 1.181470 	Validation Loss: 1.388267 	 time: 0.2
Epoch: 968 	Training Loss: 1.181457 	Validation Loss: 1.388515 	 time: 0.3
Epoch: 969 	Training Loss: 1.181440 	Validation Loss: 1.388752 	 time: 0.3
Epoch: 970 	Training Loss: 1.181418 	Validation Loss: 1.388951 	 time: 0.3
Epoch: 971 	Training Loss: 1.181391 	Validation Loss: 1.389066 	 time: 0.3
Epoch: 972 	Training Loss: 1.181363 	Validation Loss: 1.389214 	 time: 0.3
Epoch: 973 	Training Loss: 1.181338 	Validation Loss: 1.389475 	 time: 0.3
Epoch: 974 	Training Loss: 1.181318 	Validation Loss: 1.389756 	 time: 0.3
Epoch: 975 	Training Loss: 1.181301 	Validation Loss: 1.390073 	 time: 0.3
Epoch: 976 	Training Loss: 1.181288 	Validation Loss: 1.390382 	 time: 0.4
Epoch: 977 	Training Loss: 1.181278 	Validation Loss: 1.390584 	 time: 0.4
Epoch: 978 	Training Loss: 1.181268 	Validation Loss: 1.390737 	 time: 0.3
Epoch: 979 	Training Loss: 1.181260 	Validation Loss: 1.390874 	 time: 0.3
Epoch: 980 	Training Loss: 1.181251 	Validation Loss: 1.390976 	 time: 0.3
Epoch: 981 	Training Loss: 1.181242 	Validation Loss: 1.391088 	 time: 0.3
Epoch: 982 	Training Loss: 1.181234 	Validation Loss: 1.391205 	 time: 0.3
Epoch: 983 	Training Loss: 1.181225 	Validation Loss: 1.391293 	 time: 0.2
Epoch: 984 	Training Loss: 1.181216 	Validation Loss: 1.391320 	 time: 0.3
Epoch: 985 	Training Loss: 1.181206 	Validation Loss: 1.391185 	 time: 0.3
Epoch: 986 	Training Loss: 1.181194 	Validation Loss: 1.390846 	 time: 0.3
Epoch: 987 	Training Loss: 1.181180 	Validation Loss: 1.390334 	 time: 0.3
Epoch: 988 	Training Loss: 1.181152 	Validation Loss: 1.389606 	 time: 0.3
Epoch: 989 	Training Loss: 1.181123 	Validation Loss: 1.388914 	 time: 0.3
Epoch: 990 	Training Loss: 1.181112 	Validation Loss: 1.388722 	 time: 0.3
Epoch: 991 	Training Loss: 1.181099 	Validation Loss: 1.389057 	 time: 0.3
Epoch: 992 	Training Loss: 1.181080 	Validation Loss: 1.389271 	 time: 0.3
Epoch: 993 	Training Loss: 1.181060 	Validation Loss: 1.389103 	 time: 0.2
Epoch: 994 	Training Loss: 1.181043 	Validation Loss: 1.389015 	 time: 0.3
Epoch: 995 	Training Loss: 1.181026 	Validation Loss: 1.388968 	 time: 0.3
Epoch: 996 	Training Loss: 1.181011 	Validation Loss: 1.388729 	 time: 0.2
Epoch: 997 	Training Loss: 1.180998 	Validation Loss: 1.388614 	 time: 0.2
Epoch: 998 	Training Loss: 1.180987 	Validation Loss: 1.388760 	 time: 0.3
Epoch: 999 	Training Loss: 1.180978 	Validation Loss: 1.388926 	 time: 0.3
Epoch: 1000 	Training Loss: 1.180969 	Validation Loss: 1.389034 	 time: 0.3
