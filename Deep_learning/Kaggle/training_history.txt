Epoch: 1 	Training Loss: 1.796628 	Validation Loss: 1.811338 	 time: 0.3
Validation loss decreased from inf to 1.811338. Model was saved
Epoch: 2 	Training Loss: 1.810422 	Validation Loss: 1.800114 	 time: 0.3
Validation loss decreased from 1.811338 to 1.800114. Model was saved
Epoch: 3 	Training Loss: 1.799481 	Validation Loss: 1.792172 	 time: 0.3
Validation loss decreased from 1.800114 to 1.792172. Model was saved
Epoch: 4 	Training Loss: 1.791687 	Validation Loss: 1.789877 	 time: 0.3
Validation loss decreased from 1.792172 to 1.789877. Model was saved
Epoch: 5 	Training Loss: 1.789333 	Validation Loss: 1.788481 	 time: 0.3
Validation loss decreased from 1.789877 to 1.788481. Model was saved
Epoch: 6 	Training Loss: 1.787516 	Validation Loss: 1.784302 	 time: 0.3
Validation loss decreased from 1.788481 to 1.784302. Model was saved
Epoch: 7 	Training Loss: 1.782095 	Validation Loss: 1.776664 	 time: 0.3
Validation loss decreased from 1.784302 to 1.776664. Model was saved
Epoch: 8 	Training Loss: 1.772111 	Validation Loss: 1.766786 	 time: 0.3
Validation loss decreased from 1.776664 to 1.766786. Model was saved
Epoch: 9 	Training Loss: 1.758610 	Validation Loss: 1.755084 	 time: 0.3
Validation loss decreased from 1.766786 to 1.755084. Model was saved
Epoch: 10 	Training Loss: 1.742525 	Validation Loss: 1.741509 	 time: 0.3
Validation loss decreased from 1.755084 to 1.741509. Model was saved
Epoch: 11 	Training Loss: 1.724602 	Validation Loss: 1.728378 	 time: 0.3
Validation loss decreased from 1.741509 to 1.728378. Model was saved
Epoch: 12 	Training Loss: 1.705205 	Validation Loss: 1.713992 	 time: 0.3
Validation loss decreased from 1.728378 to 1.713992. Model was saved
Epoch: 13 	Training Loss: 1.685133 	Validation Loss: 1.700964 	 time: 0.3
Validation loss decreased from 1.713992 to 1.700964. Model was saved
Epoch: 14 	Training Loss: 1.666006 	Validation Loss: 1.689506 	 time: 0.3
Validation loss decreased from 1.700964 to 1.689506. Model was saved
Epoch: 15 	Training Loss: 1.647926 	Validation Loss: 1.677587 	 time: 0.3
Validation loss decreased from 1.689506 to 1.677587. Model was saved
Epoch: 16 	Training Loss: 1.630582 	Validation Loss: 1.667727 	 time: 0.3
Validation loss decreased from 1.677587 to 1.667727. Model was saved
Epoch: 17 	Training Loss: 1.613598 	Validation Loss: 1.652264 	 time: 0.3
Validation loss decreased from 1.667727 to 1.652264. Model was saved
Epoch: 18 	Training Loss: 1.598599 	Validation Loss: 1.646395 	 time: 0.3
Validation loss decreased from 1.652264 to 1.646395. Model was saved
Epoch: 19 	Training Loss: 1.586525 	Validation Loss: 1.633680 	 time: 0.3
Validation loss decreased from 1.646395 to 1.633680. Model was saved
Epoch: 20 	Training Loss: 1.576617 	Validation Loss: 1.631440 	 time: 0.3
Validation loss decreased from 1.633680 to 1.631440. Model was saved
Epoch: 21 	Training Loss: 1.568276 	Validation Loss: 1.614640 	 time: 0.3
Validation loss decreased from 1.631440 to 1.614640. Model was saved
Epoch: 22 	Training Loss: 1.554673 	Validation Loss: 1.604674 	 time: 0.3
Validation loss decreased from 1.614640 to 1.604674. Model was saved
Epoch: 23 	Training Loss: 1.549245 	Validation Loss: 1.600942 	 time: 0.3
Validation loss decreased from 1.604674 to 1.600942. Model was saved
Epoch: 24 	Training Loss: 1.538476 	Validation Loss: 1.595161 	 time: 0.3
Validation loss decreased from 1.600942 to 1.595161. Model was saved
Epoch: 25 	Training Loss: 1.532593 	Validation Loss: 1.581668 	 time: 0.3
Validation loss decreased from 1.595161 to 1.581668. Model was saved
Epoch: 26 	Training Loss: 1.523783 	Validation Loss: 1.575375 	 time: 0.3
Validation loss decreased from 1.581668 to 1.575375. Model was saved
Epoch: 27 	Training Loss: 1.518991 	Validation Loss: 1.574089 	 time: 0.3
Validation loss decreased from 1.575375 to 1.574089. Model was saved
Epoch: 28 	Training Loss: 1.512239 	Validation Loss: 1.568956 	 time: 0.3
Validation loss decreased from 1.574089 to 1.568956. Model was saved
Epoch: 29 	Training Loss: 1.508121 	Validation Loss: 1.566456 	 time: 0.3
Validation loss decreased from 1.568956 to 1.566456. Model was saved
Epoch: 30 	Training Loss: 1.502823 	Validation Loss: 1.566614 	 time: 0.3
Epoch: 31 	Training Loss: 1.499068 	Validation Loss: 1.565056 	 time: 0.3
Validation loss decreased from 1.566456 to 1.565056. Model was saved
Epoch: 32 	Training Loss: 1.493856 	Validation Loss: 1.563300 	 time: 0.3
Validation loss decreased from 1.565056 to 1.563300. Model was saved
Epoch: 33 	Training Loss: 1.490392 	Validation Loss: 1.564237 	 time: 0.3
Epoch: 34 	Training Loss: 1.486520 	Validation Loss: 1.565081 	 time: 0.3
Epoch: 35 	Training Loss: 1.482558 	Validation Loss: 1.564235 	 time: 0.3
Epoch: 36 	Training Loss: 1.480374 	Validation Loss: 1.567371 	 time: 0.3
Epoch: 37 	Training Loss: 1.476332 	Validation Loss: 1.567652 	 time: 0.3
Epoch: 38 	Training Loss: 1.473244 	Validation Loss: 1.566586 	 time: 0.3
Epoch: 39 	Training Loss: 1.471522 	Validation Loss: 1.568222 	 time: 0.3
Epoch: 40 	Training Loss: 1.468220 	Validation Loss: 1.568230 	 time: 0.3
Epoch: 41 	Training Loss: 1.465630 	Validation Loss: 1.567953 	 time: 0.3
Epoch: 42 	Training Loss: 1.463862 	Validation Loss: 1.570502 	 time: 0.3
Epoch: 43 	Training Loss: 1.460859 	Validation Loss: 1.571090 	 time: 0.3
Epoch: 44 	Training Loss: 1.458731 	Validation Loss: 1.569276 	 time: 0.3
Epoch: 45 	Training Loss: 1.457045 	Validation Loss: 1.568606 	 time: 0.3
Epoch: 46 	Training Loss: 1.454474 	Validation Loss: 1.563418 	 time: 0.3
Epoch: 47 	Training Loss: 1.452271 	Validation Loss: 1.562479 	 time: 0.3
Validation loss decreased from 1.563300 to 1.562479. Model was saved
Epoch: 48 	Training Loss: 1.450477 	Validation Loss: 1.558790 	 time: 0.3
Validation loss decreased from 1.562479 to 1.558790. Model was saved
Epoch: 49 	Training Loss: 1.448280 	Validation Loss: 1.558017 	 time: 0.3
Validation loss decreased from 1.558790 to 1.558017. Model was saved
Epoch: 50 	Training Loss: 1.445920 	Validation Loss: 1.555855 	 time: 0.3
Validation loss decreased from 1.558017 to 1.555855. Model was saved
Epoch: 51 	Training Loss: 1.443830 	Validation Loss: 1.550512 	 time: 0.3
Validation loss decreased from 1.555855 to 1.550512. Model was saved
Epoch: 52 	Training Loss: 1.442203 	Validation Loss: 1.552830 	 time: 0.3
Epoch: 53 	Training Loss: 1.440602 	Validation Loss: 1.546228 	 time: 0.3
Validation loss decreased from 1.550512 to 1.546228. Model was saved
Epoch: 54 	Training Loss: 1.438601 	Validation Loss: 1.550237 	 time: 0.3
Epoch: 55 	Training Loss: 1.437073 	Validation Loss: 1.547324 	 time: 0.3
Epoch: 56 	Training Loss: 1.438036 	Validation Loss: 1.546139 	 time: 0.3
Validation loss decreased from 1.546228 to 1.546139. Model was saved
Epoch: 57 	Training Loss: 1.438880 	Validation Loss: 1.545959 	 time: 0.3
Validation loss decreased from 1.546139 to 1.545959. Model was saved
Epoch: 58 	Training Loss: 1.434327 	Validation Loss: 1.542238 	 time: 0.3
Validation loss decreased from 1.545959 to 1.542238. Model was saved
Epoch: 59 	Training Loss: 1.429986 	Validation Loss: 1.543110 	 time: 0.3
Epoch: 60 	Training Loss: 1.432155 	Validation Loss: 1.544700 	 time: 0.3
Epoch: 61 	Training Loss: 1.427654 	Validation Loss: 1.542804 	 time: 0.3
Epoch: 62 	Training Loss: 1.426455 	Validation Loss: 1.539584 	 time: 0.3
Validation loss decreased from 1.542238 to 1.539584. Model was saved
Epoch: 63 	Training Loss: 1.426221 	Validation Loss: 1.539411 	 time: 0.3
Validation loss decreased from 1.539584 to 1.539411. Model was saved
Epoch: 64 	Training Loss: 1.421742 	Validation Loss: 1.539113 	 time: 0.3
Validation loss decreased from 1.539411 to 1.539113. Model was saved
Epoch: 65 	Training Loss: 1.423093 	Validation Loss: 1.536214 	 time: 0.3
Validation loss decreased from 1.539113 to 1.536214. Model was saved
Epoch: 66 	Training Loss: 1.418955 	Validation Loss: 1.533970 	 time: 0.3
Validation loss decreased from 1.536214 to 1.533970. Model was saved
Epoch: 67 	Training Loss: 1.417379 	Validation Loss: 1.534950 	 time: 0.3
Epoch: 68 	Training Loss: 1.416496 	Validation Loss: 1.532168 	 time: 0.3
Validation loss decreased from 1.533970 to 1.532168. Model was saved
Epoch: 69 	Training Loss: 1.412147 	Validation Loss: 1.527222 	 time: 0.3
Validation loss decreased from 1.532168 to 1.527222. Model was saved
Epoch: 70 	Training Loss: 1.412281 	Validation Loss: 1.527426 	 time: 0.3
Epoch: 71 	Training Loss: 1.408511 	Validation Loss: 1.523993 	 time: 0.3
Validation loss decreased from 1.527222 to 1.523993. Model was saved
Epoch: 72 	Training Loss: 1.405552 	Validation Loss: 1.517376 	 time: 0.3
Validation loss decreased from 1.523993 to 1.517376. Model was saved
Epoch: 73 	Training Loss: 1.404481 	Validation Loss: 1.517029 	 time: 0.3
Validation loss decreased from 1.517376 to 1.517029. Model was saved
Epoch: 74 	Training Loss: 1.400077 	Validation Loss: 1.515205 	 time: 0.3
Validation loss decreased from 1.517029 to 1.515205. Model was saved
Epoch: 75 	Training Loss: 1.398935 	Validation Loss: 1.510396 	 time: 0.3
Validation loss decreased from 1.515205 to 1.510396. Model was saved
Epoch: 76 	Training Loss: 1.396780 	Validation Loss: 1.509606 	 time: 0.3
Validation loss decreased from 1.510396 to 1.509606. Model was saved
Epoch: 77 	Training Loss: 1.394082 	Validation Loss: 1.509689 	 time: 0.3
Epoch: 78 	Training Loss: 1.393316 	Validation Loss: 1.505656 	 time: 0.3
Validation loss decreased from 1.509606 to 1.505656. Model was saved
Epoch: 79 	Training Loss: 1.390778 	Validation Loss: 1.503443 	 time: 0.3
Validation loss decreased from 1.505656 to 1.503443. Model was saved
Epoch: 80 	Training Loss: 1.389190 	Validation Loss: 1.504488 	 time: 0.3
Epoch: 81 	Training Loss: 1.388047 	Validation Loss: 1.500953 	 time: 0.3
Validation loss decreased from 1.503443 to 1.500953. Model was saved
Epoch: 82 	Training Loss: 1.385513 	Validation Loss: 1.498125 	 time: 0.3
Validation loss decreased from 1.500953 to 1.498125. Model was saved
Epoch: 83 	Training Loss: 1.384169 	Validation Loss: 1.500354 	 time: 0.3
Epoch: 84 	Training Loss: 1.382936 	Validation Loss: 1.496369 	 time: 0.3
Validation loss decreased from 1.498125 to 1.496369. Model was saved
Epoch: 85 	Training Loss: 1.380356 	Validation Loss: 1.493784 	 time: 0.3
Validation loss decreased from 1.496369 to 1.493784. Model was saved
Epoch: 86 	Training Loss: 1.379122 	Validation Loss: 1.497048 	 time: 0.3
Epoch: 87 	Training Loss: 1.378126 	Validation Loss: 1.492410 	 time: 0.3
Validation loss decreased from 1.493784 to 1.492410. Model was saved
Epoch: 88 	Training Loss: 1.375344 	Validation Loss: 1.490519 	 time: 0.3
Validation loss decreased from 1.492410 to 1.490519. Model was saved
Epoch: 89 	Training Loss: 1.373822 	Validation Loss: 1.494352 	 time: 0.3
Epoch: 90 	Training Loss: 1.373099 	Validation Loss: 1.488240 	 time: 0.3
Validation loss decreased from 1.490519 to 1.488240. Model was saved
Epoch: 91 	Training Loss: 1.370812 	Validation Loss: 1.488342 	 time: 0.3
Epoch: 92 	Training Loss: 1.368728 	Validation Loss: 1.488436 	 time: 0.3
Epoch: 93 	Training Loss: 1.367350 	Validation Loss: 1.483318 	 time: 0.3
Validation loss decreased from 1.488240 to 1.483318. Model was saved
Epoch: 94 	Training Loss: 1.366056 	Validation Loss: 1.485868 	 time: 0.3
Epoch: 95 	Training Loss: 1.364438 	Validation Loss: 1.481132 	 time: 0.3
Validation loss decreased from 1.483318 to 1.481132. Model was saved
Epoch: 96 	Training Loss: 1.362301 	Validation Loss: 1.480307 	 time: 0.3
Validation loss decreased from 1.481132 to 1.480307. Model was saved
Epoch: 97 	Training Loss: 1.360566 	Validation Loss: 1.481298 	 time: 0.3
Epoch: 98 	Training Loss: 1.359308 	Validation Loss: 1.477923 	 time: 0.3
Validation loss decreased from 1.480307 to 1.477923. Model was saved
Epoch: 99 	Training Loss: 1.357958 	Validation Loss: 1.480758 	 time: 0.3
Epoch: 100 	Training Loss: 1.356320 	Validation Loss: 1.477782 	 time: 0.3
Validation loss decreased from 1.477923 to 1.477782. Model was saved
Epoch: 101 	Training Loss: 1.354427 	Validation Loss: 1.478690 	 time: 0.3
Epoch: 102 	Training Loss: 1.352778 	Validation Loss: 1.478888 	 time: 0.3
Epoch: 103 	Training Loss: 1.351576 	Validation Loss: 1.477490 	 time: 0.3
Validation loss decreased from 1.477782 to 1.477490. Model was saved
Epoch: 104 	Training Loss: 1.351064 	Validation Loss: 1.479233 	 time: 0.3
Epoch: 105 	Training Loss: 1.353933 	Validation Loss: 1.481186 	 time: 0.3
Epoch: 106 	Training Loss: 1.354841 	Validation Loss: 1.477114 	 time: 0.3
Validation loss decreased from 1.477490 to 1.477114. Model was saved
Epoch: 107 	Training Loss: 1.355407 	Validation Loss: 1.479482 	 time: 0.3
Epoch: 108 	Training Loss: 1.345369 	Validation Loss: 1.476406 	 time: 0.3
Validation loss decreased from 1.477114 to 1.476406. Model was saved
Epoch: 109 	Training Loss: 1.351862 	Validation Loss: 1.477551 	 time: 0.3
Epoch: 110 	Training Loss: 1.349199 	Validation Loss: 1.476375 	 time: 0.3
Validation loss decreased from 1.476406 to 1.476375. Model was saved
Epoch: 111 	Training Loss: 1.344563 	Validation Loss: 1.474388 	 time: 0.3
Validation loss decreased from 1.476375 to 1.474388. Model was saved
Epoch: 112 	Training Loss: 1.345988 	Validation Loss: 1.475918 	 time: 0.3
Epoch: 113 	Training Loss: 1.339600 	Validation Loss: 1.474896 	 time: 0.3
Epoch: 114 	Training Loss: 1.341957 	Validation Loss: 1.473466 	 time: 0.3
Validation loss decreased from 1.474388 to 1.473466. Model was saved
Epoch: 115 	Training Loss: 1.336859 	Validation Loss: 1.476551 	 time: 0.3
Epoch: 116 	Training Loss: 1.337991 	Validation Loss: 1.474898 	 time: 0.3
Epoch: 117 	Training Loss: 1.334247 	Validation Loss: 1.470775 	 time: 0.3
Validation loss decreased from 1.473466 to 1.470775. Model was saved
Epoch: 118 	Training Loss: 1.334142 	Validation Loss: 1.473353 	 time: 0.3
Epoch: 119 	Training Loss: 1.331828 	Validation Loss: 1.476197 	 time: 0.3
Epoch: 120 	Training Loss: 1.330596 	Validation Loss: 1.468652 	 time: 0.3
Validation loss decreased from 1.470775 to 1.468652. Model was saved
Epoch: 121 	Training Loss: 1.329120 	Validation Loss: 1.465748 	 time: 0.3
Validation loss decreased from 1.468652 to 1.465748. Model was saved
Epoch: 122 	Training Loss: 1.327690 	Validation Loss: 1.472721 	 time: 0.3
Epoch: 123 	Training Loss: 1.326787 	Validation Loss: 1.471515 	 time: 0.3
Epoch: 124 	Training Loss: 1.324856 	Validation Loss: 1.466856 	 time: 0.3
Epoch: 125 	Training Loss: 1.324702 	Validation Loss: 1.467555 	 time: 0.3
Epoch: 126 	Training Loss: 1.322092 	Validation Loss: 1.471035 	 time: 0.3
Epoch: 127 	Training Loss: 1.321949 	Validation Loss: 1.466267 	 time: 0.3
Epoch: 128 	Training Loss: 1.319957 	Validation Loss: 1.468227 	 time: 0.3
Epoch: 129 	Training Loss: 1.319335 	Validation Loss: 1.469920 	 time: 0.3
Epoch: 130 	Training Loss: 1.318068 	Validation Loss: 1.466333 	 time: 0.3
Epoch: 131 	Training Loss: 1.317069 	Validation Loss: 1.464983 	 time: 0.3
Validation loss decreased from 1.465748 to 1.464983. Model was saved
Epoch: 132 	Training Loss: 1.315682 	Validation Loss: 1.467899 	 time: 0.3
Epoch: 133 	Training Loss: 1.314971 	Validation Loss: 1.467980 	 time: 0.3
Epoch: 134 	Training Loss: 1.313805 	Validation Loss: 1.466201 	 time: 0.3
Epoch: 135 	Training Loss: 1.312417 	Validation Loss: 1.468228 	 time: 0.3
Epoch: 136 	Training Loss: 1.311910 	Validation Loss: 1.465370 	 time: 0.3
Epoch: 137 	Training Loss: 1.310367 	Validation Loss: 1.465249 	 time: 0.3
Epoch: 138 	Training Loss: 1.309240 	Validation Loss: 1.468449 	 time: 0.3
Epoch: 139 	Training Loss: 1.308311 	Validation Loss: 1.461666 	 time: 0.3
Validation loss decreased from 1.464983 to 1.461666. Model was saved
Epoch: 140 	Training Loss: 1.307084 	Validation Loss: 1.463570 	 time: 0.3
Epoch: 141 	Training Loss: 1.306014 	Validation Loss: 1.464296 	 time: 0.3
Epoch: 142 	Training Loss: 1.304636 	Validation Loss: 1.459324 	 time: 0.3
Validation loss decreased from 1.461666 to 1.459324. Model was saved
Epoch: 143 	Training Loss: 1.304366 	Validation Loss: 1.467122 	 time: 0.3
Epoch: 144 	Training Loss: 1.303483 	Validation Loss: 1.458607 	 time: 0.3
Validation loss decreased from 1.459324 to 1.458607. Model was saved
Epoch: 145 	Training Loss: 1.302153 	Validation Loss: 1.464483 	 time: 0.3
Epoch: 146 	Training Loss: 1.301687 	Validation Loss: 1.460655 	 time: 0.3
Epoch: 147 	Training Loss: 1.300914 	Validation Loss: 1.464928 	 time: 0.3
Epoch: 148 	Training Loss: 1.301510 	Validation Loss: 1.457456 	 time: 0.3
Validation loss decreased from 1.458607 to 1.457456. Model was saved
Epoch: 149 	Training Loss: 1.299153 	Validation Loss: 1.464386 	 time: 0.3
Epoch: 150 	Training Loss: 1.297963 	Validation Loss: 1.456124 	 time: 0.3
Validation loss decreased from 1.457456 to 1.456124. Model was saved
Epoch: 151 	Training Loss: 1.296821 	Validation Loss: 1.466236 	 time: 0.3
Epoch: 152 	Training Loss: 1.296375 	Validation Loss: 1.457573 	 time: 0.3
Epoch: 153 	Training Loss: 1.295368 	Validation Loss: 1.460592 	 time: 0.3
Epoch: 154 	Training Loss: 1.293638 	Validation Loss: 1.461403 	 time: 0.3
Epoch: 155 	Training Loss: 1.292314 	Validation Loss: 1.453988 	 time: 0.3
Validation loss decreased from 1.456124 to 1.453988. Model was saved
Epoch: 156 	Training Loss: 1.292416 	Validation Loss: 1.464949 	 time: 0.3
Epoch: 157 	Training Loss: 1.293044 	Validation Loss: 1.450650 	 time: 0.3
Validation loss decreased from 1.453988 to 1.450650. Model was saved
Epoch: 158 	Training Loss: 1.291855 	Validation Loss: 1.460831 	 time: 0.3
Epoch: 159 	Training Loss: 1.289784 	Validation Loss: 1.455636 	 time: 0.3
Epoch: 160 	Training Loss: 1.288309 	Validation Loss: 1.451616 	 time: 0.3
Epoch: 161 	Training Loss: 1.288768 	Validation Loss: 1.458456 	 time: 0.3
Epoch: 162 	Training Loss: 1.287877 	Validation Loss: 1.450426 	 time: 0.3
Validation loss decreased from 1.450650 to 1.450426. Model was saved
Epoch: 163 	Training Loss: 1.285857 	Validation Loss: 1.454356 	 time: 0.3
Epoch: 164 	Training Loss: 1.284803 	Validation Loss: 1.454160 	 time: 0.3
Epoch: 165 	Training Loss: 1.284934 	Validation Loss: 1.453071 	 time: 0.3
Epoch: 166 	Training Loss: 1.285114 	Validation Loss: 1.452257 	 time: 0.3
Epoch: 167 	Training Loss: 1.283605 	Validation Loss: 1.455131 	 time: 0.3
Epoch: 168 	Training Loss: 1.282074 	Validation Loss: 1.448059 	 time: 0.3
Validation loss decreased from 1.450426 to 1.448059. Model was saved
Epoch: 169 	Training Loss: 1.281492 	Validation Loss: 1.456959 	 time: 0.3
Epoch: 170 	Training Loss: 1.281561 	Validation Loss: 1.448375 	 time: 0.3
Epoch: 171 	Training Loss: 1.280472 	Validation Loss: 1.454893 	 time: 0.3
Epoch: 172 	Training Loss: 1.279204 	Validation Loss: 1.448346 	 time: 0.3
Epoch: 173 	Training Loss: 1.278196 	Validation Loss: 1.450246 	 time: 0.3
Epoch: 174 	Training Loss: 1.278374 	Validation Loss: 1.448153 	 time: 0.3
Epoch: 175 	Training Loss: 1.278431 	Validation Loss: 1.449956 	 time: 0.3
Epoch: 176 	Training Loss: 1.278561 	Validation Loss: 1.445203 	 time: 0.3
Validation loss decreased from 1.448059 to 1.445203. Model was saved
Epoch: 177 	Training Loss: 1.275792 	Validation Loss: 1.447606 	 time: 0.3
Epoch: 178 	Training Loss: 1.274482 	Validation Loss: 1.443802 	 time: 0.3
Validation loss decreased from 1.445203 to 1.443802. Model was saved
Epoch: 179 	Training Loss: 1.274342 	Validation Loss: 1.449437 	 time: 0.3
Epoch: 180 	Training Loss: 1.274640 	Validation Loss: 1.443801 	 time: 0.3
Validation loss decreased from 1.443802 to 1.443801. Model was saved
Epoch: 181 	Training Loss: 1.273798 	Validation Loss: 1.446129 	 time: 0.3
Epoch: 182 	Training Loss: 1.271524 	Validation Loss: 1.444660 	 time: 0.3
Epoch: 183 	Training Loss: 1.270309 	Validation Loss: 1.442276 	 time: 0.3
Validation loss decreased from 1.443801 to 1.442276. Model was saved
Epoch: 184 	Training Loss: 1.270827 	Validation Loss: 1.445286 	 time: 0.3
Epoch: 185 	Training Loss: 1.270752 	Validation Loss: 1.441377 	 time: 0.3
Validation loss decreased from 1.442276 to 1.441377. Model was saved
Epoch: 186 	Training Loss: 1.269640 	Validation Loss: 1.442827 	 time: 0.3
Epoch: 187 	Training Loss: 1.267994 	Validation Loss: 1.442124 	 time: 0.3
Epoch: 188 	Training Loss: 1.267486 	Validation Loss: 1.440803 	 time: 0.3
Validation loss decreased from 1.441377 to 1.440803. Model was saved
Epoch: 189 	Training Loss: 1.268410 	Validation Loss: 1.441387 	 time: 0.3
Epoch: 190 	Training Loss: 1.267789 	Validation Loss: 1.440432 	 time: 0.3
Validation loss decreased from 1.440803 to 1.440432. Model was saved
Epoch: 191 	Training Loss: 1.268112 	Validation Loss: 1.438995 	 time: 0.3
Validation loss decreased from 1.440432 to 1.438995. Model was saved
Epoch: 192 	Training Loss: 1.268574 	Validation Loss: 1.441996 	 time: 0.3
Epoch: 193 	Training Loss: 1.274444 	Validation Loss: 1.439078 	 time: 0.3
Epoch: 194 	Training Loss: 1.270406 	Validation Loss: 1.438516 	 time: 0.3
Validation loss decreased from 1.438995 to 1.438516. Model was saved
Epoch: 195 	Training Loss: 1.265868 	Validation Loss: 1.436294 	 time: 0.3
Validation loss decreased from 1.438516 to 1.436294. Model was saved
Epoch: 196 	Training Loss: 1.264768 	Validation Loss: 1.434635 	 time: 0.3
Validation loss decreased from 1.436294 to 1.434635. Model was saved
Epoch: 197 	Training Loss: 1.265513 	Validation Loss: 1.435165 	 time: 0.3
Epoch: 198 	Training Loss: 1.264262 	Validation Loss: 1.432515 	 time: 0.3
Validation loss decreased from 1.434635 to 1.432515. Model was saved
Epoch: 199 	Training Loss: 1.262365 	Validation Loss: 1.429583 	 time: 0.3
Validation loss decreased from 1.432515 to 1.429583. Model was saved
Epoch: 200 	Training Loss: 1.263160 	Validation Loss: 1.430243 	 time: 0.3
Epoch: 201 	Training Loss: 1.261878 	Validation Loss: 1.432526 	 time: 0.3
Epoch: 202 	Training Loss: 1.262525 	Validation Loss: 1.426005 	 time: 0.3
Validation loss decreased from 1.429583 to 1.426005. Model was saved
Epoch: 203 	Training Loss: 1.260875 	Validation Loss: 1.428032 	 time: 0.3
Epoch: 204 	Training Loss: 1.263578 	Validation Loss: 1.433887 	 time: 0.3
Epoch: 205 	Training Loss: 1.264113 	Validation Loss: 1.422069 	 time: 0.3
Validation loss decreased from 1.426005 to 1.422069. Model was saved
Epoch: 206 	Training Loss: 1.257482 	Validation Loss: 1.420119 	 time: 0.3
Validation loss decreased from 1.422069 to 1.420119. Model was saved
Epoch: 207 	Training Loss: 1.264545 	Validation Loss: 1.419416 	 time: 0.3
Validation loss decreased from 1.420119 to 1.419416. Model was saved
Epoch: 208 	Training Loss: 1.255725 	Validation Loss: 1.425802 	 time: 0.3
Epoch: 209 	Training Loss: 1.257738 	Validation Loss: 1.412787 	 time: 0.3
Validation loss decreased from 1.419416 to 1.412787. Model was saved
Epoch: 210 	Training Loss: 1.254115 	Validation Loss: 1.411168 	 time: 0.3
Validation loss decreased from 1.412787 to 1.411168. Model was saved
Epoch: 211 	Training Loss: 1.255450 	Validation Loss: 1.409785 	 time: 0.3
Validation loss decreased from 1.411168 to 1.409785. Model was saved
Epoch: 212 	Training Loss: 1.250855 	Validation Loss: 1.417031 	 time: 0.3
Epoch: 213 	Training Loss: 1.252702 	Validation Loss: 1.408397 	 time: 0.3
Validation loss decreased from 1.409785 to 1.408397. Model was saved
Epoch: 214 	Training Loss: 1.249226 	Validation Loss: 1.408458 	 time: 0.3
Epoch: 215 	Training Loss: 1.250887 	Validation Loss: 1.406809 	 time: 0.3
Validation loss decreased from 1.408397 to 1.406809. Model was saved
Epoch: 216 	Training Loss: 1.247638 	Validation Loss: 1.410436 	 time: 0.3
Epoch: 217 	Training Loss: 1.248782 	Validation Loss: 1.404109 	 time: 0.3
Validation loss decreased from 1.406809 to 1.404109. Model was saved
Epoch: 218 	Training Loss: 1.245760 	Validation Loss: 1.403732 	 time: 0.3
Validation loss decreased from 1.404109 to 1.403732. Model was saved
Epoch: 219 	Training Loss: 1.247414 	Validation Loss: 1.406402 	 time: 0.3
Epoch: 220 	Training Loss: 1.244715 	Validation Loss: 1.408638 	 time: 0.3
Epoch: 221 	Training Loss: 1.245683 	Validation Loss: 1.402641 	 time: 0.3
Validation loss decreased from 1.403732 to 1.402641. Model was saved
Epoch: 222 	Training Loss: 1.243553 	Validation Loss: 1.402188 	 time: 0.3
Validation loss decreased from 1.402641 to 1.402188. Model was saved
Epoch: 223 	Training Loss: 1.244197 	Validation Loss: 1.404110 	 time: 0.3
Epoch: 224 	Training Loss: 1.242258 	Validation Loss: 1.408123 	 time: 0.3
Epoch: 225 	Training Loss: 1.242786 	Validation Loss: 1.400028 	 time: 0.3
Validation loss decreased from 1.402188 to 1.400028. Model was saved
Epoch: 226 	Training Loss: 1.241084 	Validation Loss: 1.397838 	 time: 0.3
Validation loss decreased from 1.400028 to 1.397838. Model was saved
Epoch: 227 	Training Loss: 1.241659 	Validation Loss: 1.401780 	 time: 0.3
Epoch: 228 	Training Loss: 1.240255 	Validation Loss: 1.404599 	 time: 0.3
Epoch: 229 	Training Loss: 1.240236 	Validation Loss: 1.398908 	 time: 0.3
Epoch: 230 	Training Loss: 1.239165 	Validation Loss: 1.398256 	 time: 0.3
Epoch: 231 	Training Loss: 1.239094 	Validation Loss: 1.400706 	 time: 0.3
Epoch: 232 	Training Loss: 1.238299 	Validation Loss: 1.401645 	 time: 0.3
Epoch: 233 	Training Loss: 1.237679 	Validation Loss: 1.399018 	 time: 0.3
Epoch: 234 	Training Loss: 1.237409 	Validation Loss: 1.398267 	 time: 0.3
Epoch: 235 	Training Loss: 1.236589 	Validation Loss: 1.400947 	 time: 0.3
Epoch: 236 	Training Loss: 1.236483 	Validation Loss: 1.398310 	 time: 0.3
Epoch: 237 	Training Loss: 1.235556 	Validation Loss: 1.396589 	 time: 0.3
Validation loss decreased from 1.397838 to 1.396589. Model was saved
Epoch: 238 	Training Loss: 1.235506 	Validation Loss: 1.399421 	 time: 0.3
Epoch: 239 	Training Loss: 1.234774 	Validation Loss: 1.398793 	 time: 0.3
Epoch: 240 	Training Loss: 1.234465 	Validation Loss: 1.395586 	 time: 0.3
Validation loss decreased from 1.396589 to 1.395586. Model was saved
Epoch: 241 	Training Loss: 1.233895 	Validation Loss: 1.396114 	 time: 0.3
Epoch: 242 	Training Loss: 1.233436 	Validation Loss: 1.398096 	 time: 0.3
Epoch: 243 	Training Loss: 1.233189 	Validation Loss: 1.397095 	 time: 0.3
Epoch: 244 	Training Loss: 1.232515 	Validation Loss: 1.394629 	 time: 0.3
Validation loss decreased from 1.395586 to 1.394629. Model was saved
Epoch: 245 	Training Loss: 1.232190 	Validation Loss: 1.396111 	 time: 0.3
Epoch: 246 	Training Loss: 1.231565 	Validation Loss: 1.395916 	 time: 0.3
Epoch: 247 	Training Loss: 1.231006 	Validation Loss: 1.393901 	 time: 0.3
Validation loss decreased from 1.394629 to 1.393901. Model was saved
Epoch: 248 	Training Loss: 1.230706 	Validation Loss: 1.395552 	 time: 0.3
Epoch: 249 	Training Loss: 1.230146 	Validation Loss: 1.394544 	 time: 0.3
Epoch: 250 	Training Loss: 1.229774 	Validation Loss: 1.393405 	 time: 0.3
Validation loss decreased from 1.393901 to 1.393405. Model was saved
Epoch: 251 	Training Loss: 1.229349 	Validation Loss: 1.394325 	 time: 0.3
Epoch: 252 	Training Loss: 1.228796 	Validation Loss: 1.396016 	 time: 0.3
Epoch: 253 	Training Loss: 1.228538 	Validation Loss: 1.393815 	 time: 0.3
Epoch: 254 	Training Loss: 1.228202 	Validation Loss: 1.394246 	 time: 0.3
Epoch: 255 	Training Loss: 1.227968 	Validation Loss: 1.394877 	 time: 0.3
Epoch: 256 	Training Loss: 1.227928 	Validation Loss: 1.394976 	 time: 0.3
Epoch: 257 	Training Loss: 1.227695 	Validation Loss: 1.393840 	 time: 0.3
Epoch: 258 	Training Loss: 1.227761 	Validation Loss: 1.395992 	 time: 0.3
Epoch: 259 	Training Loss: 1.228340 	Validation Loss: 1.394252 	 time: 0.3
Epoch: 260 	Training Loss: 1.228158 	Validation Loss: 1.395048 	 time: 0.3
Epoch: 261 	Training Loss: 1.227419 	Validation Loss: 1.394636 	 time: 0.3
Epoch: 262 	Training Loss: 1.226476 	Validation Loss: 1.394968 	 time: 0.3
Epoch: 263 	Training Loss: 1.225262 	Validation Loss: 1.393445 	 time: 0.3
Epoch: 264 	Training Loss: 1.224805 	Validation Loss: 1.393620 	 time: 0.3
Epoch: 265 	Training Loss: 1.225165 	Validation Loss: 1.395742 	 time: 0.3
Epoch: 266 	Training Loss: 1.225882 	Validation Loss: 1.393488 	 time: 0.3
Epoch: 267 	Training Loss: 1.225162 	Validation Loss: 1.394047 	 time: 0.3
Epoch: 268 	Training Loss: 1.223958 	Validation Loss: 1.393644 	 time: 0.3
Epoch: 269 	Training Loss: 1.222926 	Validation Loss: 1.392772 	 time: 0.3
Validation loss decreased from 1.393405 to 1.392772. Model was saved
Epoch: 270 	Training Loss: 1.223035 	Validation Loss: 1.393340 	 time: 0.3
Epoch: 271 	Training Loss: 1.223816 	Validation Loss: 1.392081 	 time: 0.3
Validation loss decreased from 1.392772 to 1.392081. Model was saved
Epoch: 272 	Training Loss: 1.224308 	Validation Loss: 1.392645 	 time: 0.3
Epoch: 273 	Training Loss: 1.223306 	Validation Loss: 1.390528 	 time: 0.3
Validation loss decreased from 1.392081 to 1.390528. Model was saved
Epoch: 274 	Training Loss: 1.221606 	Validation Loss: 1.391157 	 time: 0.3
Epoch: 275 	Training Loss: 1.221928 	Validation Loss: 1.392237 	 time: 0.3
Epoch: 276 	Training Loss: 1.222781 	Validation Loss: 1.390695 	 time: 0.3
Epoch: 277 	Training Loss: 1.222802 	Validation Loss: 1.391723 	 time: 0.3
Epoch: 278 	Training Loss: 1.221617 	Validation Loss: 1.390079 	 time: 0.3
Validation loss decreased from 1.390528 to 1.390079. Model was saved
Epoch: 279 	Training Loss: 1.220239 	Validation Loss: 1.390541 	 time: 0.3
Epoch: 280 	Training Loss: 1.221680 	Validation Loss: 1.393044 	 time: 0.3
Epoch: 281 	Training Loss: 1.222926 	Validation Loss: 1.391330 	 time: 0.3
Epoch: 282 	Training Loss: 1.222829 	Validation Loss: 1.391691 	 time: 0.3
Epoch: 283 	Training Loss: 1.220599 	Validation Loss: 1.390732 	 time: 0.3
Epoch: 284 	Training Loss: 1.220132 	Validation Loss: 1.391088 	 time: 0.3
Epoch: 285 	Training Loss: 1.221968 	Validation Loss: 1.391686 	 time: 0.3
Epoch: 286 	Training Loss: 1.220283 	Validation Loss: 1.390716 	 time: 0.3
Epoch: 287 	Training Loss: 1.218406 	Validation Loss: 1.389686 	 time: 0.3
Validation loss decreased from 1.390079 to 1.389686. Model was saved
Epoch: 288 	Training Loss: 1.219322 	Validation Loss: 1.390283 	 time: 0.3
Epoch: 289 	Training Loss: 1.218631 	Validation Loss: 1.388766 	 time: 0.3
Validation loss decreased from 1.389686 to 1.388766. Model was saved
Epoch: 290 	Training Loss: 1.217431 	Validation Loss: 1.389345 	 time: 0.3
Epoch: 291 	Training Loss: 1.218433 	Validation Loss: 1.389859 	 time: 0.3
Epoch: 292 	Training Loss: 1.218011 	Validation Loss: 1.389109 	 time: 0.3
Epoch: 293 	Training Loss: 1.217060 	Validation Loss: 1.388833 	 time: 0.3
Epoch: 294 	Training Loss: 1.217351 	Validation Loss: 1.388883 	 time: 0.3
Epoch: 295 	Training Loss: 1.216981 	Validation Loss: 1.387928 	 time: 0.3
Validation loss decreased from 1.388766 to 1.387928. Model was saved
Epoch: 296 	Training Loss: 1.216274 	Validation Loss: 1.387770 	 time: 0.3
Validation loss decreased from 1.387928 to 1.387770. Model was saved
Epoch: 297 	Training Loss: 1.216501 	Validation Loss: 1.387739 	 time: 0.3
Validation loss decreased from 1.387770 to 1.387739. Model was saved
Epoch: 298 	Training Loss: 1.216410 	Validation Loss: 1.387295 	 time: 0.3
Validation loss decreased from 1.387739 to 1.387295. Model was saved
Epoch: 299 	Training Loss: 1.215762 	Validation Loss: 1.387194 	 time: 0.3
Validation loss decreased from 1.387295 to 1.387194. Model was saved
Epoch: 300 	Training Loss: 1.215723 	Validation Loss: 1.387459 	 time: 0.3
Epoch: 301 	Training Loss: 1.215640 	Validation Loss: 1.386907 	 time: 0.3
Validation loss decreased from 1.387194 to 1.386907. Model was saved
Epoch: 302 	Training Loss: 1.215118 	Validation Loss: 1.387168 	 time: 0.3
Epoch: 303 	Training Loss: 1.214965 	Validation Loss: 1.387187 	 time: 0.3
Epoch: 304 	Training Loss: 1.215090 	Validation Loss: 1.387393 	 time: 0.3
Epoch: 305 	Training Loss: 1.214581 	Validation Loss: 1.386865 	 time: 0.3
Validation loss decreased from 1.386907 to 1.386865. Model was saved
Epoch: 306 	Training Loss: 1.214283 	Validation Loss: 1.386530 	 time: 0.3
Validation loss decreased from 1.386865 to 1.386530. Model was saved
Epoch: 307 	Training Loss: 1.214353 	Validation Loss: 1.386374 	 time: 0.3
Validation loss decreased from 1.386530 to 1.386374. Model was saved
Epoch: 308 	Training Loss: 1.213949 	Validation Loss: 1.386276 	 time: 0.3
Validation loss decreased from 1.386374 to 1.386276. Model was saved
Epoch: 309 	Training Loss: 1.213567 	Validation Loss: 1.386180 	 time: 0.3
Validation loss decreased from 1.386276 to 1.386180. Model was saved
Epoch: 310 	Training Loss: 1.213594 	Validation Loss: 1.386286 	 time: 0.3
Epoch: 311 	Training Loss: 1.213274 	Validation Loss: 1.385477 	 time: 0.3
Validation loss decreased from 1.386180 to 1.385477. Model was saved
Epoch: 312 	Training Loss: 1.212857 	Validation Loss: 1.385006 	 time: 0.3
Validation loss decreased from 1.385477 to 1.385006. Model was saved
Epoch: 313 	Training Loss: 1.212804 	Validation Loss: 1.385365 	 time: 0.3
Epoch: 314 	Training Loss: 1.212745 	Validation Loss: 1.385450 	 time: 0.3
Epoch: 315 	Training Loss: 1.212513 	Validation Loss: 1.384906 	 time: 0.3
Validation loss decreased from 1.385006 to 1.384906. Model was saved
Epoch: 316 	Training Loss: 1.212267 	Validation Loss: 1.385254 	 time: 0.3
Epoch: 317 	Training Loss: 1.212257 	Validation Loss: 1.384299 	 time: 0.3
Validation loss decreased from 1.384906 to 1.384299. Model was saved
Epoch: 318 	Training Loss: 1.212439 	Validation Loss: 1.385361 	 time: 0.3
Epoch: 319 	Training Loss: 1.212568 	Validation Loss: 1.385846 	 time: 0.3
Epoch: 320 	Training Loss: 1.213182 	Validation Loss: 1.386341 	 time: 0.3
Epoch: 321 	Training Loss: 1.214577 	Validation Loss: 1.385474 	 time: 0.3
Epoch: 322 	Training Loss: 1.212775 	Validation Loss: 1.384472 	 time: 0.3
Epoch: 323 	Training Loss: 1.211127 	Validation Loss: 1.383964 	 time: 0.3
Validation loss decreased from 1.384299 to 1.383964. Model was saved
Epoch: 324 	Training Loss: 1.210794 	Validation Loss: 1.384538 	 time: 0.3
Epoch: 325 	Training Loss: 1.211721 	Validation Loss: 1.385747 	 time: 0.3
Epoch: 326 	Training Loss: 1.213359 	Validation Loss: 1.386257 	 time: 0.3
Epoch: 327 	Training Loss: 1.212668 	Validation Loss: 1.385828 	 time: 0.3
Epoch: 328 	Training Loss: 1.211326 	Validation Loss: 1.384745 	 time: 0.3
Epoch: 329 	Training Loss: 1.210515 	Validation Loss: 1.384649 	 time: 0.3
Epoch: 330 	Training Loss: 1.210627 	Validation Loss: 1.385948 	 time: 0.3
Epoch: 331 	Training Loss: 1.212117 	Validation Loss: 1.386706 	 time: 0.3
Epoch: 332 	Training Loss: 1.212702 	Validation Loss: 1.385006 	 time: 0.3
Epoch: 333 	Training Loss: 1.210869 	Validation Loss: 1.384851 	 time: 0.3
Epoch: 334 	Training Loss: 1.209536 	Validation Loss: 1.385614 	 time: 0.3
Epoch: 335 	Training Loss: 1.210043 	Validation Loss: 1.386131 	 time: 0.3
Epoch: 336 	Training Loss: 1.211303 	Validation Loss: 1.386762 	 time: 0.3
Epoch: 337 	Training Loss: 1.211015 	Validation Loss: 1.385212 	 time: 0.3
Epoch: 338 	Training Loss: 1.208739 	Validation Loss: 1.385666 	 time: 0.3
Epoch: 339 	Training Loss: 1.209334 	Validation Loss: 1.385434 	 time: 0.3
Epoch: 340 	Training Loss: 1.211000 	Validation Loss: 1.386198 	 time: 0.3
Epoch: 341 	Training Loss: 1.209076 	Validation Loss: 1.384889 	 time: 0.3
Epoch: 342 	Training Loss: 1.207850 	Validation Loss: 1.386588 	 time: 0.3
Epoch: 343 	Training Loss: 1.208706 	Validation Loss: 1.385350 	 time: 0.3
Epoch: 344 	Training Loss: 1.207544 	Validation Loss: 1.383144 	 time: 0.3
Validation loss decreased from 1.383964 to 1.383144. Model was saved
Epoch: 345 	Training Loss: 1.207038 	Validation Loss: 1.383166 	 time: 0.3
Epoch: 346 	Training Loss: 1.207826 	Validation Loss: 1.384957 	 time: 0.3
Epoch: 347 	Training Loss: 1.207047 	Validation Loss: 1.384279 	 time: 0.3
Epoch: 348 	Training Loss: 1.206587 	Validation Loss: 1.385210 	 time: 0.3
Epoch: 349 	Training Loss: 1.206927 	Validation Loss: 1.383279 	 time: 0.3
Epoch: 350 	Training Loss: 1.206225 	Validation Loss: 1.384264 	 time: 0.3
Epoch: 351 	Training Loss: 1.206290 	Validation Loss: 1.383522 	 time: 0.3
Epoch: 352 	Training Loss: 1.206022 	Validation Loss: 1.382544 	 time: 0.3
Validation loss decreased from 1.383144 to 1.382544. Model was saved
Epoch: 353 	Training Loss: 1.205467 	Validation Loss: 1.383057 	 time: 0.3
Epoch: 354 	Training Loss: 1.205638 	Validation Loss: 1.382941 	 time: 0.3
Epoch: 355 	Training Loss: 1.205143 	Validation Loss: 1.382132 	 time: 0.3
Validation loss decreased from 1.382544 to 1.382132. Model was saved
Epoch: 356 	Training Loss: 1.204941 	Validation Loss: 1.383486 	 time: 0.3
Epoch: 357 	Training Loss: 1.205140 	Validation Loss: 1.382036 	 time: 0.3
Validation loss decreased from 1.382132 to 1.382036. Model was saved
Epoch: 358 	Training Loss: 1.204874 	Validation Loss: 1.381557 	 time: 0.3
Validation loss decreased from 1.382036 to 1.381557. Model was saved
Epoch: 359 	Training Loss: 1.204391 	Validation Loss: 1.381027 	 time: 0.3
Validation loss decreased from 1.381557 to 1.381027. Model was saved
Epoch: 360 	Training Loss: 1.204443 	Validation Loss: 1.381852 	 time: 0.3
Epoch: 361 	Training Loss: 1.204538 	Validation Loss: 1.382933 	 time: 0.3
Epoch: 362 	Training Loss: 1.204035 	Validation Loss: 1.381034 	 time: 0.3
Epoch: 363 	Training Loss: 1.204097 	Validation Loss: 1.382162 	 time: 0.3
Epoch: 364 	Training Loss: 1.203936 	Validation Loss: 1.382509 	 time: 0.3
Epoch: 365 	Training Loss: 1.203521 	Validation Loss: 1.381073 	 time: 0.3
Epoch: 366 	Training Loss: 1.203670 	Validation Loss: 1.382169 	 time: 0.3
Epoch: 367 	Training Loss: 1.203681 	Validation Loss: 1.381950 	 time: 0.3
Epoch: 368 	Training Loss: 1.203100 	Validation Loss: 1.380803 	 time: 0.3
Validation loss decreased from 1.381027 to 1.380803. Model was saved
Epoch: 369 	Training Loss: 1.203186 	Validation Loss: 1.382446 	 time: 0.3
Epoch: 370 	Training Loss: 1.203215 	Validation Loss: 1.381863 	 time: 0.3
Epoch: 371 	Training Loss: 1.202538 	Validation Loss: 1.381035 	 time: 0.3
Epoch: 372 	Training Loss: 1.202528 	Validation Loss: 1.382225 	 time: 0.3
Epoch: 373 	Training Loss: 1.202702 	Validation Loss: 1.381124 	 time: 0.3
Epoch: 374 	Training Loss: 1.202105 	Validation Loss: 1.381343 	 time: 0.3
Epoch: 375 	Training Loss: 1.201902 	Validation Loss: 1.382211 	 time: 0.3
Epoch: 376 	Training Loss: 1.202041 	Validation Loss: 1.381856 	 time: 0.3
Epoch: 377 	Training Loss: 1.201635 	Validation Loss: 1.382826 	 time: 0.3
Epoch: 378 	Training Loss: 1.201396 	Validation Loss: 1.382441 	 time: 0.3
Epoch: 379 	Training Loss: 1.201424 	Validation Loss: 1.382697 	 time: 0.3
Epoch: 380 	Training Loss: 1.201181 	Validation Loss: 1.383401 	 time: 0.3
Epoch: 381 	Training Loss: 1.200956 	Validation Loss: 1.382676 	 time: 0.3
Epoch: 382 	Training Loss: 1.200898 	Validation Loss: 1.382444 	 time: 0.3
Epoch: 383 	Training Loss: 1.200839 	Validation Loss: 1.382552 	 time: 0.3
Epoch: 384 	Training Loss: 1.200638 	Validation Loss: 1.382400 	 time: 0.3
Epoch: 385 	Training Loss: 1.200426 	Validation Loss: 1.382034 	 time: 0.3
Epoch: 386 	Training Loss: 1.200348 	Validation Loss: 1.382369 	 time: 0.3
Epoch: 387 	Training Loss: 1.200127 	Validation Loss: 1.382513 	 time: 0.3
Epoch: 388 	Training Loss: 1.199907 	Validation Loss: 1.381596 	 time: 0.3
Epoch: 389 	Training Loss: 1.199774 	Validation Loss: 1.382333 	 time: 0.3
Epoch: 390 	Training Loss: 1.199660 	Validation Loss: 1.382040 	 time: 0.3
Epoch: 391 	Training Loss: 1.199474 	Validation Loss: 1.381420 	 time: 0.3
Epoch: 392 	Training Loss: 1.199254 	Validation Loss: 1.382218 	 time: 0.3
Epoch: 393 	Training Loss: 1.199124 	Validation Loss: 1.381559 	 time: 0.3
Epoch: 394 	Training Loss: 1.199045 	Validation Loss: 1.382029 	 time: 0.3
Epoch: 395 	Training Loss: 1.198921 	Validation Loss: 1.380970 	 time: 0.3
Epoch: 396 	Training Loss: 1.198786 	Validation Loss: 1.380508 	 time: 0.3
Validation loss decreased from 1.380803 to 1.380508. Model was saved
Epoch: 397 	Training Loss: 1.198663 	Validation Loss: 1.380986 	 time: 0.3
Epoch: 398 	Training Loss: 1.198572 	Validation Loss: 1.379622 	 time: 0.3
Validation loss decreased from 1.380508 to 1.379622. Model was saved
Epoch: 399 	Training Loss: 1.198466 	Validation Loss: 1.380589 	 time: 0.3
Epoch: 400 	Training Loss: 1.198311 	Validation Loss: 1.380145 	 time: 0.3
Epoch: 401 	Training Loss: 1.198180 	Validation Loss: 1.379796 	 time: 0.3
Epoch: 402 	Training Loss: 1.198086 	Validation Loss: 1.380487 	 time: 0.3
Epoch: 403 	Training Loss: 1.197994 	Validation Loss: 1.379806 	 time: 0.3
Epoch: 404 	Training Loss: 1.197887 	Validation Loss: 1.380117 	 time: 0.3
Epoch: 405 	Training Loss: 1.197749 	Validation Loss: 1.379852 	 time: 0.3
Epoch: 406 	Training Loss: 1.197605 	Validation Loss: 1.379929 	 time: 0.3
Epoch: 407 	Training Loss: 1.197451 	Validation Loss: 1.379745 	 time: 0.3
Epoch: 408 	Training Loss: 1.197277 	Validation Loss: 1.379017 	 time: 0.3
Validation loss decreased from 1.379622 to 1.379017. Model was saved
Epoch: 409 	Training Loss: 1.197087 	Validation Loss: 1.378734 	 time: 0.3
Validation loss decreased from 1.379017 to 1.378734. Model was saved
Epoch: 410 	Training Loss: 1.196964 	Validation Loss: 1.378553 	 time: 0.3
Validation loss decreased from 1.378734 to 1.378553. Model was saved
Epoch: 411 	Training Loss: 1.196851 	Validation Loss: 1.377794 	 time: 0.3
Validation loss decreased from 1.378553 to 1.377794. Model was saved
Epoch: 412 	Training Loss: 1.196746 	Validation Loss: 1.378627 	 time: 0.3
Epoch: 413 	Training Loss: 1.196642 	Validation Loss: 1.377485 	 time: 0.3
Validation loss decreased from 1.377794 to 1.377485. Model was saved
Epoch: 414 	Training Loss: 1.196535 	Validation Loss: 1.378616 	 time: 0.3
Epoch: 415 	Training Loss: 1.196408 	Validation Loss: 1.377260 	 time: 0.3
Validation loss decreased from 1.377485 to 1.377260. Model was saved
Epoch: 416 	Training Loss: 1.196274 	Validation Loss: 1.378193 	 time: 0.3
Epoch: 417 	Training Loss: 1.196134 	Validation Loss: 1.376826 	 time: 0.3
Validation loss decreased from 1.377260 to 1.376826. Model was saved
Epoch: 418 	Training Loss: 1.195979 	Validation Loss: 1.377017 	 time: 0.3
Epoch: 419 	Training Loss: 1.195813 	Validation Loss: 1.375941 	 time: 0.3
Validation loss decreased from 1.376826 to 1.375941. Model was saved
Epoch: 420 	Training Loss: 1.195659 	Validation Loss: 1.375463 	 time: 0.3
Validation loss decreased from 1.375941 to 1.375463. Model was saved
Epoch: 421 	Training Loss: 1.195518 	Validation Loss: 1.374469 	 time: 0.3
Validation loss decreased from 1.375463 to 1.374469. Model was saved
Epoch: 422 	Training Loss: 1.195374 	Validation Loss: 1.373377 	 time: 0.3
Validation loss decreased from 1.374469 to 1.373377. Model was saved
Epoch: 423 	Training Loss: 1.195244 	Validation Loss: 1.372367 	 time: 0.3
Validation loss decreased from 1.373377 to 1.372367. Model was saved
Epoch: 424 	Training Loss: 1.195133 	Validation Loss: 1.371107 	 time: 0.3
Validation loss decreased from 1.372367 to 1.371107. Model was saved
Epoch: 425 	Training Loss: 1.195035 	Validation Loss: 1.370596 	 time: 0.3
Validation loss decreased from 1.371107 to 1.370596. Model was saved
Epoch: 426 	Training Loss: 1.194939 	Validation Loss: 1.369475 	 time: 0.3
Validation loss decreased from 1.370596 to 1.369475. Model was saved
Epoch: 427 	Training Loss: 1.194839 	Validation Loss: 1.369619 	 time: 0.3
Epoch: 428 	Training Loss: 1.194735 	Validation Loss: 1.368658 	 time: 0.3
Validation loss decreased from 1.369475 to 1.368658. Model was saved
Epoch: 429 	Training Loss: 1.194600 	Validation Loss: 1.369772 	 time: 0.3
Epoch: 430 	Training Loss: 1.194496 	Validation Loss: 1.368216 	 time: 0.3
Validation loss decreased from 1.368658 to 1.368216. Model was saved
Epoch: 431 	Training Loss: 1.194494 	Validation Loss: 1.370776 	 time: 0.3
Epoch: 432 	Training Loss: 1.194684 	Validation Loss: 1.367489 	 time: 0.3
Validation loss decreased from 1.368216 to 1.367489. Model was saved
Epoch: 433 	Training Loss: 1.195223 	Validation Loss: 1.375628 	 time: 0.3
Epoch: 434 	Training Loss: 1.197444 	Validation Loss: 1.379515 	 time: 0.3
Epoch: 435 	Training Loss: 1.208177 	Validation Loss: 1.416730 	 time: 0.3
Epoch: 436 	Training Loss: 1.262172 	Validation Loss: 1.379879 	 time: 0.3
Epoch: 437 	Training Loss: 1.228585 	Validation Loss: 1.400226 	 time: 0.3
Epoch: 438 	Training Loss: 1.237278 	Validation Loss: 1.410263 	 time: 0.3
Epoch: 439 	Training Loss: 1.245624 	Validation Loss: 1.393775 	 time: 0.3
Epoch: 440 	Training Loss: 1.240492 	Validation Loss: 1.386219 	 time: 0.3
Epoch: 441 	Training Loss: 1.214966 	Validation Loss: 1.399517 	 time: 0.3
Epoch: 442 	Training Loss: 1.237627 	Validation Loss: 1.396579 	 time: 0.3
Epoch: 443 	Training Loss: 1.233567 	Validation Loss: 1.413324 	 time: 0.3
Epoch: 444 	Training Loss: 1.261970 	Validation Loss: 1.390244 	 time: 0.3
Epoch: 445 	Training Loss: 1.218501 	Validation Loss: 1.412439 	 time: 0.3
Epoch: 446 	Training Loss: 1.234756 	Validation Loss: 1.403209 	 time: 0.3
Epoch: 447 	Training Loss: 1.235933 	Validation Loss: 1.393151 	 time: 0.3
Epoch: 448 	Training Loss: 1.223916 	Validation Loss: 1.390882 	 time: 0.3
Epoch: 449 	Training Loss: 1.224431 	Validation Loss: 1.391129 	 time: 0.3
Epoch: 450 	Training Loss: 1.233771 	Validation Loss: 1.383315 	 time: 0.3
Epoch: 451 	Training Loss: 1.208011 	Validation Loss: 1.407473 	 time: 0.3
Epoch: 452 	Training Loss: 1.232791 	Validation Loss: 1.392794 	 time: 0.3
Epoch: 453 	Training Loss: 1.215972 	Validation Loss: 1.398170 	 time: 0.3
Epoch: 454 	Training Loss: 1.215962 	Validation Loss: 1.396965 	 time: 0.3
Epoch: 455 	Training Loss: 1.224135 	Validation Loss: 1.378708 	 time: 0.3
Epoch: 456 	Training Loss: 1.205874 	Validation Loss: 1.383899 	 time: 0.3
Epoch: 457 	Training Loss: 1.211590 	Validation Loss: 1.387155 	 time: 0.3
Epoch: 458 	Training Loss: 1.214074 	Validation Loss: 1.374649 	 time: 0.3
Epoch: 459 	Training Loss: 1.202474 	Validation Loss: 1.376360 	 time: 0.3
Epoch: 460 	Training Loss: 1.208236 	Validation Loss: 1.377717 	 time: 0.3
Epoch: 461 	Training Loss: 1.206693 	Validation Loss: 1.380948 	 time: 0.3
Epoch: 462 	Training Loss: 1.199617 	Validation Loss: 1.383498 	 time: 0.3
Epoch: 463 	Training Loss: 1.204380 	Validation Loss: 1.379797 	 time: 0.3
Epoch: 464 	Training Loss: 1.202669 	Validation Loss: 1.380100 	 time: 0.3
Epoch: 465 	Training Loss: 1.198086 	Validation Loss: 1.380088 	 time: 0.3
Epoch: 466 	Training Loss: 1.201382 	Validation Loss: 1.380377 	 time: 0.3
Epoch: 467 	Training Loss: 1.198279 	Validation Loss: 1.383032 	 time: 0.3
Epoch: 468 	Training Loss: 1.196012 	Validation Loss: 1.383995 	 time: 0.3
Epoch: 469 	Training Loss: 1.198226 	Validation Loss: 1.381207 	 time: 0.3
Epoch: 470 	Training Loss: 1.195947 	Validation Loss: 1.381642 	 time: 0.3
Epoch: 471 	Training Loss: 1.195250 	Validation Loss: 1.382247 	 time: 0.3
Epoch: 472 	Training Loss: 1.196240 	Validation Loss: 1.381132 	 time: 0.3
Epoch: 473 	Training Loss: 1.192945 	Validation Loss: 1.381120 	 time: 0.3
Epoch: 474 	Training Loss: 1.194029 	Validation Loss: 1.381973 	 time: 0.3
Epoch: 475 	Training Loss: 1.193599 	Validation Loss: 1.382310 	 time: 0.3
Epoch: 476 	Training Loss: 1.192559 	Validation Loss: 1.382028 	 time: 0.3
Epoch: 477 	Training Loss: 1.193240 	Validation Loss: 1.379778 	 time: 0.3
Epoch: 478 	Training Loss: 1.191769 	Validation Loss: 1.381235 	 time: 0.3
Epoch: 479 	Training Loss: 1.191712 	Validation Loss: 1.382609 	 time: 0.3
Epoch: 480 	Training Loss: 1.191661 	Validation Loss: 1.381158 	 time: 0.3
Epoch: 481 	Training Loss: 1.190972 	Validation Loss: 1.379442 	 time: 0.3
Epoch: 482 	Training Loss: 1.191412 	Validation Loss: 1.378976 	 time: 0.3
Epoch: 483 	Training Loss: 1.190431 	Validation Loss: 1.377854 	 time: 0.3
Epoch: 484 	Training Loss: 1.190414 	Validation Loss: 1.376307 	 time: 0.3
Epoch: 485 	Training Loss: 1.190423 	Validation Loss: 1.376955 	 time: 0.3
Epoch: 486 	Training Loss: 1.190049 	Validation Loss: 1.377762 	 time: 0.3
Epoch: 487 	Training Loss: 1.190001 	Validation Loss: 1.377217 	 time: 0.3
Epoch: 488 	Training Loss: 1.189605 	Validation Loss: 1.376086 	 time: 0.3
Epoch: 489 	Training Loss: 1.189544 	Validation Loss: 1.375102 	 time: 0.3
Epoch: 490 	Training Loss: 1.189497 	Validation Loss: 1.374543 	 time: 0.3
Epoch: 491 	Training Loss: 1.189092 	Validation Loss: 1.373690 	 time: 0.3
Epoch: 492 	Training Loss: 1.189054 	Validation Loss: 1.373267 	 time: 0.3
Epoch: 493 	Training Loss: 1.188663 	Validation Loss: 1.372966 	 time: 0.3
Epoch: 494 	Training Loss: 1.188592 	Validation Loss: 1.373347 	 time: 0.3
Epoch: 495 	Training Loss: 1.188510 	Validation Loss: 1.373683 	 time: 0.3
Epoch: 496 	Training Loss: 1.188312 	Validation Loss: 1.373032 	 time: 0.3
Epoch: 497 	Training Loss: 1.188217 	Validation Loss: 1.371154 	 time: 0.3
Epoch: 498 	Training Loss: 1.188006 	Validation Loss: 1.370785 	 time: 0.3
Epoch: 499 	Training Loss: 1.187994 	Validation Loss: 1.370615 	 time: 0.3
Epoch: 500 	Training Loss: 1.187812 	Validation Loss: 1.370402 	 time: 0.3
Epoch: 501 	Training Loss: 1.187673 	Validation Loss: 1.369711 	 time: 0.3
Epoch: 502 	Training Loss: 1.187542 	Validation Loss: 1.368986 	 time: 0.3
Epoch: 503 	Training Loss: 1.187384 	Validation Loss: 1.368503 	 time: 0.3
Epoch: 504 	Training Loss: 1.187260 	Validation Loss: 1.367990 	 time: 0.3
Epoch: 505 	Training Loss: 1.187133 	Validation Loss: 1.367343 	 time: 0.3
Validation loss decreased from 1.367489 to 1.367343. Model was saved
Epoch: 506 	Training Loss: 1.187022 	Validation Loss: 1.367301 	 time: 0.3
Validation loss decreased from 1.367343 to 1.367301. Model was saved
Epoch: 507 	Training Loss: 1.186922 	Validation Loss: 1.367906 	 time: 0.3
Epoch: 508 	Training Loss: 1.186829 	Validation Loss: 1.368420 	 time: 0.3
Epoch: 509 	Training Loss: 1.186744 	Validation Loss: 1.368385 	 time: 0.3
Epoch: 510 	Training Loss: 1.186628 	Validation Loss: 1.368205 	 time: 0.3
Epoch: 511 	Training Loss: 1.186551 	Validation Loss: 1.368374 	 time: 0.3
Epoch: 512 	Training Loss: 1.186464 	Validation Loss: 1.368813 	 time: 0.3
Epoch: 513 	Training Loss: 1.186373 	Validation Loss: 1.368974 	 time: 0.3
Epoch: 514 	Training Loss: 1.186296 	Validation Loss: 1.368361 	 time: 0.3
Epoch: 515 	Training Loss: 1.186210 	Validation Loss: 1.367688 	 time: 0.3
Epoch: 516 	Training Loss: 1.186136 	Validation Loss: 1.367430 	 time: 0.3
Epoch: 517 	Training Loss: 1.186046 	Validation Loss: 1.367272 	 time: 0.3
Validation loss decreased from 1.367301 to 1.367272. Model was saved
Epoch: 518 	Training Loss: 1.185965 	Validation Loss: 1.366949 	 time: 0.3
Validation loss decreased from 1.367272 to 1.366949. Model was saved
Epoch: 519 	Training Loss: 1.185883 	Validation Loss: 1.366719 	 time: 0.3
Validation loss decreased from 1.366949 to 1.366719. Model was saved
Epoch: 520 	Training Loss: 1.185819 	Validation Loss: 1.366582 	 time: 0.3
Validation loss decreased from 1.366719 to 1.366582. Model was saved
Epoch: 521 	Training Loss: 1.185760 	Validation Loss: 1.366488 	 time: 0.3
Validation loss decreased from 1.366582 to 1.366488. Model was saved
Epoch: 522 	Training Loss: 1.185697 	Validation Loss: 1.366312 	 time: 0.3
Validation loss decreased from 1.366488 to 1.366312. Model was saved
Epoch: 523 	Training Loss: 1.185634 	Validation Loss: 1.365773 	 time: 0.3
Validation loss decreased from 1.366312 to 1.365773. Model was saved
Epoch: 524 	Training Loss: 1.185570 	Validation Loss: 1.365249 	 time: 0.3
Validation loss decreased from 1.365773 to 1.365249. Model was saved
Epoch: 525 	Training Loss: 1.185504 	Validation Loss: 1.365138 	 time: 0.3
Validation loss decreased from 1.365249 to 1.365138. Model was saved
Epoch: 526 	Training Loss: 1.185425 	Validation Loss: 1.365119 	 time: 0.3
Validation loss decreased from 1.365138 to 1.365119. Model was saved
Epoch: 527 	Training Loss: 1.185346 	Validation Loss: 1.364728 	 time: 0.3
Validation loss decreased from 1.365119 to 1.364728. Model was saved
Epoch: 528 	Training Loss: 1.185261 	Validation Loss: 1.364063 	 time: 0.3
Validation loss decreased from 1.364728 to 1.364063. Model was saved
Epoch: 529 	Training Loss: 1.185180 	Validation Loss: 1.363376 	 time: 0.3
Validation loss decreased from 1.364063 to 1.363376. Model was saved
Epoch: 530 	Training Loss: 1.185108 	Validation Loss: 1.362779 	 time: 0.3
Validation loss decreased from 1.363376 to 1.362779. Model was saved
Epoch: 531 	Training Loss: 1.185040 	Validation Loss: 1.362114 	 time: 0.3
Validation loss decreased from 1.362779 to 1.362114. Model was saved
Epoch: 532 	Training Loss: 1.184976 	Validation Loss: 1.361216 	 time: 0.3
Validation loss decreased from 1.362114 to 1.361216. Model was saved
Epoch: 533 	Training Loss: 1.184913 	Validation Loss: 1.360235 	 time: 0.3
Validation loss decreased from 1.361216 to 1.360235. Model was saved
Epoch: 534 	Training Loss: 1.184854 	Validation Loss: 1.359483 	 time: 0.3
Validation loss decreased from 1.360235 to 1.359483. Model was saved
Epoch: 535 	Training Loss: 1.184793 	Validation Loss: 1.359004 	 time: 0.3
Validation loss decreased from 1.359483 to 1.359004. Model was saved
Epoch: 536 	Training Loss: 1.184733 	Validation Loss: 1.358630 	 time: 0.3
Validation loss decreased from 1.359004 to 1.358630. Model was saved
Epoch: 537 	Training Loss: 1.184670 	Validation Loss: 1.358319 	 time: 0.3
Validation loss decreased from 1.358630 to 1.358319. Model was saved
Epoch: 538 	Training Loss: 1.184603 	Validation Loss: 1.358147 	 time: 0.3
Validation loss decreased from 1.358319 to 1.358147. Model was saved
Epoch: 539 	Training Loss: 1.184542 	Validation Loss: 1.358080 	 time: 0.3
Validation loss decreased from 1.358147 to 1.358080. Model was saved
Epoch: 540 	Training Loss: 1.184479 	Validation Loss: 1.358017 	 time: 0.3
Validation loss decreased from 1.358080 to 1.358017. Model was saved
Epoch: 541 	Training Loss: 1.184409 	Validation Loss: 1.357863 	 time: 0.3
Validation loss decreased from 1.358017 to 1.357863. Model was saved
Epoch: 542 	Training Loss: 1.184353 	Validation Loss: 1.357682 	 time: 0.3
Validation loss decreased from 1.357863 to 1.357682. Model was saved
Epoch: 543 	Training Loss: 1.184301 	Validation Loss: 1.357619 	 time: 0.3
Validation loss decreased from 1.357682 to 1.357619. Model was saved
Epoch: 544 	Training Loss: 1.184245 	Validation Loss: 1.357645 	 time: 0.2
Epoch: 545 	Training Loss: 1.184182 	Validation Loss: 1.357526 	 time: 0.3
Validation loss decreased from 1.357619 to 1.357526. Model was saved
Epoch: 546 	Training Loss: 1.184113 	Validation Loss: 1.357247 	 time: 0.3
Validation loss decreased from 1.357526 to 1.357247. Model was saved
Epoch: 547 	Training Loss: 1.184041 	Validation Loss: 1.357045 	 time: 0.3
Validation loss decreased from 1.357247 to 1.357045. Model was saved
Epoch: 548 	Training Loss: 1.183974 	Validation Loss: 1.356982 	 time: 0.3
Validation loss decreased from 1.357045 to 1.356982. Model was saved
Epoch: 549 	Training Loss: 1.183915 	Validation Loss: 1.356954 	 time: 0.3
Validation loss decreased from 1.356982 to 1.356954. Model was saved
Epoch: 550 	Training Loss: 1.183858 	Validation Loss: 1.356911 	 time: 0.3
Validation loss decreased from 1.356954 to 1.356911. Model was saved
Epoch: 551 	Training Loss: 1.183802 	Validation Loss: 1.356850 	 time: 0.3
Validation loss decreased from 1.356911 to 1.356850. Model was saved
Epoch: 552 	Training Loss: 1.183750 	Validation Loss: 1.356794 	 time: 0.3
Validation loss decreased from 1.356850 to 1.356794. Model was saved
Epoch: 553 	Training Loss: 1.183699 	Validation Loss: 1.356778 	 time: 0.3
Validation loss decreased from 1.356794 to 1.356778. Model was saved
Epoch: 554 	Training Loss: 1.183649 	Validation Loss: 1.356716 	 time: 0.3
Validation loss decreased from 1.356778 to 1.356716. Model was saved
Epoch: 555 	Training Loss: 1.183599 	Validation Loss: 1.356584 	 time: 0.3
Validation loss decreased from 1.356716 to 1.356584. Model was saved
Epoch: 556 	Training Loss: 1.183549 	Validation Loss: 1.356492 	 time: 0.3
Validation loss decreased from 1.356584 to 1.356492. Model was saved
Epoch: 557 	Training Loss: 1.183499 	Validation Loss: 1.356421 	 time: 0.3
Validation loss decreased from 1.356492 to 1.356421. Model was saved
Epoch: 558 	Training Loss: 1.183448 	Validation Loss: 1.356279 	 time: 0.3
Validation loss decreased from 1.356421 to 1.356279. Model was saved
Epoch: 559 	Training Loss: 1.183398 	Validation Loss: 1.356103 	 time: 0.3
Validation loss decreased from 1.356279 to 1.356103. Model was saved
Epoch: 560 	Training Loss: 1.183346 	Validation Loss: 1.355938 	 time: 0.3
Validation loss decreased from 1.356103 to 1.355938. Model was saved
Epoch: 561 	Training Loss: 1.183295 	Validation Loss: 1.355791 	 time: 0.3
Validation loss decreased from 1.355938 to 1.355791. Model was saved
Epoch: 562 	Training Loss: 1.183244 	Validation Loss: 1.355703 	 time: 0.3
Validation loss decreased from 1.355791 to 1.355703. Model was saved
Epoch: 563 	Training Loss: 1.183193 	Validation Loss: 1.355606 	 time: 0.3
Validation loss decreased from 1.355703 to 1.355606. Model was saved
Epoch: 564 	Training Loss: 1.183142 	Validation Loss: 1.355463 	 time: 0.3
Validation loss decreased from 1.355606 to 1.355463. Model was saved
Epoch: 565 	Training Loss: 1.183093 	Validation Loss: 1.355369 	 time: 0.3
Validation loss decreased from 1.355463 to 1.355369. Model was saved
Epoch: 566 	Training Loss: 1.183043 	Validation Loss: 1.355293 	 time: 0.3
Validation loss decreased from 1.355369 to 1.355293. Model was saved
Epoch: 567 	Training Loss: 1.182994 	Validation Loss: 1.355166 	 time: 0.3
Validation loss decreased from 1.355293 to 1.355166. Model was saved
Epoch: 568 	Training Loss: 1.182944 	Validation Loss: 1.355018 	 time: 0.3
Validation loss decreased from 1.355166 to 1.355018. Model was saved
Epoch: 569 	Training Loss: 1.182890 	Validation Loss: 1.354823 	 time: 0.3
Validation loss decreased from 1.355018 to 1.354823. Model was saved
Epoch: 570 	Training Loss: 1.182830 	Validation Loss: 1.354540 	 time: 0.3
Validation loss decreased from 1.354823 to 1.354540. Model was saved
Epoch: 571 	Training Loss: 1.182755 	Validation Loss: 1.354149 	 time: 0.3
Validation loss decreased from 1.354540 to 1.354149. Model was saved
Epoch: 572 	Training Loss: 1.182667 	Validation Loss: 1.353701 	 time: 0.3
Validation loss decreased from 1.354149 to 1.353701. Model was saved
Epoch: 573 	Training Loss: 1.182595 	Validation Loss: 1.353227 	 time: 0.3
Validation loss decreased from 1.353701 to 1.353227. Model was saved
Epoch: 574 	Training Loss: 1.182534 	Validation Loss: 1.352752 	 time: 0.3
Validation loss decreased from 1.353227 to 1.352752. Model was saved
Epoch: 575 	Training Loss: 1.182475 	Validation Loss: 1.352333 	 time: 0.3
Validation loss decreased from 1.352752 to 1.352333. Model was saved
Epoch: 576 	Training Loss: 1.182416 	Validation Loss: 1.352009 	 time: 0.3
Validation loss decreased from 1.352333 to 1.352009. Model was saved
Epoch: 577 	Training Loss: 1.182358 	Validation Loss: 1.351819 	 time: 0.3
Validation loss decreased from 1.352009 to 1.351819. Model was saved
Epoch: 578 	Training Loss: 1.182303 	Validation Loss: 1.351700 	 time: 0.3
Validation loss decreased from 1.351819 to 1.351700. Model was saved
Epoch: 579 	Training Loss: 1.182249 	Validation Loss: 1.351615 	 time: 0.3
Validation loss decreased from 1.351700 to 1.351615. Model was saved
Epoch: 580 	Training Loss: 1.182190 	Validation Loss: 1.351685 	 time: 0.3
Epoch: 581 	Training Loss: 1.182122 	Validation Loss: 1.351878 	 time: 0.3
Epoch: 582 	Training Loss: 1.182051 	Validation Loss: 1.352043 	 time: 0.3
Epoch: 583 	Training Loss: 1.181991 	Validation Loss: 1.352054 	 time: 0.3
Epoch: 584 	Training Loss: 1.181940 	Validation Loss: 1.352078 	 time: 0.3
Epoch: 585 	Training Loss: 1.181890 	Validation Loss: 1.352103 	 time: 0.3
Epoch: 586 	Training Loss: 1.181840 	Validation Loss: 1.351983 	 time: 0.2
Epoch: 587 	Training Loss: 1.181789 	Validation Loss: 1.351954 	 time: 0.3
Epoch: 588 	Training Loss: 1.181740 	Validation Loss: 1.352088 	 time: 0.3
Epoch: 589 	Training Loss: 1.181691 	Validation Loss: 1.352243 	 time: 0.3
Epoch: 590 	Training Loss: 1.181642 	Validation Loss: 1.352417 	 time: 0.3
Epoch: 591 	Training Loss: 1.181596 	Validation Loss: 1.352531 	 time: 0.3
Epoch: 592 	Training Loss: 1.181548 	Validation Loss: 1.352557 	 time: 0.3
Epoch: 593 	Training Loss: 1.181494 	Validation Loss: 1.352597 	 time: 0.3
Epoch: 594 	Training Loss: 1.181429 	Validation Loss: 1.352582 	 time: 0.3
Epoch: 595 	Training Loss: 1.181370 	Validation Loss: 1.352516 	 time: 0.3
Epoch: 596 	Training Loss: 1.181328 	Validation Loss: 1.352587 	 time: 0.3
Epoch: 597 	Training Loss: 1.181280 	Validation Loss: 1.352764 	 time: 0.3
Epoch: 598 	Training Loss: 1.181218 	Validation Loss: 1.352982 	 time: 0.3
Epoch: 599 	Training Loss: 1.181147 	Validation Loss: 1.353330 	 time: 0.3
Epoch: 600 	Training Loss: 1.181094 	Validation Loss: 1.353631 	 time: 0.3
Epoch: 601 	Training Loss: 1.181038 	Validation Loss: 1.353781 	 time: 0.3
Epoch: 602 	Training Loss: 1.180972 	Validation Loss: 1.353819 	 time: 0.3
Epoch: 603 	Training Loss: 1.180900 	Validation Loss: 1.353827 	 time: 0.3
Epoch: 604 	Training Loss: 1.180811 	Validation Loss: 1.353949 	 time: 0.3
Epoch: 605 	Training Loss: 1.180717 	Validation Loss: 1.354119 	 time: 0.3
Epoch: 606 	Training Loss: 1.180645 	Validation Loss: 1.354279 	 time: 0.3
Epoch: 607 	Training Loss: 1.180584 	Validation Loss: 1.354488 	 time: 0.3
Epoch: 608 	Training Loss: 1.180531 	Validation Loss: 1.354678 	 time: 0.3
Epoch: 609 	Training Loss: 1.180479 	Validation Loss: 1.354781 	 time: 0.3
Epoch: 610 	Training Loss: 1.180428 	Validation Loss: 1.354678 	 time: 0.3
Epoch: 611 	Training Loss: 1.180376 	Validation Loss: 1.354411 	 time: 0.3
Epoch: 612 	Training Loss: 1.180317 	Validation Loss: 1.354262 	 time: 0.3
Epoch: 613 	Training Loss: 1.180221 	Validation Loss: 1.354191 	 time: 0.3
Epoch: 614 	Training Loss: 1.180136 	Validation Loss: 1.354249 	 time: 0.3
Epoch: 615 	Training Loss: 1.180086 	Validation Loss: 1.354407 	 time: 0.3
Epoch: 616 	Training Loss: 1.180041 	Validation Loss: 1.354600 	 time: 0.3
Epoch: 617 	Training Loss: 1.179990 	Validation Loss: 1.354747 	 time: 0.3
Epoch: 618 	Training Loss: 1.179929 	Validation Loss: 1.354870 	 time: 0.3
Epoch: 619 	Training Loss: 1.179870 	Validation Loss: 1.355037 	 time: 0.3
Epoch: 620 	Training Loss: 1.179820 	Validation Loss: 1.355270 	 time: 0.3
Epoch: 621 	Training Loss: 1.179769 	Validation Loss: 1.355512 	 time: 0.3
Epoch: 622 	Training Loss: 1.179713 	Validation Loss: 1.355813 	 time: 0.3
Epoch: 623 	Training Loss: 1.179654 	Validation Loss: 1.356141 	 time: 0.3
Epoch: 624 	Training Loss: 1.179595 	Validation Loss: 1.356353 	 time: 0.3
Epoch: 625 	Training Loss: 1.179541 	Validation Loss: 1.356454 	 time: 0.3
Epoch: 626 	Training Loss: 1.179493 	Validation Loss: 1.356489 	 time: 0.3
Epoch: 627 	Training Loss: 1.179450 	Validation Loss: 1.356500 	 time: 0.3
Epoch: 628 	Training Loss: 1.179410 	Validation Loss: 1.356557 	 time: 0.3
Epoch: 629 	Training Loss: 1.179372 	Validation Loss: 1.356656 	 time: 0.3
Epoch: 630 	Training Loss: 1.179334 	Validation Loss: 1.356763 	 time: 0.3
Epoch: 631 	Training Loss: 1.179298 	Validation Loss: 1.356849 	 time: 0.3
Epoch: 632 	Training Loss: 1.179263 	Validation Loss: 1.356869 	 time: 0.3
Epoch: 633 	Training Loss: 1.179227 	Validation Loss: 1.356833 	 time: 0.3
Epoch: 634 	Training Loss: 1.179179 	Validation Loss: 1.356753 	 time: 0.3
Epoch: 635 	Training Loss: 1.179098 	Validation Loss: 1.356689 	 time: 0.3
Epoch: 636 	Training Loss: 1.179059 	Validation Loss: 1.356726 	 time: 0.3
Epoch: 637 	Training Loss: 1.179025 	Validation Loss: 1.356812 	 time: 0.3
Epoch: 638 	Training Loss: 1.178989 	Validation Loss: 1.356884 	 time: 0.3
Epoch: 639 	Training Loss: 1.178954 	Validation Loss: 1.356922 	 time: 0.3
Epoch: 640 	Training Loss: 1.178918 	Validation Loss: 1.356891 	 time: 0.3
Epoch: 641 	Training Loss: 1.178881 	Validation Loss: 1.356838 	 time: 0.3
Epoch: 642 	Training Loss: 1.178843 	Validation Loss: 1.356808 	 time: 0.3
Epoch: 643 	Training Loss: 1.178804 	Validation Loss: 1.356819 	 time: 0.3
Epoch: 644 	Training Loss: 1.178762 	Validation Loss: 1.356844 	 time: 0.3
Epoch: 645 	Training Loss: 1.178711 	Validation Loss: 1.356832 	 time: 0.3
Epoch: 646 	Training Loss: 1.178651 	Validation Loss: 1.356811 	 time: 0.3
Epoch: 647 	Training Loss: 1.178591 	Validation Loss: 1.356764 	 time: 0.3
Epoch: 648 	Training Loss: 1.178539 	Validation Loss: 1.356677 	 time: 0.3
Epoch: 649 	Training Loss: 1.178497 	Validation Loss: 1.356614 	 time: 0.3
Epoch: 650 	Training Loss: 1.178460 	Validation Loss: 1.356567 	 time: 0.3
Epoch: 651 	Training Loss: 1.178426 	Validation Loss: 1.356525 	 time: 0.3
Epoch: 652 	Training Loss: 1.178393 	Validation Loss: 1.356495 	 time: 0.3
Epoch: 653 	Training Loss: 1.178361 	Validation Loss: 1.356447 	 time: 0.3
Epoch: 654 	Training Loss: 1.178328 	Validation Loss: 1.356363 	 time: 0.3
Epoch: 655 	Training Loss: 1.178295 	Validation Loss: 1.356258 	 time: 0.3
Epoch: 656 	Training Loss: 1.178259 	Validation Loss: 1.356163 	 time: 0.3
Epoch: 657 	Training Loss: 1.178219 	Validation Loss: 1.356070 	 time: 0.3
Epoch: 658 	Training Loss: 1.178167 	Validation Loss: 1.355970 	 time: 0.3
Epoch: 659 	Training Loss: 1.178099 	Validation Loss: 1.355932 	 time: 0.3
Epoch: 660 	Training Loss: 1.178050 	Validation Loss: 1.355855 	 time: 0.3
Epoch: 661 	Training Loss: 1.178013 	Validation Loss: 1.355774 	 time: 0.3
Epoch: 662 	Training Loss: 1.177976 	Validation Loss: 1.355706 	 time: 0.3
Epoch: 663 	Training Loss: 1.177934 	Validation Loss: 1.355570 	 time: 0.3
Epoch: 664 	Training Loss: 1.177885 	Validation Loss: 1.355442 	 time: 0.3
Epoch: 665 	Training Loss: 1.177827 	Validation Loss: 1.355312 	 time: 0.3
Epoch: 666 	Training Loss: 1.177757 	Validation Loss: 1.355236 	 time: 0.3
Epoch: 667 	Training Loss: 1.177678 	Validation Loss: 1.355250 	 time: 0.3
Epoch: 668 	Training Loss: 1.177604 	Validation Loss: 1.355319 	 time: 0.3
Epoch: 669 	Training Loss: 1.177538 	Validation Loss: 1.355422 	 time: 0.3
Epoch: 670 	Training Loss: 1.177478 	Validation Loss: 1.355462 	 time: 0.3
Epoch: 671 	Training Loss: 1.177423 	Validation Loss: 1.355459 	 time: 0.3
Epoch: 672 	Training Loss: 1.177374 	Validation Loss: 1.355452 	 time: 0.3
Epoch: 673 	Training Loss: 1.177331 	Validation Loss: 1.355467 	 time: 0.3
Epoch: 674 	Training Loss: 1.177292 	Validation Loss: 1.355600 	 time: 0.3
Epoch: 675 	Training Loss: 1.177253 	Validation Loss: 1.355815 	 time: 0.3
Epoch: 676 	Training Loss: 1.177214 	Validation Loss: 1.356045 	 time: 0.3
Epoch: 677 	Training Loss: 1.177173 	Validation Loss: 1.356230 	 time: 0.3
Epoch: 678 	Training Loss: 1.177129 	Validation Loss: 1.356316 	 time: 0.3
Epoch: 679 	Training Loss: 1.177078 	Validation Loss: 1.356325 	 time: 0.3
Epoch: 680 	Training Loss: 1.177034 	Validation Loss: 1.356226 	 time: 0.3
Epoch: 681 	Training Loss: 1.176986 	Validation Loss: 1.356196 	 time: 0.3
Epoch: 682 	Training Loss: 1.176945 	Validation Loss: 1.356182 	 time: 0.3
Epoch: 683 	Training Loss: 1.176903 	Validation Loss: 1.356229 	 time: 0.3
Epoch: 684 	Training Loss: 1.176867 	Validation Loss: 1.356336 	 time: 0.3
Epoch: 685 	Training Loss: 1.176834 	Validation Loss: 1.356347 	 time: 0.3
Epoch: 686 	Training Loss: 1.176800 	Validation Loss: 1.356347 	 time: 0.3
Epoch: 687 	Training Loss: 1.176765 	Validation Loss: 1.356246 	 time: 0.3
Epoch: 688 	Training Loss: 1.176728 	Validation Loss: 1.356122 	 time: 0.3
Epoch: 689 	Training Loss: 1.176694 	Validation Loss: 1.356011 	 time: 0.3
Epoch: 690 	Training Loss: 1.176665 	Validation Loss: 1.355859 	 time: 0.3
Epoch: 691 	Training Loss: 1.176635 	Validation Loss: 1.355731 	 time: 0.3
Epoch: 692 	Training Loss: 1.176606 	Validation Loss: 1.355510 	 time: 0.3
Epoch: 693 	Training Loss: 1.176577 	Validation Loss: 1.355244 	 time: 0.3
Epoch: 694 	Training Loss: 1.176547 	Validation Loss: 1.355031 	 time: 0.3
Epoch: 695 	Training Loss: 1.176517 	Validation Loss: 1.354896 	 time: 0.3
Epoch: 696 	Training Loss: 1.176490 	Validation Loss: 1.354922 	 time: 0.3
Epoch: 697 	Training Loss: 1.176462 	Validation Loss: 1.355026 	 time: 0.3
Epoch: 698 	Training Loss: 1.176433 	Validation Loss: 1.355182 	 time: 0.3
Epoch: 699 	Training Loss: 1.176403 	Validation Loss: 1.355331 	 time: 0.3
Epoch: 700 	Training Loss: 1.176371 	Validation Loss: 1.355432 	 time: 0.3
Epoch: 701 	Training Loss: 1.176340 	Validation Loss: 1.355547 	 time: 0.3
Epoch: 702 	Training Loss: 1.176306 	Validation Loss: 1.355658 	 time: 0.3
Epoch: 703 	Training Loss: 1.176269 	Validation Loss: 1.355825 	 time: 0.3
Epoch: 704 	Training Loss: 1.176217 	Validation Loss: 1.356030 	 time: 0.3
Epoch: 705 	Training Loss: 1.176148 	Validation Loss: 1.356114 	 time: 0.3
Epoch: 706 	Training Loss: 1.176096 	Validation Loss: 1.356017 	 time: 0.3
Epoch: 707 	Training Loss: 1.176057 	Validation Loss: 1.355894 	 time: 0.3
Epoch: 708 	Training Loss: 1.176021 	Validation Loss: 1.355873 	 time: 0.3
Epoch: 709 	Training Loss: 1.175986 	Validation Loss: 1.355800 	 time: 0.3
Epoch: 710 	Training Loss: 1.175948 	Validation Loss: 1.355840 	 time: 0.3
Epoch: 711 	Training Loss: 1.175907 	Validation Loss: 1.355936 	 time: 0.3
Epoch: 712 	Training Loss: 1.175850 	Validation Loss: 1.355918 	 time: 0.3
Epoch: 713 	Training Loss: 1.175785 	Validation Loss: 1.355819 	 time: 0.3
Epoch: 714 	Training Loss: 1.175739 	Validation Loss: 1.355814 	 time: 0.3
Epoch: 715 	Training Loss: 1.175701 	Validation Loss: 1.355929 	 time: 0.3
Epoch: 716 	Training Loss: 1.175667 	Validation Loss: 1.355932 	 time: 0.3
Epoch: 717 	Training Loss: 1.175630 	Validation Loss: 1.355937 	 time: 0.3
Epoch: 718 	Training Loss: 1.175596 	Validation Loss: 1.355954 	 time: 0.3
Epoch: 719 	Training Loss: 1.175563 	Validation Loss: 1.355895 	 time: 0.3
Epoch: 720 	Training Loss: 1.175531 	Validation Loss: 1.355826 	 time: 0.3
Epoch: 721 	Training Loss: 1.175499 	Validation Loss: 1.355858 	 time: 0.3
Epoch: 722 	Training Loss: 1.175465 	Validation Loss: 1.355945 	 time: 0.3
Epoch: 723 	Training Loss: 1.175429 	Validation Loss: 1.356045 	 time: 0.3
Epoch: 724 	Training Loss: 1.175391 	Validation Loss: 1.356255 	 time: 0.3
Epoch: 725 	Training Loss: 1.175349 	Validation Loss: 1.356456 	 time: 0.3
Epoch: 726 	Training Loss: 1.175303 	Validation Loss: 1.356514 	 time: 0.3
Epoch: 727 	Training Loss: 1.175253 	Validation Loss: 1.356489 	 time: 0.3
Epoch: 728 	Training Loss: 1.175210 	Validation Loss: 1.356503 	 time: 0.3
Epoch: 729 	Training Loss: 1.175175 	Validation Loss: 1.356574 	 time: 0.3
Epoch: 730 	Training Loss: 1.175139 	Validation Loss: 1.356693 	 time: 0.3
Epoch: 731 	Training Loss: 1.175109 	Validation Loss: 1.356825 	 time: 0.3
Epoch: 732 	Training Loss: 1.175079 	Validation Loss: 1.356860 	 time: 0.3
Epoch: 733 	Training Loss: 1.175045 	Validation Loss: 1.356824 	 time: 0.2
Epoch: 734 	Training Loss: 1.175010 	Validation Loss: 1.356798 	 time: 0.3
Epoch: 735 	Training Loss: 1.174976 	Validation Loss: 1.356792 	 time: 0.3
Epoch: 736 	Training Loss: 1.174943 	Validation Loss: 1.356771 	 time: 0.3
Epoch: 737 	Training Loss: 1.174911 	Validation Loss: 1.356771 	 time: 0.2
Epoch: 738 	Training Loss: 1.174881 	Validation Loss: 1.356699 	 time: 0.3
Epoch: 739 	Training Loss: 1.174849 	Validation Loss: 1.356535 	 time: 0.3
Epoch: 740 	Training Loss: 1.174816 	Validation Loss: 1.356379 	 time: 0.3
Epoch: 741 	Training Loss: 1.174783 	Validation Loss: 1.356297 	 time: 0.3
Epoch: 742 	Training Loss: 1.174753 	Validation Loss: 1.356223 	 time: 0.3
Epoch: 743 	Training Loss: 1.174726 	Validation Loss: 1.356141 	 time: 0.3
Epoch: 744 	Training Loss: 1.174698 	Validation Loss: 1.356023 	 time: 0.3
Epoch: 745 	Training Loss: 1.174671 	Validation Loss: 1.355876 	 time: 0.3
Epoch: 746 	Training Loss: 1.174645 	Validation Loss: 1.355735 	 time: 0.3
Epoch: 747 	Training Loss: 1.174622 	Validation Loss: 1.355599 	 time: 0.3
Epoch: 748 	Training Loss: 1.174599 	Validation Loss: 1.355436 	 time: 0.3
Epoch: 749 	Training Loss: 1.174577 	Validation Loss: 1.355238 	 time: 0.3
Epoch: 750 	Training Loss: 1.174554 	Validation Loss: 1.355017 	 time: 0.3
Epoch: 751 	Training Loss: 1.174531 	Validation Loss: 1.354779 	 time: 0.3
Epoch: 752 	Training Loss: 1.174507 	Validation Loss: 1.354538 	 time: 0.3
Epoch: 753 	Training Loss: 1.174481 	Validation Loss: 1.354306 	 time: 0.3
Epoch: 754 	Training Loss: 1.174447 	Validation Loss: 1.354087 	 time: 0.3
Epoch: 755 	Training Loss: 1.174397 	Validation Loss: 1.353913 	 time: 0.3
Epoch: 756 	Training Loss: 1.174357 	Validation Loss: 1.353772 	 time: 0.3
Epoch: 757 	Training Loss: 1.174332 	Validation Loss: 1.353598 	 time: 0.3
Epoch: 758 	Training Loss: 1.174314 	Validation Loss: 1.353445 	 time: 0.3
Epoch: 759 	Training Loss: 1.174297 	Validation Loss: 1.353347 	 time: 0.3
Epoch: 760 	Training Loss: 1.174280 	Validation Loss: 1.353251 	 time: 0.3
Epoch: 761 	Training Loss: 1.174259 	Validation Loss: 1.353172 	 time: 0.3
Epoch: 762 	Training Loss: 1.174237 	Validation Loss: 1.353094 	 time: 0.3
Epoch: 763 	Training Loss: 1.174215 	Validation Loss: 1.352926 	 time: 0.3
Epoch: 764 	Training Loss: 1.174194 	Validation Loss: 1.352697 	 time: 0.3
Epoch: 765 	Training Loss: 1.174175 	Validation Loss: 1.352481 	 time: 0.3
Epoch: 766 	Training Loss: 1.174157 	Validation Loss: 1.352290 	 time: 0.3
Epoch: 767 	Training Loss: 1.174140 	Validation Loss: 1.352145 	 time: 0.3
Epoch: 768 	Training Loss: 1.174123 	Validation Loss: 1.352077 	 time: 0.3
Epoch: 769 	Training Loss: 1.174106 	Validation Loss: 1.352013 	 time: 0.3
Epoch: 770 	Training Loss: 1.174088 	Validation Loss: 1.351925 	 time: 0.3
Epoch: 771 	Training Loss: 1.174071 	Validation Loss: 1.351848 	 time: 0.3
Epoch: 772 	Training Loss: 1.174053 	Validation Loss: 1.351774 	 time: 0.3
Epoch: 773 	Training Loss: 1.174034 	Validation Loss: 1.351671 	 time: 0.3
Epoch: 774 	Training Loss: 1.174015 	Validation Loss: 1.351571 	 time: 0.3
Validation loss decreased from 1.351615 to 1.351571. Model was saved
Epoch: 775 	Training Loss: 1.173994 	Validation Loss: 1.351470 	 time: 0.3
Validation loss decreased from 1.351571 to 1.351470. Model was saved
Epoch: 776 	Training Loss: 1.173975 	Validation Loss: 1.351348 	 time: 0.3
Validation loss decreased from 1.351470 to 1.351348. Model was saved
Epoch: 777 	Training Loss: 1.173957 	Validation Loss: 1.351223 	 time: 0.3
Validation loss decreased from 1.351348 to 1.351223. Model was saved
Epoch: 778 	Training Loss: 1.173939 	Validation Loss: 1.351082 	 time: 0.3
Validation loss decreased from 1.351223 to 1.351082. Model was saved
Epoch: 779 	Training Loss: 1.173921 	Validation Loss: 1.350913 	 time: 0.3
Validation loss decreased from 1.351082 to 1.350913. Model was saved
Epoch: 780 	Training Loss: 1.173900 	Validation Loss: 1.350738 	 time: 0.3
Validation loss decreased from 1.350913 to 1.350738. Model was saved
Epoch: 781 	Training Loss: 1.173877 	Validation Loss: 1.350557 	 time: 0.3
Validation loss decreased from 1.350738 to 1.350557. Model was saved
Epoch: 782 	Training Loss: 1.173854 	Validation Loss: 1.350365 	 time: 0.3
Validation loss decreased from 1.350557 to 1.350365. Model was saved
Epoch: 783 	Training Loss: 1.173830 	Validation Loss: 1.350195 	 time: 0.3
Validation loss decreased from 1.350365 to 1.350195. Model was saved
Epoch: 784 	Training Loss: 1.173794 	Validation Loss: 1.350015 	 time: 0.3
Validation loss decreased from 1.350195 to 1.350015. Model was saved
Epoch: 785 	Training Loss: 1.173746 	Validation Loss: 1.349810 	 time: 0.3
Validation loss decreased from 1.350015 to 1.349810. Model was saved
Epoch: 786 	Training Loss: 1.173727 	Validation Loss: 1.349649 	 time: 0.3
Validation loss decreased from 1.349810 to 1.349649. Model was saved
Epoch: 787 	Training Loss: 1.173715 	Validation Loss: 1.349422 	 time: 0.3
Validation loss decreased from 1.349649 to 1.349422. Model was saved
Epoch: 788 	Training Loss: 1.173700 	Validation Loss: 1.349042 	 time: 0.3
Validation loss decreased from 1.349422 to 1.349042. Model was saved
Epoch: 789 	Training Loss: 1.173680 	Validation Loss: 1.348708 	 time: 0.3
Validation loss decreased from 1.349042 to 1.348708. Model was saved
Epoch: 790 	Training Loss: 1.173659 	Validation Loss: 1.348347 	 time: 0.3
Validation loss decreased from 1.348708 to 1.348347. Model was saved
Epoch: 791 	Training Loss: 1.173637 	Validation Loss: 1.348047 	 time: 0.3
Validation loss decreased from 1.348347 to 1.348047. Model was saved
Epoch: 792 	Training Loss: 1.173616 	Validation Loss: 1.347750 	 time: 0.3
Validation loss decreased from 1.348047 to 1.347750. Model was saved
Epoch: 793 	Training Loss: 1.173596 	Validation Loss: 1.347512 	 time: 0.3
Validation loss decreased from 1.347750 to 1.347512. Model was saved
Epoch: 794 	Training Loss: 1.173577 	Validation Loss: 1.347183 	 time: 0.3
Validation loss decreased from 1.347512 to 1.347183. Model was saved
Epoch: 795 	Training Loss: 1.173559 	Validation Loss: 1.347028 	 time: 0.3
Validation loss decreased from 1.347183 to 1.347028. Model was saved
Epoch: 796 	Training Loss: 1.173542 	Validation Loss: 1.346698 	 time: 0.3
Validation loss decreased from 1.347028 to 1.346698. Model was saved
Epoch: 797 	Training Loss: 1.173528 	Validation Loss: 1.346629 	 time: 0.3
Validation loss decreased from 1.346698 to 1.346629. Model was saved
Epoch: 798 	Training Loss: 1.173517 	Validation Loss: 1.346343 	 time: 0.3
Validation loss decreased from 1.346629 to 1.346343. Model was saved
Epoch: 799 	Training Loss: 1.173509 	Validation Loss: 1.346344 	 time: 0.3
Epoch: 800 	Training Loss: 1.173496 	Validation Loss: 1.346327 	 time: 0.3
Validation loss decreased from 1.346343 to 1.346327. Model was saved
Epoch: 801 	Training Loss: 1.173468 	Validation Loss: 1.346188 	 time: 0.3
Validation loss decreased from 1.346327 to 1.346188. Model was saved
Epoch: 802 	Training Loss: 1.173434 	Validation Loss: 1.346225 	 time: 0.3
Epoch: 803 	Training Loss: 1.173407 	Validation Loss: 1.346292 	 time: 0.3
Epoch: 804 	Training Loss: 1.173381 	Validation Loss: 1.346322 	 time: 0.3
Epoch: 805 	Training Loss: 1.173343 	Validation Loss: 1.346405 	 time: 0.3
Epoch: 806 	Training Loss: 1.173310 	Validation Loss: 1.346495 	 time: 0.3
Epoch: 807 	Training Loss: 1.173291 	Validation Loss: 1.346293 	 time: 0.3
Epoch: 808 	Training Loss: 1.173277 	Validation Loss: 1.346408 	 time: 0.3
Epoch: 809 	Training Loss: 1.173275 	Validation Loss: 1.346483 	 time: 0.3
Epoch: 810 	Training Loss: 1.173269 	Validation Loss: 1.346341 	 time: 0.3
Epoch: 811 	Training Loss: 1.173261 	Validation Loss: 1.346275 	 time: 0.3
Epoch: 812 	Training Loss: 1.173237 	Validation Loss: 1.346323 	 time: 0.3
Epoch: 813 	Training Loss: 1.173204 	Validation Loss: 1.346006 	 time: 0.3
Validation loss decreased from 1.346188 to 1.346006. Model was saved
Epoch: 814 	Training Loss: 1.173174 	Validation Loss: 1.346339 	 time: 0.3
Epoch: 815 	Training Loss: 1.173145 	Validation Loss: 1.346125 	 time: 0.3
Epoch: 816 	Training Loss: 1.173106 	Validation Loss: 1.346436 	 time: 0.3
Epoch: 817 	Training Loss: 1.173063 	Validation Loss: 1.346716 	 time: 0.3
Epoch: 818 	Training Loss: 1.173017 	Validation Loss: 1.346506 	 time: 0.3
Epoch: 819 	Training Loss: 1.172965 	Validation Loss: 1.346400 	 time: 0.3
Epoch: 820 	Training Loss: 1.172920 	Validation Loss: 1.346354 	 time: 0.3
Epoch: 821 	Training Loss: 1.172881 	Validation Loss: 1.346172 	 time: 0.3
Epoch: 822 	Training Loss: 1.172845 	Validation Loss: 1.346230 	 time: 0.3
Epoch: 823 	Training Loss: 1.172802 	Validation Loss: 1.346542 	 time: 0.3
Epoch: 824 	Training Loss: 1.172775 	Validation Loss: 1.346131 	 time: 0.3
Epoch: 825 	Training Loss: 1.172766 	Validation Loss: 1.346906 	 time: 0.3
Epoch: 826 	Training Loss: 1.172786 	Validation Loss: 1.345799 	 time: 0.3
Validation loss decreased from 1.346006 to 1.345799. Model was saved
Epoch: 827 	Training Loss: 1.172944 	Validation Loss: 1.347721 	 time: 0.3
Epoch: 828 	Training Loss: 1.173998 	Validation Loss: 1.349406 	 time: 0.3
Epoch: 829 	Training Loss: 1.177152 	Validation Loss: 1.381827 	 time: 0.3
Epoch: 830 	Training Loss: 1.214212 	Validation Loss: 1.407907 	 time: 0.3
Epoch: 831 	Training Loss: 1.258998 	Validation Loss: 1.369275 	 time: 0.3
Epoch: 832 	Training Loss: 1.217113 	Validation Loss: 1.388785 	 time: 0.3
Epoch: 833 	Training Loss: 1.254334 	Validation Loss: 1.385431 	 time: 0.3
Epoch: 834 	Training Loss: 1.220825 	Validation Loss: 1.418056 	 time: 0.3
Epoch: 835 	Training Loss: 1.239994 	Validation Loss: 1.393856 	 time: 0.3
Epoch: 836 	Training Loss: 1.223928 	Validation Loss: 1.394439 	 time: 0.3
Epoch: 837 	Training Loss: 1.213132 	Validation Loss: 1.371078 	 time: 0.3
Epoch: 838 	Training Loss: 1.217499 	Validation Loss: 1.363206 	 time: 0.3
Epoch: 839 	Training Loss: 1.205039 	Validation Loss: 1.372909 	 time: 0.3
Epoch: 840 	Training Loss: 1.208184 	Validation Loss: 1.377258 	 time: 0.3
Epoch: 841 	Training Loss: 1.207798 	Validation Loss: 1.361104 	 time: 0.3
Epoch: 842 	Training Loss: 1.197687 	Validation Loss: 1.359794 	 time: 0.3
Epoch: 843 	Training Loss: 1.201504 	Validation Loss: 1.354655 	 time: 0.3
Epoch: 844 	Training Loss: 1.197469 	Validation Loss: 1.358045 	 time: 0.3
Epoch: 845 	Training Loss: 1.191017 	Validation Loss: 1.366369 	 time: 0.3
Epoch: 846 	Training Loss: 1.196559 	Validation Loss: 1.361655 	 time: 0.3
Epoch: 847 	Training Loss: 1.189370 	Validation Loss: 1.353603 	 time: 0.3
Epoch: 848 	Training Loss: 1.189325 	Validation Loss: 1.351418 	 time: 0.3
Epoch: 849 	Training Loss: 1.189628 	Validation Loss: 1.360897 	 time: 0.3
Epoch: 850 	Training Loss: 1.186279 	Validation Loss: 1.362251 	 time: 0.3
Epoch: 851 	Training Loss: 1.185809 	Validation Loss: 1.358564 	 time: 0.3
Epoch: 852 	Training Loss: 1.183782 	Validation Loss: 1.361858 	 time: 0.3
Epoch: 853 	Training Loss: 1.183741 	Validation Loss: 1.352720 	 time: 0.3
Epoch: 854 	Training Loss: 1.181713 	Validation Loss: 1.352365 	 time: 0.3
Epoch: 855 	Training Loss: 1.181460 	Validation Loss: 1.350579 	 time: 0.3
Epoch: 856 	Training Loss: 1.181216 	Validation Loss: 1.344331 	 time: 0.3
Validation loss decreased from 1.345799 to 1.344331. Model was saved
Epoch: 857 	Training Loss: 1.179074 	Validation Loss: 1.345772 	 time: 0.3
Epoch: 858 	Training Loss: 1.180198 	Validation Loss: 1.348512 	 time: 0.3
Epoch: 859 	Training Loss: 1.178969 	Validation Loss: 1.344474 	 time: 0.3
Epoch: 860 	Training Loss: 1.178385 	Validation Loss: 1.340385 	 time: 0.3
Validation loss decreased from 1.344331 to 1.340385. Model was saved
Epoch: 861 	Training Loss: 1.177966 	Validation Loss: 1.339198 	 time: 0.3
Validation loss decreased from 1.340385 to 1.339198. Model was saved
Epoch: 862 	Training Loss: 1.177579 	Validation Loss: 1.344766 	 time: 0.3
Epoch: 863 	Training Loss: 1.177069 	Validation Loss: 1.345906 	 time: 0.3
Epoch: 864 	Training Loss: 1.176766 	Validation Loss: 1.344494 	 time: 0.3
Epoch: 865 	Training Loss: 1.176659 	Validation Loss: 1.345514 	 time: 0.3
Epoch: 866 	Training Loss: 1.175744 	Validation Loss: 1.346804 	 time: 0.3
Epoch: 867 	Training Loss: 1.175903 	Validation Loss: 1.345019 	 time: 0.3
Epoch: 868 	Training Loss: 1.175349 	Validation Loss: 1.346082 	 time: 0.3
Epoch: 869 	Training Loss: 1.175092 	Validation Loss: 1.349476 	 time: 0.3
Epoch: 870 	Training Loss: 1.174816 	Validation Loss: 1.350332 	 time: 0.3
Epoch: 871 	Training Loss: 1.174756 	Validation Loss: 1.347413 	 time: 0.3
Epoch: 872 	Training Loss: 1.174366 	Validation Loss: 1.345362 	 time: 0.3
Epoch: 873 	Training Loss: 1.174099 	Validation Loss: 1.345953 	 time: 0.3
Epoch: 874 	Training Loss: 1.174107 	Validation Loss: 1.344629 	 time: 0.3
Epoch: 875 	Training Loss: 1.173744 	Validation Loss: 1.343813 	 time: 0.3
Epoch: 876 	Training Loss: 1.173697 	Validation Loss: 1.343918 	 time: 0.3
Epoch: 877 	Training Loss: 1.173548 	Validation Loss: 1.344973 	 time: 0.3
Epoch: 878 	Training Loss: 1.173431 	Validation Loss: 1.343442 	 time: 0.3
Epoch: 879 	Training Loss: 1.173231 	Validation Loss: 1.341478 	 time: 0.3
Epoch: 880 	Training Loss: 1.173135 	Validation Loss: 1.340416 	 time: 0.3
Epoch: 881 	Training Loss: 1.172999 	Validation Loss: 1.340471 	 time: 0.3
Epoch: 882 	Training Loss: 1.172816 	Validation Loss: 1.340566 	 time: 0.3
Epoch: 883 	Training Loss: 1.172733 	Validation Loss: 1.339958 	 time: 0.3
Epoch: 884 	Training Loss: 1.172601 	Validation Loss: 1.339665 	 time: 0.3
Epoch: 885 	Training Loss: 1.172477 	Validation Loss: 1.340396 	 time: 0.3
Epoch: 886 	Training Loss: 1.172369 	Validation Loss: 1.341738 	 time: 0.3
Epoch: 887 	Training Loss: 1.172290 	Validation Loss: 1.342389 	 time: 0.3
Epoch: 888 	Training Loss: 1.172133 	Validation Loss: 1.343757 	 time: 0.3
Epoch: 889 	Training Loss: 1.172046 	Validation Loss: 1.344649 	 time: 0.3
Epoch: 890 	Training Loss: 1.171890 	Validation Loss: 1.344390 	 time: 0.3
Epoch: 891 	Training Loss: 1.171790 	Validation Loss: 1.343719 	 time: 0.3
Epoch: 892 	Training Loss: 1.171710 	Validation Loss: 1.343926 	 time: 0.3
Epoch: 893 	Training Loss: 1.171619 	Validation Loss: 1.344734 	 time: 0.3
Epoch: 894 	Training Loss: 1.171500 	Validation Loss: 1.345076 	 time: 0.3
Epoch: 895 	Training Loss: 1.171391 	Validation Loss: 1.345142 	 time: 0.3
Epoch: 896 	Training Loss: 1.171268 	Validation Loss: 1.345143 	 time: 0.3
Epoch: 897 	Training Loss: 1.171156 	Validation Loss: 1.345519 	 time: 0.3
Epoch: 898 	Training Loss: 1.171090 	Validation Loss: 1.345769 	 time: 0.3
Epoch: 899 	Training Loss: 1.171001 	Validation Loss: 1.345442 	 time: 0.3
Epoch: 900 	Training Loss: 1.170936 	Validation Loss: 1.344786 	 time: 0.3
Epoch: 901 	Training Loss: 1.170865 	Validation Loss: 1.344035 	 time: 0.3
Epoch: 902 	Training Loss: 1.170774 	Validation Loss: 1.342881 	 time: 0.3
Epoch: 903 	Training Loss: 1.170679 	Validation Loss: 1.341843 	 time: 0.3
Epoch: 904 	Training Loss: 1.170605 	Validation Loss: 1.341852 	 time: 0.3
Epoch: 905 	Training Loss: 1.170506 	Validation Loss: 1.342209 	 time: 0.3
Epoch: 906 	Training Loss: 1.170454 	Validation Loss: 1.342197 	 time: 0.3
Epoch: 907 	Training Loss: 1.170369 	Validation Loss: 1.342414 	 time: 0.3
Epoch: 908 	Training Loss: 1.170305 	Validation Loss: 1.342763 	 time: 0.3
Epoch: 909 	Training Loss: 1.170239 	Validation Loss: 1.343330 	 time: 0.3
Epoch: 910 	Training Loss: 1.170152 	Validation Loss: 1.344637 	 time: 0.3
Epoch: 911 	Training Loss: 1.170072 	Validation Loss: 1.345994 	 time: 0.3
Epoch: 912 	Training Loss: 1.170033 	Validation Loss: 1.347317 	 time: 0.3
Epoch: 913 	Training Loss: 1.169988 	Validation Loss: 1.348305 	 time: 0.3
Epoch: 914 	Training Loss: 1.169939 	Validation Loss: 1.348503 	 time: 0.3
Epoch: 915 	Training Loss: 1.169870 	Validation Loss: 1.348227 	 time: 0.3
Epoch: 916 	Training Loss: 1.169793 	Validation Loss: 1.347979 	 time: 0.3
Epoch: 917 	Training Loss: 1.169719 	Validation Loss: 1.347514 	 time: 0.3
Epoch: 918 	Training Loss: 1.169652 	Validation Loss: 1.346681 	 time: 0.3
Epoch: 919 	Training Loss: 1.169579 	Validation Loss: 1.345977 	 time: 0.3
Epoch: 920 	Training Loss: 1.169511 	Validation Loss: 1.345748 	 time: 0.3
Epoch: 921 	Training Loss: 1.169457 	Validation Loss: 1.345602 	 time: 0.3
Epoch: 922 	Training Loss: 1.169410 	Validation Loss: 1.345258 	 time: 0.3
Epoch: 923 	Training Loss: 1.169371 	Validation Loss: 1.344792 	 time: 0.3
Epoch: 924 	Training Loss: 1.169324 	Validation Loss: 1.344339 	 time: 0.3
Epoch: 925 	Training Loss: 1.169283 	Validation Loss: 1.343989 	 time: 0.3
Epoch: 926 	Training Loss: 1.169240 	Validation Loss: 1.343915 	 time: 0.3
Epoch: 927 	Training Loss: 1.169204 	Validation Loss: 1.344026 	 time: 0.3
Epoch: 928 	Training Loss: 1.169168 	Validation Loss: 1.344106 	 time: 0.3
Epoch: 929 	Training Loss: 1.169133 	Validation Loss: 1.344043 	 time: 0.3
Epoch: 930 	Training Loss: 1.169098 	Validation Loss: 1.343908 	 time: 0.3
Epoch: 931 	Training Loss: 1.169062 	Validation Loss: 1.343819 	 time: 0.3
Epoch: 932 	Training Loss: 1.169030 	Validation Loss: 1.343763 	 time: 0.3
Epoch: 933 	Training Loss: 1.168997 	Validation Loss: 1.343726 	 time: 0.3
Epoch: 934 	Training Loss: 1.168966 	Validation Loss: 1.343845 	 time: 0.3
Epoch: 935 	Training Loss: 1.168933 	Validation Loss: 1.344083 	 time: 0.3
Epoch: 936 	Training Loss: 1.168898 	Validation Loss: 1.344150 	 time: 0.3
Epoch: 937 	Training Loss: 1.168860 	Validation Loss: 1.343959 	 time: 0.3
Epoch: 938 	Training Loss: 1.168818 	Validation Loss: 1.343712 	 time: 0.3
Epoch: 939 	Training Loss: 1.168775 	Validation Loss: 1.343537 	 time: 0.3
Epoch: 940 	Training Loss: 1.168738 	Validation Loss: 1.343393 	 time: 0.3
Epoch: 941 	Training Loss: 1.168707 	Validation Loss: 1.343249 	 time: 0.3
Epoch: 942 	Training Loss: 1.168676 	Validation Loss: 1.343095 	 time: 0.3
Epoch: 943 	Training Loss: 1.168646 	Validation Loss: 1.342864 	 time: 0.3
Epoch: 944 	Training Loss: 1.168617 	Validation Loss: 1.342567 	 time: 0.3
Epoch: 945 	Training Loss: 1.168588 	Validation Loss: 1.342261 	 time: 0.3
Epoch: 946 	Training Loss: 1.168559 	Validation Loss: 1.341974 	 time: 0.3
Epoch: 947 	Training Loss: 1.168530 	Validation Loss: 1.341652 	 time: 0.3
Epoch: 948 	Training Loss: 1.168499 	Validation Loss: 1.341201 	 time: 0.3
Epoch: 949 	Training Loss: 1.168464 	Validation Loss: 1.340668 	 time: 0.3
Epoch: 950 	Training Loss: 1.168416 	Validation Loss: 1.340217 	 time: 0.3
Epoch: 951 	Training Loss: 1.168359 	Validation Loss: 1.339858 	 time: 0.3
Epoch: 952 	Training Loss: 1.168319 	Validation Loss: 1.339653 	 time: 0.3
Epoch: 953 	Training Loss: 1.168286 	Validation Loss: 1.339459 	 time: 0.3
Epoch: 954 	Training Loss: 1.168254 	Validation Loss: 1.339136 	 time: 0.3
Validation loss decreased from 1.339198 to 1.339136. Model was saved
Epoch: 955 	Training Loss: 1.168223 	Validation Loss: 1.338880 	 time: 0.3
Validation loss decreased from 1.339136 to 1.338880. Model was saved
Epoch: 956 	Training Loss: 1.168192 	Validation Loss: 1.338655 	 time: 0.3
Validation loss decreased from 1.338880 to 1.338655. Model was saved
Epoch: 957 	Training Loss: 1.168160 	Validation Loss: 1.338359 	 time: 0.3
Validation loss decreased from 1.338655 to 1.338359. Model was saved
Epoch: 958 	Training Loss: 1.168128 	Validation Loss: 1.338184 	 time: 0.3
Validation loss decreased from 1.338359 to 1.338184. Model was saved
Epoch: 959 	Training Loss: 1.168096 	Validation Loss: 1.338091 	 time: 0.3
Validation loss decreased from 1.338184 to 1.338091. Model was saved
Epoch: 960 	Training Loss: 1.168064 	Validation Loss: 1.337881 	 time: 0.3
Validation loss decreased from 1.338091 to 1.337881. Model was saved
Epoch: 961 	Training Loss: 1.168031 	Validation Loss: 1.337600 	 time: 0.3
Validation loss decreased from 1.337881 to 1.337600. Model was saved
Epoch: 962 	Training Loss: 1.167998 	Validation Loss: 1.337234 	 time: 0.3
Validation loss decreased from 1.337600 to 1.337234. Model was saved
Epoch: 963 	Training Loss: 1.167964 	Validation Loss: 1.336749 	 time: 0.3
Validation loss decreased from 1.337234 to 1.336749. Model was saved
Epoch: 964 	Training Loss: 1.167930 	Validation Loss: 1.336309 	 time: 0.3
Validation loss decreased from 1.336749 to 1.336309. Model was saved
Epoch: 965 	Training Loss: 1.167896 	Validation Loss: 1.335962 	 time: 0.3
Validation loss decreased from 1.336309 to 1.335962. Model was saved
Epoch: 966 	Training Loss: 1.167863 	Validation Loss: 1.335620 	 time: 0.3
Validation loss decreased from 1.335962 to 1.335620. Model was saved
Epoch: 967 	Training Loss: 1.167827 	Validation Loss: 1.335342 	 time: 0.3
Validation loss decreased from 1.335620 to 1.335342. Model was saved
Epoch: 968 	Training Loss: 1.167787 	Validation Loss: 1.335172 	 time: 0.3
Validation loss decreased from 1.335342 to 1.335172. Model was saved
Epoch: 969 	Training Loss: 1.167744 	Validation Loss: 1.335081 	 time: 0.3
Validation loss decreased from 1.335172 to 1.335081. Model was saved
Epoch: 970 	Training Loss: 1.167701 	Validation Loss: 1.335064 	 time: 0.3
Validation loss decreased from 1.335081 to 1.335064. Model was saved
Epoch: 971 	Training Loss: 1.167660 	Validation Loss: 1.335061 	 time: 0.3
Validation loss decreased from 1.335064 to 1.335061. Model was saved
Epoch: 972 	Training Loss: 1.167620 	Validation Loss: 1.335098 	 time: 0.3
Epoch: 973 	Training Loss: 1.167578 	Validation Loss: 1.335322 	 time: 0.3
Epoch: 974 	Training Loss: 1.167540 	Validation Loss: 1.335651 	 time: 0.3
Epoch: 975 	Training Loss: 1.167508 	Validation Loss: 1.335870 	 time: 0.3
Epoch: 976 	Training Loss: 1.167478 	Validation Loss: 1.335938 	 time: 0.3
Epoch: 977 	Training Loss: 1.167446 	Validation Loss: 1.335872 	 time: 0.3
Epoch: 978 	Training Loss: 1.167414 	Validation Loss: 1.335698 	 time: 0.3
Epoch: 979 	Training Loss: 1.167382 	Validation Loss: 1.335501 	 time: 0.3
Epoch: 980 	Training Loss: 1.167349 	Validation Loss: 1.335256 	 time: 0.3
Epoch: 981 	Training Loss: 1.167316 	Validation Loss: 1.334970 	 time: 0.3
Validation loss decreased from 1.335061 to 1.334970. Model was saved
Epoch: 982 	Training Loss: 1.167284 	Validation Loss: 1.334750 	 time: 0.3
Validation loss decreased from 1.334970 to 1.334750. Model was saved
Epoch: 983 	Training Loss: 1.167255 	Validation Loss: 1.334612 	 time: 0.3
Validation loss decreased from 1.334750 to 1.334612. Model was saved
Epoch: 984 	Training Loss: 1.167225 	Validation Loss: 1.334522 	 time: 0.3
Validation loss decreased from 1.334612 to 1.334522. Model was saved
Epoch: 985 	Training Loss: 1.167196 	Validation Loss: 1.334415 	 time: 0.3
Validation loss decreased from 1.334522 to 1.334415. Model was saved
Epoch: 986 	Training Loss: 1.167164 	Validation Loss: 1.334248 	 time: 0.3
Validation loss decreased from 1.334415 to 1.334248. Model was saved
Epoch: 987 	Training Loss: 1.167130 	Validation Loss: 1.334055 	 time: 0.3
Validation loss decreased from 1.334248 to 1.334055. Model was saved
Epoch: 988 	Training Loss: 1.167097 	Validation Loss: 1.333843 	 time: 0.3
Validation loss decreased from 1.334055 to 1.333843. Model was saved
Epoch: 989 	Training Loss: 1.167064 	Validation Loss: 1.333603 	 time: 0.3
Validation loss decreased from 1.333843 to 1.333603. Model was saved
Epoch: 990 	Training Loss: 1.167033 	Validation Loss: 1.333400 	 time: 0.3
Validation loss decreased from 1.333603 to 1.333400. Model was saved
Epoch: 991 	Training Loss: 1.167003 	Validation Loss: 1.333243 	 time: 0.3
Validation loss decreased from 1.333400 to 1.333243. Model was saved
Epoch: 992 	Training Loss: 1.166973 	Validation Loss: 1.333062 	 time: 0.3
Validation loss decreased from 1.333243 to 1.333062. Model was saved
Epoch: 993 	Training Loss: 1.166943 	Validation Loss: 1.332824 	 time: 0.3
Validation loss decreased from 1.333062 to 1.332824. Model was saved
Epoch: 994 	Training Loss: 1.166912 	Validation Loss: 1.332532 	 time: 0.3
Validation loss decreased from 1.332824 to 1.332532. Model was saved
Epoch: 995 	Training Loss: 1.166880 	Validation Loss: 1.332217 	 time: 0.3
Validation loss decreased from 1.332532 to 1.332217. Model was saved
Epoch: 996 	Training Loss: 1.166845 	Validation Loss: 1.331894 	 time: 0.3
Validation loss decreased from 1.332217 to 1.331894. Model was saved
Epoch: 997 	Training Loss: 1.166807 	Validation Loss: 1.331532 	 time: 0.3
Validation loss decreased from 1.331894 to 1.331532. Model was saved
Epoch: 998 	Training Loss: 1.166766 	Validation Loss: 1.331171 	 time: 0.3
Validation loss decreased from 1.331532 to 1.331171. Model was saved
Epoch: 999 	Training Loss: 1.166735 	Validation Loss: 1.330939 	 time: 0.3
Validation loss decreased from 1.331171 to 1.330939. Model was saved
Epoch: 1000 	Training Loss: 1.166691 	Validation Loss: 1.330420 	 time: 0.3
Validation loss decreased from 1.330939 to 1.330420. Model was saved
