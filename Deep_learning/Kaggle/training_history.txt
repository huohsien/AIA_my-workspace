Epoch: 1 	Training Loss: 1.792462 	Validation Loss: 1.816469 	 time: 0.3
Validation loss decreased from inf to 1.816469. Model was saved
Epoch: 2 	Training Loss: 1.818102 	Validation Loss: 1.799411 	 time: 0.3
Validation loss decreased from 1.816469 to 1.799411. Model was saved
Epoch: 3 	Training Loss: 1.800439 	Validation Loss: 1.790233 	 time: 0.3
Validation loss decreased from 1.799411 to 1.790233. Model was saved
Epoch: 4 	Training Loss: 1.789447 	Validation Loss: 1.785720 	 time: 0.3
Validation loss decreased from 1.790233 to 1.785720. Model was saved
Epoch: 5 	Training Loss: 1.782279 	Validation Loss: 1.778085 	 time: 0.3
Validation loss decreased from 1.785720 to 1.778085. Model was saved
Epoch: 6 	Training Loss: 1.771058 	Validation Loss: 1.766386 	 time: 0.3
Validation loss decreased from 1.778085 to 1.766386. Model was saved
Epoch: 7 	Training Loss: 1.754448 	Validation Loss: 1.753926 	 time: 0.3
Validation loss decreased from 1.766386 to 1.753926. Model was saved
Epoch: 8 	Training Loss: 1.735886 	Validation Loss: 1.743498 	 time: 0.3
Validation loss decreased from 1.753926 to 1.743498. Model was saved
Epoch: 9 	Training Loss: 1.714581 	Validation Loss: 1.734428 	 time: 0.3
Validation loss decreased from 1.743498 to 1.734428. Model was saved
Epoch: 10 	Training Loss: 1.701312 	Validation Loss: 1.718195 	 time: 0.3
Validation loss decreased from 1.734428 to 1.718195. Model was saved
Epoch: 11 	Training Loss: 1.680649 	Validation Loss: 1.700996 	 time: 0.3
Validation loss decreased from 1.718195 to 1.700996. Model was saved
Epoch: 12 	Training Loss: 1.667625 	Validation Loss: 1.684519 	 time: 0.3
Validation loss decreased from 1.700996 to 1.684519. Model was saved
Epoch: 13 	Training Loss: 1.651575 	Validation Loss: 1.672153 	 time: 0.3
Validation loss decreased from 1.684519 to 1.672153. Model was saved
Epoch: 14 	Training Loss: 1.636743 	Validation Loss: 1.659400 	 time: 0.3
Validation loss decreased from 1.672153 to 1.659400. Model was saved
Epoch: 15 	Training Loss: 1.626029 	Validation Loss: 1.641842 	 time: 0.3
Validation loss decreased from 1.659400 to 1.641842. Model was saved
Epoch: 16 	Training Loss: 1.615676 	Validation Loss: 1.630798 	 time: 0.3
Validation loss decreased from 1.641842 to 1.630798. Model was saved
Epoch: 17 	Training Loss: 1.607622 	Validation Loss: 1.629342 	 time: 0.3
Validation loss decreased from 1.630798 to 1.629342. Model was saved
Epoch: 18 	Training Loss: 1.595417 	Validation Loss: 1.614326 	 time: 0.3
Validation loss decreased from 1.629342 to 1.614326. Model was saved
Epoch: 19 	Training Loss: 1.582890 	Validation Loss: 1.603369 	 time: 0.3
Validation loss decreased from 1.614326 to 1.603369. Model was saved
Epoch: 20 	Training Loss: 1.580143 	Validation Loss: 1.598126 	 time: 0.3
Validation loss decreased from 1.603369 to 1.598126. Model was saved
Epoch: 21 	Training Loss: 1.572648 	Validation Loss: 1.595509 	 time: 0.3
Validation loss decreased from 1.598126 to 1.595509. Model was saved
Epoch: 22 	Training Loss: 1.565619 	Validation Loss: 1.590143 	 time: 0.3
Validation loss decreased from 1.595509 to 1.590143. Model was saved
Epoch: 23 	Training Loss: 1.561976 	Validation Loss: 1.589057 	 time: 0.3
Validation loss decreased from 1.590143 to 1.589057. Model was saved
Epoch: 24 	Training Loss: 1.552127 	Validation Loss: 1.588976 	 time: 0.3
Validation loss decreased from 1.589057 to 1.588976. Model was saved
Epoch: 25 	Training Loss: 1.551901 	Validation Loss: 1.586385 	 time: 0.3
Validation loss decreased from 1.588976 to 1.586385. Model was saved
Epoch: 26 	Training Loss: 1.543592 	Validation Loss: 1.586961 	 time: 0.3
Epoch: 27 	Training Loss: 1.543540 	Validation Loss: 1.593230 	 time: 0.3
Epoch: 28 	Training Loss: 1.539855 	Validation Loss: 1.591153 	 time: 0.3
Epoch: 29 	Training Loss: 1.537625 	Validation Loss: 1.584553 	 time: 0.3
Validation loss decreased from 1.586385 to 1.584553. Model was saved
Epoch: 30 	Training Loss: 1.531676 	Validation Loss: 1.580465 	 time: 0.3
Validation loss decreased from 1.584553 to 1.580465. Model was saved
Epoch: 31 	Training Loss: 1.529644 	Validation Loss: 1.578223 	 time: 0.3
Validation loss decreased from 1.580465 to 1.578223. Model was saved
Epoch: 32 	Training Loss: 1.525306 	Validation Loss: 1.575697 	 time: 0.3
Validation loss decreased from 1.578223 to 1.575697. Model was saved
Epoch: 33 	Training Loss: 1.523041 	Validation Loss: 1.568257 	 time: 0.3
Validation loss decreased from 1.575697 to 1.568257. Model was saved
Epoch: 34 	Training Loss: 1.521048 	Validation Loss: 1.560469 	 time: 0.3
Validation loss decreased from 1.568257 to 1.560469. Model was saved
Epoch: 35 	Training Loss: 1.522056 	Validation Loss: 1.558341 	 time: 0.3
Validation loss decreased from 1.560469 to 1.558341. Model was saved
Epoch: 36 	Training Loss: 1.515197 	Validation Loss: 1.558128 	 time: 0.3
Validation loss decreased from 1.558341 to 1.558128. Model was saved
Epoch: 37 	Training Loss: 1.510347 	Validation Loss: 1.558674 	 time: 0.3
Epoch: 38 	Training Loss: 1.510813 	Validation Loss: 1.554712 	 time: 0.3
Validation loss decreased from 1.558128 to 1.554712. Model was saved
Epoch: 39 	Training Loss: 1.511549 	Validation Loss: 1.551611 	 time: 0.3
Validation loss decreased from 1.554712 to 1.551611. Model was saved
Epoch: 40 	Training Loss: 1.512961 	Validation Loss: 1.552943 	 time: 0.3
Epoch: 41 	Training Loss: 1.512472 	Validation Loss: 1.556570 	 time: 0.3
Epoch: 42 	Training Loss: 1.508651 	Validation Loss: 1.553696 	 time: 0.3
Epoch: 43 	Training Loss: 1.509096 	Validation Loss: 1.547621 	 time: 0.3
Validation loss decreased from 1.551611 to 1.547621. Model was saved
Epoch: 44 	Training Loss: 1.506523 	Validation Loss: 1.544938 	 time: 0.3
Validation loss decreased from 1.547621 to 1.544938. Model was saved
Epoch: 45 	Training Loss: 1.507164 	Validation Loss: 1.547946 	 time: 0.3
Epoch: 46 	Training Loss: 1.501325 	Validation Loss: 1.552397 	 time: 0.3
Epoch: 47 	Training Loss: 1.505444 	Validation Loss: 1.549841 	 time: 0.3
Epoch: 48 	Training Loss: 1.498938 	Validation Loss: 1.547737 	 time: 0.3
Epoch: 49 	Training Loss: 1.500207 	Validation Loss: 1.547651 	 time: 0.3
Epoch: 50 	Training Loss: 1.499602 	Validation Loss: 1.545290 	 time: 0.3
Epoch: 51 	Training Loss: 1.499919 	Validation Loss: 1.545459 	 time: 0.3
Epoch: 52 	Training Loss: 1.494803 	Validation Loss: 1.551551 	 time: 0.3
Epoch: 53 	Training Loss: 1.497356 	Validation Loss: 1.556477 	 time: 0.3
Epoch: 54 	Training Loss: 1.499298 	Validation Loss: 1.560159 	 time: 0.3
Epoch: 55 	Training Loss: 1.496090 	Validation Loss: 1.554096 	 time: 0.3
Epoch: 56 	Training Loss: 1.493580 	Validation Loss: 1.550390 	 time: 0.3
Epoch: 57 	Training Loss: 1.493836 	Validation Loss: 1.550654 	 time: 0.3
Epoch: 58 	Training Loss: 1.491562 	Validation Loss: 1.555424 	 time: 0.3
Epoch: 59 	Training Loss: 1.485967 	Validation Loss: 1.556906 	 time: 0.3
Epoch: 60 	Training Loss: 1.494532 	Validation Loss: 1.553597 	 time: 0.3
Epoch: 61 	Training Loss: 1.489434 	Validation Loss: 1.544028 	 time: 0.3
Validation loss decreased from 1.544938 to 1.544028. Model was saved
Epoch: 62 	Training Loss: 1.489470 	Validation Loss: 1.539034 	 time: 0.3
Validation loss decreased from 1.544028 to 1.539034. Model was saved
Epoch: 63 	Training Loss: 1.486965 	Validation Loss: 1.540028 	 time: 0.3
Epoch: 64 	Training Loss: 1.487742 	Validation Loss: 1.544129 	 time: 0.3
Epoch: 65 	Training Loss: 1.483365 	Validation Loss: 1.545430 	 time: 0.3
Epoch: 66 	Training Loss: 1.483536 	Validation Loss: 1.545423 	 time: 0.3
Epoch: 67 	Training Loss: 1.480780 	Validation Loss: 1.543172 	 time: 0.3
Epoch: 68 	Training Loss: 1.482198 	Validation Loss: 1.540320 	 time: 0.3
Epoch: 69 	Training Loss: 1.481968 	Validation Loss: 1.539236 	 time: 0.3
Epoch: 70 	Training Loss: 1.483961 	Validation Loss: 1.541669 	 time: 0.3
Epoch: 71 	Training Loss: 1.478810 	Validation Loss: 1.541366 	 time: 0.3
Epoch: 72 	Training Loss: 1.480145 	Validation Loss: 1.536833 	 time: 0.3
Validation loss decreased from 1.539034 to 1.536833. Model was saved
Epoch: 73 	Training Loss: 1.482208 	Validation Loss: 1.531223 	 time: 0.3
Validation loss decreased from 1.536833 to 1.531223. Model was saved
Epoch: 74 	Training Loss: 1.478500 	Validation Loss: 1.527611 	 time: 0.3
Validation loss decreased from 1.531223 to 1.527611. Model was saved
Epoch: 75 	Training Loss: 1.478483 	Validation Loss: 1.528461 	 time: 0.3
Epoch: 76 	Training Loss: 1.479959 	Validation Loss: 1.529637 	 time: 0.3
Epoch: 77 	Training Loss: 1.473143 	Validation Loss: 1.534751 	 time: 0.3
Epoch: 78 	Training Loss: 1.474749 	Validation Loss: 1.534090 	 time: 0.3
Epoch: 79 	Training Loss: 1.472136 	Validation Loss: 1.530093 	 time: 0.3
Epoch: 80 	Training Loss: 1.474413 	Validation Loss: 1.530602 	 time: 0.3
Epoch: 81 	Training Loss: 1.469248 	Validation Loss: 1.536272 	 time: 0.3
Epoch: 82 	Training Loss: 1.472026 	Validation Loss: 1.538138 	 time: 0.3
Epoch: 83 	Training Loss: 1.468741 	Validation Loss: 1.536537 	 time: 0.3
Epoch: 84 	Training Loss: 1.470667 	Validation Loss: 1.533932 	 time: 0.3
Epoch: 85 	Training Loss: 1.462965 	Validation Loss: 1.534884 	 time: 0.3
Epoch: 86 	Training Loss: 1.468243 	Validation Loss: 1.537870 	 time: 0.3
Epoch: 87 	Training Loss: 1.462434 	Validation Loss: 1.543019 	 time: 0.3
Epoch: 88 	Training Loss: 1.465377 	Validation Loss: 1.542911 	 time: 0.3
Epoch: 89 	Training Loss: 1.462852 	Validation Loss: 1.538265 	 time: 0.3
Epoch: 90 	Training Loss: 1.464610 	Validation Loss: 1.531643 	 time: 0.3
Epoch: 91 	Training Loss: 1.461736 	Validation Loss: 1.528940 	 time: 0.3
Epoch: 92 	Training Loss: 1.462501 	Validation Loss: 1.531914 	 time: 0.3
Epoch: 93 	Training Loss: 1.458454 	Validation Loss: 1.533828 	 time: 0.3
Epoch: 94 	Training Loss: 1.459649 	Validation Loss: 1.530748 	 time: 0.3
Epoch: 95 	Training Loss: 1.459298 	Validation Loss: 1.524679 	 time: 0.3
Validation loss decreased from 1.527611 to 1.524679. Model was saved
Epoch: 96 	Training Loss: 1.463235 	Validation Loss: 1.523652 	 time: 0.3
Validation loss decreased from 1.524679 to 1.523652. Model was saved
Epoch: 97 	Training Loss: 1.459800 	Validation Loss: 1.524576 	 time: 0.3
Epoch: 98 	Training Loss: 1.458946 	Validation Loss: 1.527088 	 time: 0.3
Epoch: 99 	Training Loss: 1.461504 	Validation Loss: 1.526602 	 time: 0.3
Epoch: 100 	Training Loss: 1.462583 	Validation Loss: 1.525153 	 time: 0.3
Epoch: 101 	Training Loss: 1.460563 	Validation Loss: 1.524070 	 time: 0.3
Epoch: 102 	Training Loss: 1.459592 	Validation Loss: 1.526123 	 time: 0.3
Epoch: 103 	Training Loss: 1.457541 	Validation Loss: 1.524517 	 time: 0.3
Epoch: 104 	Training Loss: 1.459491 	Validation Loss: 1.519032 	 time: 0.3
Validation loss decreased from 1.523652 to 1.519032. Model was saved
Epoch: 105 	Training Loss: 1.455437 	Validation Loss: 1.513416 	 time: 0.3
Validation loss decreased from 1.519032 to 1.513416. Model was saved
Epoch: 106 	Training Loss: 1.454831 	Validation Loss: 1.514059 	 time: 0.3
Epoch: 107 	Training Loss: 1.453102 	Validation Loss: 1.517590 	 time: 0.3
Epoch: 108 	Training Loss: 1.452504 	Validation Loss: 1.518013 	 time: 0.3
Epoch: 109 	Training Loss: 1.451521 	Validation Loss: 1.514958 	 time: 0.3
Epoch: 110 	Training Loss: 1.452558 	Validation Loss: 1.511984 	 time: 0.3
Validation loss decreased from 1.513416 to 1.511984. Model was saved
Epoch: 111 	Training Loss: 1.457302 	Validation Loss: 1.513191 	 time: 0.3
Epoch: 112 	Training Loss: 1.455606 	Validation Loss: 1.515598 	 time: 0.3
Epoch: 113 	Training Loss: 1.452026 	Validation Loss: 1.518657 	 time: 0.3
Epoch: 114 	Training Loss: 1.449750 	Validation Loss: 1.518757 	 time: 0.3
Epoch: 115 	Training Loss: 1.449002 	Validation Loss: 1.515966 	 time: 0.3
Epoch: 116 	Training Loss: 1.449978 	Validation Loss: 1.514301 	 time: 0.3
Epoch: 117 	Training Loss: 1.445166 	Validation Loss: 1.510181 	 time: 0.3
Validation loss decreased from 1.511984 to 1.510181. Model was saved
Epoch: 118 	Training Loss: 1.450463 	Validation Loss: 1.509637 	 time: 0.3
Validation loss decreased from 1.510181 to 1.509637. Model was saved
Epoch: 119 	Training Loss: 1.442717 	Validation Loss: 1.510879 	 time: 0.3
Epoch: 120 	Training Loss: 1.449395 	Validation Loss: 1.509929 	 time: 0.3
Epoch: 121 	Training Loss: 1.446605 	Validation Loss: 1.507615 	 time: 0.3
Validation loss decreased from 1.509637 to 1.507615. Model was saved
Epoch: 122 	Training Loss: 1.444606 	Validation Loss: 1.508819 	 time: 0.3
Epoch: 123 	Training Loss: 1.448192 	Validation Loss: 1.510760 	 time: 0.3
Epoch: 124 	Training Loss: 1.446023 	Validation Loss: 1.511544 	 time: 0.3
Epoch: 125 	Training Loss: 1.444457 	Validation Loss: 1.509674 	 time: 0.3
Epoch: 126 	Training Loss: 1.444016 	Validation Loss: 1.506123 	 time: 0.3
Validation loss decreased from 1.507615 to 1.506123. Model was saved
Epoch: 127 	Training Loss: 1.445777 	Validation Loss: 1.505294 	 time: 0.3
Validation loss decreased from 1.506123 to 1.505294. Model was saved
Epoch: 128 	Training Loss: 1.446481 	Validation Loss: 1.506770 	 time: 0.3
Epoch: 129 	Training Loss: 1.443529 	Validation Loss: 1.503643 	 time: 0.3
Validation loss decreased from 1.505294 to 1.503643. Model was saved
Epoch: 130 	Training Loss: 1.440746 	Validation Loss: 1.498075 	 time: 0.3
Validation loss decreased from 1.503643 to 1.498075. Model was saved
Epoch: 131 	Training Loss: 1.443308 	Validation Loss: 1.493231 	 time: 0.3
Validation loss decreased from 1.498075 to 1.493231. Model was saved
Epoch: 132 	Training Loss: 1.439136 	Validation Loss: 1.489529 	 time: 0.3
Validation loss decreased from 1.493231 to 1.489529. Model was saved
Epoch: 133 	Training Loss: 1.441291 	Validation Loss: 1.490114 	 time: 0.3
Epoch: 134 	Training Loss: 1.439635 	Validation Loss: 1.492396 	 time: 0.3
Epoch: 135 	Training Loss: 1.439513 	Validation Loss: 1.497809 	 time: 0.3
Epoch: 136 	Training Loss: 1.438439 	Validation Loss: 1.500757 	 time: 0.3
Epoch: 137 	Training Loss: 1.435262 	Validation Loss: 1.499547 	 time: 0.3
Epoch: 138 	Training Loss: 1.438527 	Validation Loss: 1.499278 	 time: 0.3
Epoch: 139 	Training Loss: 1.436772 	Validation Loss: 1.499566 	 time: 0.3
Epoch: 140 	Training Loss: 1.436099 	Validation Loss: 1.499830 	 time: 0.3
Epoch: 141 	Training Loss: 1.438722 	Validation Loss: 1.497396 	 time: 0.3
Epoch: 142 	Training Loss: 1.437978 	Validation Loss: 1.495655 	 time: 0.3
Epoch: 143 	Training Loss: 1.443250 	Validation Loss: 1.494377 	 time: 0.3
Epoch: 144 	Training Loss: 1.437004 	Validation Loss: 1.494750 	 time: 0.3
Epoch: 145 	Training Loss: 1.436182 	Validation Loss: 1.496771 	 time: 0.3
Epoch: 146 	Training Loss: 1.434856 	Validation Loss: 1.498747 	 time: 0.3
Epoch: 147 	Training Loss: 1.431877 	Validation Loss: 1.498635 	 time: 0.3
Epoch: 148 	Training Loss: 1.433775 	Validation Loss: 1.496612 	 time: 0.3
Epoch: 149 	Training Loss: 1.428932 	Validation Loss: 1.491587 	 time: 0.3
Epoch: 150 	Training Loss: 1.430507 	Validation Loss: 1.491668 	 time: 0.3
Epoch: 151 	Training Loss: 1.430272 	Validation Loss: 1.492188 	 time: 0.3
Epoch: 152 	Training Loss: 1.432040 	Validation Loss: 1.492800 	 time: 0.3
Epoch: 153 	Training Loss: 1.431200 	Validation Loss: 1.487224 	 time: 0.3
Validation loss decreased from 1.489529 to 1.487224. Model was saved
Epoch: 154 	Training Loss: 1.425564 	Validation Loss: 1.480692 	 time: 0.3
Validation loss decreased from 1.487224 to 1.480692. Model was saved
Epoch: 155 	Training Loss: 1.424981 	Validation Loss: 1.476666 	 time: 0.3
Validation loss decreased from 1.480692 to 1.476666. Model was saved
Epoch: 156 	Training Loss: 1.432925 	Validation Loss: 1.479701 	 time: 0.3
Epoch: 157 	Training Loss: 1.423165 	Validation Loss: 1.484533 	 time: 0.3
Epoch: 158 	Training Loss: 1.426822 	Validation Loss: 1.482517 	 time: 0.3
Epoch: 159 	Training Loss: 1.424020 	Validation Loss: 1.481562 	 time: 0.3
Epoch: 160 	Training Loss: 1.427852 	Validation Loss: 1.481849 	 time: 0.3
Epoch: 161 	Training Loss: 1.428577 	Validation Loss: 1.484174 	 time: 0.3
Epoch: 162 	Training Loss: 1.428515 	Validation Loss: 1.485037 	 time: 0.3
Epoch: 163 	Training Loss: 1.426039 	Validation Loss: 1.481216 	 time: 0.3
Epoch: 164 	Training Loss: 1.428914 	Validation Loss: 1.478295 	 time: 0.3
Epoch: 165 	Training Loss: 1.425225 	Validation Loss: 1.478242 	 time: 0.3
Epoch: 166 	Training Loss: 1.424215 	Validation Loss: 1.480081 	 time: 0.3
Epoch: 167 	Training Loss: 1.425737 	Validation Loss: 1.484862 	 time: 0.3
Epoch: 168 	Training Loss: 1.426310 	Validation Loss: 1.487477 	 time: 0.3
Epoch: 169 	Training Loss: 1.425706 	Validation Loss: 1.486790 	 time: 0.3
Epoch: 170 	Training Loss: 1.423607 	Validation Loss: 1.484831 	 time: 0.3
Epoch: 171 	Training Loss: 1.424261 	Validation Loss: 1.480217 	 time: 0.3
Epoch: 172 	Training Loss: 1.419591 	Validation Loss: 1.479406 	 time: 0.3
Epoch: 173 	Training Loss: 1.423934 	Validation Loss: 1.479018 	 time: 0.3
Epoch: 174 	Training Loss: 1.422766 	Validation Loss: 1.476929 	 time: 0.3
Epoch: 175 	Training Loss: 1.418170 	Validation Loss: 1.472829 	 time: 0.3
Validation loss decreased from 1.476666 to 1.472829. Model was saved
Epoch: 176 	Training Loss: 1.419438 	Validation Loss: 1.472520 	 time: 0.3
Validation loss decreased from 1.472829 to 1.472520. Model was saved
Epoch: 177 	Training Loss: 1.419349 	Validation Loss: 1.472430 	 time: 0.3
Validation loss decreased from 1.472520 to 1.472430. Model was saved
Epoch: 178 	Training Loss: 1.417145 	Validation Loss: 1.474823 	 time: 0.3
Epoch: 179 	Training Loss: 1.421435 	Validation Loss: 1.476042 	 time: 0.3
Epoch: 180 	Training Loss: 1.423569 	Validation Loss: 1.478299 	 time: 0.3
Epoch: 181 	Training Loss: 1.418569 	Validation Loss: 1.482203 	 time: 0.3
Epoch: 182 	Training Loss: 1.423297 	Validation Loss: 1.484250 	 time: 0.3
Epoch: 183 	Training Loss: 1.425421 	Validation Loss: 1.486625 	 time: 0.3
Epoch: 184 	Training Loss: 1.420749 	Validation Loss: 1.483279 	 time: 0.3
Epoch: 185 	Training Loss: 1.416965 	Validation Loss: 1.478093 	 time: 0.3
Epoch: 186 	Training Loss: 1.417505 	Validation Loss: 1.470081 	 time: 0.3
Validation loss decreased from 1.472430 to 1.470081. Model was saved
Epoch: 187 	Training Loss: 1.421057 	Validation Loss: 1.463085 	 time: 0.3
Validation loss decreased from 1.470081 to 1.463085. Model was saved
Epoch: 188 	Training Loss: 1.416572 	Validation Loss: 1.460975 	 time: 0.3
Validation loss decreased from 1.463085 to 1.460975. Model was saved
Epoch: 189 	Training Loss: 1.419174 	Validation Loss: 1.463230 	 time: 0.3
Epoch: 190 	Training Loss: 1.420221 	Validation Loss: 1.462108 	 time: 0.3
Epoch: 191 	Training Loss: 1.413844 	Validation Loss: 1.457314 	 time: 0.3
Validation loss decreased from 1.460975 to 1.457314. Model was saved
Epoch: 192 	Training Loss: 1.419707 	Validation Loss: 1.453638 	 time: 0.3
Validation loss decreased from 1.457314 to 1.453638. Model was saved
Epoch: 193 	Training Loss: 1.416807 	Validation Loss: 1.456397 	 time: 0.3
Epoch: 194 	Training Loss: 1.413968 	Validation Loss: 1.461705 	 time: 0.3
Epoch: 195 	Training Loss: 1.416054 	Validation Loss: 1.468517 	 time: 0.3
Epoch: 196 	Training Loss: 1.417331 	Validation Loss: 1.473600 	 time: 0.3
Epoch: 197 	Training Loss: 1.419449 	Validation Loss: 1.472668 	 time: 0.3
Epoch: 198 	Training Loss: 1.416348 	Validation Loss: 1.469230 	 time: 0.3
Epoch: 199 	Training Loss: 1.414806 	Validation Loss: 1.465672 	 time: 0.3
Epoch: 200 	Training Loss: 1.421319 	Validation Loss: 1.467211 	 time: 0.3
Epoch: 201 	Training Loss: 1.414587 	Validation Loss: 1.471508 	 time: 0.3
Epoch: 202 	Training Loss: 1.416784 	Validation Loss: 1.474837 	 time: 0.3
Epoch: 203 	Training Loss: 1.415181 	Validation Loss: 1.469089 	 time: 0.3
Epoch: 204 	Training Loss: 1.414643 	Validation Loss: 1.461674 	 time: 0.3
Epoch: 205 	Training Loss: 1.411690 	Validation Loss: 1.457543 	 time: 0.3
Epoch: 206 	Training Loss: 1.416795 	Validation Loss: 1.457980 	 time: 0.3
Epoch: 207 	Training Loss: 1.417289 	Validation Loss: 1.462341 	 time: 0.3
Epoch: 208 	Training Loss: 1.416722 	Validation Loss: 1.464541 	 time: 0.3
Epoch: 209 	Training Loss: 1.410908 	Validation Loss: 1.464932 	 time: 0.3
Epoch: 210 	Training Loss: 1.412481 	Validation Loss: 1.461107 	 time: 0.3
Epoch: 211 	Training Loss: 1.413822 	Validation Loss: 1.460610 	 time: 0.3
Epoch: 212 	Training Loss: 1.410361 	Validation Loss: 1.457598 	 time: 0.3
Epoch: 213 	Training Loss: 1.410030 	Validation Loss: 1.453199 	 time: 0.3
Validation loss decreased from 1.453638 to 1.453199. Model was saved
Epoch: 214 	Training Loss: 1.412400 	Validation Loss: 1.451710 	 time: 0.3
Validation loss decreased from 1.453199 to 1.451710. Model was saved
Epoch: 215 	Training Loss: 1.414539 	Validation Loss: 1.454305 	 time: 0.3
Epoch: 216 	Training Loss: 1.408941 	Validation Loss: 1.458664 	 time: 0.3
Epoch: 217 	Training Loss: 1.417784 	Validation Loss: 1.462788 	 time: 0.3
Epoch: 218 	Training Loss: 1.409862 	Validation Loss: 1.465620 	 time: 0.3
Epoch: 219 	Training Loss: 1.411942 	Validation Loss: 1.463918 	 time: 0.3
Epoch: 220 	Training Loss: 1.414154 	Validation Loss: 1.463658 	 time: 0.3
Epoch: 221 	Training Loss: 1.409495 	Validation Loss: 1.464072 	 time: 0.3
Epoch: 222 	Training Loss: 1.411033 	Validation Loss: 1.465349 	 time: 0.3
Epoch: 223 	Training Loss: 1.409089 	Validation Loss: 1.468757 	 time: 0.3
Epoch: 224 	Training Loss: 1.411648 	Validation Loss: 1.468975 	 time: 0.3
Epoch: 225 	Training Loss: 1.403543 	Validation Loss: 1.466150 	 time: 0.3
Epoch: 226 	Training Loss: 1.409375 	Validation Loss: 1.465848 	 time: 0.3
Epoch: 227 	Training Loss: 1.409512 	Validation Loss: 1.466639 	 time: 0.3
Epoch: 228 	Training Loss: 1.411374 	Validation Loss: 1.471041 	 time: 0.3
Epoch: 229 	Training Loss: 1.411256 	Validation Loss: 1.475093 	 time: 0.3
Epoch: 230 	Training Loss: 1.410758 	Validation Loss: 1.475090 	 time: 0.3
Epoch: 231 	Training Loss: 1.409986 	Validation Loss: 1.476102 	 time: 0.3
Epoch: 232 	Training Loss: 1.410198 	Validation Loss: 1.478438 	 time: 0.3
Epoch: 233 	Training Loss: 1.411354 	Validation Loss: 1.479574 	 time: 0.3
Epoch: 234 	Training Loss: 1.407796 	Validation Loss: 1.479530 	 time: 0.3
Epoch: 235 	Training Loss: 1.404850 	Validation Loss: 1.475688 	 time: 0.3
Epoch: 236 	Training Loss: 1.406601 	Validation Loss: 1.472964 	 time: 0.3
Epoch: 237 	Training Loss: 1.407072 	Validation Loss: 1.472957 	 time: 0.3
Epoch: 238 	Training Loss: 1.403040 	Validation Loss: 1.472182 	 time: 0.3
Epoch: 239 	Training Loss: 1.407959 	Validation Loss: 1.470871 	 time: 0.3
Epoch: 240 	Training Loss: 1.410079 	Validation Loss: 1.469772 	 time: 0.3
Epoch: 241 	Training Loss: 1.407146 	Validation Loss: 1.466026 	 time: 0.3
Epoch: 242 	Training Loss: 1.408864 	Validation Loss: 1.465259 	 time: 0.3
Epoch: 243 	Training Loss: 1.415964 	Validation Loss: 1.467754 	 time: 0.3
Epoch: 244 	Training Loss: 1.410438 	Validation Loss: 1.466111 	 time: 0.3
Epoch: 245 	Training Loss: 1.413033 	Validation Loss: 1.464542 	 time: 0.3
Epoch: 246 	Training Loss: 1.410595 	Validation Loss: 1.465878 	 time: 0.3
Epoch: 247 	Training Loss: 1.407147 	Validation Loss: 1.467933 	 time: 0.3
Epoch: 248 	Training Loss: 1.407733 	Validation Loss: 1.469146 	 time: 0.3
Epoch: 249 	Training Loss: 1.405117 	Validation Loss: 1.470125 	 time: 0.3
Epoch: 250 	Training Loss: 1.411698 	Validation Loss: 1.467770 	 time: 0.3
Epoch: 251 	Training Loss: 1.411620 	Validation Loss: 1.461872 	 time: 0.3
Epoch: 252 	Training Loss: 1.402706 	Validation Loss: 1.459759 	 time: 0.3
Epoch: 253 	Training Loss: 1.406399 	Validation Loss: 1.463707 	 time: 0.3
Epoch: 254 	Training Loss: 1.408934 	Validation Loss: 1.469758 	 time: 0.3
Epoch: 255 	Training Loss: 1.410707 	Validation Loss: 1.474437 	 time: 0.3
Epoch: 256 	Training Loss: 1.407014 	Validation Loss: 1.479602 	 time: 0.3
Epoch: 257 	Training Loss: 1.405933 	Validation Loss: 1.484067 	 time: 0.3
Epoch: 258 	Training Loss: 1.404348 	Validation Loss: 1.484397 	 time: 0.3
Epoch: 259 	Training Loss: 1.408236 	Validation Loss: 1.481406 	 time: 0.3
Epoch: 260 	Training Loss: 1.403065 	Validation Loss: 1.476126 	 time: 0.3
Epoch: 261 	Training Loss: 1.404033 	Validation Loss: 1.473621 	 time: 0.3
Epoch: 262 	Training Loss: 1.407122 	Validation Loss: 1.473687 	 time: 0.3
Epoch: 263 	Training Loss: 1.410426 	Validation Loss: 1.471279 	 time: 0.3
Epoch: 264 	Training Loss: 1.402672 	Validation Loss: 1.468225 	 time: 0.3
Epoch: 265 	Training Loss: 1.403365 	Validation Loss: 1.464622 	 time: 0.3
Epoch: 266 	Training Loss: 1.402850 	Validation Loss: 1.462183 	 time: 0.3
Epoch: 267 	Training Loss: 1.403116 	Validation Loss: 1.463201 	 time: 0.3
Epoch: 268 	Training Loss: 1.402610 	Validation Loss: 1.465567 	 time: 0.3
Epoch: 269 	Training Loss: 1.404720 	Validation Loss: 1.466416 	 time: 0.3
Epoch: 270 	Training Loss: 1.402207 	Validation Loss: 1.464970 	 time: 0.3
Epoch: 271 	Training Loss: 1.402433 	Validation Loss: 1.462970 	 time: 0.3
Epoch: 272 	Training Loss: 1.402322 	Validation Loss: 1.462654 	 time: 0.3
Epoch: 273 	Training Loss: 1.404594 	Validation Loss: 1.462299 	 time: 0.3
Epoch: 274 	Training Loss: 1.399287 	Validation Loss: 1.461304 	 time: 0.3
Epoch: 275 	Training Loss: 1.401509 	Validation Loss: 1.460640 	 time: 0.3
Epoch: 276 	Training Loss: 1.404013 	Validation Loss: 1.459091 	 time: 0.3
Epoch: 277 	Training Loss: 1.407625 	Validation Loss: 1.457263 	 time: 0.3
Epoch: 278 	Training Loss: 1.401753 	Validation Loss: 1.456649 	 time: 0.3
Epoch: 279 	Training Loss: 1.400307 	Validation Loss: 1.454720 	 time: 0.3
Epoch: 280 	Training Loss: 1.402468 	Validation Loss: 1.452100 	 time: 0.3
Epoch: 281 	Training Loss: 1.404156 	Validation Loss: 1.453011 	 time: 0.3
Epoch: 282 	Training Loss: 1.401986 	Validation Loss: 1.452333 	 time: 0.3
Epoch: 283 	Training Loss: 1.403576 	Validation Loss: 1.450721 	 time: 0.3
Validation loss decreased from 1.451710 to 1.450721. Model was saved
Epoch: 284 	Training Loss: 1.405804 	Validation Loss: 1.450072 	 time: 0.3
Validation loss decreased from 1.450721 to 1.450072. Model was saved
Epoch: 285 	Training Loss: 1.402094 	Validation Loss: 1.449997 	 time: 0.3
Validation loss decreased from 1.450072 to 1.449997. Model was saved
Epoch: 286 	Training Loss: 1.401537 	Validation Loss: 1.449270 	 time: 0.3
Validation loss decreased from 1.449997 to 1.449270. Model was saved
Epoch: 287 	Training Loss: 1.404444 	Validation Loss: 1.447554 	 time: 0.3
Validation loss decreased from 1.449270 to 1.447554. Model was saved
Epoch: 288 	Training Loss: 1.403102 	Validation Loss: 1.447997 	 time: 0.3
Epoch: 289 	Training Loss: 1.405147 	Validation Loss: 1.449018 	 time: 0.3
Epoch: 290 	Training Loss: 1.402997 	Validation Loss: 1.451058 	 time: 0.3
Epoch: 291 	Training Loss: 1.401906 	Validation Loss: 1.453393 	 time: 0.3
Epoch: 292 	Training Loss: 1.403060 	Validation Loss: 1.454725 	 time: 0.3
Epoch: 293 	Training Loss: 1.400083 	Validation Loss: 1.455303 	 time: 0.3
Epoch: 294 	Training Loss: 1.402420 	Validation Loss: 1.454572 	 time: 0.3
Epoch: 295 	Training Loss: 1.403884 	Validation Loss: 1.454807 	 time: 0.3
Epoch: 296 	Training Loss: 1.404941 	Validation Loss: 1.457613 	 time: 0.3
Epoch: 297 	Training Loss: 1.402364 	Validation Loss: 1.460795 	 time: 0.3
Epoch: 298 	Training Loss: 1.400703 	Validation Loss: 1.463561 	 time: 0.3
Epoch: 299 	Training Loss: 1.400600 	Validation Loss: 1.465120 	 time: 0.3
Epoch: 300 	Training Loss: 1.402598 	Validation Loss: 1.466054 	 time: 0.3
Epoch: 301 	Training Loss: 1.402485 	Validation Loss: 1.465842 	 time: 0.3
Epoch: 302 	Training Loss: 1.395025 	Validation Loss: 1.465173 	 time: 0.3
Epoch: 303 	Training Loss: 1.398625 	Validation Loss: 1.466633 	 time: 0.3
Epoch: 304 	Training Loss: 1.398617 	Validation Loss: 1.469655 	 time: 0.3
Epoch: 305 	Training Loss: 1.401925 	Validation Loss: 1.469879 	 time: 0.3
Epoch: 306 	Training Loss: 1.398219 	Validation Loss: 1.465732 	 time: 0.3
Epoch: 307 	Training Loss: 1.399604 	Validation Loss: 1.460982 	 time: 0.3
Epoch: 308 	Training Loss: 1.397867 	Validation Loss: 1.457752 	 time: 0.3
Epoch: 309 	Training Loss: 1.398069 	Validation Loss: 1.454251 	 time: 0.3
Epoch: 310 	Training Loss: 1.403124 	Validation Loss: 1.453053 	 time: 0.3
Epoch: 311 	Training Loss: 1.398856 	Validation Loss: 1.453915 	 time: 0.3
Epoch: 312 	Training Loss: 1.394367 	Validation Loss: 1.455235 	 time: 0.3
Epoch: 313 	Training Loss: 1.402588 	Validation Loss: 1.454428 	 time: 0.3
Epoch: 314 	Training Loss: 1.396527 	Validation Loss: 1.453806 	 time: 0.3
Epoch: 315 	Training Loss: 1.399126 	Validation Loss: 1.452185 	 time: 0.3
Epoch: 316 	Training Loss: 1.399007 	Validation Loss: 1.451312 	 time: 0.3
Epoch: 317 	Training Loss: 1.391609 	Validation Loss: 1.450279 	 time: 0.3
Epoch: 318 	Training Loss: 1.399197 	Validation Loss: 1.449107 	 time: 0.3
Epoch: 319 	Training Loss: 1.397190 	Validation Loss: 1.448710 	 time: 0.3
Epoch: 320 	Training Loss: 1.397931 	Validation Loss: 1.447960 	 time: 0.3
Epoch: 321 	Training Loss: 1.394509 	Validation Loss: 1.446829 	 time: 0.3
Validation loss decreased from 1.447554 to 1.446829. Model was saved
Epoch: 322 	Training Loss: 1.388899 	Validation Loss: 1.444743 	 time: 0.3
Validation loss decreased from 1.446829 to 1.444743. Model was saved
Epoch: 323 	Training Loss: 1.391823 	Validation Loss: 1.442434 	 time: 0.3
Validation loss decreased from 1.444743 to 1.442434. Model was saved
Epoch: 324 	Training Loss: 1.389018 	Validation Loss: 1.440993 	 time: 0.3
Validation loss decreased from 1.442434 to 1.440993. Model was saved
Epoch: 325 	Training Loss: 1.392935 	Validation Loss: 1.441025 	 time: 0.3
Epoch: 326 	Training Loss: 1.390203 	Validation Loss: 1.442300 	 time: 0.3
Epoch: 327 	Training Loss: 1.395900 	Validation Loss: 1.443617 	 time: 0.3
Epoch: 328 	Training Loss: 1.392430 	Validation Loss: 1.446069 	 time: 0.3
Epoch: 329 	Training Loss: 1.396966 	Validation Loss: 1.445622 	 time: 0.3
Epoch: 330 	Training Loss: 1.393403 	Validation Loss: 1.443246 	 time: 0.3
Epoch: 331 	Training Loss: 1.395285 	Validation Loss: 1.441777 	 time: 0.3
Epoch: 332 	Training Loss: 1.393818 	Validation Loss: 1.440743 	 time: 0.3
Validation loss decreased from 1.440993 to 1.440743. Model was saved
Epoch: 333 	Training Loss: 1.391298 	Validation Loss: 1.437750 	 time: 0.3
Validation loss decreased from 1.440743 to 1.437750. Model was saved
Epoch: 334 	Training Loss: 1.395815 	Validation Loss: 1.435207 	 time: 0.3
Validation loss decreased from 1.437750 to 1.435207. Model was saved
Epoch: 335 	Training Loss: 1.386220 	Validation Loss: 1.435533 	 time: 0.3
Epoch: 336 	Training Loss: 1.392562 	Validation Loss: 1.438072 	 time: 0.3
Epoch: 337 	Training Loss: 1.389864 	Validation Loss: 1.441402 	 time: 0.3
Epoch: 338 	Training Loss: 1.394289 	Validation Loss: 1.443776 	 time: 0.3
Epoch: 339 	Training Loss: 1.392867 	Validation Loss: 1.443001 	 time: 0.3
Epoch: 340 	Training Loss: 1.386774 	Validation Loss: 1.438609 	 time: 0.3
Epoch: 341 	Training Loss: 1.396304 	Validation Loss: 1.434905 	 time: 0.3
Validation loss decreased from 1.435207 to 1.434905. Model was saved
Epoch: 342 	Training Loss: 1.390628 	Validation Loss: 1.435696 	 time: 0.3
Epoch: 343 	Training Loss: 1.391126 	Validation Loss: 1.437949 	 time: 0.3
Epoch: 344 	Training Loss: 1.389536 	Validation Loss: 1.441525 	 time: 0.3
Epoch: 345 	Training Loss: 1.391269 	Validation Loss: 1.443185 	 time: 0.3
Epoch: 346 	Training Loss: 1.383749 	Validation Loss: 1.443634 	 time: 0.3
Epoch: 347 	Training Loss: 1.391682 	Validation Loss: 1.441637 	 time: 0.3
Epoch: 348 	Training Loss: 1.390648 	Validation Loss: 1.439125 	 time: 0.3
Epoch: 349 	Training Loss: 1.392639 	Validation Loss: 1.440542 	 time: 0.3
Epoch: 350 	Training Loss: 1.390254 	Validation Loss: 1.443780 	 time: 0.3
Epoch: 351 	Training Loss: 1.390779 	Validation Loss: 1.448119 	 time: 0.3
Epoch: 352 	Training Loss: 1.385346 	Validation Loss: 1.449262 	 time: 0.3
Epoch: 353 	Training Loss: 1.388350 	Validation Loss: 1.445865 	 time: 0.3
Epoch: 354 	Training Loss: 1.391006 	Validation Loss: 1.443127 	 time: 0.3
Epoch: 355 	Training Loss: 1.386493 	Validation Loss: 1.439306 	 time: 0.3
Epoch: 356 	Training Loss: 1.390828 	Validation Loss: 1.436645 	 time: 0.3
Epoch: 357 	Training Loss: 1.387563 	Validation Loss: 1.436312 	 time: 0.3
Epoch: 358 	Training Loss: 1.388263 	Validation Loss: 1.438463 	 time: 0.3
Epoch: 359 	Training Loss: 1.387260 	Validation Loss: 1.440405 	 time: 0.3
Epoch: 360 	Training Loss: 1.391073 	Validation Loss: 1.441933 	 time: 0.3
Epoch: 361 	Training Loss: 1.391259 	Validation Loss: 1.439992 	 time: 0.3
Epoch: 362 	Training Loss: 1.386463 	Validation Loss: 1.436685 	 time: 0.3
Epoch: 363 	Training Loss: 1.393156 	Validation Loss: 1.435793 	 time: 0.3
Epoch: 364 	Training Loss: 1.393370 	Validation Loss: 1.436209 	 time: 0.3
Epoch: 365 	Training Loss: 1.385311 	Validation Loss: 1.438472 	 time: 0.3
Epoch: 366 	Training Loss: 1.392202 	Validation Loss: 1.441587 	 time: 0.3
Epoch: 367 	Training Loss: 1.393342 	Validation Loss: 1.443122 	 time: 0.3
Epoch: 368 	Training Loss: 1.391805 	Validation Loss: 1.440718 	 time: 0.3
Epoch: 369 	Training Loss: 1.386959 	Validation Loss: 1.435263 	 time: 0.3
Epoch: 370 	Training Loss: 1.388594 	Validation Loss: 1.432120 	 time: 0.3
Validation loss decreased from 1.434905 to 1.432120. Model was saved
Epoch: 371 	Training Loss: 1.391586 	Validation Loss: 1.432991 	 time: 0.3
Epoch: 372 	Training Loss: 1.394272 	Validation Loss: 1.435143 	 time: 0.3
Epoch: 373 	Training Loss: 1.386018 	Validation Loss: 1.436792 	 time: 0.3
Epoch: 374 	Training Loss: 1.390985 	Validation Loss: 1.438408 	 time: 0.3
Epoch: 375 	Training Loss: 1.387133 	Validation Loss: 1.440379 	 time: 0.3
Epoch: 376 	Training Loss: 1.390301 	Validation Loss: 1.441943 	 time: 0.3
Epoch: 377 	Training Loss: 1.387686 	Validation Loss: 1.443897 	 time: 0.3
Epoch: 378 	Training Loss: 1.387386 	Validation Loss: 1.444645 	 time: 0.3
Epoch: 379 	Training Loss: 1.388871 	Validation Loss: 1.446241 	 time: 0.3
Epoch: 380 	Training Loss: 1.386165 	Validation Loss: 1.447800 	 time: 0.3
Epoch: 381 	Training Loss: 1.390034 	Validation Loss: 1.449539 	 time: 0.3
Epoch: 382 	Training Loss: 1.388426 	Validation Loss: 1.451487 	 time: 0.3
Epoch: 383 	Training Loss: 1.388597 	Validation Loss: 1.454087 	 time: 0.3
Epoch: 384 	Training Loss: 1.384356 	Validation Loss: 1.454681 	 time: 0.3
Epoch: 385 	Training Loss: 1.382662 	Validation Loss: 1.452639 	 time: 0.3
Epoch: 386 	Training Loss: 1.385454 	Validation Loss: 1.449986 	 time: 0.3
Epoch: 387 	Training Loss: 1.388470 	Validation Loss: 1.447815 	 time: 0.3
Epoch: 388 	Training Loss: 1.387783 	Validation Loss: 1.447323 	 time: 0.3
Epoch: 389 	Training Loss: 1.383211 	Validation Loss: 1.448525 	 time: 0.3
Epoch: 390 	Training Loss: 1.392478 	Validation Loss: 1.450784 	 time: 0.3
Epoch: 391 	Training Loss: 1.384782 	Validation Loss: 1.449528 	 time: 0.3
Epoch: 392 	Training Loss: 1.389011 	Validation Loss: 1.447003 	 time: 0.3
Epoch: 393 	Training Loss: 1.387518 	Validation Loss: 1.444675 	 time: 0.3
Epoch: 394 	Training Loss: 1.387167 	Validation Loss: 1.444117 	 time: 0.3
Epoch: 395 	Training Loss: 1.384777 	Validation Loss: 1.444674 	 time: 0.3
Epoch: 396 	Training Loss: 1.387512 	Validation Loss: 1.444277 	 time: 0.3
Epoch: 397 	Training Loss: 1.385900 	Validation Loss: 1.443398 	 time: 0.3
Epoch: 398 	Training Loss: 1.379532 	Validation Loss: 1.443139 	 time: 0.3
Epoch: 399 	Training Loss: 1.389346 	Validation Loss: 1.442579 	 time: 0.3
Epoch: 400 	Training Loss: 1.388275 	Validation Loss: 1.442494 	 time: 0.3
Epoch: 401 	Training Loss: 1.389630 	Validation Loss: 1.442670 	 time: 0.3
Epoch: 402 	Training Loss: 1.384742 	Validation Loss: 1.443664 	 time: 0.3
Epoch: 403 	Training Loss: 1.384560 	Validation Loss: 1.442121 	 time: 0.3
Epoch: 404 	Training Loss: 1.386467 	Validation Loss: 1.439838 	 time: 0.3
Epoch: 405 	Training Loss: 1.385791 	Validation Loss: 1.438425 	 time: 0.3
Epoch: 406 	Training Loss: 1.389720 	Validation Loss: 1.438959 	 time: 0.3
Epoch: 407 	Training Loss: 1.385222 	Validation Loss: 1.441980 	 time: 0.3
Epoch: 408 	Training Loss: 1.387634 	Validation Loss: 1.445203 	 time: 0.3
Epoch: 409 	Training Loss: 1.389975 	Validation Loss: 1.447583 	 time: 0.3
Epoch: 410 	Training Loss: 1.381767 	Validation Loss: 1.447330 	 time: 0.3
Epoch: 411 	Training Loss: 1.379134 	Validation Loss: 1.444475 	 time: 0.3
Epoch: 412 	Training Loss: 1.384941 	Validation Loss: 1.440357 	 time: 0.3
Epoch: 413 	Training Loss: 1.381451 	Validation Loss: 1.438027 	 time: 0.3
Epoch: 414 	Training Loss: 1.384845 	Validation Loss: 1.437077 	 time: 0.3
Epoch: 415 	Training Loss: 1.380192 	Validation Loss: 1.434541 	 time: 0.3
Epoch: 416 	Training Loss: 1.385630 	Validation Loss: 1.433567 	 time: 0.3
Epoch: 417 	Training Loss: 1.386534 	Validation Loss: 1.433829 	 time: 0.3
Epoch: 418 	Training Loss: 1.385161 	Validation Loss: 1.433731 	 time: 0.3
Epoch: 419 	Training Loss: 1.386562 	Validation Loss: 1.432864 	 time: 0.3
Epoch: 420 	Training Loss: 1.387008 	Validation Loss: 1.433669 	 time: 0.3
Epoch: 421 	Training Loss: 1.385124 	Validation Loss: 1.437340 	 time: 0.3
Epoch: 422 	Training Loss: 1.381146 	Validation Loss: 1.440349 	 time: 0.3
Epoch: 423 	Training Loss: 1.388874 	Validation Loss: 1.439264 	 time: 0.3
Epoch: 424 	Training Loss: 1.390572 	Validation Loss: 1.434547 	 time: 0.3
Epoch: 425 	Training Loss: 1.380109 	Validation Loss: 1.431303 	 time: 0.3
Validation loss decreased from 1.432120 to 1.431303. Model was saved
Epoch: 426 	Training Loss: 1.389505 	Validation Loss: 1.432492 	 time: 0.3
Epoch: 427 	Training Loss: 1.385312 	Validation Loss: 1.436383 	 time: 0.3
Epoch: 428 	Training Loss: 1.388660 	Validation Loss: 1.440485 	 time: 0.3
Epoch: 429 	Training Loss: 1.386480 	Validation Loss: 1.444544 	 time: 0.3
Epoch: 430 	Training Loss: 1.383951 	Validation Loss: 1.446942 	 time: 0.3
Epoch: 431 	Training Loss: 1.384885 	Validation Loss: 1.446779 	 time: 0.3
Epoch: 432 	Training Loss: 1.382413 	Validation Loss: 1.445037 	 time: 0.3
Epoch: 433 	Training Loss: 1.387347 	Validation Loss: 1.444457 	 time: 0.3
Epoch: 434 	Training Loss: 1.386381 	Validation Loss: 1.445234 	 time: 0.3
Epoch: 435 	Training Loss: 1.382745 	Validation Loss: 1.444782 	 time: 0.3
Epoch: 436 	Training Loss: 1.373445 	Validation Loss: 1.445151 	 time: 0.3
Epoch: 437 	Training Loss: 1.380293 	Validation Loss: 1.444380 	 time: 0.3
Epoch: 438 	Training Loss: 1.382282 	Validation Loss: 1.442000 	 time: 0.3
Epoch: 439 	Training Loss: 1.382476 	Validation Loss: 1.438367 	 time: 0.3
Epoch: 440 	Training Loss: 1.382296 	Validation Loss: 1.437777 	 time: 0.3
Epoch: 441 	Training Loss: 1.378445 	Validation Loss: 1.436594 	 time: 0.3
Epoch: 442 	Training Loss: 1.382776 	Validation Loss: 1.435848 	 time: 0.3
Epoch: 443 	Training Loss: 1.383576 	Validation Loss: 1.437322 	 time: 0.3
Epoch: 444 	Training Loss: 1.382838 	Validation Loss: 1.441003 	 time: 0.3
Epoch: 445 	Training Loss: 1.382447 	Validation Loss: 1.441911 	 time: 0.3
Epoch: 446 	Training Loss: 1.382537 	Validation Loss: 1.438511 	 time: 0.3
Epoch: 447 	Training Loss: 1.382707 	Validation Loss: 1.434644 	 time: 0.3
Epoch: 448 	Training Loss: 1.386802 	Validation Loss: 1.432800 	 time: 0.3
Epoch: 449 	Training Loss: 1.384954 	Validation Loss: 1.433116 	 time: 0.3
Epoch: 450 	Training Loss: 1.380613 	Validation Loss: 1.434401 	 time: 0.3
Epoch: 451 	Training Loss: 1.386551 	Validation Loss: 1.437023 	 time: 0.3
Epoch: 452 	Training Loss: 1.381860 	Validation Loss: 1.437954 	 time: 0.3
Epoch: 453 	Training Loss: 1.380962 	Validation Loss: 1.436812 	 time: 0.3
Epoch: 454 	Training Loss: 1.378859 	Validation Loss: 1.433916 	 time: 0.3
Epoch: 455 	Training Loss: 1.381841 	Validation Loss: 1.432069 	 time: 0.3
Epoch: 456 	Training Loss: 1.383223 	Validation Loss: 1.432119 	 time: 0.3
Epoch: 457 	Training Loss: 1.380213 	Validation Loss: 1.433090 	 time: 0.3
Epoch: 458 	Training Loss: 1.381058 	Validation Loss: 1.437604 	 time: 0.3
Epoch: 459 	Training Loss: 1.382146 	Validation Loss: 1.440460 	 time: 0.3
Epoch: 460 	Training Loss: 1.382499 	Validation Loss: 1.441044 	 time: 0.3
Epoch: 461 	Training Loss: 1.381425 	Validation Loss: 1.439606 	 time: 0.3
Epoch: 462 	Training Loss: 1.380436 	Validation Loss: 1.438106 	 time: 0.3
Epoch: 463 	Training Loss: 1.378450 	Validation Loss: 1.436127 	 time: 0.3
Epoch: 464 	Training Loss: 1.384867 	Validation Loss: 1.435753 	 time: 0.3
Epoch: 465 	Training Loss: 1.381689 	Validation Loss: 1.435743 	 time: 0.3
Epoch: 466 	Training Loss: 1.384781 	Validation Loss: 1.436002 	 time: 0.3
Epoch: 467 	Training Loss: 1.381792 	Validation Loss: 1.436067 	 time: 0.3
Epoch: 468 	Training Loss: 1.377647 	Validation Loss: 1.436417 	 time: 0.3
Epoch: 469 	Training Loss: 1.380069 	Validation Loss: 1.437359 	 time: 0.3
Epoch: 470 	Training Loss: 1.384656 	Validation Loss: 1.437623 	 time: 0.3
Epoch: 471 	Training Loss: 1.383853 	Validation Loss: 1.435962 	 time: 0.3
Epoch: 472 	Training Loss: 1.382757 	Validation Loss: 1.434502 	 time: 0.3
Epoch: 473 	Training Loss: 1.377492 	Validation Loss: 1.432563 	 time: 0.3
Epoch: 474 	Training Loss: 1.377890 	Validation Loss: 1.432994 	 time: 0.3
Epoch: 475 	Training Loss: 1.379138 	Validation Loss: 1.435694 	 time: 0.3
Epoch: 476 	Training Loss: 1.384394 	Validation Loss: 1.437095 	 time: 0.3
Epoch: 477 	Training Loss: 1.384021 	Validation Loss: 1.436865 	 time: 0.3
Epoch: 478 	Training Loss: 1.385625 	Validation Loss: 1.435876 	 time: 0.3
Epoch: 479 	Training Loss: 1.380519 	Validation Loss: 1.435656 	 time: 0.3
Epoch: 480 	Training Loss: 1.380782 	Validation Loss: 1.437331 	 time: 0.3
Epoch: 481 	Training Loss: 1.378943 	Validation Loss: 1.440664 	 time: 0.3
Epoch: 482 	Training Loss: 1.380314 	Validation Loss: 1.443386 	 time: 0.3
Epoch: 483 	Training Loss: 1.380196 	Validation Loss: 1.445132 	 time: 0.3
Epoch: 484 	Training Loss: 1.376691 	Validation Loss: 1.445390 	 time: 0.3
Epoch: 485 	Training Loss: 1.379358 	Validation Loss: 1.445665 	 time: 0.3
Epoch: 486 	Training Loss: 1.381951 	Validation Loss: 1.445077 	 time: 0.3
Epoch: 487 	Training Loss: 1.383185 	Validation Loss: 1.444532 	 time: 0.3
Epoch: 488 	Training Loss: 1.380489 	Validation Loss: 1.446510 	 time: 0.3
Epoch: 489 	Training Loss: 1.379913 	Validation Loss: 1.448142 	 time: 0.3
Epoch: 490 	Training Loss: 1.383108 	Validation Loss: 1.449318 	 time: 0.3
Epoch: 491 	Training Loss: 1.377633 	Validation Loss: 1.450305 	 time: 0.3
Epoch: 492 	Training Loss: 1.380218 	Validation Loss: 1.449831 	 time: 0.3
Epoch: 493 	Training Loss: 1.377287 	Validation Loss: 1.450469 	 time: 0.3
Epoch: 494 	Training Loss: 1.380906 	Validation Loss: 1.451339 	 time: 0.3
Epoch: 495 	Training Loss: 1.377544 	Validation Loss: 1.451015 	 time: 0.3
Epoch: 496 	Training Loss: 1.378160 	Validation Loss: 1.449865 	 time: 0.3
Epoch: 497 	Training Loss: 1.379950 	Validation Loss: 1.446877 	 time: 0.3
Epoch: 498 	Training Loss: 1.380925 	Validation Loss: 1.443968 	 time: 0.3
Epoch: 499 	Training Loss: 1.380769 	Validation Loss: 1.440115 	 time: 0.3
Epoch: 500 	Training Loss: 1.379608 	Validation Loss: 1.439058 	 time: 0.3
Epoch: 501 	Training Loss: 1.377426 	Validation Loss: 1.439882 	 time: 0.3
Epoch: 502 	Training Loss: 1.379589 	Validation Loss: 1.440514 	 time: 0.3
Epoch: 503 	Training Loss: 1.380622 	Validation Loss: 1.439996 	 time: 0.3
Epoch: 504 	Training Loss: 1.376694 	Validation Loss: 1.438215 	 time: 0.3
Epoch: 505 	Training Loss: 1.382585 	Validation Loss: 1.437270 	 time: 0.3
Epoch: 506 	Training Loss: 1.380282 	Validation Loss: 1.436091 	 time: 0.3
Epoch: 507 	Training Loss: 1.378761 	Validation Loss: 1.436897 	 time: 0.3
Epoch: 508 	Training Loss: 1.378763 	Validation Loss: 1.436110 	 time: 0.3
Epoch: 509 	Training Loss: 1.377204 	Validation Loss: 1.436738 	 time: 0.3
Epoch: 510 	Training Loss: 1.380187 	Validation Loss: 1.437069 	 time: 0.3
Epoch: 511 	Training Loss: 1.379321 	Validation Loss: 1.437758 	 time: 0.3
Epoch: 512 	Training Loss: 1.379993 	Validation Loss: 1.437056 	 time: 0.3
Epoch: 513 	Training Loss: 1.378539 	Validation Loss: 1.437608 	 time: 0.3
Epoch: 514 	Training Loss: 1.382075 	Validation Loss: 1.437526 	 time: 0.3
Epoch: 515 	Training Loss: 1.379660 	Validation Loss: 1.433471 	 time: 0.3
Epoch: 516 	Training Loss: 1.381360 	Validation Loss: 1.429831 	 time: 0.3
Validation loss decreased from 1.431303 to 1.429831. Model was saved
Epoch: 517 	Training Loss: 1.376265 	Validation Loss: 1.428160 	 time: 0.3
Validation loss decreased from 1.429831 to 1.428160. Model was saved
Epoch: 518 	Training Loss: 1.379236 	Validation Loss: 1.426708 	 time: 0.3
Validation loss decreased from 1.428160 to 1.426708. Model was saved
Epoch: 519 	Training Loss: 1.380288 	Validation Loss: 1.428187 	 time: 0.3
Epoch: 520 	Training Loss: 1.374946 	Validation Loss: 1.430850 	 time: 0.3
Epoch: 521 	Training Loss: 1.376921 	Validation Loss: 1.433310 	 time: 0.3
Epoch: 522 	Training Loss: 1.378378 	Validation Loss: 1.433838 	 time: 0.3
Epoch: 523 	Training Loss: 1.379279 	Validation Loss: 1.433449 	 time: 0.3
Epoch: 524 	Training Loss: 1.381981 	Validation Loss: 1.433502 	 time: 0.3
Epoch: 525 	Training Loss: 1.377720 	Validation Loss: 1.433809 	 time: 0.3
Epoch: 526 	Training Loss: 1.377582 	Validation Loss: 1.433714 	 time: 0.3
Epoch: 527 	Training Loss: 1.377375 	Validation Loss: 1.433047 	 time: 0.3
Epoch: 528 	Training Loss: 1.373926 	Validation Loss: 1.430368 	 time: 0.3
Epoch: 529 	Training Loss: 1.375681 	Validation Loss: 1.428202 	 time: 0.3
Epoch: 530 	Training Loss: 1.375864 	Validation Loss: 1.425765 	 time: 0.3
Validation loss decreased from 1.426708 to 1.425765. Model was saved
Epoch: 531 	Training Loss: 1.379264 	Validation Loss: 1.422926 	 time: 0.3
Validation loss decreased from 1.425765 to 1.422926. Model was saved
Epoch: 532 	Training Loss: 1.380656 	Validation Loss: 1.420829 	 time: 0.3
Validation loss decreased from 1.422926 to 1.420829. Model was saved
Epoch: 533 	Training Loss: 1.371181 	Validation Loss: 1.420403 	 time: 0.3
Validation loss decreased from 1.420829 to 1.420403. Model was saved
Epoch: 534 	Training Loss: 1.377893 	Validation Loss: 1.420758 	 time: 0.3
Epoch: 535 	Training Loss: 1.373873 	Validation Loss: 1.420108 	 time: 0.3
Validation loss decreased from 1.420403 to 1.420108. Model was saved
Epoch: 536 	Training Loss: 1.380580 	Validation Loss: 1.421019 	 time: 0.3
Epoch: 537 	Training Loss: 1.380627 	Validation Loss: 1.424201 	 time: 0.3
Epoch: 538 	Training Loss: 1.375246 	Validation Loss: 1.427516 	 time: 0.3
Epoch: 539 	Training Loss: 1.376132 	Validation Loss: 1.429126 	 time: 0.3
Epoch: 540 	Training Loss: 1.379088 	Validation Loss: 1.429272 	 time: 0.3
Epoch: 541 	Training Loss: 1.382118 	Validation Loss: 1.428380 	 time: 0.3
Epoch: 542 	Training Loss: 1.371735 	Validation Loss: 1.427681 	 time: 0.3
Epoch: 543 	Training Loss: 1.379675 	Validation Loss: 1.427636 	 time: 0.3
Epoch: 544 	Training Loss: 1.378550 	Validation Loss: 1.428228 	 time: 0.3
Epoch: 545 	Training Loss: 1.380048 	Validation Loss: 1.429035 	 time: 0.3
Epoch: 546 	Training Loss: 1.378569 	Validation Loss: 1.429094 	 time: 0.3
Epoch: 547 	Training Loss: 1.377728 	Validation Loss: 1.430025 	 time: 0.3
Epoch: 548 	Training Loss: 1.377376 	Validation Loss: 1.430784 	 time: 0.3
Epoch: 549 	Training Loss: 1.381236 	Validation Loss: 1.428223 	 time: 0.3
Epoch: 550 	Training Loss: 1.378390 	Validation Loss: 1.425107 	 time: 0.3
Epoch: 551 	Training Loss: 1.377900 	Validation Loss: 1.423060 	 time: 0.3
Epoch: 552 	Training Loss: 1.373808 	Validation Loss: 1.422623 	 time: 0.3
Epoch: 553 	Training Loss: 1.376581 	Validation Loss: 1.422547 	 time: 0.3
Epoch: 554 	Training Loss: 1.380374 	Validation Loss: 1.421469 	 time: 0.3
Epoch: 555 	Training Loss: 1.373360 	Validation Loss: 1.419837 	 time: 0.3
Validation loss decreased from 1.420108 to 1.419837. Model was saved
Epoch: 556 	Training Loss: 1.377974 	Validation Loss: 1.419546 	 time: 0.3
Validation loss decreased from 1.419837 to 1.419546. Model was saved
Epoch: 557 	Training Loss: 1.380922 	Validation Loss: 1.421039 	 time: 0.3
Epoch: 558 	Training Loss: 1.378111 	Validation Loss: 1.420897 	 time: 0.3
Epoch: 559 	Training Loss: 1.377589 	Validation Loss: 1.419266 	 time: 0.3
Validation loss decreased from 1.419546 to 1.419266. Model was saved
Epoch: 560 	Training Loss: 1.373156 	Validation Loss: 1.419275 	 time: 0.3
Epoch: 561 	Training Loss: 1.376416 	Validation Loss: 1.418206 	 time: 0.3
Validation loss decreased from 1.419266 to 1.418206. Model was saved
Epoch: 562 	Training Loss: 1.373840 	Validation Loss: 1.416575 	 time: 0.3
Validation loss decreased from 1.418206 to 1.416575. Model was saved
Epoch: 563 	Training Loss: 1.375208 	Validation Loss: 1.412181 	 time: 0.3
Validation loss decreased from 1.416575 to 1.412181. Model was saved
Epoch: 564 	Training Loss: 1.375566 	Validation Loss: 1.408303 	 time: 0.3
Validation loss decreased from 1.412181 to 1.408303. Model was saved
Epoch: 565 	Training Loss: 1.380004 	Validation Loss: 1.406169 	 time: 0.3
Validation loss decreased from 1.408303 to 1.406169. Model was saved
Epoch: 566 	Training Loss: 1.373446 	Validation Loss: 1.404663 	 time: 0.3
Validation loss decreased from 1.406169 to 1.404663. Model was saved
Epoch: 567 	Training Loss: 1.376540 	Validation Loss: 1.405707 	 time: 0.3
Epoch: 568 	Training Loss: 1.377278 	Validation Loss: 1.409907 	 time: 0.3
Epoch: 569 	Training Loss: 1.373551 	Validation Loss: 1.414481 	 time: 0.3
Epoch: 570 	Training Loss: 1.379243 	Validation Loss: 1.416615 	 time: 0.3
Epoch: 571 	Training Loss: 1.375965 	Validation Loss: 1.415601 	 time: 0.3
Epoch: 572 	Training Loss: 1.378021 	Validation Loss: 1.414179 	 time: 0.3
Epoch: 573 	Training Loss: 1.373415 	Validation Loss: 1.413528 	 time: 0.3
Epoch: 574 	Training Loss: 1.375761 	Validation Loss: 1.415067 	 time: 0.3
Epoch: 575 	Training Loss: 1.378651 	Validation Loss: 1.417587 	 time: 0.3
Epoch: 576 	Training Loss: 1.376351 	Validation Loss: 1.418730 	 time: 0.3
Epoch: 577 	Training Loss: 1.377537 	Validation Loss: 1.418055 	 time: 0.3
Epoch: 578 	Training Loss: 1.371675 	Validation Loss: 1.415861 	 time: 0.3
Epoch: 579 	Training Loss: 1.375897 	Validation Loss: 1.414268 	 time: 0.3
Epoch: 580 	Training Loss: 1.377489 	Validation Loss: 1.414001 	 time: 0.3
Epoch: 581 	Training Loss: 1.372402 	Validation Loss: 1.416017 	 time: 0.3
Epoch: 582 	Training Loss: 1.377636 	Validation Loss: 1.417299 	 time: 0.3
Epoch: 583 	Training Loss: 1.375518 	Validation Loss: 1.419277 	 time: 0.3
Epoch: 584 	Training Loss: 1.368743 	Validation Loss: 1.420821 	 time: 0.3
Epoch: 585 	Training Loss: 1.378743 	Validation Loss: 1.422487 	 time: 0.3
Epoch: 586 	Training Loss: 1.373739 	Validation Loss: 1.423111 	 time: 0.3
Epoch: 587 	Training Loss: 1.373029 	Validation Loss: 1.424858 	 time: 0.3
Epoch: 588 	Training Loss: 1.380272 	Validation Loss: 1.424150 	 time: 0.3
Epoch: 589 	Training Loss: 1.375549 	Validation Loss: 1.421678 	 time: 0.3
Epoch: 590 	Training Loss: 1.373812 	Validation Loss: 1.418622 	 time: 0.3
Epoch: 591 	Training Loss: 1.375911 	Validation Loss: 1.416411 	 time: 0.3
Epoch: 592 	Training Loss: 1.375357 	Validation Loss: 1.417175 	 time: 0.3
Epoch: 593 	Training Loss: 1.373766 	Validation Loss: 1.418087 	 time: 0.3
Epoch: 594 	Training Loss: 1.373390 	Validation Loss: 1.418645 	 time: 0.3
Epoch: 595 	Training Loss: 1.371760 	Validation Loss: 1.420846 	 time: 0.3
Epoch: 596 	Training Loss: 1.379075 	Validation Loss: 1.421504 	 time: 0.3
Epoch: 597 	Training Loss: 1.377227 	Validation Loss: 1.421198 	 time: 0.3
Epoch: 598 	Training Loss: 1.373181 	Validation Loss: 1.419641 	 time: 0.3
Epoch: 599 	Training Loss: 1.377708 	Validation Loss: 1.417132 	 time: 0.3
Epoch: 600 	Training Loss: 1.374879 	Validation Loss: 1.413489 	 time: 0.3
Epoch: 601 	Training Loss: 1.374156 	Validation Loss: 1.412308 	 time: 0.3
Epoch: 602 	Training Loss: 1.378121 	Validation Loss: 1.412554 	 time: 0.3
Epoch: 603 	Training Loss: 1.373523 	Validation Loss: 1.415312 	 time: 0.3
Epoch: 604 	Training Loss: 1.370999 	Validation Loss: 1.421634 	 time: 0.3
Epoch: 605 	Training Loss: 1.370441 	Validation Loss: 1.428561 	 time: 0.3
Epoch: 606 	Training Loss: 1.372634 	Validation Loss: 1.433082 	 time: 0.3
Epoch: 607 	Training Loss: 1.378858 	Validation Loss: 1.431747 	 time: 0.3
Epoch: 608 	Training Loss: 1.376727 	Validation Loss: 1.426268 	 time: 0.3
Epoch: 609 	Training Loss: 1.371703 	Validation Loss: 1.420022 	 time: 0.3
Epoch: 610 	Training Loss: 1.374639 	Validation Loss: 1.416133 	 time: 0.3
Epoch: 611 	Training Loss: 1.378024 	Validation Loss: 1.413459 	 time: 0.3
Epoch: 612 	Training Loss: 1.377781 	Validation Loss: 1.414488 	 time: 0.3
Epoch: 613 	Training Loss: 1.377488 	Validation Loss: 1.417216 	 time: 0.3
Epoch: 614 	Training Loss: 1.378095 	Validation Loss: 1.419483 	 time: 0.3
Epoch: 615 	Training Loss: 1.373631 	Validation Loss: 1.420345 	 time: 0.3
Epoch: 616 	Training Loss: 1.377581 	Validation Loss: 1.421339 	 time: 0.3
Epoch: 617 	Training Loss: 1.377505 	Validation Loss: 1.420324 	 time: 0.3
Epoch: 618 	Training Loss: 1.377536 	Validation Loss: 1.415174 	 time: 0.3
Epoch: 619 	Training Loss: 1.375825 	Validation Loss: 1.410851 	 time: 0.3
Epoch: 620 	Training Loss: 1.375772 	Validation Loss: 1.411153 	 time: 0.3
Epoch: 621 	Training Loss: 1.371184 	Validation Loss: 1.412746 	 time: 0.3
Epoch: 622 	Training Loss: 1.373832 	Validation Loss: 1.414633 	 time: 0.3
Epoch: 623 	Training Loss: 1.377601 	Validation Loss: 1.416379 	 time: 0.3
Epoch: 624 	Training Loss: 1.374078 	Validation Loss: 1.418471 	 time: 0.3
Epoch: 625 	Training Loss: 1.374297 	Validation Loss: 1.423431 	 time: 0.3
Epoch: 626 	Training Loss: 1.374061 	Validation Loss: 1.426035 	 time: 0.3
Epoch: 627 	Training Loss: 1.371345 	Validation Loss: 1.425000 	 time: 0.3
Epoch: 628 	Training Loss: 1.376317 	Validation Loss: 1.423033 	 time: 0.3
Epoch: 629 	Training Loss: 1.375902 	Validation Loss: 1.417920 	 time: 0.3
Epoch: 630 	Training Loss: 1.376057 	Validation Loss: 1.414755 	 time: 0.3
Epoch: 631 	Training Loss: 1.374447 	Validation Loss: 1.415924 	 time: 0.3
Epoch: 632 	Training Loss: 1.371803 	Validation Loss: 1.418290 	 time: 0.3
Epoch: 633 	Training Loss: 1.368149 	Validation Loss: 1.419729 	 time: 0.3
Epoch: 634 	Training Loss: 1.372069 	Validation Loss: 1.421172 	 time: 0.3
Epoch: 635 	Training Loss: 1.371455 	Validation Loss: 1.421223 	 time: 0.3
Epoch: 636 	Training Loss: 1.370961 	Validation Loss: 1.419820 	 time: 0.3
Epoch: 637 	Training Loss: 1.372927 	Validation Loss: 1.420546 	 time: 0.3
Epoch: 638 	Training Loss: 1.369733 	Validation Loss: 1.422178 	 time: 0.3
Epoch: 639 	Training Loss: 1.371654 	Validation Loss: 1.425061 	 time: 0.3
Epoch: 640 	Training Loss: 1.378517 	Validation Loss: 1.427053 	 time: 0.3
Epoch: 641 	Training Loss: 1.373581 	Validation Loss: 1.428579 	 time: 0.3
Epoch: 642 	Training Loss: 1.376010 	Validation Loss: 1.427960 	 time: 0.3
Epoch: 643 	Training Loss: 1.373824 	Validation Loss: 1.427322 	 time: 0.3
Epoch: 644 	Training Loss: 1.371750 	Validation Loss: 1.428373 	 time: 0.3
Epoch: 645 	Training Loss: 1.374714 	Validation Loss: 1.428612 	 time: 0.3
Epoch: 646 	Training Loss: 1.375968 	Validation Loss: 1.427815 	 time: 0.3
Epoch: 647 	Training Loss: 1.369843 	Validation Loss: 1.426133 	 time: 0.3
Epoch: 648 	Training Loss: 1.376398 	Validation Loss: 1.422416 	 time: 0.3
Epoch: 649 	Training Loss: 1.371618 	Validation Loss: 1.418287 	 time: 0.3
Epoch: 650 	Training Loss: 1.375697 	Validation Loss: 1.414975 	 time: 0.3
Epoch: 651 	Training Loss: 1.373884 	Validation Loss: 1.414470 	 time: 0.3
Epoch: 652 	Training Loss: 1.368540 	Validation Loss: 1.415144 	 time: 0.3
Epoch: 653 	Training Loss: 1.375725 	Validation Loss: 1.415919 	 time: 0.3
Epoch: 654 	Training Loss: 1.374755 	Validation Loss: 1.416622 	 time: 0.3
Epoch: 655 	Training Loss: 1.376909 	Validation Loss: 1.415492 	 time: 0.3
Epoch: 656 	Training Loss: 1.372392 	Validation Loss: 1.413513 	 time: 0.3
Epoch: 657 	Training Loss: 1.373704 	Validation Loss: 1.411834 	 time: 0.3
Epoch: 658 	Training Loss: 1.378990 	Validation Loss: 1.409862 	 time: 0.3
Epoch: 659 	Training Loss: 1.371029 	Validation Loss: 1.410239 	 time: 0.3
Epoch: 660 	Training Loss: 1.375398 	Validation Loss: 1.410172 	 time: 0.3
Epoch: 661 	Training Loss: 1.370160 	Validation Loss: 1.410590 	 time: 0.3
Epoch: 662 	Training Loss: 1.368306 	Validation Loss: 1.411473 	 time: 0.3
Epoch: 663 	Training Loss: 1.376950 	Validation Loss: 1.411942 	 time: 0.3
Epoch: 664 	Training Loss: 1.373747 	Validation Loss: 1.413815 	 time: 0.3
Epoch: 665 	Training Loss: 1.372717 	Validation Loss: 1.415277 	 time: 0.3
Epoch: 666 	Training Loss: 1.373901 	Validation Loss: 1.416549 	 time: 0.3
Epoch: 667 	Training Loss: 1.370739 	Validation Loss: 1.416960 	 time: 0.3
Epoch: 668 	Training Loss: 1.370911 	Validation Loss: 1.417497 	 time: 0.3
Epoch: 669 	Training Loss: 1.372068 	Validation Loss: 1.417853 	 time: 0.3
Epoch: 670 	Training Loss: 1.375276 	Validation Loss: 1.419899 	 time: 0.3
Epoch: 671 	Training Loss: 1.375430 	Validation Loss: 1.421904 	 time: 0.3
Epoch: 672 	Training Loss: 1.367079 	Validation Loss: 1.424151 	 time: 0.3
Epoch: 673 	Training Loss: 1.374513 	Validation Loss: 1.422969 	 time: 0.3
Epoch: 674 	Training Loss: 1.368414 	Validation Loss: 1.419640 	 time: 0.3
Epoch: 675 	Training Loss: 1.371585 	Validation Loss: 1.414863 	 time: 0.3
Epoch: 676 	Training Loss: 1.375663 	Validation Loss: 1.410074 	 time: 0.3
Epoch: 677 	Training Loss: 1.371595 	Validation Loss: 1.406168 	 time: 0.3
Epoch: 678 	Training Loss: 1.373435 	Validation Loss: 1.401723 	 time: 0.3
Validation loss decreased from 1.404663 to 1.401723. Model was saved
Epoch: 679 	Training Loss: 1.374867 	Validation Loss: 1.400462 	 time: 0.3
Validation loss decreased from 1.401723 to 1.400462. Model was saved
Epoch: 680 	Training Loss: 1.372802 	Validation Loss: 1.401759 	 time: 0.3
Epoch: 681 	Training Loss: 1.373196 	Validation Loss: 1.404911 	 time: 0.3
Epoch: 682 	Training Loss: 1.377007 	Validation Loss: 1.405658 	 time: 0.3
Epoch: 683 	Training Loss: 1.374167 	Validation Loss: 1.404412 	 time: 0.3
Epoch: 684 	Training Loss: 1.372091 	Validation Loss: 1.403887 	 time: 0.3
Epoch: 685 	Training Loss: 1.372739 	Validation Loss: 1.403852 	 time: 0.3
Epoch: 686 	Training Loss: 1.375622 	Validation Loss: 1.405963 	 time: 0.3
Epoch: 687 	Training Loss: 1.373863 	Validation Loss: 1.407617 	 time: 0.3
Epoch: 688 	Training Loss: 1.372678 	Validation Loss: 1.409796 	 time: 0.3
Epoch: 689 	Training Loss: 1.373547 	Validation Loss: 1.410890 	 time: 0.3
Epoch: 690 	Training Loss: 1.377369 	Validation Loss: 1.411008 	 time: 0.3
Epoch: 691 	Training Loss: 1.372922 	Validation Loss: 1.408647 	 time: 0.3
Epoch: 692 	Training Loss: 1.367886 	Validation Loss: 1.405463 	 time: 0.3
Epoch: 693 	Training Loss: 1.368943 	Validation Loss: 1.401367 	 time: 0.3
Epoch: 694 	Training Loss: 1.367623 	Validation Loss: 1.398108 	 time: 0.3
Validation loss decreased from 1.400462 to 1.398108. Model was saved
Epoch: 695 	Training Loss: 1.372651 	Validation Loss: 1.397419 	 time: 0.3
Validation loss decreased from 1.398108 to 1.397419. Model was saved
Epoch: 696 	Training Loss: 1.365047 	Validation Loss: 1.398242 	 time: 0.3
Epoch: 697 	Training Loss: 1.375110 	Validation Loss: 1.399120 	 time: 0.3
Epoch: 698 	Training Loss: 1.369617 	Validation Loss: 1.398943 	 time: 0.3
Epoch: 699 	Training Loss: 1.373097 	Validation Loss: 1.397225 	 time: 0.3
Validation loss decreased from 1.397419 to 1.397225. Model was saved
Epoch: 700 	Training Loss: 1.368793 	Validation Loss: 1.394135 	 time: 0.3
Validation loss decreased from 1.397225 to 1.394135. Model was saved
Epoch: 701 	Training Loss: 1.375203 	Validation Loss: 1.392457 	 time: 0.3
Validation loss decreased from 1.394135 to 1.392457. Model was saved
Epoch: 702 	Training Loss: 1.372048 	Validation Loss: 1.392211 	 time: 0.3
Validation loss decreased from 1.392457 to 1.392211. Model was saved
Epoch: 703 	Training Loss: 1.368205 	Validation Loss: 1.391968 	 time: 0.3
Validation loss decreased from 1.392211 to 1.391968. Model was saved
Epoch: 704 	Training Loss: 1.374818 	Validation Loss: 1.390278 	 time: 0.3
Validation loss decreased from 1.391968 to 1.390278. Model was saved
Epoch: 705 	Training Loss: 1.372455 	Validation Loss: 1.390024 	 time: 0.3
Validation loss decreased from 1.390278 to 1.390024. Model was saved
Epoch: 706 	Training Loss: 1.366874 	Validation Loss: 1.393643 	 time: 0.3
Epoch: 707 	Training Loss: 1.375070 	Validation Loss: 1.398941 	 time: 0.3
Epoch: 708 	Training Loss: 1.372246 	Validation Loss: 1.403714 	 time: 0.3
Epoch: 709 	Training Loss: 1.373741 	Validation Loss: 1.406703 	 time: 0.3
Epoch: 710 	Training Loss: 1.369775 	Validation Loss: 1.409209 	 time: 0.3
Epoch: 711 	Training Loss: 1.372592 	Validation Loss: 1.412458 	 time: 0.3
Epoch: 712 	Training Loss: 1.365975 	Validation Loss: 1.412759 	 time: 0.3
Epoch: 713 	Training Loss: 1.366802 	Validation Loss: 1.410558 	 time: 0.3
Epoch: 714 	Training Loss: 1.372271 	Validation Loss: 1.407571 	 time: 0.3
Epoch: 715 	Training Loss: 1.372702 	Validation Loss: 1.404551 	 time: 0.3
Epoch: 716 	Training Loss: 1.368901 	Validation Loss: 1.402946 	 time: 0.3
Epoch: 717 	Training Loss: 1.373339 	Validation Loss: 1.402665 	 time: 0.3
Epoch: 718 	Training Loss: 1.373557 	Validation Loss: 1.404484 	 time: 0.3
Epoch: 719 	Training Loss: 1.370921 	Validation Loss: 1.407269 	 time: 0.3
Epoch: 720 	Training Loss: 1.373659 	Validation Loss: 1.409328 	 time: 0.3
Epoch: 721 	Training Loss: 1.372874 	Validation Loss: 1.411457 	 time: 0.3
Epoch: 722 	Training Loss: 1.376225 	Validation Loss: 1.413364 	 time: 0.3
Epoch: 723 	Training Loss: 1.370978 	Validation Loss: 1.414351 	 time: 0.3
Epoch: 724 	Training Loss: 1.372387 	Validation Loss: 1.413978 	 time: 0.3
Epoch: 725 	Training Loss: 1.372286 	Validation Loss: 1.412914 	 time: 0.3
Epoch: 726 	Training Loss: 1.375808 	Validation Loss: 1.414546 	 time: 0.3
Epoch: 727 	Training Loss: 1.370034 	Validation Loss: 1.418263 	 time: 0.3
Epoch: 728 	Training Loss: 1.371718 	Validation Loss: 1.422782 	 time: 0.3
Epoch: 729 	Training Loss: 1.370979 	Validation Loss: 1.427068 	 time: 0.3
Epoch: 730 	Training Loss: 1.374817 	Validation Loss: 1.429418 	 time: 0.3
Epoch: 731 	Training Loss: 1.373752 	Validation Loss: 1.428044 	 time: 0.3
Epoch: 732 	Training Loss: 1.378492 	Validation Loss: 1.422548 	 time: 0.3
Epoch: 733 	Training Loss: 1.372876 	Validation Loss: 1.416461 	 time: 0.3
Epoch: 734 	Training Loss: 1.372361 	Validation Loss: 1.413626 	 time: 0.3
Epoch: 735 	Training Loss: 1.373747 	Validation Loss: 1.410206 	 time: 0.3
Epoch: 736 	Training Loss: 1.374546 	Validation Loss: 1.407304 	 time: 0.3
Epoch: 737 	Training Loss: 1.368628 	Validation Loss: 1.406812 	 time: 0.3
Epoch: 738 	Training Loss: 1.370825 	Validation Loss: 1.409111 	 time: 0.3
Epoch: 739 	Training Loss: 1.369722 	Validation Loss: 1.411873 	 time: 0.3
Epoch: 740 	Training Loss: 1.369204 	Validation Loss: 1.413773 	 time: 0.3
Epoch: 741 	Training Loss: 1.373223 	Validation Loss: 1.416444 	 time: 0.3
Epoch: 742 	Training Loss: 1.376999 	Validation Loss: 1.415880 	 time: 0.3
Epoch: 743 	Training Loss: 1.372243 	Validation Loss: 1.414153 	 time: 0.3
Epoch: 744 	Training Loss: 1.373519 	Validation Loss: 1.412801 	 time: 0.3
Epoch: 745 	Training Loss: 1.367523 	Validation Loss: 1.414223 	 time: 0.3
Epoch: 746 	Training Loss: 1.371339 	Validation Loss: 1.417413 	 time: 0.3
Epoch: 747 	Training Loss: 1.374030 	Validation Loss: 1.420322 	 time: 0.3
Epoch: 748 	Training Loss: 1.376854 	Validation Loss: 1.422299 	 time: 0.3
Epoch: 749 	Training Loss: 1.375547 	Validation Loss: 1.422357 	 time: 0.3
Epoch: 750 	Training Loss: 1.371595 	Validation Loss: 1.420051 	 time: 0.3
Epoch: 751 	Training Loss: 1.370637 	Validation Loss: 1.417214 	 time: 0.3
Epoch: 752 	Training Loss: 1.375412 	Validation Loss: 1.414843 	 time: 0.3
Epoch: 753 	Training Loss: 1.375490 	Validation Loss: 1.410855 	 time: 0.3
Epoch: 754 	Training Loss: 1.374641 	Validation Loss: 1.407699 	 time: 0.3
Epoch: 755 	Training Loss: 1.370349 	Validation Loss: 1.406448 	 time: 0.3
Epoch: 756 	Training Loss: 1.371414 	Validation Loss: 1.408603 	 time: 0.3
Epoch: 757 	Training Loss: 1.375848 	Validation Loss: 1.413488 	 time: 0.3
Epoch: 758 	Training Loss: 1.373057 	Validation Loss: 1.416456 	 time: 0.3
Epoch: 759 	Training Loss: 1.368496 	Validation Loss: 1.418377 	 time: 0.3
Epoch: 760 	Training Loss: 1.372753 	Validation Loss: 1.420283 	 time: 0.3
Epoch: 761 	Training Loss: 1.373298 	Validation Loss: 1.421027 	 time: 0.3
Epoch: 762 	Training Loss: 1.365712 	Validation Loss: 1.420248 	 time: 0.3
Epoch: 763 	Training Loss: 1.373787 	Validation Loss: 1.417130 	 time: 0.3
Epoch: 764 	Training Loss: 1.372956 	Validation Loss: 1.414164 	 time: 0.3
Epoch: 765 	Training Loss: 1.372232 	Validation Loss: 1.411451 	 time: 0.3
Epoch: 766 	Training Loss: 1.367123 	Validation Loss: 1.408005 	 time: 0.3
Epoch: 767 	Training Loss: 1.373538 	Validation Loss: 1.404864 	 time: 0.3
Epoch: 768 	Training Loss: 1.369776 	Validation Loss: 1.403440 	 time: 0.3
Epoch: 769 	Training Loss: 1.370265 	Validation Loss: 1.401138 	 time: 0.3
Epoch: 770 	Training Loss: 1.368414 	Validation Loss: 1.398664 	 time: 0.3
Epoch: 771 	Training Loss: 1.367242 	Validation Loss: 1.397472 	 time: 0.3
Epoch: 772 	Training Loss: 1.372126 	Validation Loss: 1.397313 	 time: 0.3
Epoch: 773 	Training Loss: 1.366330 	Validation Loss: 1.398305 	 time: 0.3
Epoch: 774 	Training Loss: 1.374210 	Validation Loss: 1.398789 	 time: 0.3
Epoch: 775 	Training Loss: 1.370363 	Validation Loss: 1.398362 	 time: 0.3
Epoch: 776 	Training Loss: 1.370875 	Validation Loss: 1.397316 	 time: 0.3
Epoch: 777 	Training Loss: 1.370827 	Validation Loss: 1.395884 	 time: 0.3
Epoch: 778 	Training Loss: 1.371647 	Validation Loss: 1.395902 	 time: 0.3
Epoch: 779 	Training Loss: 1.366906 	Validation Loss: 1.398309 	 time: 0.3
Epoch: 780 	Training Loss: 1.365321 	Validation Loss: 1.401647 	 time: 0.3
Epoch: 781 	Training Loss: 1.367474 	Validation Loss: 1.402509 	 time: 0.3
Epoch: 782 	Training Loss: 1.368943 	Validation Loss: 1.401546 	 time: 0.3
Epoch: 783 	Training Loss: 1.373032 	Validation Loss: 1.401195 	 time: 0.3
Epoch: 784 	Training Loss: 1.370868 	Validation Loss: 1.401603 	 time: 0.3
Epoch: 785 	Training Loss: 1.367280 	Validation Loss: 1.403207 	 time: 0.3
Epoch: 786 	Training Loss: 1.369934 	Validation Loss: 1.403343 	 time: 0.3
Epoch: 787 	Training Loss: 1.367380 	Validation Loss: 1.400618 	 time: 0.3
Epoch: 788 	Training Loss: 1.369744 	Validation Loss: 1.396264 	 time: 0.3
Epoch: 789 	Training Loss: 1.370393 	Validation Loss: 1.394602 	 time: 0.3
Epoch: 790 	Training Loss: 1.370923 	Validation Loss: 1.395136 	 time: 0.3
Epoch: 791 	Training Loss: 1.369063 	Validation Loss: 1.396350 	 time: 0.3
Epoch: 792 	Training Loss: 1.367932 	Validation Loss: 1.397099 	 time: 0.3
Epoch: 793 	Training Loss: 1.369134 	Validation Loss: 1.397452 	 time: 0.3
Epoch: 794 	Training Loss: 1.373718 	Validation Loss: 1.397731 	 time: 0.3
Epoch: 795 	Training Loss: 1.372405 	Validation Loss: 1.396899 	 time: 0.3
Epoch: 796 	Training Loss: 1.372484 	Validation Loss: 1.394290 	 time: 0.3
Epoch: 797 	Training Loss: 1.366422 	Validation Loss: 1.391819 	 time: 0.3
Epoch: 798 	Training Loss: 1.369493 	Validation Loss: 1.389013 	 time: 0.3
Validation loss decreased from 1.390024 to 1.389013. Model was saved
Epoch: 799 	Training Loss: 1.370385 	Validation Loss: 1.387567 	 time: 0.3
Validation loss decreased from 1.389013 to 1.387567. Model was saved
Epoch: 800 	Training Loss: 1.367787 	Validation Loss: 1.389188 	 time: 0.3
Epoch: 801 	Training Loss: 1.373470 	Validation Loss: 1.390030 	 time: 0.3
Epoch: 802 	Training Loss: 1.371675 	Validation Loss: 1.389562 	 time: 0.3
Epoch: 803 	Training Loss: 1.368959 	Validation Loss: 1.390224 	 time: 0.3
Epoch: 804 	Training Loss: 1.371823 	Validation Loss: 1.391954 	 time: 0.3
Epoch: 805 	Training Loss: 1.369522 	Validation Loss: 1.392613 	 time: 0.3
Epoch: 806 	Training Loss: 1.368764 	Validation Loss: 1.392740 	 time: 0.3
Epoch: 807 	Training Loss: 1.364449 	Validation Loss: 1.394134 	 time: 0.3
Epoch: 808 	Training Loss: 1.371907 	Validation Loss: 1.396428 	 time: 0.3
Epoch: 809 	Training Loss: 1.363054 	Validation Loss: 1.398149 	 time: 0.3
Epoch: 810 	Training Loss: 1.369039 	Validation Loss: 1.399010 	 time: 0.3
Epoch: 811 	Training Loss: 1.373491 	Validation Loss: 1.397376 	 time: 0.3
Epoch: 812 	Training Loss: 1.365780 	Validation Loss: 1.396695 	 time: 0.3
Epoch: 813 	Training Loss: 1.371527 	Validation Loss: 1.397936 	 time: 0.3
Epoch: 814 	Training Loss: 1.372365 	Validation Loss: 1.400530 	 time: 0.3
Epoch: 815 	Training Loss: 1.367922 	Validation Loss: 1.402656 	 time: 0.3
Epoch: 816 	Training Loss: 1.367750 	Validation Loss: 1.403823 	 time: 0.3
Epoch: 817 	Training Loss: 1.370518 	Validation Loss: 1.404428 	 time: 0.3
Epoch: 818 	Training Loss: 1.375206 	Validation Loss: 1.404679 	 time: 0.3
Epoch: 819 	Training Loss: 1.371103 	Validation Loss: 1.403568 	 time: 0.3
Epoch: 820 	Training Loss: 1.366095 	Validation Loss: 1.401175 	 time: 0.3
Epoch: 821 	Training Loss: 1.364027 	Validation Loss: 1.398796 	 time: 0.3
Epoch: 822 	Training Loss: 1.369506 	Validation Loss: 1.396809 	 time: 0.3
Epoch: 823 	Training Loss: 1.369711 	Validation Loss: 1.396265 	 time: 0.3
Epoch: 824 	Training Loss: 1.369295 	Validation Loss: 1.397499 	 time: 0.3
Epoch: 825 	Training Loss: 1.372132 	Validation Loss: 1.399835 	 time: 0.3
Epoch: 826 	Training Loss: 1.367553 	Validation Loss: 1.400859 	 time: 0.3
Epoch: 827 	Training Loss: 1.374569 	Validation Loss: 1.402849 	 time: 0.3
Epoch: 828 	Training Loss: 1.371544 	Validation Loss: 1.405043 	 time: 0.3
Epoch: 829 	Training Loss: 1.371487 	Validation Loss: 1.408652 	 time: 0.3
Epoch: 830 	Training Loss: 1.367254 	Validation Loss: 1.411431 	 time: 0.3
Epoch: 831 	Training Loss: 1.367828 	Validation Loss: 1.413446 	 time: 0.3
Epoch: 832 	Training Loss: 1.370466 	Validation Loss: 1.411767 	 time: 0.3
Epoch: 833 	Training Loss: 1.372229 	Validation Loss: 1.410265 	 time: 0.3
Epoch: 834 	Training Loss: 1.369154 	Validation Loss: 1.409559 	 time: 0.3
Epoch: 835 	Training Loss: 1.374434 	Validation Loss: 1.408956 	 time: 0.3
Epoch: 836 	Training Loss: 1.373633 	Validation Loss: 1.411305 	 time: 0.3
Epoch: 837 	Training Loss: 1.370635 	Validation Loss: 1.412384 	 time: 0.3
Epoch: 838 	Training Loss: 1.369331 	Validation Loss: 1.413994 	 time: 0.3
Epoch: 839 	Training Loss: 1.365556 	Validation Loss: 1.413753 	 time: 0.3
Epoch: 840 	Training Loss: 1.372858 	Validation Loss: 1.413653 	 time: 0.3
Epoch: 841 	Training Loss: 1.364206 	Validation Loss: 1.411791 	 time: 0.3
Epoch: 842 	Training Loss: 1.363733 	Validation Loss: 1.409025 	 time: 0.3
Epoch: 843 	Training Loss: 1.363390 	Validation Loss: 1.405559 	 time: 0.3
Epoch: 844 	Training Loss: 1.376388 	Validation Loss: 1.401208 	 time: 0.3
Epoch: 845 	Training Loss: 1.370884 	Validation Loss: 1.398651 	 time: 0.3
Epoch: 846 	Training Loss: 1.374243 	Validation Loss: 1.397671 	 time: 0.3
Epoch: 847 	Training Loss: 1.370900 	Validation Loss: 1.397614 	 time: 0.3
Epoch: 848 	Training Loss: 1.370965 	Validation Loss: 1.399171 	 time: 0.3
Epoch: 849 	Training Loss: 1.372306 	Validation Loss: 1.399887 	 time: 0.3
Epoch: 850 	Training Loss: 1.373905 	Validation Loss: 1.400682 	 time: 0.3
Epoch: 851 	Training Loss: 1.367306 	Validation Loss: 1.402957 	 time: 0.3
Epoch: 852 	Training Loss: 1.369654 	Validation Loss: 1.406117 	 time: 0.3
Epoch: 853 	Training Loss: 1.369637 	Validation Loss: 1.410502 	 time: 0.3
Epoch: 854 	Training Loss: 1.364697 	Validation Loss: 1.412536 	 time: 0.3
Epoch: 855 	Training Loss: 1.369176 	Validation Loss: 1.413326 	 time: 0.3
Epoch: 856 	Training Loss: 1.366965 	Validation Loss: 1.414574 	 time: 0.3
Epoch: 857 	Training Loss: 1.371884 	Validation Loss: 1.414099 	 time: 0.3
Epoch: 858 	Training Loss: 1.368077 	Validation Loss: 1.414320 	 time: 0.3
Epoch: 859 	Training Loss: 1.371773 	Validation Loss: 1.412166 	 time: 0.3
Epoch: 860 	Training Loss: 1.364987 	Validation Loss: 1.408518 	 time: 0.3
Epoch: 861 	Training Loss: 1.365182 	Validation Loss: 1.403347 	 time: 0.3
Epoch: 862 	Training Loss: 1.368184 	Validation Loss: 1.396964 	 time: 0.3
Epoch: 863 	Training Loss: 1.367889 	Validation Loss: 1.393389 	 time: 0.3
Epoch: 864 	Training Loss: 1.364372 	Validation Loss: 1.391503 	 time: 0.3
Epoch: 865 	Training Loss: 1.365590 	Validation Loss: 1.392446 	 time: 0.3
Epoch: 866 	Training Loss: 1.370809 	Validation Loss: 1.395004 	 time: 0.3
Epoch: 867 	Training Loss: 1.366774 	Validation Loss: 1.396669 	 time: 0.3
Epoch: 868 	Training Loss: 1.368183 	Validation Loss: 1.397801 	 time: 0.3
Epoch: 869 	Training Loss: 1.370495 	Validation Loss: 1.396664 	 time: 0.3
Epoch: 870 	Training Loss: 1.368513 	Validation Loss: 1.392898 	 time: 0.3
Epoch: 871 	Training Loss: 1.368702 	Validation Loss: 1.389671 	 time: 0.3
Epoch: 872 	Training Loss: 1.364611 	Validation Loss: 1.387561 	 time: 0.3
Validation loss decreased from 1.387567 to 1.387561. Model was saved
Epoch: 873 	Training Loss: 1.365864 	Validation Loss: 1.385834 	 time: 0.3
Validation loss decreased from 1.387561 to 1.385834. Model was saved
Epoch: 874 	Training Loss: 1.374877 	Validation Loss: 1.386396 	 time: 0.3
Epoch: 875 	Training Loss: 1.370199 	Validation Loss: 1.388223 	 time: 0.3
Epoch: 876 	Training Loss: 1.361705 	Validation Loss: 1.390599 	 time: 0.3
Epoch: 877 	Training Loss: 1.367792 	Validation Loss: 1.393593 	 time: 0.3
Epoch: 878 	Training Loss: 1.368533 	Validation Loss: 1.395591 	 time: 0.3
Epoch: 879 	Training Loss: 1.367270 	Validation Loss: 1.395435 	 time: 0.3
Epoch: 880 	Training Loss: 1.370045 	Validation Loss: 1.394796 	 time: 0.3
Epoch: 881 	Training Loss: 1.366374 	Validation Loss: 1.395705 	 time: 0.3
Epoch: 882 	Training Loss: 1.366533 	Validation Loss: 1.397305 	 time: 0.3
Epoch: 883 	Training Loss: 1.366345 	Validation Loss: 1.398196 	 time: 0.3
Epoch: 884 	Training Loss: 1.369870 	Validation Loss: 1.397579 	 time: 0.3
Epoch: 885 	Training Loss: 1.369864 	Validation Loss: 1.396282 	 time: 0.3
Epoch: 886 	Training Loss: 1.370030 	Validation Loss: 1.395651 	 time: 0.3
Epoch: 887 	Training Loss: 1.364621 	Validation Loss: 1.395771 	 time: 0.3
Epoch: 888 	Training Loss: 1.367325 	Validation Loss: 1.394810 	 time: 0.3
Epoch: 889 	Training Loss: 1.372102 	Validation Loss: 1.393886 	 time: 0.3
Epoch: 890 	Training Loss: 1.368798 	Validation Loss: 1.391867 	 time: 0.3
Epoch: 891 	Training Loss: 1.367850 	Validation Loss: 1.389139 	 time: 0.3
Epoch: 892 	Training Loss: 1.367954 	Validation Loss: 1.386271 	 time: 0.3
Epoch: 893 	Training Loss: 1.372024 	Validation Loss: 1.383831 	 time: 0.3
Validation loss decreased from 1.385834 to 1.383831. Model was saved
Epoch: 894 	Training Loss: 1.367570 	Validation Loss: 1.382459 	 time: 0.3
Validation loss decreased from 1.383831 to 1.382459. Model was saved
Epoch: 895 	Training Loss: 1.369207 	Validation Loss: 1.381818 	 time: 0.3
Validation loss decreased from 1.382459 to 1.381818. Model was saved
Epoch: 896 	Training Loss: 1.363288 	Validation Loss: 1.379423 	 time: 0.3
Validation loss decreased from 1.381818 to 1.379423. Model was saved
Epoch: 897 	Training Loss: 1.365246 	Validation Loss: 1.378626 	 time: 0.3
Validation loss decreased from 1.379423 to 1.378626. Model was saved
Epoch: 898 	Training Loss: 1.369204 	Validation Loss: 1.378297 	 time: 0.3
Validation loss decreased from 1.378626 to 1.378297. Model was saved
Epoch: 899 	Training Loss: 1.366894 	Validation Loss: 1.377273 	 time: 0.3
Validation loss decreased from 1.378297 to 1.377273. Model was saved
Epoch: 900 	Training Loss: 1.367671 	Validation Loss: 1.377160 	 time: 0.3
Validation loss decreased from 1.377273 to 1.377160. Model was saved
Epoch: 901 	Training Loss: 1.368030 	Validation Loss: 1.377390 	 time: 0.3
Epoch: 902 	Training Loss: 1.364752 	Validation Loss: 1.378079 	 time: 0.3
Epoch: 903 	Training Loss: 1.366614 	Validation Loss: 1.380683 	 time: 0.3
Epoch: 904 	Training Loss: 1.369550 	Validation Loss: 1.386339 	 time: 0.3
Epoch: 905 	Training Loss: 1.373728 	Validation Loss: 1.395538 	 time: 0.3
Epoch: 906 	Training Loss: 1.368088 	Validation Loss: 1.398886 	 time: 0.3
Epoch: 907 	Training Loss: 1.365816 	Validation Loss: 1.401363 	 time: 0.3
Epoch: 908 	Training Loss: 1.362206 	Validation Loss: 1.402736 	 time: 0.3
Epoch: 909 	Training Loss: 1.368137 	Validation Loss: 1.402756 	 time: 0.3
Epoch: 910 	Training Loss: 1.364394 	Validation Loss: 1.402845 	 time: 0.3
Epoch: 911 	Training Loss: 1.373338 	Validation Loss: 1.401230 	 time: 0.3
Epoch: 912 	Training Loss: 1.369960 	Validation Loss: 1.398858 	 time: 0.3
Epoch: 913 	Training Loss: 1.368996 	Validation Loss: 1.394589 	 time: 0.3
Epoch: 914 	Training Loss: 1.364821 	Validation Loss: 1.392128 	 time: 0.3
Epoch: 915 	Training Loss: 1.369582 	Validation Loss: 1.391564 	 time: 0.3
Epoch: 916 	Training Loss: 1.369476 	Validation Loss: 1.392517 	 time: 0.3
Epoch: 917 	Training Loss: 1.373825 	Validation Loss: 1.395521 	 time: 0.3
Epoch: 918 	Training Loss: 1.363828 	Validation Loss: 1.398703 	 time: 0.3
Epoch: 919 	Training Loss: 1.364870 	Validation Loss: 1.401250 	 time: 0.3
Epoch: 920 	Training Loss: 1.368753 	Validation Loss: 1.401313 	 time: 0.3
Epoch: 921 	Training Loss: 1.368147 	Validation Loss: 1.400346 	 time: 0.3
Epoch: 922 	Training Loss: 1.361678 	Validation Loss: 1.399055 	 time: 0.3
Epoch: 923 	Training Loss: 1.375085 	Validation Loss: 1.399145 	 time: 0.3
Epoch: 924 	Training Loss: 1.365272 	Validation Loss: 1.403931 	 time: 0.3
Epoch: 925 	Training Loss: 1.370156 	Validation Loss: 1.406118 	 time: 0.3
Epoch: 926 	Training Loss: 1.370167 	Validation Loss: 1.407721 	 time: 0.3
Epoch: 927 	Training Loss: 1.370079 	Validation Loss: 1.409024 	 time: 0.3
Epoch: 928 	Training Loss: 1.367316 	Validation Loss: 1.407965 	 time: 0.3
Epoch: 929 	Training Loss: 1.364596 	Validation Loss: 1.406268 	 time: 0.3
Epoch: 930 	Training Loss: 1.365730 	Validation Loss: 1.403837 	 time: 0.3
Epoch: 931 	Training Loss: 1.366373 	Validation Loss: 1.402880 	 time: 0.3
Epoch: 932 	Training Loss: 1.367279 	Validation Loss: 1.402052 	 time: 0.3
Epoch: 933 	Training Loss: 1.366973 	Validation Loss: 1.401650 	 time: 0.3
Epoch: 934 	Training Loss: 1.365703 	Validation Loss: 1.403690 	 time: 0.3
Epoch: 935 	Training Loss: 1.371773 	Validation Loss: 1.403621 	 time: 0.3
Epoch: 936 	Training Loss: 1.368141 	Validation Loss: 1.400413 	 time: 0.3
Epoch: 937 	Training Loss: 1.366485 	Validation Loss: 1.398467 	 time: 0.3
Epoch: 938 	Training Loss: 1.361053 	Validation Loss: 1.398916 	 time: 0.3
Epoch: 939 	Training Loss: 1.363612 	Validation Loss: 1.401023 	 time: 0.3
Epoch: 940 	Training Loss: 1.368322 	Validation Loss: 1.402576 	 time: 0.3
Epoch: 941 	Training Loss: 1.363765 	Validation Loss: 1.403944 	 time: 0.3
Epoch: 942 	Training Loss: 1.366796 	Validation Loss: 1.406603 	 time: 0.3
Epoch: 943 	Training Loss: 1.364702 	Validation Loss: 1.408741 	 time: 0.3
Epoch: 944 	Training Loss: 1.365670 	Validation Loss: 1.411024 	 time: 0.3
Epoch: 945 	Training Loss: 1.364946 	Validation Loss: 1.412545 	 time: 0.3
Epoch: 946 	Training Loss: 1.367485 	Validation Loss: 1.413073 	 time: 0.3
Epoch: 947 	Training Loss: 1.359214 	Validation Loss: 1.412486 	 time: 0.3
Epoch: 948 	Training Loss: 1.361131 	Validation Loss: 1.411083 	 time: 0.3
Epoch: 949 	Training Loss: 1.359171 	Validation Loss: 1.408789 	 time: 0.3
Epoch: 950 	Training Loss: 1.367080 	Validation Loss: 1.406184 	 time: 0.3
Epoch: 951 	Training Loss: 1.365630 	Validation Loss: 1.405028 	 time: 0.3
Epoch: 952 	Training Loss: 1.368212 	Validation Loss: 1.404339 	 time: 0.3
Epoch: 953 	Training Loss: 1.368144 	Validation Loss: 1.404940 	 time: 0.3
Epoch: 954 	Training Loss: 1.366497 	Validation Loss: 1.406710 	 time: 0.3
Epoch: 955 	Training Loss: 1.364936 	Validation Loss: 1.407851 	 time: 0.3
Epoch: 956 	Training Loss: 1.362164 	Validation Loss: 1.407410 	 time: 0.3
Epoch: 957 	Training Loss: 1.362483 	Validation Loss: 1.405072 	 time: 0.3
Epoch: 958 	Training Loss: 1.367306 	Validation Loss: 1.403964 	 time: 0.3
Epoch: 959 	Training Loss: 1.364810 	Validation Loss: 1.401060 	 time: 0.3
Epoch: 960 	Training Loss: 1.373399 	Validation Loss: 1.396784 	 time: 0.3
Epoch: 961 	Training Loss: 1.366289 	Validation Loss: 1.393836 	 time: 0.3
Epoch: 962 	Training Loss: 1.365998 	Validation Loss: 1.392638 	 time: 0.3
Epoch: 963 	Training Loss: 1.363303 	Validation Loss: 1.392157 	 time: 0.3
Epoch: 964 	Training Loss: 1.362158 	Validation Loss: 1.392904 	 time: 0.3
Epoch: 965 	Training Loss: 1.365253 	Validation Loss: 1.394449 	 time: 0.3
Epoch: 966 	Training Loss: 1.366515 	Validation Loss: 1.393334 	 time: 0.3
Epoch: 967 	Training Loss: 1.365268 	Validation Loss: 1.391758 	 time: 0.3
Epoch: 968 	Training Loss: 1.363844 	Validation Loss: 1.389401 	 time: 0.3
Epoch: 969 	Training Loss: 1.371282 	Validation Loss: 1.388402 	 time: 0.3
Epoch: 970 	Training Loss: 1.364990 	Validation Loss: 1.388221 	 time: 0.3
Epoch: 971 	Training Loss: 1.363481 	Validation Loss: 1.389253 	 time: 0.3
Epoch: 972 	Training Loss: 1.369881 	Validation Loss: 1.392216 	 time: 0.3
Epoch: 973 	Training Loss: 1.366668 	Validation Loss: 1.395686 	 time: 0.3
Epoch: 974 	Training Loss: 1.366154 	Validation Loss: 1.400196 	 time: 0.3
Epoch: 975 	Training Loss: 1.371257 	Validation Loss: 1.402416 	 time: 0.3
Epoch: 976 	Training Loss: 1.363664 	Validation Loss: 1.403486 	 time: 0.3
Epoch: 977 	Training Loss: 1.364970 	Validation Loss: 1.402670 	 time: 0.3
Epoch: 978 	Training Loss: 1.371480 	Validation Loss: 1.402821 	 time: 0.3
Epoch: 979 	Training Loss: 1.369278 	Validation Loss: 1.402347 	 time: 0.3
Epoch: 980 	Training Loss: 1.361830 	Validation Loss: 1.401076 	 time: 0.3
Epoch: 981 	Training Loss: 1.369331 	Validation Loss: 1.398736 	 time: 0.3
Epoch: 982 	Training Loss: 1.363977 	Validation Loss: 1.395889 	 time: 0.3
Epoch: 983 	Training Loss: 1.366125 	Validation Loss: 1.393296 	 time: 0.3
Epoch: 984 	Training Loss: 1.364573 	Validation Loss: 1.391307 	 time: 0.3
Epoch: 985 	Training Loss: 1.368133 	Validation Loss: 1.388901 	 time: 0.3
Epoch: 986 	Training Loss: 1.365261 	Validation Loss: 1.387749 	 time: 0.3
Epoch: 987 	Training Loss: 1.364322 	Validation Loss: 1.386453 	 time: 0.3
Epoch: 988 	Training Loss: 1.363704 	Validation Loss: 1.385233 	 time: 0.3
Epoch: 989 	Training Loss: 1.364844 	Validation Loss: 1.384183 	 time: 0.3
Epoch: 990 	Training Loss: 1.366556 	Validation Loss: 1.383874 	 time: 0.3
Epoch: 991 	Training Loss: 1.364720 	Validation Loss: 1.385067 	 time: 0.3
Epoch: 992 	Training Loss: 1.364586 	Validation Loss: 1.387841 	 time: 0.3
Epoch: 993 	Training Loss: 1.366226 	Validation Loss: 1.391585 	 time: 0.3
Epoch: 994 	Training Loss: 1.366155 	Validation Loss: 1.393291 	 time: 0.3
Epoch: 995 	Training Loss: 1.362960 	Validation Loss: 1.391504 	 time: 0.3
Epoch: 996 	Training Loss: 1.368460 	Validation Loss: 1.389890 	 time: 0.3
Epoch: 997 	Training Loss: 1.368615 	Validation Loss: 1.386814 	 time: 0.3
Epoch: 998 	Training Loss: 1.363264 	Validation Loss: 1.384561 	 time: 0.3
Epoch: 999 	Training Loss: 1.365981 	Validation Loss: 1.384377 	 time: 0.3
Epoch: 1000 	Training Loss: 1.362718 	Validation Loss: 1.386396 	 time: 0.3
Epoch: 1001 	Training Loss: 1.362989 	Validation Loss: 1.389137 	 time: 0.3
Epoch: 1002 	Training Loss: 1.368715 	Validation Loss: 1.390456 	 time: 0.3
Epoch: 1003 	Training Loss: 1.364505 	Validation Loss: 1.390528 	 time: 0.3
Epoch: 1004 	Training Loss: 1.363932 	Validation Loss: 1.390814 	 time: 0.3
Epoch: 1005 	Training Loss: 1.367347 	Validation Loss: 1.391791 	 time: 0.3
Epoch: 1006 	Training Loss: 1.364314 	Validation Loss: 1.392973 	 time: 0.3
Epoch: 1007 	Training Loss: 1.364751 	Validation Loss: 1.393096 	 time: 0.3
Epoch: 1008 	Training Loss: 1.367459 	Validation Loss: 1.391020 	 time: 0.3
Epoch: 1009 	Training Loss: 1.363182 	Validation Loss: 1.387832 	 time: 0.3
Epoch: 1010 	Training Loss: 1.364922 	Validation Loss: 1.384377 	 time: 0.3
Epoch: 1011 	Training Loss: 1.363846 	Validation Loss: 1.382751 	 time: 0.3
Epoch: 1012 	Training Loss: 1.366452 	Validation Loss: 1.382073 	 time: 0.3
Epoch: 1013 	Training Loss: 1.369531 	Validation Loss: 1.381226 	 time: 0.3
Epoch: 1014 	Training Loss: 1.365121 	Validation Loss: 1.379000 	 time: 0.3
Epoch: 1015 	Training Loss: 1.367301 	Validation Loss: 1.377103 	 time: 0.3
Validation loss decreased from 1.377160 to 1.377103. Model was saved
Epoch: 1016 	Training Loss: 1.367277 	Validation Loss: 1.375565 	 time: 0.3
Validation loss decreased from 1.377103 to 1.375565. Model was saved
Epoch: 1017 	Training Loss: 1.367358 	Validation Loss: 1.375682 	 time: 0.3
Epoch: 1018 	Training Loss: 1.369830 	Validation Loss: 1.375778 	 time: 0.3
Epoch: 1019 	Training Loss: 1.371334 	Validation Loss: 1.377082 	 time: 0.3
Epoch: 1020 	Training Loss: 1.367106 	Validation Loss: 1.377597 	 time: 0.3
Epoch: 1021 	Training Loss: 1.362903 	Validation Loss: 1.377786 	 time: 0.3
Epoch: 1022 	Training Loss: 1.369840 	Validation Loss: 1.377078 	 time: 0.3
Epoch: 1023 	Training Loss: 1.360553 	Validation Loss: 1.375750 	 time: 0.3
Epoch: 1024 	Training Loss: 1.368430 	Validation Loss: 1.376228 	 time: 0.3
Epoch: 1025 	Training Loss: 1.362808 	Validation Loss: 1.378352 	 time: 0.3
Epoch: 1026 	Training Loss: 1.374244 	Validation Loss: 1.382209 	 time: 0.3
Epoch: 1027 	Training Loss: 1.367051 	Validation Loss: 1.385771 	 time: 0.3
Epoch: 1028 	Training Loss: 1.367038 	Validation Loss: 1.388963 	 time: 0.3
Epoch: 1029 	Training Loss: 1.363040 	Validation Loss: 1.391004 	 time: 0.3
Epoch: 1030 	Training Loss: 1.367049 	Validation Loss: 1.393122 	 time: 0.3
Epoch: 1031 	Training Loss: 1.361794 	Validation Loss: 1.396990 	 time: 0.3
Epoch: 1032 	Training Loss: 1.362675 	Validation Loss: 1.399109 	 time: 0.3
Epoch: 1033 	Training Loss: 1.368496 	Validation Loss: 1.397900 	 time: 0.3
Epoch: 1034 	Training Loss: 1.368516 	Validation Loss: 1.395087 	 time: 0.3
Epoch: 1035 	Training Loss: 1.361075 	Validation Loss: 1.392618 	 time: 0.3
Epoch: 1036 	Training Loss: 1.365500 	Validation Loss: 1.390086 	 time: 0.3
Epoch: 1037 	Training Loss: 1.364051 	Validation Loss: 1.387612 	 time: 0.3
Epoch: 1038 	Training Loss: 1.364409 	Validation Loss: 1.385278 	 time: 0.3
Epoch: 1039 	Training Loss: 1.355465 	Validation Loss: 1.383107 	 time: 0.3
Epoch: 1040 	Training Loss: 1.360760 	Validation Loss: 1.381459 	 time: 0.3
Epoch: 1041 	Training Loss: 1.365443 	Validation Loss: 1.382316 	 time: 0.3
Epoch: 1042 	Training Loss: 1.365542 	Validation Loss: 1.382351 	 time: 0.3
Epoch: 1043 	Training Loss: 1.363492 	Validation Loss: 1.383211 	 time: 0.3
Epoch: 1044 	Training Loss: 1.367676 	Validation Loss: 1.383099 	 time: 0.3
Epoch: 1045 	Training Loss: 1.363297 	Validation Loss: 1.384259 	 time: 0.3
Epoch: 1046 	Training Loss: 1.366214 	Validation Loss: 1.385958 	 time: 0.3
Epoch: 1047 	Training Loss: 1.359308 	Validation Loss: 1.387548 	 time: 0.3
Epoch: 1048 	Training Loss: 1.366391 	Validation Loss: 1.387695 	 time: 0.3
Epoch: 1049 	Training Loss: 1.363993 	Validation Loss: 1.387870 	 time: 0.3
Epoch: 1050 	Training Loss: 1.367454 	Validation Loss: 1.389159 	 time: 0.3
Epoch: 1051 	Training Loss: 1.362323 	Validation Loss: 1.390820 	 time: 0.3
Epoch: 1052 	Training Loss: 1.363177 	Validation Loss: 1.391484 	 time: 0.3
Epoch: 1053 	Training Loss: 1.361809 	Validation Loss: 1.391899 	 time: 0.3
Epoch: 1054 	Training Loss: 1.367427 	Validation Loss: 1.393799 	 time: 0.3
Epoch: 1055 	Training Loss: 1.365997 	Validation Loss: 1.395165 	 time: 0.3
Epoch: 1056 	Training Loss: 1.367520 	Validation Loss: 1.395741 	 time: 0.3
Epoch: 1057 	Training Loss: 1.365610 	Validation Loss: 1.397741 	 time: 0.3
Epoch: 1058 	Training Loss: 1.367963 	Validation Loss: 1.399552 	 time: 0.3
Epoch: 1059 	Training Loss: 1.362973 	Validation Loss: 1.399717 	 time: 0.3
Epoch: 1060 	Training Loss: 1.367234 	Validation Loss: 1.399357 	 time: 0.3
Epoch: 1061 	Training Loss: 1.367867 	Validation Loss: 1.398350 	 time: 0.3
Epoch: 1062 	Training Loss: 1.363924 	Validation Loss: 1.397985 	 time: 0.3
Epoch: 1063 	Training Loss: 1.369250 	Validation Loss: 1.397942 	 time: 0.3
Epoch: 1064 	Training Loss: 1.364347 	Validation Loss: 1.397179 	 time: 0.3
Epoch: 1065 	Training Loss: 1.361539 	Validation Loss: 1.395032 	 time: 0.3
Epoch: 1066 	Training Loss: 1.364811 	Validation Loss: 1.393488 	 time: 0.3
Epoch: 1067 	Training Loss: 1.365216 	Validation Loss: 1.392692 	 time: 0.3
Epoch: 1068 	Training Loss: 1.367298 	Validation Loss: 1.392538 	 time: 0.3
Epoch: 1069 	Training Loss: 1.369427 	Validation Loss: 1.392491 	 time: 0.3
Epoch: 1070 	Training Loss: 1.365172 	Validation Loss: 1.392443 	 time: 0.3
Epoch: 1071 	Training Loss: 1.368643 	Validation Loss: 1.391578 	 time: 0.3
Epoch: 1072 	Training Loss: 1.363848 	Validation Loss: 1.390173 	 time: 0.3
Epoch: 1073 	Training Loss: 1.367813 	Validation Loss: 1.389588 	 time: 0.3
Epoch: 1074 	Training Loss: 1.367011 	Validation Loss: 1.389755 	 time: 0.3
Epoch: 1075 	Training Loss: 1.365182 	Validation Loss: 1.390777 	 time: 0.3
Epoch: 1076 	Training Loss: 1.363496 	Validation Loss: 1.391374 	 time: 0.2
Epoch: 1077 	Training Loss: 1.363832 	Validation Loss: 1.390208 	 time: 0.3
Epoch: 1078 	Training Loss: 1.359892 	Validation Loss: 1.388013 	 time: 0.3
Epoch: 1079 	Training Loss: 1.364850 	Validation Loss: 1.386137 	 time: 0.3
Epoch: 1080 	Training Loss: 1.363090 	Validation Loss: 1.383188 	 time: 0.3
Epoch: 1081 	Training Loss: 1.367136 	Validation Loss: 1.380567 	 time: 0.3
Epoch: 1082 	Training Loss: 1.368962 	Validation Loss: 1.378495 	 time: 0.3
Epoch: 1083 	Training Loss: 1.365799 	Validation Loss: 1.377053 	 time: 0.3
Epoch: 1084 	Training Loss: 1.361477 	Validation Loss: 1.376408 	 time: 0.3
Epoch: 1085 	Training Loss: 1.365666 	Validation Loss: 1.377175 	 time: 0.3
Epoch: 1086 	Training Loss: 1.363832 	Validation Loss: 1.379225 	 time: 0.3
Epoch: 1087 	Training Loss: 1.365690 	Validation Loss: 1.381580 	 time: 0.3
Epoch: 1088 	Training Loss: 1.367320 	Validation Loss: 1.384787 	 time: 0.3
Epoch: 1089 	Training Loss: 1.358946 	Validation Loss: 1.388255 	 time: 0.3
Epoch: 1090 	Training Loss: 1.363027 	Validation Loss: 1.391104 	 time: 0.3
Epoch: 1091 	Training Loss: 1.368581 	Validation Loss: 1.392814 	 time: 0.3
Epoch: 1092 	Training Loss: 1.362125 	Validation Loss: 1.394159 	 time: 0.3
Epoch: 1093 	Training Loss: 1.366075 	Validation Loss: 1.394877 	 time: 0.3
Epoch: 1094 	Training Loss: 1.364525 	Validation Loss: 1.396542 	 time: 0.3
Epoch: 1095 	Training Loss: 1.369041 	Validation Loss: 1.396399 	 time: 0.3
Epoch: 1096 	Training Loss: 1.367197 	Validation Loss: 1.394533 	 time: 0.3
Epoch: 1097 	Training Loss: 1.364681 	Validation Loss: 1.392750 	 time: 0.3
Epoch: 1098 	Training Loss: 1.364538 	Validation Loss: 1.392826 	 time: 0.3
Epoch: 1099 	Training Loss: 1.372625 	Validation Loss: 1.392361 	 time: 0.3
Epoch: 1100 	Training Loss: 1.361989 	Validation Loss: 1.392779 	 time: 0.3
Epoch: 1101 	Training Loss: 1.366123 	Validation Loss: 1.391546 	 time: 0.3
Epoch: 1102 	Training Loss: 1.363567 	Validation Loss: 1.388739 	 time: 0.3
Epoch: 1103 	Training Loss: 1.367181 	Validation Loss: 1.385491 	 time: 0.3
Epoch: 1104 	Training Loss: 1.364350 	Validation Loss: 1.383878 	 time: 0.3
Epoch: 1105 	Training Loss: 1.360497 	Validation Loss: 1.383918 	 time: 0.3
Epoch: 1106 	Training Loss: 1.363983 	Validation Loss: 1.384648 	 time: 0.3
Epoch: 1107 	Training Loss: 1.364573 	Validation Loss: 1.385544 	 time: 0.3
Epoch: 1108 	Training Loss: 1.365708 	Validation Loss: 1.386275 	 time: 0.3
Epoch: 1109 	Training Loss: 1.361354 	Validation Loss: 1.386729 	 time: 0.3
Epoch: 1110 	Training Loss: 1.364592 	Validation Loss: 1.388006 	 time: 0.3
Epoch: 1111 	Training Loss: 1.360560 	Validation Loss: 1.389443 	 time: 0.3
Epoch: 1112 	Training Loss: 1.362647 	Validation Loss: 1.390323 	 time: 0.3
Epoch: 1113 	Training Loss: 1.368426 	Validation Loss: 1.392346 	 time: 0.3
Epoch: 1114 	Training Loss: 1.359632 	Validation Loss: 1.393851 	 time: 0.3
Epoch: 1115 	Training Loss: 1.359860 	Validation Loss: 1.394295 	 time: 0.3
Epoch: 1116 	Training Loss: 1.362323 	Validation Loss: 1.391988 	 time: 0.3
Epoch: 1117 	Training Loss: 1.362986 	Validation Loss: 1.388323 	 time: 0.3
Epoch: 1118 	Training Loss: 1.362872 	Validation Loss: 1.385502 	 time: 0.3
Epoch: 1119 	Training Loss: 1.359553 	Validation Loss: 1.384716 	 time: 0.3
Epoch: 1120 	Training Loss: 1.367713 	Validation Loss: 1.384384 	 time: 0.3
Epoch: 1121 	Training Loss: 1.364703 	Validation Loss: 1.384260 	 time: 0.3
Epoch: 1122 	Training Loss: 1.365414 	Validation Loss: 1.384421 	 time: 0.3
Epoch: 1123 	Training Loss: 1.365929 	Validation Loss: 1.383719 	 time: 0.3
Epoch: 1124 	Training Loss: 1.366649 	Validation Loss: 1.381931 	 time: 0.3
Epoch: 1125 	Training Loss: 1.363118 	Validation Loss: 1.380383 	 time: 0.3
Epoch: 1126 	Training Loss: 1.363196 	Validation Loss: 1.378206 	 time: 0.3
Epoch: 1127 	Training Loss: 1.366935 	Validation Loss: 1.375532 	 time: 0.3
Validation loss decreased from 1.375565 to 1.375532. Model was saved
Epoch: 1128 	Training Loss: 1.363332 	Validation Loss: 1.373281 	 time: 0.3
Validation loss decreased from 1.375532 to 1.373281. Model was saved
Epoch: 1129 	Training Loss: 1.362943 	Validation Loss: 1.371620 	 time: 0.3
Validation loss decreased from 1.373281 to 1.371620. Model was saved
Epoch: 1130 	Training Loss: 1.365256 	Validation Loss: 1.371327 	 time: 0.3
Validation loss decreased from 1.371620 to 1.371327. Model was saved
Epoch: 1131 	Training Loss: 1.364383 	Validation Loss: 1.370167 	 time: 0.3
Validation loss decreased from 1.371327 to 1.370167. Model was saved
Epoch: 1132 	Training Loss: 1.368251 	Validation Loss: 1.368562 	 time: 0.3
Validation loss decreased from 1.370167 to 1.368562. Model was saved
Epoch: 1133 	Training Loss: 1.365942 	Validation Loss: 1.365698 	 time: 0.3
Validation loss decreased from 1.368562 to 1.365698. Model was saved
Epoch: 1134 	Training Loss: 1.362215 	Validation Loss: 1.364481 	 time: 0.3
Validation loss decreased from 1.365698 to 1.364481. Model was saved
Epoch: 1135 	Training Loss: 1.359675 	Validation Loss: 1.364756 	 time: 0.3
Epoch: 1136 	Training Loss: 1.361970 	Validation Loss: 1.365326 	 time: 0.3
Epoch: 1137 	Training Loss: 1.363485 	Validation Loss: 1.367346 	 time: 0.3
Epoch: 1138 	Training Loss: 1.362476 	Validation Loss: 1.369997 	 time: 0.3
Epoch: 1139 	Training Loss: 1.365891 	Validation Loss: 1.371376 	 time: 0.3
Epoch: 1140 	Training Loss: 1.366287 	Validation Loss: 1.371850 	 time: 0.3
Epoch: 1141 	Training Loss: 1.369229 	Validation Loss: 1.371621 	 time: 0.3
Epoch: 1142 	Training Loss: 1.361697 	Validation Loss: 1.371649 	 time: 0.3
Epoch: 1143 	Training Loss: 1.367937 	Validation Loss: 1.370522 	 time: 0.3
Epoch: 1144 	Training Loss: 1.367111 	Validation Loss: 1.367507 	 time: 0.3
Epoch: 1145 	Training Loss: 1.365376 	Validation Loss: 1.366042 	 time: 0.3
Epoch: 1146 	Training Loss: 1.360884 	Validation Loss: 1.364884 	 time: 0.3
Epoch: 1147 	Training Loss: 1.365024 	Validation Loss: 1.364297 	 time: 0.3
Validation loss decreased from 1.364481 to 1.364297. Model was saved
Epoch: 1148 	Training Loss: 1.360365 	Validation Loss: 1.364255 	 time: 0.3
Validation loss decreased from 1.364297 to 1.364255. Model was saved
Epoch: 1149 	Training Loss: 1.367813 	Validation Loss: 1.366332 	 time: 0.3
Epoch: 1150 	Training Loss: 1.367496 	Validation Loss: 1.369139 	 time: 0.3
Epoch: 1151 	Training Loss: 1.365393 	Validation Loss: 1.372414 	 time: 0.3
Epoch: 1152 	Training Loss: 1.364897 	Validation Loss: 1.375698 	 time: 0.3
Epoch: 1153 	Training Loss: 1.361958 	Validation Loss: 1.378295 	 time: 0.3
Epoch: 1154 	Training Loss: 1.363833 	Validation Loss: 1.380262 	 time: 0.3
Epoch: 1155 	Training Loss: 1.362790 	Validation Loss: 1.380048 	 time: 0.3
Epoch: 1156 	Training Loss: 1.362971 	Validation Loss: 1.378793 	 time: 0.3
Epoch: 1157 	Training Loss: 1.364421 	Validation Loss: 1.376173 	 time: 0.3
Epoch: 1158 	Training Loss: 1.369795 	Validation Loss: 1.374160 	 time: 0.3
Epoch: 1159 	Training Loss: 1.367131 	Validation Loss: 1.372700 	 time: 0.3
Epoch: 1160 	Training Loss: 1.363035 	Validation Loss: 1.372032 	 time: 0.3
Epoch: 1161 	Training Loss: 1.363528 	Validation Loss: 1.372118 	 time: 0.3
Epoch: 1162 	Training Loss: 1.360348 	Validation Loss: 1.372689 	 time: 0.3
Epoch: 1163 	Training Loss: 1.365689 	Validation Loss: 1.374840 	 time: 0.3
Epoch: 1164 	Training Loss: 1.361642 	Validation Loss: 1.377611 	 time: 0.3
Epoch: 1165 	Training Loss: 1.362738 	Validation Loss: 1.380171 	 time: 0.3
Epoch: 1166 	Training Loss: 1.367725 	Validation Loss: 1.381280 	 time: 0.3
Epoch: 1167 	Training Loss: 1.368326 	Validation Loss: 1.381535 	 time: 0.3
Epoch: 1168 	Training Loss: 1.360651 	Validation Loss: 1.381288 	 time: 0.3
Epoch: 1169 	Training Loss: 1.364873 	Validation Loss: 1.378625 	 time: 0.3
Epoch: 1170 	Training Loss: 1.364537 	Validation Loss: 1.377602 	 time: 0.3
Epoch: 1171 	Training Loss: 1.362039 	Validation Loss: 1.377900 	 time: 0.3
Epoch: 1172 	Training Loss: 1.361601 	Validation Loss: 1.377853 	 time: 0.3
Epoch: 1173 	Training Loss: 1.364148 	Validation Loss: 1.378834 	 time: 0.3
Epoch: 1174 	Training Loss: 1.363536 	Validation Loss: 1.383699 	 time: 0.3
Epoch: 1175 	Training Loss: 1.362028 	Validation Loss: 1.387573 	 time: 0.3
Epoch: 1176 	Training Loss: 1.357921 	Validation Loss: 1.388046 	 time: 0.3
Epoch: 1177 	Training Loss: 1.363438 	Validation Loss: 1.386896 	 time: 0.3
Epoch: 1178 	Training Loss: 1.364832 	Validation Loss: 1.386134 	 time: 0.3
Epoch: 1179 	Training Loss: 1.366919 	Validation Loss: 1.385359 	 time: 0.3
Epoch: 1180 	Training Loss: 1.360337 	Validation Loss: 1.384486 	 time: 0.3
Epoch: 1181 	Training Loss: 1.369107 	Validation Loss: 1.382594 	 time: 0.3
Epoch: 1182 	Training Loss: 1.363719 	Validation Loss: 1.379019 	 time: 0.3
Epoch: 1183 	Training Loss: 1.368976 	Validation Loss: 1.374349 	 time: 0.3
Epoch: 1184 	Training Loss: 1.363418 	Validation Loss: 1.370837 	 time: 0.3
Epoch: 1185 	Training Loss: 1.361365 	Validation Loss: 1.368034 	 time: 0.3
Epoch: 1186 	Training Loss: 1.360870 	Validation Loss: 1.366529 	 time: 0.3
Epoch: 1187 	Training Loss: 1.359295 	Validation Loss: 1.368260 	 time: 0.3
Epoch: 1188 	Training Loss: 1.361625 	Validation Loss: 1.371358 	 time: 0.3
Epoch: 1189 	Training Loss: 1.366357 	Validation Loss: 1.372909 	 time: 0.3
Epoch: 1190 	Training Loss: 1.360353 	Validation Loss: 1.373763 	 time: 0.3
Epoch: 1191 	Training Loss: 1.363454 	Validation Loss: 1.374809 	 time: 0.3
Epoch: 1192 	Training Loss: 1.365828 	Validation Loss: 1.375759 	 time: 0.3
Epoch: 1193 	Training Loss: 1.362928 	Validation Loss: 1.377008 	 time: 0.3
Epoch: 1194 	Training Loss: 1.369351 	Validation Loss: 1.377507 	 time: 0.3
Epoch: 1195 	Training Loss: 1.362555 	Validation Loss: 1.378221 	 time: 0.3
Epoch: 1196 	Training Loss: 1.359266 	Validation Loss: 1.378253 	 time: 0.3
Epoch: 1197 	Training Loss: 1.360224 	Validation Loss: 1.376430 	 time: 0.3
Epoch: 1198 	Training Loss: 1.361710 	Validation Loss: 1.373427 	 time: 0.3
Epoch: 1199 	Training Loss: 1.361294 	Validation Loss: 1.372699 	 time: 0.3
Epoch: 1200 	Training Loss: 1.365205 	Validation Loss: 1.374980 	 time: 0.3
Epoch: 1201 	Training Loss: 1.363050 	Validation Loss: 1.377560 	 time: 0.3
Epoch: 1202 	Training Loss: 1.360976 	Validation Loss: 1.377647 	 time: 0.3
Epoch: 1203 	Training Loss: 1.364701 	Validation Loss: 1.374802 	 time: 0.3
Epoch: 1204 	Training Loss: 1.363655 	Validation Loss: 1.372215 	 time: 0.3
Epoch: 1205 	Training Loss: 1.360991 	Validation Loss: 1.370543 	 time: 0.3
Epoch: 1206 	Training Loss: 1.361694 	Validation Loss: 1.369719 	 time: 0.3
Epoch: 1207 	Training Loss: 1.360123 	Validation Loss: 1.369177 	 time: 0.3
Epoch: 1208 	Training Loss: 1.360106 	Validation Loss: 1.369724 	 time: 0.3
Epoch: 1209 	Training Loss: 1.367528 	Validation Loss: 1.371360 	 time: 0.3
Epoch: 1210 	Training Loss: 1.360911 	Validation Loss: 1.374182 	 time: 0.3
Epoch: 1211 	Training Loss: 1.362477 	Validation Loss: 1.376354 	 time: 0.3
Epoch: 1212 	Training Loss: 1.366129 	Validation Loss: 1.378543 	 time: 0.3
Epoch: 1213 	Training Loss: 1.364519 	Validation Loss: 1.383121 	 time: 0.3
Epoch: 1214 	Training Loss: 1.362219 	Validation Loss: 1.388763 	 time: 0.3
Epoch: 1215 	Training Loss: 1.359993 	Validation Loss: 1.394676 	 time: 0.3
Epoch: 1216 	Training Loss: 1.361688 	Validation Loss: 1.399107 	 time: 0.3
Epoch: 1217 	Training Loss: 1.364690 	Validation Loss: 1.402291 	 time: 0.3
Epoch: 1218 	Training Loss: 1.362973 	Validation Loss: 1.407026 	 time: 0.3
Epoch: 1219 	Training Loss: 1.366202 	Validation Loss: 1.409285 	 time: 0.3
Epoch: 1220 	Training Loss: 1.361758 	Validation Loss: 1.408854 	 time: 0.3
Epoch: 1221 	Training Loss: 1.354516 	Validation Loss: 1.407667 	 time: 0.3
Epoch: 1222 	Training Loss: 1.361104 	Validation Loss: 1.404660 	 time: 0.3
Epoch: 1223 	Training Loss: 1.362531 	Validation Loss: 1.399308 	 time: 0.3
Epoch: 1224 	Training Loss: 1.362877 	Validation Loss: 1.395887 	 time: 0.3
Epoch: 1225 	Training Loss: 1.358107 	Validation Loss: 1.393929 	 time: 0.3
Epoch: 1226 	Training Loss: 1.362392 	Validation Loss: 1.392045 	 time: 0.3
Epoch: 1227 	Training Loss: 1.368299 	Validation Loss: 1.389184 	 time: 0.3
Epoch: 1228 	Training Loss: 1.362345 	Validation Loss: 1.386036 	 time: 0.3
Epoch: 1229 	Training Loss: 1.368372 	Validation Loss: 1.383228 	 time: 0.3
Epoch: 1230 	Training Loss: 1.360006 	Validation Loss: 1.379436 	 time: 0.3
Epoch: 1231 	Training Loss: 1.365587 	Validation Loss: 1.376733 	 time: 0.3
Epoch: 1232 	Training Loss: 1.359021 	Validation Loss: 1.374475 	 time: 0.3
Epoch: 1233 	Training Loss: 1.363254 	Validation Loss: 1.371785 	 time: 0.3
Epoch: 1234 	Training Loss: 1.366844 	Validation Loss: 1.368638 	 time: 0.3
Epoch: 1235 	Training Loss: 1.363107 	Validation Loss: 1.366978 	 time: 0.3
Epoch: 1236 	Training Loss: 1.362375 	Validation Loss: 1.365659 	 time: 0.3
Epoch: 1237 	Training Loss: 1.368009 	Validation Loss: 1.364524 	 time: 0.3
Epoch: 1238 	Training Loss: 1.362138 	Validation Loss: 1.365517 	 time: 0.3
Epoch: 1239 	Training Loss: 1.359999 	Validation Loss: 1.366620 	 time: 0.3
Epoch: 1240 	Training Loss: 1.361265 	Validation Loss: 1.370013 	 time: 0.3
Epoch: 1241 	Training Loss: 1.362604 	Validation Loss: 1.373383 	 time: 0.3
Epoch: 1242 	Training Loss: 1.362436 	Validation Loss: 1.374941 	 time: 0.3
Epoch: 1243 	Training Loss: 1.358872 	Validation Loss: 1.376278 	 time: 0.3
Epoch: 1244 	Training Loss: 1.368891 	Validation Loss: 1.377749 	 time: 0.3
Epoch: 1245 	Training Loss: 1.363176 	Validation Loss: 1.380384 	 time: 0.3
Epoch: 1246 	Training Loss: 1.358585 	Validation Loss: 1.381909 	 time: 0.3
Epoch: 1247 	Training Loss: 1.361439 	Validation Loss: 1.384055 	 time: 0.3
Epoch: 1248 	Training Loss: 1.362587 	Validation Loss: 1.386051 	 time: 0.3
Epoch: 1249 	Training Loss: 1.360390 	Validation Loss: 1.387344 	 time: 0.3
Epoch: 1250 	Training Loss: 1.364740 	Validation Loss: 1.389190 	 time: 0.3
Epoch: 1251 	Training Loss: 1.358584 	Validation Loss: 1.391251 	 time: 0.3
Epoch: 1252 	Training Loss: 1.360417 	Validation Loss: 1.393389 	 time: 0.3
Epoch: 1253 	Training Loss: 1.362000 	Validation Loss: 1.396025 	 time: 0.3
Epoch: 1254 	Training Loss: 1.365495 	Validation Loss: 1.396625 	 time: 0.3
Epoch: 1255 	Training Loss: 1.363698 	Validation Loss: 1.395089 	 time: 0.3
Epoch: 1256 	Training Loss: 1.357672 	Validation Loss: 1.394219 	 time: 0.3
Epoch: 1257 	Training Loss: 1.364969 	Validation Loss: 1.394393 	 time: 0.3
Epoch: 1258 	Training Loss: 1.365919 	Validation Loss: 1.395579 	 time: 0.3
Epoch: 1259 	Training Loss: 1.362528 	Validation Loss: 1.397973 	 time: 0.3
Epoch: 1260 	Training Loss: 1.361845 	Validation Loss: 1.399827 	 time: 0.3
Epoch: 1261 	Training Loss: 1.363563 	Validation Loss: 1.397228 	 time: 0.3
Epoch: 1262 	Training Loss: 1.360252 	Validation Loss: 1.393882 	 time: 0.3
Epoch: 1263 	Training Loss: 1.360472 	Validation Loss: 1.389998 	 time: 0.3
Epoch: 1264 	Training Loss: 1.361382 	Validation Loss: 1.386393 	 time: 0.3
Epoch: 1265 	Training Loss: 1.361080 	Validation Loss: 1.382359 	 time: 0.3
Epoch: 1266 	Training Loss: 1.363338 	Validation Loss: 1.379694 	 time: 0.3
Epoch: 1267 	Training Loss: 1.364833 	Validation Loss: 1.378097 	 time: 0.3
Epoch: 1268 	Training Loss: 1.370775 	Validation Loss: 1.380155 	 time: 0.3
Epoch: 1269 	Training Loss: 1.363028 	Validation Loss: 1.382995 	 time: 0.3
Epoch: 1270 	Training Loss: 1.357710 	Validation Loss: 1.383805 	 time: 0.3
Epoch: 1271 	Training Loss: 1.361068 	Validation Loss: 1.382785 	 time: 0.3
Epoch: 1272 	Training Loss: 1.358563 	Validation Loss: 1.382752 	 time: 0.3
Epoch: 1273 	Training Loss: 1.358030 	Validation Loss: 1.383838 	 time: 0.3
Epoch: 1274 	Training Loss: 1.360762 	Validation Loss: 1.385467 	 time: 0.3
Epoch: 1275 	Training Loss: 1.363151 	Validation Loss: 1.385013 	 time: 0.3
Epoch: 1276 	Training Loss: 1.361739 	Validation Loss: 1.384136 	 time: 0.3
Epoch: 1277 	Training Loss: 1.363516 	Validation Loss: 1.383684 	 time: 0.3
Epoch: 1278 	Training Loss: 1.361448 	Validation Loss: 1.383596 	 time: 0.3
Epoch: 1279 	Training Loss: 1.366505 	Validation Loss: 1.384558 	 time: 0.3
Epoch: 1280 	Training Loss: 1.364267 	Validation Loss: 1.387374 	 time: 0.3
Epoch: 1281 	Training Loss: 1.363578 	Validation Loss: 1.391771 	 time: 0.3
Epoch: 1282 	Training Loss: 1.362089 	Validation Loss: 1.394656 	 time: 0.3
Epoch: 1283 	Training Loss: 1.360034 	Validation Loss: 1.392216 	 time: 0.3
Epoch: 1284 	Training Loss: 1.363010 	Validation Loss: 1.386648 	 time: 0.3
Epoch: 1285 	Training Loss: 1.362307 	Validation Loss: 1.382443 	 time: 0.3
Epoch: 1286 	Training Loss: 1.361555 	Validation Loss: 1.377610 	 time: 0.3
Epoch: 1287 	Training Loss: 1.358602 	Validation Loss: 1.373879 	 time: 0.3
Epoch: 1288 	Training Loss: 1.360268 	Validation Loss: 1.371825 	 time: 0.3
Epoch: 1289 	Training Loss: 1.354832 	Validation Loss: 1.371771 	 time: 0.3
Epoch: 1290 	Training Loss: 1.365914 	Validation Loss: 1.372679 	 time: 0.3
Epoch: 1291 	Training Loss: 1.360347 	Validation Loss: 1.373172 	 time: 0.3
Epoch: 1292 	Training Loss: 1.361530 	Validation Loss: 1.373149 	 time: 0.3
Epoch: 1293 	Training Loss: 1.366417 	Validation Loss: 1.373865 	 time: 0.3
Epoch: 1294 	Training Loss: 1.361065 	Validation Loss: 1.375425 	 time: 0.3
Epoch: 1295 	Training Loss: 1.362617 	Validation Loss: 1.377302 	 time: 0.3
Epoch: 1296 	Training Loss: 1.361361 	Validation Loss: 1.378507 	 time: 0.3
Epoch: 1297 	Training Loss: 1.361806 	Validation Loss: 1.378496 	 time: 0.3
Epoch: 1298 	Training Loss: 1.360211 	Validation Loss: 1.377949 	 time: 0.3
Epoch: 1299 	Training Loss: 1.361002 	Validation Loss: 1.377896 	 time: 0.3
Epoch: 1300 	Training Loss: 1.363222 	Validation Loss: 1.378492 	 time: 0.3
Epoch: 1301 	Training Loss: 1.358857 	Validation Loss: 1.378575 	 time: 0.3
Epoch: 1302 	Training Loss: 1.363751 	Validation Loss: 1.378425 	 time: 0.3
Epoch: 1303 	Training Loss: 1.362888 	Validation Loss: 1.378803 	 time: 0.3
Epoch: 1304 	Training Loss: 1.366569 	Validation Loss: 1.381389 	 time: 0.3
Epoch: 1305 	Training Loss: 1.358647 	Validation Loss: 1.384221 	 time: 0.3
Epoch: 1306 	Training Loss: 1.361268 	Validation Loss: 1.386561 	 time: 0.3
Epoch: 1307 	Training Loss: 1.360582 	Validation Loss: 1.386102 	 time: 0.3
Epoch: 1308 	Training Loss: 1.365121 	Validation Loss: 1.384150 	 time: 0.3
Epoch: 1309 	Training Loss: 1.360798 	Validation Loss: 1.381376 	 time: 0.3
Epoch: 1310 	Training Loss: 1.359333 	Validation Loss: 1.378792 	 time: 0.3
Epoch: 1311 	Training Loss: 1.362010 	Validation Loss: 1.377400 	 time: 0.3
Epoch: 1312 	Training Loss: 1.361335 	Validation Loss: 1.376143 	 time: 0.3
Epoch: 1313 	Training Loss: 1.362296 	Validation Loss: 1.375267 	 time: 0.3
Epoch: 1314 	Training Loss: 1.364989 	Validation Loss: 1.375262 	 time: 0.3
Epoch: 1315 	Training Loss: 1.368288 	Validation Loss: 1.374490 	 time: 0.3
Epoch: 1316 	Training Loss: 1.362779 	Validation Loss: 1.373897 	 time: 0.3
Epoch: 1317 	Training Loss: 1.365616 	Validation Loss: 1.374217 	 time: 0.3
Epoch: 1318 	Training Loss: 1.367067 	Validation Loss: 1.375238 	 time: 0.3
Epoch: 1319 	Training Loss: 1.365444 	Validation Loss: 1.375978 	 time: 0.3
Epoch: 1320 	Training Loss: 1.364163 	Validation Loss: 1.377672 	 time: 0.3
Epoch: 1321 	Training Loss: 1.363103 	Validation Loss: 1.380937 	 time: 0.3
Epoch: 1322 	Training Loss: 1.362450 	Validation Loss: 1.382986 	 time: 0.3
Epoch: 1323 	Training Loss: 1.355247 	Validation Loss: 1.382879 	 time: 0.3
Epoch: 1324 	Training Loss: 1.361717 	Validation Loss: 1.383808 	 time: 0.3
Epoch: 1325 	Training Loss: 1.362391 	Validation Loss: 1.384760 	 time: 0.3
Epoch: 1326 	Training Loss: 1.365022 	Validation Loss: 1.385863 	 time: 0.3
Epoch: 1327 	Training Loss: 1.362804 	Validation Loss: 1.385729 	 time: 0.3
Epoch: 1328 	Training Loss: 1.363085 	Validation Loss: 1.383507 	 time: 0.3
Epoch: 1329 	Training Loss: 1.359529 	Validation Loss: 1.380471 	 time: 0.3
Epoch: 1330 	Training Loss: 1.360827 	Validation Loss: 1.380305 	 time: 0.3
Epoch: 1331 	Training Loss: 1.358859 	Validation Loss: 1.382359 	 time: 0.3
Epoch: 1332 	Training Loss: 1.361923 	Validation Loss: 1.385361 	 time: 0.3
Epoch: 1333 	Training Loss: 1.361372 	Validation Loss: 1.387802 	 time: 0.3
Epoch: 1334 	Training Loss: 1.360379 	Validation Loss: 1.388562 	 time: 0.3
Epoch: 1335 	Training Loss: 1.359948 	Validation Loss: 1.388939 	 time: 0.3
Epoch: 1336 	Training Loss: 1.359943 	Validation Loss: 1.388587 	 time: 0.3
Epoch: 1337 	Training Loss: 1.365317 	Validation Loss: 1.387841 	 time: 0.3
Epoch: 1338 	Training Loss: 1.361828 	Validation Loss: 1.387280 	 time: 0.3
Epoch: 1339 	Training Loss: 1.357365 	Validation Loss: 1.384984 	 time: 0.3
Epoch: 1340 	Training Loss: 1.361850 	Validation Loss: 1.382661 	 time: 0.3
Epoch: 1341 	Training Loss: 1.359770 	Validation Loss: 1.382381 	 time: 0.3
Epoch: 1342 	Training Loss: 1.362600 	Validation Loss: 1.382003 	 time: 0.3
Epoch: 1343 	Training Loss: 1.369145 	Validation Loss: 1.381405 	 time: 0.3
Epoch: 1344 	Training Loss: 1.362929 	Validation Loss: 1.381510 	 time: 0.3
Epoch: 1345 	Training Loss: 1.367927 	Validation Loss: 1.383082 	 time: 0.3
Epoch: 1346 	Training Loss: 1.361619 	Validation Loss: 1.382141 	 time: 0.3
Epoch: 1347 	Training Loss: 1.362948 	Validation Loss: 1.380922 	 time: 0.3
Epoch: 1348 	Training Loss: 1.357463 	Validation Loss: 1.379988 	 time: 0.3
Epoch: 1349 	Training Loss: 1.362475 	Validation Loss: 1.379608 	 time: 0.3
Epoch: 1350 	Training Loss: 1.362154 	Validation Loss: 1.380151 	 time: 0.3
Epoch: 1351 	Training Loss: 1.358613 	Validation Loss: 1.380278 	 time: 0.3
Epoch: 1352 	Training Loss: 1.365228 	Validation Loss: 1.379005 	 time: 0.3
Epoch: 1353 	Training Loss: 1.358100 	Validation Loss: 1.377791 	 time: 0.3
Epoch: 1354 	Training Loss: 1.361937 	Validation Loss: 1.377816 	 time: 0.3
Epoch: 1355 	Training Loss: 1.359576 	Validation Loss: 1.378184 	 time: 0.3
Epoch: 1356 	Training Loss: 1.363425 	Validation Loss: 1.379276 	 time: 0.3
Epoch: 1357 	Training Loss: 1.360746 	Validation Loss: 1.378228 	 time: 0.3
Epoch: 1358 	Training Loss: 1.360990 	Validation Loss: 1.374546 	 time: 0.3
Epoch: 1359 	Training Loss: 1.361153 	Validation Loss: 1.369879 	 time: 0.3
Epoch: 1360 	Training Loss: 1.361467 	Validation Loss: 1.368984 	 time: 0.3
Epoch: 1361 	Training Loss: 1.363792 	Validation Loss: 1.368259 	 time: 0.3
Epoch: 1362 	Training Loss: 1.361917 	Validation Loss: 1.367054 	 time: 0.3
Epoch: 1363 	Training Loss: 1.356026 	Validation Loss: 1.365774 	 time: 0.3
Epoch: 1364 	Training Loss: 1.359937 	Validation Loss: 1.365525 	 time: 0.3
Epoch: 1365 	Training Loss: 1.363760 	Validation Loss: 1.365750 	 time: 0.3
Epoch: 1366 	Training Loss: 1.362431 	Validation Loss: 1.366302 	 time: 0.3
Epoch: 1367 	Training Loss: 1.361719 	Validation Loss: 1.366087 	 time: 0.3
Epoch: 1368 	Training Loss: 1.363959 	Validation Loss: 1.365929 	 time: 0.3
Epoch: 1369 	Training Loss: 1.367815 	Validation Loss: 1.366669 	 time: 0.3
Epoch: 1370 	Training Loss: 1.362129 	Validation Loss: 1.367521 	 time: 0.3
Epoch: 1371 	Training Loss: 1.360569 	Validation Loss: 1.368487 	 time: 0.3
Epoch: 1372 	Training Loss: 1.363513 	Validation Loss: 1.369179 	 time: 0.3
Epoch: 1373 	Training Loss: 1.357263 	Validation Loss: 1.370394 	 time: 0.3
Epoch: 1374 	Training Loss: 1.360985 	Validation Loss: 1.371996 	 time: 0.3
Epoch: 1375 	Training Loss: 1.359874 	Validation Loss: 1.373119 	 time: 0.3
Epoch: 1376 	Training Loss: 1.361388 	Validation Loss: 1.374635 	 time: 0.3
Epoch: 1377 	Training Loss: 1.364244 	Validation Loss: 1.377404 	 time: 0.3
Epoch: 1378 	Training Loss: 1.360772 	Validation Loss: 1.379014 	 time: 0.3
Epoch: 1379 	Training Loss: 1.355293 	Validation Loss: 1.378803 	 time: 0.3
Epoch: 1380 	Training Loss: 1.361406 	Validation Loss: 1.378256 	 time: 0.3
Epoch: 1381 	Training Loss: 1.357807 	Validation Loss: 1.377781 	 time: 0.3
Epoch: 1382 	Training Loss: 1.363057 	Validation Loss: 1.377492 	 time: 0.3
Epoch: 1383 	Training Loss: 1.364702 	Validation Loss: 1.376971 	 time: 0.3
Epoch: 1384 	Training Loss: 1.358688 	Validation Loss: 1.375227 	 time: 0.3
Epoch: 1385 	Training Loss: 1.357851 	Validation Loss: 1.372734 	 time: 0.3
Epoch: 1386 	Training Loss: 1.362864 	Validation Loss: 1.370678 	 time: 0.3
Epoch: 1387 	Training Loss: 1.357465 	Validation Loss: 1.368337 	 time: 0.3
Epoch: 1388 	Training Loss: 1.356373 	Validation Loss: 1.366066 	 time: 0.3
Epoch: 1389 	Training Loss: 1.361114 	Validation Loss: 1.364507 	 time: 0.3
Epoch: 1390 	Training Loss: 1.363245 	Validation Loss: 1.362529 	 time: 0.3
Validation loss decreased from 1.364255 to 1.362529. Model was saved
Epoch: 1391 	Training Loss: 1.361781 	Validation Loss: 1.360635 	 time: 0.3
Validation loss decreased from 1.362529 to 1.360635. Model was saved
Epoch: 1392 	Training Loss: 1.358273 	Validation Loss: 1.358577 	 time: 0.3
Validation loss decreased from 1.360635 to 1.358577. Model was saved
Epoch: 1393 	Training Loss: 1.359365 	Validation Loss: 1.357495 	 time: 0.3
Validation loss decreased from 1.358577 to 1.357495. Model was saved
Epoch: 1394 	Training Loss: 1.368233 	Validation Loss: 1.356457 	 time: 0.3
Validation loss decreased from 1.357495 to 1.356457. Model was saved
Epoch: 1395 	Training Loss: 1.360536 	Validation Loss: 1.357073 	 time: 0.3
Epoch: 1396 	Training Loss: 1.360186 	Validation Loss: 1.357978 	 time: 0.3
Epoch: 1397 	Training Loss: 1.357592 	Validation Loss: 1.359100 	 time: 0.3
Epoch: 1398 	Training Loss: 1.360929 	Validation Loss: 1.360137 	 time: 0.3
Epoch: 1399 	Training Loss: 1.361798 	Validation Loss: 1.362309 	 time: 0.3
Epoch: 1400 	Training Loss: 1.357545 	Validation Loss: 1.365041 	 time: 0.3
Epoch: 1401 	Training Loss: 1.362761 	Validation Loss: 1.367918 	 time: 0.3
Epoch: 1402 	Training Loss: 1.362686 	Validation Loss: 1.370380 	 time: 0.3
Epoch: 1403 	Training Loss: 1.361543 	Validation Loss: 1.371189 	 time: 0.3
Epoch: 1404 	Training Loss: 1.361265 	Validation Loss: 1.371684 	 time: 0.3
Epoch: 1405 	Training Loss: 1.365443 	Validation Loss: 1.371697 	 time: 0.3
Epoch: 1406 	Training Loss: 1.357225 	Validation Loss: 1.370875 	 time: 0.3
Epoch: 1407 	Training Loss: 1.366743 	Validation Loss: 1.370144 	 time: 0.3
Epoch: 1408 	Training Loss: 1.360063 	Validation Loss: 1.369020 	 time: 0.3
Epoch: 1409 	Training Loss: 1.364364 	Validation Loss: 1.368000 	 time: 0.3
Epoch: 1410 	Training Loss: 1.361126 	Validation Loss: 1.367530 	 time: 0.3
Epoch: 1411 	Training Loss: 1.356265 	Validation Loss: 1.367344 	 time: 0.3
Epoch: 1412 	Training Loss: 1.360250 	Validation Loss: 1.367811 	 time: 0.3
Epoch: 1413 	Training Loss: 1.360850 	Validation Loss: 1.368413 	 time: 0.3
Epoch: 1414 	Training Loss: 1.358868 	Validation Loss: 1.368821 	 time: 0.3
Epoch: 1415 	Training Loss: 1.363577 	Validation Loss: 1.367081 	 time: 0.3
Epoch: 1416 	Training Loss: 1.362621 	Validation Loss: 1.364819 	 time: 0.3
Epoch: 1417 	Training Loss: 1.363611 	Validation Loss: 1.361625 	 time: 0.3
Epoch: 1418 	Training Loss: 1.357409 	Validation Loss: 1.360673 	 time: 0.3
Epoch: 1419 	Training Loss: 1.360041 	Validation Loss: 1.360045 	 time: 0.3
Epoch: 1420 	Training Loss: 1.356071 	Validation Loss: 1.360413 	 time: 0.3
Epoch: 1421 	Training Loss: 1.363400 	Validation Loss: 1.362077 	 time: 0.3
Epoch: 1422 	Training Loss: 1.353832 	Validation Loss: 1.363971 	 time: 0.3
Epoch: 1423 	Training Loss: 1.363895 	Validation Loss: 1.366554 	 time: 0.3
Epoch: 1424 	Training Loss: 1.359750 	Validation Loss: 1.369026 	 time: 0.3
Epoch: 1425 	Training Loss: 1.360555 	Validation Loss: 1.370360 	 time: 0.3
Epoch: 1426 	Training Loss: 1.361325 	Validation Loss: 1.371452 	 time: 0.3
Epoch: 1427 	Training Loss: 1.359683 	Validation Loss: 1.371526 	 time: 0.3
Epoch: 1428 	Training Loss: 1.365492 	Validation Loss: 1.371652 	 time: 0.3
Epoch: 1429 	Training Loss: 1.357603 	Validation Loss: 1.372450 	 time: 0.3
Epoch: 1430 	Training Loss: 1.358230 	Validation Loss: 1.373454 	 time: 0.3
Epoch: 1431 	Training Loss: 1.357659 	Validation Loss: 1.373731 	 time: 0.3
Epoch: 1432 	Training Loss: 1.359119 	Validation Loss: 1.373999 	 time: 0.3
Epoch: 1433 	Training Loss: 1.359021 	Validation Loss: 1.374016 	 time: 0.3
Epoch: 1434 	Training Loss: 1.360836 	Validation Loss: 1.373970 	 time: 0.3
Epoch: 1435 	Training Loss: 1.362800 	Validation Loss: 1.373013 	 time: 0.3
Epoch: 1436 	Training Loss: 1.363155 	Validation Loss: 1.372508 	 time: 0.3
Epoch: 1437 	Training Loss: 1.360178 	Validation Loss: 1.372881 	 time: 0.3
Epoch: 1438 	Training Loss: 1.362216 	Validation Loss: 1.373578 	 time: 0.3
Epoch: 1439 	Training Loss: 1.360781 	Validation Loss: 1.375091 	 time: 0.3
Epoch: 1440 	Training Loss: 1.361220 	Validation Loss: 1.377229 	 time: 0.3
Epoch: 1441 	Training Loss: 1.357592 	Validation Loss: 1.378858 	 time: 0.3
Epoch: 1442 	Training Loss: 1.357578 	Validation Loss: 1.379123 	 time: 0.3
Epoch: 1443 	Training Loss: 1.358601 	Validation Loss: 1.377676 	 time: 0.3
Epoch: 1444 	Training Loss: 1.359454 	Validation Loss: 1.375739 	 time: 0.3
Epoch: 1445 	Training Loss: 1.365024 	Validation Loss: 1.375057 	 time: 0.3
Epoch: 1446 	Training Loss: 1.363246 	Validation Loss: 1.374905 	 time: 0.3
Epoch: 1447 	Training Loss: 1.359545 	Validation Loss: 1.374455 	 time: 0.3
Epoch: 1448 	Training Loss: 1.359202 	Validation Loss: 1.374780 	 time: 0.3
Epoch: 1449 	Training Loss: 1.363206 	Validation Loss: 1.376466 	 time: 0.3
Epoch: 1450 	Training Loss: 1.361936 	Validation Loss: 1.378547 	 time: 0.3
Epoch: 1451 	Training Loss: 1.359648 	Validation Loss: 1.381102 	 time: 0.3
Epoch: 1452 	Training Loss: 1.365920 	Validation Loss: 1.381074 	 time: 0.3
Epoch: 1453 	Training Loss: 1.359319 	Validation Loss: 1.379009 	 time: 0.3
Epoch: 1454 	Training Loss: 1.354694 	Validation Loss: 1.376123 	 time: 0.3
Epoch: 1455 	Training Loss: 1.360140 	Validation Loss: 1.374894 	 time: 0.3
Epoch: 1456 	Training Loss: 1.357355 	Validation Loss: 1.374510 	 time: 0.3
Epoch: 1457 	Training Loss: 1.361265 	Validation Loss: 1.373985 	 time: 0.3
Epoch: 1458 	Training Loss: 1.362173 	Validation Loss: 1.373370 	 time: 0.3
Epoch: 1459 	Training Loss: 1.358391 	Validation Loss: 1.372553 	 time: 0.3
Epoch: 1460 	Training Loss: 1.358038 	Validation Loss: 1.371995 	 time: 0.3
Epoch: 1461 	Training Loss: 1.358494 	Validation Loss: 1.371771 	 time: 0.3
Epoch: 1462 	Training Loss: 1.359040 	Validation Loss: 1.372100 	 time: 0.3
Epoch: 1463 	Training Loss: 1.358780 	Validation Loss: 1.372124 	 time: 0.3
Epoch: 1464 	Training Loss: 1.363440 	Validation Loss: 1.371387 	 time: 0.3
Epoch: 1465 	Training Loss: 1.361732 	Validation Loss: 1.370193 	 time: 0.3
Epoch: 1466 	Training Loss: 1.361245 	Validation Loss: 1.369497 	 time: 0.3
Epoch: 1467 	Training Loss: 1.357103 	Validation Loss: 1.370295 	 time: 0.3
Epoch: 1468 	Training Loss: 1.364485 	Validation Loss: 1.371961 	 time: 0.3
Epoch: 1469 	Training Loss: 1.357871 	Validation Loss: 1.374257 	 time: 0.3
Epoch: 1470 	Training Loss: 1.356191 	Validation Loss: 1.374968 	 time: 0.3
Epoch: 1471 	Training Loss: 1.359648 	Validation Loss: 1.374877 	 time: 0.3
Epoch: 1472 	Training Loss: 1.358865 	Validation Loss: 1.374467 	 time: 0.3
Epoch: 1473 	Training Loss: 1.366638 	Validation Loss: 1.374402 	 time: 0.3
Epoch: 1474 	Training Loss: 1.355726 	Validation Loss: 1.374027 	 time: 0.3
Epoch: 1475 	Training Loss: 1.365205 	Validation Loss: 1.372620 	 time: 0.3
Epoch: 1476 	Training Loss: 1.359521 	Validation Loss: 1.373187 	 time: 0.3
Epoch: 1477 	Training Loss: 1.360392 	Validation Loss: 1.374977 	 time: 0.3
Epoch: 1478 	Training Loss: 1.365000 	Validation Loss: 1.377863 	 time: 0.3
Epoch: 1479 	Training Loss: 1.359784 	Validation Loss: 1.380725 	 time: 0.3
Epoch: 1480 	Training Loss: 1.357901 	Validation Loss: 1.382059 	 time: 0.3
Epoch: 1481 	Training Loss: 1.356175 	Validation Loss: 1.382772 	 time: 0.3
Epoch: 1482 	Training Loss: 1.358431 	Validation Loss: 1.384230 	 time: 0.3
Epoch: 1483 	Training Loss: 1.359666 	Validation Loss: 1.385430 	 time: 0.3
Epoch: 1484 	Training Loss: 1.360701 	Validation Loss: 1.386314 	 time: 0.3
Epoch: 1485 	Training Loss: 1.360482 	Validation Loss: 1.386513 	 time: 0.3
Epoch: 1486 	Training Loss: 1.362535 	Validation Loss: 1.385618 	 time: 0.3
Epoch: 1487 	Training Loss: 1.367556 	Validation Loss: 1.385313 	 time: 0.3
Epoch: 1488 	Training Loss: 1.359226 	Validation Loss: 1.385453 	 time: 0.3
Epoch: 1489 	Training Loss: 1.361524 	Validation Loss: 1.385467 	 time: 0.3
Epoch: 1490 	Training Loss: 1.364793 	Validation Loss: 1.384551 	 time: 0.3
Epoch: 1491 	Training Loss: 1.361866 	Validation Loss: 1.382455 	 time: 0.3
Epoch: 1492 	Training Loss: 1.358839 	Validation Loss: 1.381418 	 time: 0.3
Epoch: 1493 	Training Loss: 1.366755 	Validation Loss: 1.380640 	 time: 0.3
Epoch: 1494 	Training Loss: 1.354941 	Validation Loss: 1.381002 	 time: 0.3
Epoch: 1495 	Training Loss: 1.357321 	Validation Loss: 1.381206 	 time: 0.3
Epoch: 1496 	Training Loss: 1.362606 	Validation Loss: 1.381296 	 time: 0.3
Epoch: 1497 	Training Loss: 1.359788 	Validation Loss: 1.381421 	 time: 0.3
Epoch: 1498 	Training Loss: 1.364926 	Validation Loss: 1.381784 	 time: 0.3
Epoch: 1499 	Training Loss: 1.362974 	Validation Loss: 1.381748 	 time: 0.3
Epoch: 1500 	Training Loss: 1.364387 	Validation Loss: 1.379924 	 time: 0.3
Epoch: 1501 	Training Loss: 1.359482 	Validation Loss: 1.377374 	 time: 0.3
Epoch: 1502 	Training Loss: 1.360822 	Validation Loss: 1.376976 	 time: 0.3
Epoch: 1503 	Training Loss: 1.358077 	Validation Loss: 1.375431 	 time: 0.3
Epoch: 1504 	Training Loss: 1.363268 	Validation Loss: 1.374771 	 time: 0.3
Epoch: 1505 	Training Loss: 1.361050 	Validation Loss: 1.375960 	 time: 0.3
Epoch: 1506 	Training Loss: 1.357372 	Validation Loss: 1.376954 	 time: 0.3
Epoch: 1507 	Training Loss: 1.354896 	Validation Loss: 1.377001 	 time: 0.3
Epoch: 1508 	Training Loss: 1.360893 	Validation Loss: 1.377158 	 time: 0.3
Epoch: 1509 	Training Loss: 1.358345 	Validation Loss: 1.375363 	 time: 0.3
Epoch: 1510 	Training Loss: 1.358437 	Validation Loss: 1.373003 	 time: 0.3
Epoch: 1511 	Training Loss: 1.356320 	Validation Loss: 1.370766 	 time: 0.3
Epoch: 1512 	Training Loss: 1.357572 	Validation Loss: 1.370075 	 time: 0.3
Epoch: 1513 	Training Loss: 1.358268 	Validation Loss: 1.370729 	 time: 0.3
Epoch: 1514 	Training Loss: 1.357718 	Validation Loss: 1.373582 	 time: 0.3
Epoch: 1515 	Training Loss: 1.362892 	Validation Loss: 1.375235 	 time: 0.3
Epoch: 1516 	Training Loss: 1.358876 	Validation Loss: 1.376489 	 time: 0.3
Epoch: 1517 	Training Loss: 1.362808 	Validation Loss: 1.376194 	 time: 0.3
Epoch: 1518 	Training Loss: 1.358721 	Validation Loss: 1.375567 	 time: 0.3
Epoch: 1519 	Training Loss: 1.360129 	Validation Loss: 1.374501 	 time: 0.3
Epoch: 1520 	Training Loss: 1.363484 	Validation Loss: 1.373760 	 time: 0.3
Epoch: 1521 	Training Loss: 1.355606 	Validation Loss: 1.372709 	 time: 0.3
Epoch: 1522 	Training Loss: 1.356407 	Validation Loss: 1.372693 	 time: 0.3
Epoch: 1523 	Training Loss: 1.362255 	Validation Loss: 1.373925 	 time: 0.3
Epoch: 1524 	Training Loss: 1.360886 	Validation Loss: 1.375389 	 time: 0.3
Epoch: 1525 	Training Loss: 1.362198 	Validation Loss: 1.375971 	 time: 0.3
Epoch: 1526 	Training Loss: 1.356083 	Validation Loss: 1.377372 	 time: 0.3
Epoch: 1527 	Training Loss: 1.358543 	Validation Loss: 1.378954 	 time: 0.3
Epoch: 1528 	Training Loss: 1.355868 	Validation Loss: 1.379824 	 time: 0.3
Epoch: 1529 	Training Loss: 1.358663 	Validation Loss: 1.379306 	 time: 0.3
Epoch: 1530 	Training Loss: 1.356831 	Validation Loss: 1.379027 	 time: 0.3
Epoch: 1531 	Training Loss: 1.356765 	Validation Loss: 1.377821 	 time: 0.3
Epoch: 1532 	Training Loss: 1.354246 	Validation Loss: 1.377014 	 time: 0.3
Epoch: 1533 	Training Loss: 1.359953 	Validation Loss: 1.375756 	 time: 0.3
Epoch: 1534 	Training Loss: 1.363604 	Validation Loss: 1.375103 	 time: 0.3
Epoch: 1535 	Training Loss: 1.357924 	Validation Loss: 1.374708 	 time: 0.3
Epoch: 1536 	Training Loss: 1.359558 	Validation Loss: 1.375476 	 time: 0.3
Epoch: 1537 	Training Loss: 1.358398 	Validation Loss: 1.377183 	 time: 0.3
Epoch: 1538 	Training Loss: 1.358902 	Validation Loss: 1.378448 	 time: 0.3
Epoch: 1539 	Training Loss: 1.355491 	Validation Loss: 1.379509 	 time: 0.3
Epoch: 1540 	Training Loss: 1.360574 	Validation Loss: 1.381110 	 time: 0.3
Epoch: 1541 	Training Loss: 1.358595 	Validation Loss: 1.382873 	 time: 0.3
Epoch: 1542 	Training Loss: 1.360245 	Validation Loss: 1.384321 	 time: 0.3
Epoch: 1543 	Training Loss: 1.356642 	Validation Loss: 1.385103 	 time: 0.3
Epoch: 1544 	Training Loss: 1.362148 	Validation Loss: 1.384938 	 time: 0.3
Epoch: 1545 	Training Loss: 1.356302 	Validation Loss: 1.383685 	 time: 0.3
Epoch: 1546 	Training Loss: 1.365108 	Validation Loss: 1.381419 	 time: 0.3
Epoch: 1547 	Training Loss: 1.357792 	Validation Loss: 1.378413 	 time: 0.3
Epoch: 1548 	Training Loss: 1.357741 	Validation Loss: 1.376310 	 time: 0.3
Epoch: 1549 	Training Loss: 1.358216 	Validation Loss: 1.374879 	 time: 0.3
Epoch: 1550 	Training Loss: 1.367347 	Validation Loss: 1.375055 	 time: 0.3
Epoch: 1551 	Training Loss: 1.358051 	Validation Loss: 1.373990 	 time: 0.3
Epoch: 1552 	Training Loss: 1.358674 	Validation Loss: 1.374877 	 time: 0.3
Epoch: 1553 	Training Loss: 1.353923 	Validation Loss: 1.377096 	 time: 0.3
Epoch: 1554 	Training Loss: 1.358764 	Validation Loss: 1.378600 	 time: 0.3
