{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appearedTimeOfDay</th>\n",
       "      <th>appearedHour</th>\n",
       "      <th>appearedMinute</th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>city</th>\n",
       "      <th>continent</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>...</th>\n",
       "      <th>cooc_142</th>\n",
       "      <th>cooc_143</th>\n",
       "      <th>cooc_144</th>\n",
       "      <th>cooc_145</th>\n",
       "      <th>cooc_146</th>\n",
       "      <th>cooc_147</th>\n",
       "      <th>cooc_148</th>\n",
       "      <th>cooc_149</th>\n",
       "      <th>cooc_150</th>\n",
       "      <th>cooc_151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evening</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>Los_Angeles</td>\n",
       "      <td>America</td>\n",
       "      <td>PartlyCloudy</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  appearedTimeOfDay  appearedHour  appearedMinute  terrainType  closeToWater  \\\n",
       "0           evening            19              10           13         False   \n",
       "1             night             5              19           13          True   \n",
       "2           evening            19              46            0          True   \n",
       "3           morning            11              10            0          True   \n",
       "4           evening            18              32           13          True   \n",
       "\n",
       "          city  continent       weather  temperature  windSpeed  ...  \\\n",
       "0      Bangkok       Asia         Clear         27.8       9.00  ...   \n",
       "1     New_York    America         Clear         26.1       8.70  ...   \n",
       "2     New_York    America         Clear         24.7      16.82  ...   \n",
       "3       Hobart  Australia         Clear         12.7      13.25  ...   \n",
       "4  Los_Angeles    America  PartlyCloudy         19.1       5.78  ...   \n",
       "\n",
       "   cooc_142 cooc_143  cooc_144  cooc_145  cooc_146  cooc_147  cooc_148  \\\n",
       "0     False    False     False     False     False     False     False   \n",
       "1     False    False     False     False     False     False     False   \n",
       "2     False    False     False     False     False     False     False   \n",
       "3     False    False     False     False     False     False     False   \n",
       "4     False    False     False     False     False     False     False   \n",
       "\n",
       "   cooc_149  cooc_150  cooc_151  \n",
       "0     False     False     False  \n",
       "1     False     False     False  \n",
       "2     False     False     False  \n",
       "3     False     False     False  \n",
       "4     False     False     False  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1008.96</td>\n",
       "      <td>6019.04440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1018.96</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>128.89505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1011.36</td>\n",
       "      <td>4188.39100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.990268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0         13.0           0.0         27.8       9.00   1008.96   \n",
       "1         13.0           1.0         26.1       8.70   1018.96   \n",
       "2          0.0           1.0         24.7      16.82   1023.22   \n",
       "3          0.0           1.0         12.7      13.25   1014.19   \n",
       "4         13.0           1.0         19.1       5.78   1011.36   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural  ...  \\\n",
       "0          6019.04440    1.0       1.0       1.0    0.0  ...   \n",
       "1             0.00000    0.0       0.0       0.0    1.0  ...   \n",
       "2             0.00000    0.0       0.0       0.0    1.0  ...   \n",
       "3           128.89505    0.0       0.0       0.0    1.0  ...   \n",
       "4          4188.39100    1.0       1.0       1.0    0.0  ...   \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                             0                      1   \n",
       "1                             0                      0   \n",
       "2                             0                      1   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                        0                   0                0   \n",
       "1                        1                   0                0   \n",
       "2                        0                   0                0   \n",
       "3                        1                   0                0   \n",
       "4                        0                   0                0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                              0                                0   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              1                                0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0                 0                 0             -0.953717  \n",
       "1                 0                 0              0.984041  \n",
       "2                 0                 0             -0.894934  \n",
       "3                 0                 0              0.216440  \n",
       "4                 0                 0             -0.990268  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terrainType',\n",
       " 'closeToWater',\n",
       " 'temperature',\n",
       " 'windSpeed',\n",
       " 'pressure',\n",
       " 'population_density',\n",
       " 'urban',\n",
       " 'suburban',\n",
       " 'midurban',\n",
       " 'rural',\n",
       " 'gymDistanceKm',\n",
       " 'gymIn100m',\n",
       " 'gymIn250m',\n",
       " 'gymIn500m',\n",
       " 'gymIn1000m',\n",
       " 'gymIn2500m',\n",
       " 'gymIn5000m',\n",
       " 'pokestopDistanceKm',\n",
       " 'pokestopIn100m',\n",
       " 'pokestopIn250m',\n",
       " 'pokestopIn500m',\n",
       " 'pokestopIn1000m',\n",
       " 'pokestopIn2500m',\n",
       " 'pokestopIn5000m',\n",
       " 'cooc_1',\n",
       " 'cooc_2',\n",
       " 'cooc_3',\n",
       " 'cooc_4',\n",
       " 'cooc_5',\n",
       " 'cooc_6',\n",
       " 'cooc_7',\n",
       " 'cooc_8',\n",
       " 'cooc_9',\n",
       " 'cooc_10',\n",
       " 'cooc_11',\n",
       " 'cooc_12',\n",
       " 'cooc_13',\n",
       " 'cooc_14',\n",
       " 'cooc_15',\n",
       " 'cooc_16',\n",
       " 'cooc_17',\n",
       " 'cooc_18',\n",
       " 'cooc_19',\n",
       " 'cooc_20',\n",
       " 'cooc_21',\n",
       " 'cooc_22',\n",
       " 'cooc_23',\n",
       " 'cooc_24',\n",
       " 'cooc_25',\n",
       " 'cooc_26',\n",
       " 'cooc_27',\n",
       " 'cooc_28',\n",
       " 'cooc_29',\n",
       " 'cooc_30',\n",
       " 'cooc_31',\n",
       " 'cooc_32',\n",
       " 'cooc_33',\n",
       " 'cooc_34',\n",
       " 'cooc_35',\n",
       " 'cooc_36',\n",
       " 'cooc_37',\n",
       " 'cooc_38',\n",
       " 'cooc_39',\n",
       " 'cooc_40',\n",
       " 'cooc_41',\n",
       " 'cooc_42',\n",
       " 'cooc_43',\n",
       " 'cooc_44',\n",
       " 'cooc_45',\n",
       " 'cooc_46',\n",
       " 'cooc_47',\n",
       " 'cooc_48',\n",
       " 'cooc_49',\n",
       " 'cooc_50',\n",
       " 'cooc_51',\n",
       " 'cooc_52',\n",
       " 'cooc_53',\n",
       " 'cooc_54',\n",
       " 'cooc_55',\n",
       " 'cooc_56',\n",
       " 'cooc_57',\n",
       " 'cooc_58',\n",
       " 'cooc_59',\n",
       " 'cooc_60',\n",
       " 'cooc_61',\n",
       " 'cooc_62',\n",
       " 'cooc_63',\n",
       " 'cooc_64',\n",
       " 'cooc_65',\n",
       " 'cooc_66',\n",
       " 'cooc_67',\n",
       " 'cooc_68',\n",
       " 'cooc_69',\n",
       " 'cooc_70',\n",
       " 'cooc_71',\n",
       " 'cooc_72',\n",
       " 'cooc_73',\n",
       " 'cooc_74',\n",
       " 'cooc_75',\n",
       " 'cooc_76',\n",
       " 'cooc_77',\n",
       " 'cooc_78',\n",
       " 'cooc_79',\n",
       " 'cooc_80',\n",
       " 'cooc_81',\n",
       " 'cooc_82',\n",
       " 'cooc_83',\n",
       " 'cooc_84',\n",
       " 'cooc_85',\n",
       " 'cooc_86',\n",
       " 'cooc_87',\n",
       " 'cooc_88',\n",
       " 'cooc_89',\n",
       " 'cooc_90',\n",
       " 'cooc_91',\n",
       " 'cooc_92',\n",
       " 'cooc_93',\n",
       " 'cooc_94',\n",
       " 'cooc_95',\n",
       " 'cooc_96',\n",
       " 'cooc_97',\n",
       " 'cooc_98',\n",
       " 'cooc_99',\n",
       " 'cooc_100',\n",
       " 'cooc_101',\n",
       " 'cooc_102',\n",
       " 'cooc_103',\n",
       " 'cooc_104',\n",
       " 'cooc_105',\n",
       " 'cooc_106',\n",
       " 'cooc_107',\n",
       " 'cooc_108',\n",
       " 'cooc_109',\n",
       " 'cooc_110',\n",
       " 'cooc_111',\n",
       " 'cooc_112',\n",
       " 'cooc_113',\n",
       " 'cooc_114',\n",
       " 'cooc_115',\n",
       " 'cooc_116',\n",
       " 'cooc_117',\n",
       " 'cooc_118',\n",
       " 'cooc_119',\n",
       " 'cooc_120',\n",
       " 'cooc_121',\n",
       " 'cooc_122',\n",
       " 'cooc_123',\n",
       " 'cooc_124',\n",
       " 'cooc_125',\n",
       " 'cooc_126',\n",
       " 'cooc_127',\n",
       " 'cooc_128',\n",
       " 'cooc_129',\n",
       " 'cooc_130',\n",
       " 'cooc_131',\n",
       " 'cooc_132',\n",
       " 'cooc_133',\n",
       " 'cooc_134',\n",
       " 'cooc_135',\n",
       " 'cooc_136',\n",
       " 'cooc_137',\n",
       " 'cooc_138',\n",
       " 'cooc_139',\n",
       " 'cooc_140',\n",
       " 'cooc_141',\n",
       " 'cooc_142',\n",
       " 'cooc_143',\n",
       " 'cooc_144',\n",
       " 'cooc_145',\n",
       " 'cooc_146',\n",
       " 'cooc_147',\n",
       " 'cooc_148',\n",
       " 'cooc_149',\n",
       " 'cooc_150',\n",
       " 'cooc_151',\n",
       " 'appearedTimeOfDay_afternoon',\n",
       " 'appearedTimeOfDay_evening',\n",
       " 'appearedTimeOfDay_morning',\n",
       " 'appearedTimeOfDay_night',\n",
       " 'city_Adelaide',\n",
       " 'city_Amsterdam',\n",
       " 'city_Athens',\n",
       " 'city_Auckland',\n",
       " 'city_Bahia',\n",
       " 'city_Bangkok',\n",
       " 'city_Belem',\n",
       " 'city_Berlin',\n",
       " 'city_Boise',\n",
       " 'city_Brisbane',\n",
       " 'city_Brunei',\n",
       " 'city_Brussels',\n",
       " 'city_Bucharest',\n",
       " 'city_Buenos_Aires',\n",
       " 'city_Casablanca',\n",
       " 'city_Chicago',\n",
       " 'city_Copenhagen',\n",
       " 'city_Denver',\n",
       " 'city_Detroit',\n",
       " 'city_Dubai',\n",
       " 'city_Dublin',\n",
       " 'city_Edmonton',\n",
       " 'city_Guam',\n",
       " 'city_Halifax',\n",
       " 'city_Helsinki',\n",
       " 'city_Ho_Chi_Minh',\n",
       " 'city_Hobart',\n",
       " 'city_Hong_Kong',\n",
       " 'city_Honolulu',\n",
       " 'city_Indianapolis',\n",
       " 'city_Jakarta',\n",
       " 'city_Karachi',\n",
       " 'city_Kolkata',\n",
       " 'city_Kuala_Lumpur',\n",
       " 'city_Kuching',\n",
       " 'city_Lisbon',\n",
       " 'city_Ljubljana',\n",
       " 'city_London',\n",
       " 'city_Los_Angeles',\n",
       " 'city_Louisville',\n",
       " 'city_Luanda',\n",
       " 'city_Madrid',\n",
       " 'city_Manila',\n",
       " 'city_Melbourne',\n",
       " 'city_Mexico_City',\n",
       " 'city_Monterrey',\n",
       " 'city_Montreal',\n",
       " 'city_New_York',\n",
       " 'city_Nicosia',\n",
       " 'city_Noumea',\n",
       " 'city_Oslo',\n",
       " 'city_Paris',\n",
       " 'city_Perth',\n",
       " 'city_Phoenix',\n",
       " 'city_Prague',\n",
       " 'city_Puerto_Rico',\n",
       " 'city_Regina',\n",
       " 'city_Rome',\n",
       " 'city_Santiago',\n",
       " 'city_Sao_Paulo',\n",
       " 'city_Singapore',\n",
       " 'city_Stockholm',\n",
       " 'city_Sydney',\n",
       " 'city_Tahiti',\n",
       " 'city_Taipei',\n",
       " 'city_Tokyo',\n",
       " 'city_Toronto',\n",
       " 'city_Tripoli',\n",
       " 'city_Tunis',\n",
       " 'city_Vancouver',\n",
       " 'city_Vienna',\n",
       " 'city_Vilnius',\n",
       " 'city_Warsaw',\n",
       " 'city_Zagreb',\n",
       " 'city_Zurich',\n",
       " 'continent_Africa',\n",
       " 'continent_America',\n",
       " 'continent_America/Argentina',\n",
       " 'continent_America/Indiana',\n",
       " 'continent_America/Kentucky',\n",
       " 'continent_Asia',\n",
       " 'continent_Australia',\n",
       " 'continent_Europe',\n",
       " 'continent_Pacific',\n",
       " 'weather_Breezy',\n",
       " 'weather_BreezyandMostlyCloudy',\n",
       " 'weather_BreezyandOvercast',\n",
       " 'weather_BreezyandPartlyCloudy',\n",
       " 'weather_Clear',\n",
       " 'weather_DangerouslyWindy',\n",
       " 'weather_Drizzle',\n",
       " 'weather_DrizzleandBreezy',\n",
       " 'weather_Dry',\n",
       " 'weather_DryandPartlyCloudy',\n",
       " 'weather_Foggy',\n",
       " 'weather_HeavyRain',\n",
       " 'weather_Humid',\n",
       " 'weather_HumidandOvercast',\n",
       " 'weather_HumidandPartlyCloudy',\n",
       " 'weather_LightRain',\n",
       " 'weather_LightRainandBreezy',\n",
       " 'weather_MostlyCloudy',\n",
       " 'weather_Overcast',\n",
       " 'weather_PartlyCloudy',\n",
       " 'weather_Rain',\n",
       " 'weather_RainandWindy',\n",
       " 'weather_Windy',\n",
       " 'weather_WindyandFoggy',\n",
       " 'weather_WindyandPartlyCloudy',\n",
       " 'weatherIcon_clear-day',\n",
       " 'weatherIcon_clear-night',\n",
       " 'weatherIcon_cloudy',\n",
       " 'weatherIcon_fog',\n",
       " 'weatherIcon_partly-cloudy-day',\n",
       " 'weatherIcon_partly-cloudy-night',\n",
       " 'weatherIcon_rain',\n",
       " 'weatherIcon_wind',\n",
       " 'appearedTimeDayCycle']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631868</td>\n",
       "      <td>0.160342</td>\n",
       "      <td>0.333774</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.154997</td>\n",
       "      <td>0.598044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.710624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217033</td>\n",
       "      <td>0.236059</td>\n",
       "      <td>0.471987</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.102975</td>\n",
       "      <td>0.397199</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0       0.8125           0.0     0.631868   0.160342  0.333774   \n",
       "1       0.8125           1.0     0.585165   0.154997  0.598044   \n",
       "2       0.0000           1.0     0.546703   0.299662  0.710624   \n",
       "3       0.0000           1.0     0.217033   0.236059  0.471987   \n",
       "4       0.8125           1.0     0.392857   0.102975  0.397199   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural  ...  \\\n",
       "0            0.601904    1.0       1.0       1.0    0.0  ...   \n",
       "1            0.000000    0.0       0.0       0.0    1.0  ...   \n",
       "2            0.000000    0.0       0.0       0.0    1.0  ...   \n",
       "3            0.012890    0.0       0.0       0.0    1.0  ...   \n",
       "4            0.418839    1.0       1.0       1.0    0.0  ...   \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                           0.0                    1.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    1.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                      0.0                 0.0              0.0   \n",
       "1                      1.0                 0.0              0.0   \n",
       "2                      0.0                 0.0              0.0   \n",
       "3                      1.0                 0.0              0.0   \n",
       "4                      0.0                 0.0              0.0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            1.0                              0.0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0               0.0               0.0              0.023142  \n",
       "1               0.0               0.0              0.992020  \n",
       "2               0.0               0.0              0.052533  \n",
       "3               0.0               0.0              0.608220  \n",
       "4               0.0               0.0              0.004866  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7160 entries, 0 to 7159\n",
      "Columns: 297 entries, terrainType to appearedTimeDayCycle\n",
      "dtypes: float64(272), int64(25)\n",
      "memory usage: 16.3 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7160, 297)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5011, 297), (1719, 297), (430, 297))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.7\n",
    "test_ratio = 0.2\n",
    "# split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data per batch to load\n",
    "batch_size = 10000\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))      \n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huohsien/anaconda2/envs/ai/lib/python3.7/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.787868 \tValidation Loss: 1.763355 \t time: 0.2\n",
      "Validation loss decreased from inf to 1.763355. Model was saved\n",
      "Epoch: 2 \tTraining Loss: 1.763234 \tValidation Loss: 1.757408 \t time: 0.2\n",
      "Validation loss decreased from 1.763355 to 1.757408. Model was saved\n",
      "Epoch: 3 \tTraining Loss: 1.757253 \tValidation Loss: 1.758227 \t time: 0.2\n",
      "Epoch: 4 \tTraining Loss: 1.758061 \tValidation Loss: 1.759415 \t time: 0.2\n",
      "Epoch: 5 \tTraining Loss: 1.759249 \tValidation Loss: 1.759722 \t time: 0.2\n",
      "Epoch: 6 \tTraining Loss: 1.759559 \tValidation Loss: 1.759287 \t time: 0.2\n",
      "Epoch: 7 \tTraining Loss: 1.759133 \tValidation Loss: 1.758441 \t time: 0.2\n",
      "Epoch: 8 \tTraining Loss: 1.758286 \tValidation Loss: 1.757493 \t time: 0.2\n",
      "Epoch: 9 \tTraining Loss: 1.757338 \tValidation Loss: 1.756683 \t time: 0.2\n",
      "Validation loss decreased from 1.757408 to 1.756683. Model was saved\n",
      "Epoch: 10 \tTraining Loss: 1.756512 \tValidation Loss: 1.756066 \t time: 0.2\n",
      "Validation loss decreased from 1.756683 to 1.756066. Model was saved\n",
      "Epoch: 11 \tTraining Loss: 1.755870 \tValidation Loss: 1.755484 \t time: 0.2\n",
      "Validation loss decreased from 1.756066 to 1.755484. Model was saved\n",
      "Epoch: 12 \tTraining Loss: 1.755228 \tValidation Loss: 1.754663 \t time: 0.3\n",
      "Validation loss decreased from 1.755484 to 1.754663. Model was saved\n",
      "Epoch: 13 \tTraining Loss: 1.754319 \tValidation Loss: 1.753377 \t time: 0.2\n",
      "Validation loss decreased from 1.754663 to 1.753377. Model was saved\n",
      "Epoch: 14 \tTraining Loss: 1.752910 \tValidation Loss: 1.751549 \t time: 0.2\n",
      "Validation loss decreased from 1.753377 to 1.751549. Model was saved\n",
      "Epoch: 15 \tTraining Loss: 1.750910 \tValidation Loss: 1.749193 \t time: 0.2\n",
      "Validation loss decreased from 1.751549 to 1.749193. Model was saved\n",
      "Epoch: 16 \tTraining Loss: 1.748337 \tValidation Loss: 1.746349 \t time: 0.2\n",
      "Validation loss decreased from 1.749193 to 1.746349. Model was saved\n",
      "Epoch: 17 \tTraining Loss: 1.745220 \tValidation Loss: 1.743005 \t time: 0.2\n",
      "Validation loss decreased from 1.746349 to 1.743005. Model was saved\n",
      "Epoch: 18 \tTraining Loss: 1.741547 \tValidation Loss: 1.739108 \t time: 0.2\n",
      "Validation loss decreased from 1.743005 to 1.739108. Model was saved\n",
      "Epoch: 19 \tTraining Loss: 1.737259 \tValidation Loss: 1.734586 \t time: 0.2\n",
      "Validation loss decreased from 1.739108 to 1.734586. Model was saved\n",
      "Epoch: 20 \tTraining Loss: 1.732272 \tValidation Loss: 1.729416 \t time: 0.2\n",
      "Validation loss decreased from 1.734586 to 1.729416. Model was saved\n",
      "Epoch: 21 \tTraining Loss: 1.726560 \tValidation Loss: 1.723639 \t time: 0.2\n",
      "Validation loss decreased from 1.729416 to 1.723639. Model was saved\n",
      "Epoch: 22 \tTraining Loss: 1.720161 \tValidation Loss: 1.717380 \t time: 0.2\n",
      "Validation loss decreased from 1.723639 to 1.717380. Model was saved\n",
      "Epoch: 23 \tTraining Loss: 1.713206 \tValidation Loss: 1.710796 \t time: 0.2\n",
      "Validation loss decreased from 1.717380 to 1.710796. Model was saved\n",
      "Epoch: 24 \tTraining Loss: 1.705838 \tValidation Loss: 1.704021 \t time: 0.2\n",
      "Validation loss decreased from 1.710796 to 1.704021. Model was saved\n",
      "Epoch: 25 \tTraining Loss: 1.698199 \tValidation Loss: 1.697148 \t time: 0.2\n",
      "Validation loss decreased from 1.704021 to 1.697148. Model was saved\n",
      "Epoch: 26 \tTraining Loss: 1.690379 \tValidation Loss: 1.690214 \t time: 0.2\n",
      "Validation loss decreased from 1.697148 to 1.690214. Model was saved\n",
      "Epoch: 27 \tTraining Loss: 1.682429 \tValidation Loss: 1.683210 \t time: 0.2\n",
      "Validation loss decreased from 1.690214 to 1.683210. Model was saved\n",
      "Epoch: 28 \tTraining Loss: 1.674340 \tValidation Loss: 1.676133 \t time: 0.2\n",
      "Validation loss decreased from 1.683210 to 1.676133. Model was saved\n",
      "Epoch: 29 \tTraining Loss: 1.666121 \tValidation Loss: 1.669046 \t time: 0.2\n",
      "Validation loss decreased from 1.676133 to 1.669046. Model was saved\n",
      "Epoch: 30 \tTraining Loss: 1.657837 \tValidation Loss: 1.661997 \t time: 0.2\n",
      "Validation loss decreased from 1.669046 to 1.661997. Model was saved\n",
      "Epoch: 31 \tTraining Loss: 1.649556 \tValidation Loss: 1.654972 \t time: 0.2\n",
      "Validation loss decreased from 1.661997 to 1.654972. Model was saved\n",
      "Epoch: 32 \tTraining Loss: 1.641279 \tValidation Loss: 1.647937 \t time: 0.2\n",
      "Validation loss decreased from 1.654972 to 1.647937. Model was saved\n",
      "Epoch: 33 \tTraining Loss: 1.633022 \tValidation Loss: 1.640903 \t time: 0.2\n",
      "Validation loss decreased from 1.647937 to 1.640903. Model was saved\n",
      "Epoch: 34 \tTraining Loss: 1.624836 \tValidation Loss: 1.633904 \t time: 0.2\n",
      "Validation loss decreased from 1.640903 to 1.633904. Model was saved\n",
      "Epoch: 35 \tTraining Loss: 1.616782 \tValidation Loss: 1.626977 \t time: 0.3\n",
      "Validation loss decreased from 1.633904 to 1.626977. Model was saved\n",
      "Epoch: 36 \tTraining Loss: 1.608954 \tValidation Loss: 1.620162 \t time: 0.3\n",
      "Validation loss decreased from 1.626977 to 1.620162. Model was saved\n",
      "Epoch: 37 \tTraining Loss: 1.601341 \tValidation Loss: 1.613548 \t time: 0.2\n",
      "Validation loss decreased from 1.620162 to 1.613548. Model was saved\n",
      "Epoch: 38 \tTraining Loss: 1.593940 \tValidation Loss: 1.607141 \t time: 0.2\n",
      "Validation loss decreased from 1.613548 to 1.607141. Model was saved\n",
      "Epoch: 39 \tTraining Loss: 1.586773 \tValidation Loss: 1.600878 \t time: 0.2\n",
      "Validation loss decreased from 1.607141 to 1.600878. Model was saved\n",
      "Epoch: 40 \tTraining Loss: 1.579865 \tValidation Loss: 1.594979 \t time: 0.2\n",
      "Validation loss decreased from 1.600878 to 1.594979. Model was saved\n",
      "Epoch: 41 \tTraining Loss: 1.573235 \tValidation Loss: 1.589507 \t time: 0.2\n",
      "Validation loss decreased from 1.594979 to 1.589507. Model was saved\n",
      "Epoch: 42 \tTraining Loss: 1.566801 \tValidation Loss: 1.584128 \t time: 0.2\n",
      "Validation loss decreased from 1.589507 to 1.584128. Model was saved\n",
      "Epoch: 43 \tTraining Loss: 1.560471 \tValidation Loss: 1.578781 \t time: 0.2\n",
      "Validation loss decreased from 1.584128 to 1.578781. Model was saved\n",
      "Epoch: 44 \tTraining Loss: 1.554187 \tValidation Loss: 1.573624 \t time: 0.2\n",
      "Validation loss decreased from 1.578781 to 1.573624. Model was saved\n",
      "Epoch: 45 \tTraining Loss: 1.547900 \tValidation Loss: 1.568555 \t time: 0.2\n",
      "Validation loss decreased from 1.573624 to 1.568555. Model was saved\n",
      "Epoch: 46 \tTraining Loss: 1.541680 \tValidation Loss: 1.563514 \t time: 0.2\n",
      "Validation loss decreased from 1.568555 to 1.563514. Model was saved\n",
      "Epoch: 47 \tTraining Loss: 1.535651 \tValidation Loss: 1.558745 \t time: 0.2\n",
      "Validation loss decreased from 1.563514 to 1.558745. Model was saved\n",
      "Epoch: 48 \tTraining Loss: 1.529931 \tValidation Loss: 1.554333 \t time: 0.3\n",
      "Validation loss decreased from 1.558745 to 1.554333. Model was saved\n",
      "Epoch: 49 \tTraining Loss: 1.524575 \tValidation Loss: 1.550152 \t time: 0.2\n",
      "Validation loss decreased from 1.554333 to 1.550152. Model was saved\n",
      "Epoch: 50 \tTraining Loss: 1.519601 \tValidation Loss: 1.546217 \t time: 0.2\n",
      "Validation loss decreased from 1.550152 to 1.546217. Model was saved\n",
      "Epoch: 51 \tTraining Loss: 1.514975 \tValidation Loss: 1.542607 \t time: 0.2\n",
      "Validation loss decreased from 1.546217 to 1.542607. Model was saved\n",
      "Epoch: 52 \tTraining Loss: 1.510665 \tValidation Loss: 1.539298 \t time: 0.2\n",
      "Validation loss decreased from 1.542607 to 1.539298. Model was saved\n",
      "Epoch: 53 \tTraining Loss: 1.506634 \tValidation Loss: 1.536246 \t time: 0.2\n",
      "Validation loss decreased from 1.539298 to 1.536246. Model was saved\n",
      "Epoch: 54 \tTraining Loss: 1.502854 \tValidation Loss: 1.533482 \t time: 0.2\n",
      "Validation loss decreased from 1.536246 to 1.533482. Model was saved\n",
      "Epoch: 55 \tTraining Loss: 1.499316 \tValidation Loss: 1.530917 \t time: 0.2\n",
      "Validation loss decreased from 1.533482 to 1.530917. Model was saved\n",
      "Epoch: 56 \tTraining Loss: 1.496024 \tValidation Loss: 1.528518 \t time: 0.2\n",
      "Validation loss decreased from 1.530917 to 1.528518. Model was saved\n",
      "Epoch: 57 \tTraining Loss: 1.492988 \tValidation Loss: 1.526465 \t time: 0.2\n",
      "Validation loss decreased from 1.528518 to 1.526465. Model was saved\n",
      "Epoch: 58 \tTraining Loss: 1.490217 \tValidation Loss: 1.524761 \t time: 0.2\n",
      "Validation loss decreased from 1.526465 to 1.524761. Model was saved\n",
      "Epoch: 59 \tTraining Loss: 1.487675 \tValidation Loss: 1.523176 \t time: 0.2\n",
      "Validation loss decreased from 1.524761 to 1.523176. Model was saved\n",
      "Epoch: 60 \tTraining Loss: 1.485302 \tValidation Loss: 1.521681 \t time: 0.2\n",
      "Validation loss decreased from 1.523176 to 1.521681. Model was saved\n",
      "Epoch: 61 \tTraining Loss: 1.483018 \tValidation Loss: 1.520325 \t time: 0.2\n",
      "Validation loss decreased from 1.521681 to 1.520325. Model was saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62 \tTraining Loss: 1.480764 \tValidation Loss: 1.518970 \t time: 0.2\n",
      "Validation loss decreased from 1.520325 to 1.518970. Model was saved\n",
      "Epoch: 63 \tTraining Loss: 1.478511 \tValidation Loss: 1.517591 \t time: 0.2\n",
      "Validation loss decreased from 1.518970 to 1.517591. Model was saved\n",
      "Epoch: 64 \tTraining Loss: 1.476247 \tValidation Loss: 1.516305 \t time: 0.2\n",
      "Validation loss decreased from 1.517591 to 1.516305. Model was saved\n",
      "Epoch: 65 \tTraining Loss: 1.473985 \tValidation Loss: 1.515087 \t time: 0.2\n",
      "Validation loss decreased from 1.516305 to 1.515087. Model was saved\n",
      "Epoch: 66 \tTraining Loss: 1.471753 \tValidation Loss: 1.513906 \t time: 0.2\n",
      "Validation loss decreased from 1.515087 to 1.513906. Model was saved\n",
      "Epoch: 67 \tTraining Loss: 1.469575 \tValidation Loss: 1.512798 \t time: 0.2\n",
      "Validation loss decreased from 1.513906 to 1.512798. Model was saved\n",
      "Epoch: 68 \tTraining Loss: 1.467478 \tValidation Loss: 1.511731 \t time: 0.2\n",
      "Validation loss decreased from 1.512798 to 1.511731. Model was saved\n",
      "Epoch: 69 \tTraining Loss: 1.465448 \tValidation Loss: 1.510696 \t time: 0.3\n",
      "Validation loss decreased from 1.511731 to 1.510696. Model was saved\n",
      "Epoch: 70 \tTraining Loss: 1.463489 \tValidation Loss: 1.509688 \t time: 0.2\n",
      "Validation loss decreased from 1.510696 to 1.509688. Model was saved\n",
      "Epoch: 71 \tTraining Loss: 1.461594 \tValidation Loss: 1.508710 \t time: 0.2\n",
      "Validation loss decreased from 1.509688 to 1.508710. Model was saved\n",
      "Epoch: 72 \tTraining Loss: 1.459753 \tValidation Loss: 1.507823 \t time: 0.2\n",
      "Validation loss decreased from 1.508710 to 1.507823. Model was saved\n",
      "Epoch: 73 \tTraining Loss: 1.457970 \tValidation Loss: 1.506891 \t time: 0.2\n",
      "Validation loss decreased from 1.507823 to 1.506891. Model was saved\n",
      "Epoch: 74 \tTraining Loss: 1.456242 \tValidation Loss: 1.505964 \t time: 0.3\n",
      "Validation loss decreased from 1.506891 to 1.505964. Model was saved\n",
      "Epoch: 75 \tTraining Loss: 1.454570 \tValidation Loss: 1.505062 \t time: 0.2\n",
      "Validation loss decreased from 1.505964 to 1.505062. Model was saved\n",
      "Epoch: 76 \tTraining Loss: 1.452974 \tValidation Loss: 1.504088 \t time: 0.2\n",
      "Validation loss decreased from 1.505062 to 1.504088. Model was saved\n",
      "Epoch: 77 \tTraining Loss: 1.451452 \tValidation Loss: 1.503262 \t time: 0.2\n",
      "Validation loss decreased from 1.504088 to 1.503262. Model was saved\n",
      "Epoch: 78 \tTraining Loss: 1.449997 \tValidation Loss: 1.502411 \t time: 0.2\n",
      "Validation loss decreased from 1.503262 to 1.502411. Model was saved\n",
      "Epoch: 79 \tTraining Loss: 1.448592 \tValidation Loss: 1.501677 \t time: 0.2\n",
      "Validation loss decreased from 1.502411 to 1.501677. Model was saved\n",
      "Epoch: 80 \tTraining Loss: 1.447231 \tValidation Loss: 1.500872 \t time: 0.2\n",
      "Validation loss decreased from 1.501677 to 1.500872. Model was saved\n",
      "Epoch: 81 \tTraining Loss: 1.445900 \tValidation Loss: 1.500249 \t time: 0.3\n",
      "Validation loss decreased from 1.500872 to 1.500249. Model was saved\n",
      "Epoch: 82 \tTraining Loss: 1.444605 \tValidation Loss: 1.499424 \t time: 0.2\n",
      "Validation loss decreased from 1.500249 to 1.499424. Model was saved\n",
      "Epoch: 83 \tTraining Loss: 1.443366 \tValidation Loss: 1.499120 \t time: 0.2\n",
      "Validation loss decreased from 1.499424 to 1.499120. Model was saved\n",
      "Epoch: 84 \tTraining Loss: 1.442164 \tValidation Loss: 1.498228 \t time: 0.2\n",
      "Validation loss decreased from 1.499120 to 1.498228. Model was saved\n",
      "Epoch: 85 \tTraining Loss: 1.440925 \tValidation Loss: 1.497978 \t time: 0.2\n",
      "Validation loss decreased from 1.498228 to 1.497978. Model was saved\n",
      "Epoch: 86 \tTraining Loss: 1.439629 \tValidation Loss: 1.497348 \t time: 0.2\n",
      "Validation loss decreased from 1.497978 to 1.497348. Model was saved\n",
      "Epoch: 87 \tTraining Loss: 1.438411 \tValidation Loss: 1.496835 \t time: 0.2\n",
      "Validation loss decreased from 1.497348 to 1.496835. Model was saved\n",
      "Epoch: 88 \tTraining Loss: 1.437306 \tValidation Loss: 1.496714 \t time: 0.2\n",
      "Validation loss decreased from 1.496835 to 1.496714. Model was saved\n",
      "Epoch: 89 \tTraining Loss: 1.436191 \tValidation Loss: 1.495973 \t time: 0.2\n",
      "Validation loss decreased from 1.496714 to 1.495973. Model was saved\n",
      "Epoch: 90 \tTraining Loss: 1.434999 \tValidation Loss: 1.495764 \t time: 0.2\n",
      "Validation loss decreased from 1.495973 to 1.495764. Model was saved\n",
      "Epoch: 91 \tTraining Loss: 1.433819 \tValidation Loss: 1.495435 \t time: 0.2\n",
      "Validation loss decreased from 1.495764 to 1.495435. Model was saved\n",
      "Epoch: 92 \tTraining Loss: 1.432732 \tValidation Loss: 1.494847 \t time: 0.2\n",
      "Validation loss decreased from 1.495435 to 1.494847. Model was saved\n",
      "Epoch: 93 \tTraining Loss: 1.431690 \tValidation Loss: 1.494804 \t time: 0.2\n",
      "Validation loss decreased from 1.494847 to 1.494804. Model was saved\n",
      "Epoch: 94 \tTraining Loss: 1.430624 \tValidation Loss: 1.494130 \t time: 0.2\n",
      "Validation loss decreased from 1.494804 to 1.494130. Model was saved\n",
      "Epoch: 95 \tTraining Loss: 1.429531 \tValidation Loss: 1.493883 \t time: 0.2\n",
      "Validation loss decreased from 1.494130 to 1.493883. Model was saved\n",
      "Epoch: 96 \tTraining Loss: 1.428487 \tValidation Loss: 1.493640 \t time: 0.2\n",
      "Validation loss decreased from 1.493883 to 1.493640. Model was saved\n",
      "Epoch: 97 \tTraining Loss: 1.427517 \tValidation Loss: 1.493099 \t time: 0.2\n",
      "Validation loss decreased from 1.493640 to 1.493099. Model was saved\n",
      "Epoch: 98 \tTraining Loss: 1.426592 \tValidation Loss: 1.493090 \t time: 0.2\n",
      "Validation loss decreased from 1.493099 to 1.493090. Model was saved\n",
      "Epoch: 99 \tTraining Loss: 1.425673 \tValidation Loss: 1.492535 \t time: 0.2\n",
      "Validation loss decreased from 1.493090 to 1.492535. Model was saved\n",
      "Epoch: 100 \tTraining Loss: 1.424747 \tValidation Loss: 1.492424 \t time: 0.2\n",
      "Validation loss decreased from 1.492535 to 1.492424. Model was saved\n",
      "Epoch: 101 \tTraining Loss: 1.423817 \tValidation Loss: 1.492080 \t time: 0.2\n",
      "Validation loss decreased from 1.492424 to 1.492080. Model was saved\n",
      "Epoch: 102 \tTraining Loss: 1.422885 \tValidation Loss: 1.491765 \t time: 0.3\n",
      "Validation loss decreased from 1.492080 to 1.491765. Model was saved\n",
      "Epoch: 103 \tTraining Loss: 1.421979 \tValidation Loss: 1.491577 \t time: 0.2\n",
      "Validation loss decreased from 1.491765 to 1.491577. Model was saved\n",
      "Epoch: 104 \tTraining Loss: 1.421107 \tValidation Loss: 1.491238 \t time: 0.3\n",
      "Validation loss decreased from 1.491577 to 1.491238. Model was saved\n",
      "Epoch: 105 \tTraining Loss: 1.420277 \tValidation Loss: 1.491094 \t time: 0.2\n",
      "Validation loss decreased from 1.491238 to 1.491094. Model was saved\n",
      "Epoch: 106 \tTraining Loss: 1.419463 \tValidation Loss: 1.490783 \t time: 0.2\n",
      "Validation loss decreased from 1.491094 to 1.490783. Model was saved\n",
      "Epoch: 107 \tTraining Loss: 1.418645 \tValidation Loss: 1.490624 \t time: 0.3\n",
      "Validation loss decreased from 1.490783 to 1.490624. Model was saved\n",
      "Epoch: 108 \tTraining Loss: 1.417797 \tValidation Loss: 1.490325 \t time: 0.2\n",
      "Validation loss decreased from 1.490624 to 1.490325. Model was saved\n",
      "Epoch: 109 \tTraining Loss: 1.416961 \tValidation Loss: 1.490269 \t time: 0.2\n",
      "Validation loss decreased from 1.490325 to 1.490269. Model was saved\n",
      "Epoch: 110 \tTraining Loss: 1.416147 \tValidation Loss: 1.489917 \t time: 0.2\n",
      "Validation loss decreased from 1.490269 to 1.489917. Model was saved\n",
      "Epoch: 111 \tTraining Loss: 1.415359 \tValidation Loss: 1.489954 \t time: 0.2\n",
      "Epoch: 112 \tTraining Loss: 1.414580 \tValidation Loss: 1.489547 \t time: 0.2\n",
      "Validation loss decreased from 1.489917 to 1.489547. Model was saved\n",
      "Epoch: 113 \tTraining Loss: 1.413793 \tValidation Loss: 1.489555 \t time: 0.2\n",
      "Epoch: 114 \tTraining Loss: 1.412996 \tValidation Loss: 1.489235 \t time: 0.3\n",
      "Validation loss decreased from 1.489547 to 1.489235. Model was saved\n",
      "Epoch: 115 \tTraining Loss: 1.412200 \tValidation Loss: 1.489050 \t time: 0.3\n",
      "Validation loss decreased from 1.489235 to 1.489050. Model was saved\n",
      "Epoch: 116 \tTraining Loss: 1.411412 \tValidation Loss: 1.488966 \t time: 0.2\n",
      "Validation loss decreased from 1.489050 to 1.488966. Model was saved\n",
      "Epoch: 117 \tTraining Loss: 1.410644 \tValidation Loss: 1.488560 \t time: 0.2\n",
      "Validation loss decreased from 1.488966 to 1.488560. Model was saved\n",
      "Epoch: 118 \tTraining Loss: 1.409894 \tValidation Loss: 1.488795 \t time: 0.3\n",
      "Epoch: 119 \tTraining Loss: 1.409191 \tValidation Loss: 1.488172 \t time: 0.2\n",
      "Validation loss decreased from 1.488560 to 1.488172. Model was saved\n",
      "Epoch: 120 \tTraining Loss: 1.408549 \tValidation Loss: 1.488603 \t time: 0.2\n",
      "Epoch: 121 \tTraining Loss: 1.407942 \tValidation Loss: 1.488225 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122 \tTraining Loss: 1.407297 \tValidation Loss: 1.487756 \t time: 0.2\n",
      "Validation loss decreased from 1.488172 to 1.487756. Model was saved\n",
      "Epoch: 123 \tTraining Loss: 1.406590 \tValidation Loss: 1.488460 \t time: 0.2\n",
      "Epoch: 124 \tTraining Loss: 1.405708 \tValidation Loss: 1.487299 \t time: 0.3\n",
      "Validation loss decreased from 1.487756 to 1.487299. Model was saved\n",
      "Epoch: 125 \tTraining Loss: 1.404667 \tValidation Loss: 1.487394 \t time: 0.2\n",
      "Epoch: 126 \tTraining Loss: 1.404008 \tValidation Loss: 1.487903 \t time: 0.3\n",
      "Epoch: 127 \tTraining Loss: 1.403478 \tValidation Loss: 1.486861 \t time: 0.2\n",
      "Validation loss decreased from 1.487299 to 1.486861. Model was saved\n",
      "Epoch: 128 \tTraining Loss: 1.402430 \tValidation Loss: 1.486871 \t time: 0.2\n",
      "Epoch: 129 \tTraining Loss: 1.401632 \tValidation Loss: 1.487324 \t time: 0.3\n",
      "Epoch: 130 \tTraining Loss: 1.401137 \tValidation Loss: 1.486363 \t time: 0.2\n",
      "Validation loss decreased from 1.486861 to 1.486363. Model was saved\n",
      "Epoch: 131 \tTraining Loss: 1.400117 \tValidation Loss: 1.486094 \t time: 0.2\n",
      "Validation loss decreased from 1.486363 to 1.486094. Model was saved\n",
      "Epoch: 132 \tTraining Loss: 1.399237 \tValidation Loss: 1.486400 \t time: 0.2\n",
      "Epoch: 133 \tTraining Loss: 1.398597 \tValidation Loss: 1.485333 \t time: 0.3\n",
      "Validation loss decreased from 1.486094 to 1.485333. Model was saved\n",
      "Epoch: 134 \tTraining Loss: 1.397573 \tValidation Loss: 1.484722 \t time: 0.2\n",
      "Validation loss decreased from 1.485333 to 1.484722. Model was saved\n",
      "Epoch: 135 \tTraining Loss: 1.396602 \tValidation Loss: 1.484560 \t time: 0.3\n",
      "Validation loss decreased from 1.484722 to 1.484560. Model was saved\n",
      "Epoch: 136 \tTraining Loss: 1.395674 \tValidation Loss: 1.483212 \t time: 0.2\n",
      "Validation loss decreased from 1.484560 to 1.483212. Model was saved\n",
      "Epoch: 137 \tTraining Loss: 1.394562 \tValidation Loss: 1.482255 \t time: 0.3\n",
      "Validation loss decreased from 1.483212 to 1.482255. Model was saved\n",
      "Epoch: 138 \tTraining Loss: 1.393522 \tValidation Loss: 1.481411 \t time: 0.2\n",
      "Validation loss decreased from 1.482255 to 1.481411. Model was saved\n",
      "Epoch: 139 \tTraining Loss: 1.392348 \tValidation Loss: 1.480044 \t time: 0.2\n",
      "Validation loss decreased from 1.481411 to 1.480044. Model was saved\n",
      "Epoch: 140 \tTraining Loss: 1.391109 \tValidation Loss: 1.478868 \t time: 0.2\n",
      "Validation loss decreased from 1.480044 to 1.478868. Model was saved\n",
      "Epoch: 141 \tTraining Loss: 1.389968 \tValidation Loss: 1.477934 \t time: 0.2\n",
      "Validation loss decreased from 1.478868 to 1.477934. Model was saved\n",
      "Epoch: 142 \tTraining Loss: 1.388625 \tValidation Loss: 1.476787 \t time: 0.2\n",
      "Validation loss decreased from 1.477934 to 1.476787. Model was saved\n",
      "Epoch: 143 \tTraining Loss: 1.387234 \tValidation Loss: 1.475512 \t time: 0.2\n",
      "Validation loss decreased from 1.476787 to 1.475512. Model was saved\n",
      "Epoch: 144 \tTraining Loss: 1.385946 \tValidation Loss: 1.474658 \t time: 0.2\n",
      "Validation loss decreased from 1.475512 to 1.474658. Model was saved\n",
      "Epoch: 145 \tTraining Loss: 1.384596 \tValidation Loss: 1.473643 \t time: 0.3\n",
      "Validation loss decreased from 1.474658 to 1.473643. Model was saved\n",
      "Epoch: 146 \tTraining Loss: 1.383333 \tValidation Loss: 1.472384 \t time: 0.3\n",
      "Validation loss decreased from 1.473643 to 1.472384. Model was saved\n",
      "Epoch: 147 \tTraining Loss: 1.382143 \tValidation Loss: 1.471654 \t time: 0.3\n",
      "Validation loss decreased from 1.472384 to 1.471654. Model was saved\n",
      "Epoch: 148 \tTraining Loss: 1.380882 \tValidation Loss: 1.470797 \t time: 0.3\n",
      "Validation loss decreased from 1.471654 to 1.470797. Model was saved\n",
      "Epoch: 149 \tTraining Loss: 1.379694 \tValidation Loss: 1.469665 \t time: 0.2\n",
      "Validation loss decreased from 1.470797 to 1.469665. Model was saved\n",
      "Epoch: 150 \tTraining Loss: 1.378540 \tValidation Loss: 1.469046 \t time: 0.3\n",
      "Validation loss decreased from 1.469665 to 1.469046. Model was saved\n",
      "Epoch: 151 \tTraining Loss: 1.377355 \tValidation Loss: 1.468343 \t time: 0.3\n",
      "Validation loss decreased from 1.469046 to 1.468343. Model was saved\n",
      "Epoch: 152 \tTraining Loss: 1.376246 \tValidation Loss: 1.467445 \t time: 0.3\n",
      "Validation loss decreased from 1.468343 to 1.467445. Model was saved\n",
      "Epoch: 153 \tTraining Loss: 1.375171 \tValidation Loss: 1.466991 \t time: 0.3\n",
      "Validation loss decreased from 1.467445 to 1.466991. Model was saved\n",
      "Epoch: 154 \tTraining Loss: 1.374102 \tValidation Loss: 1.466464 \t time: 0.2\n",
      "Validation loss decreased from 1.466991 to 1.466464. Model was saved\n",
      "Epoch: 155 \tTraining Loss: 1.373096 \tValidation Loss: 1.465869 \t time: 0.2\n",
      "Validation loss decreased from 1.466464 to 1.465869. Model was saved\n",
      "Epoch: 156 \tTraining Loss: 1.372105 \tValidation Loss: 1.465570 \t time: 0.2\n",
      "Validation loss decreased from 1.465869 to 1.465570. Model was saved\n",
      "Epoch: 157 \tTraining Loss: 1.371125 \tValidation Loss: 1.465371 \t time: 0.3\n",
      "Validation loss decreased from 1.465570 to 1.465371. Model was saved\n",
      "Epoch: 158 \tTraining Loss: 1.370198 \tValidation Loss: 1.464987 \t time: 0.3\n",
      "Validation loss decreased from 1.465371 to 1.464987. Model was saved\n",
      "Epoch: 159 \tTraining Loss: 1.369283 \tValidation Loss: 1.464849 \t time: 0.2\n",
      "Validation loss decreased from 1.464987 to 1.464849. Model was saved\n",
      "Epoch: 160 \tTraining Loss: 1.368361 \tValidation Loss: 1.464854 \t time: 0.2\n",
      "Epoch: 161 \tTraining Loss: 1.367466 \tValidation Loss: 1.464433 \t time: 0.3\n",
      "Validation loss decreased from 1.464849 to 1.464433. Model was saved\n",
      "Epoch: 162 \tTraining Loss: 1.366576 \tValidation Loss: 1.464512 \t time: 0.2\n",
      "Epoch: 163 \tTraining Loss: 1.365676 \tValidation Loss: 1.464276 \t time: 0.2\n",
      "Validation loss decreased from 1.464433 to 1.464276. Model was saved\n",
      "Epoch: 164 \tTraining Loss: 1.364799 \tValidation Loss: 1.464083 \t time: 0.2\n",
      "Validation loss decreased from 1.464276 to 1.464083. Model was saved\n",
      "Epoch: 165 \tTraining Loss: 1.363929 \tValidation Loss: 1.463868 \t time: 0.3\n",
      "Validation loss decreased from 1.464083 to 1.463868. Model was saved\n",
      "Epoch: 166 \tTraining Loss: 1.363064 \tValidation Loss: 1.463918 \t time: 0.3\n",
      "Epoch: 167 \tTraining Loss: 1.362228 \tValidation Loss: 1.463303 \t time: 0.3\n",
      "Validation loss decreased from 1.463868 to 1.463303. Model was saved\n",
      "Epoch: 168 \tTraining Loss: 1.361452 \tValidation Loss: 1.463772 \t time: 0.2\n",
      "Epoch: 169 \tTraining Loss: 1.360711 \tValidation Loss: 1.462987 \t time: 0.3\n",
      "Validation loss decreased from 1.463303 to 1.462987. Model was saved\n",
      "Epoch: 170 \tTraining Loss: 1.360062 \tValidation Loss: 1.463459 \t time: 0.2\n",
      "Epoch: 171 \tTraining Loss: 1.359273 \tValidation Loss: 1.462703 \t time: 0.2\n",
      "Validation loss decreased from 1.462987 to 1.462703. Model was saved\n",
      "Epoch: 172 \tTraining Loss: 1.358263 \tValidation Loss: 1.462879 \t time: 0.2\n",
      "Epoch: 173 \tTraining Loss: 1.357114 \tValidation Loss: 1.462593 \t time: 0.3\n",
      "Validation loss decreased from 1.462703 to 1.462593. Model was saved\n",
      "Epoch: 174 \tTraining Loss: 1.356222 \tValidation Loss: 1.462383 \t time: 0.3\n",
      "Validation loss decreased from 1.462593 to 1.462383. Model was saved\n",
      "Epoch: 175 \tTraining Loss: 1.355608 \tValidation Loss: 1.462805 \t time: 0.2\n",
      "Epoch: 176 \tTraining Loss: 1.354985 \tValidation Loss: 1.462161 \t time: 0.2\n",
      "Validation loss decreased from 1.462383 to 1.462161. Model was saved\n",
      "Epoch: 177 \tTraining Loss: 1.354173 \tValidation Loss: 1.462542 \t time: 0.3\n",
      "Epoch: 178 \tTraining Loss: 1.353184 \tValidation Loss: 1.462299 \t time: 0.2\n",
      "Epoch: 179 \tTraining Loss: 1.352340 \tValidation Loss: 1.462063 \t time: 0.3\n",
      "Validation loss decreased from 1.462161 to 1.462063. Model was saved\n",
      "Epoch: 180 \tTraining Loss: 1.351708 \tValidation Loss: 1.462443 \t time: 0.3\n",
      "Epoch: 181 \tTraining Loss: 1.351087 \tValidation Loss: 1.461892 \t time: 0.3\n",
      "Validation loss decreased from 1.462063 to 1.461892. Model was saved\n",
      "Epoch: 182 \tTraining Loss: 1.350337 \tValidation Loss: 1.462097 \t time: 0.3\n",
      "Epoch: 183 \tTraining Loss: 1.349457 \tValidation Loss: 1.461917 \t time: 0.2\n",
      "Epoch: 184 \tTraining Loss: 1.348651 \tValidation Loss: 1.461716 \t time: 0.2\n",
      "Validation loss decreased from 1.461892 to 1.461716. Model was saved\n",
      "Epoch: 185 \tTraining Loss: 1.347978 \tValidation Loss: 1.461948 \t time: 0.3\n",
      "Epoch: 186 \tTraining Loss: 1.347332 \tValidation Loss: 1.461538 \t time: 0.3\n",
      "Validation loss decreased from 1.461716 to 1.461538. Model was saved\n",
      "Epoch: 187 \tTraining Loss: 1.346615 \tValidation Loss: 1.461719 \t time: 0.3\n",
      "Epoch: 188 \tTraining Loss: 1.345814 \tValidation Loss: 1.461432 \t time: 0.3\n",
      "Validation loss decreased from 1.461538 to 1.461432. Model was saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 189 \tTraining Loss: 1.345036 \tValidation Loss: 1.461333 \t time: 0.3\n",
      "Validation loss decreased from 1.461432 to 1.461333. Model was saved\n",
      "Epoch: 190 \tTraining Loss: 1.344337 \tValidation Loss: 1.461393 \t time: 0.2\n",
      "Epoch: 191 \tTraining Loss: 1.343682 \tValidation Loss: 1.460977 \t time: 0.3\n",
      "Validation loss decreased from 1.461333 to 1.460977. Model was saved\n",
      "Epoch: 192 \tTraining Loss: 1.343007 \tValidation Loss: 1.461164 \t time: 0.3\n",
      "Epoch: 193 \tTraining Loss: 1.342276 \tValidation Loss: 1.460692 \t time: 0.3\n",
      "Validation loss decreased from 1.460977 to 1.460692. Model was saved\n",
      "Epoch: 194 \tTraining Loss: 1.341518 \tValidation Loss: 1.460665 \t time: 0.3\n",
      "Validation loss decreased from 1.460692 to 1.460665. Model was saved\n",
      "Epoch: 195 \tTraining Loss: 1.340758 \tValidation Loss: 1.460458 \t time: 0.3\n",
      "Validation loss decreased from 1.460665 to 1.460458. Model was saved\n",
      "Epoch: 196 \tTraining Loss: 1.340032 \tValidation Loss: 1.460131 \t time: 0.2\n",
      "Validation loss decreased from 1.460458 to 1.460131. Model was saved\n",
      "Epoch: 197 \tTraining Loss: 1.339332 \tValidation Loss: 1.460126 \t time: 0.3\n",
      "Validation loss decreased from 1.460131 to 1.460126. Model was saved\n",
      "Epoch: 198 \tTraining Loss: 1.338649 \tValidation Loss: 1.459681 \t time: 0.3\n",
      "Validation loss decreased from 1.460126 to 1.459681. Model was saved\n",
      "Epoch: 199 \tTraining Loss: 1.337967 \tValidation Loss: 1.459717 \t time: 0.3\n",
      "Epoch: 200 \tTraining Loss: 1.337269 \tValidation Loss: 1.459272 \t time: 0.3\n",
      "Validation loss decreased from 1.459681 to 1.459272. Model was saved\n",
      "Epoch: 201 \tTraining Loss: 1.336563 \tValidation Loss: 1.459323 \t time: 0.3\n",
      "Epoch: 202 \tTraining Loss: 1.335837 \tValidation Loss: 1.458954 \t time: 0.3\n",
      "Validation loss decreased from 1.459272 to 1.458954. Model was saved\n",
      "Epoch: 203 \tTraining Loss: 1.335114 \tValidation Loss: 1.458974 \t time: 0.3\n",
      "Epoch: 204 \tTraining Loss: 1.334393 \tValidation Loss: 1.458768 \t time: 0.2\n",
      "Validation loss decreased from 1.458954 to 1.458768. Model was saved\n",
      "Epoch: 205 \tTraining Loss: 1.333677 \tValidation Loss: 1.458701 \t time: 0.2\n",
      "Validation loss decreased from 1.458768 to 1.458701. Model was saved\n",
      "Epoch: 206 \tTraining Loss: 1.332976 \tValidation Loss: 1.458622 \t time: 0.3\n",
      "Validation loss decreased from 1.458701 to 1.458622. Model was saved\n",
      "Epoch: 207 \tTraining Loss: 1.332289 \tValidation Loss: 1.458444 \t time: 0.3\n",
      "Validation loss decreased from 1.458622 to 1.458444. Model was saved\n",
      "Epoch: 208 \tTraining Loss: 1.331610 \tValidation Loss: 1.458423 \t time: 0.3\n",
      "Validation loss decreased from 1.458444 to 1.458423. Model was saved\n",
      "Epoch: 209 \tTraining Loss: 1.330940 \tValidation Loss: 1.458119 \t time: 0.3\n",
      "Validation loss decreased from 1.458423 to 1.458119. Model was saved\n",
      "Epoch: 210 \tTraining Loss: 1.330276 \tValidation Loss: 1.458168 \t time: 0.3\n",
      "Epoch: 211 \tTraining Loss: 1.329629 \tValidation Loss: 1.457772 \t time: 0.2\n",
      "Validation loss decreased from 1.458119 to 1.457772. Model was saved\n",
      "Epoch: 212 \tTraining Loss: 1.329010 \tValidation Loss: 1.457955 \t time: 0.3\n",
      "Epoch: 213 \tTraining Loss: 1.328410 \tValidation Loss: 1.457483 \t time: 0.2\n",
      "Validation loss decreased from 1.457772 to 1.457483. Model was saved\n",
      "Epoch: 214 \tTraining Loss: 1.327874 \tValidation Loss: 1.457821 \t time: 0.3\n",
      "Epoch: 215 \tTraining Loss: 1.327298 \tValidation Loss: 1.457282 \t time: 0.3\n",
      "Validation loss decreased from 1.457483 to 1.457282. Model was saved\n",
      "Epoch: 216 \tTraining Loss: 1.326713 \tValidation Loss: 1.457550 \t time: 0.3\n",
      "Epoch: 217 \tTraining Loss: 1.325904 \tValidation Loss: 1.457134 \t time: 0.2\n",
      "Validation loss decreased from 1.457282 to 1.457134. Model was saved\n",
      "Epoch: 218 \tTraining Loss: 1.325056 \tValidation Loss: 1.457173 \t time: 0.3\n",
      "Epoch: 219 \tTraining Loss: 1.324268 \tValidation Loss: 1.457207 \t time: 0.2\n",
      "Epoch: 220 \tTraining Loss: 1.323654 \tValidation Loss: 1.457098 \t time: 0.3\n",
      "Validation loss decreased from 1.457134 to 1.457098. Model was saved\n",
      "Epoch: 221 \tTraining Loss: 1.323159 \tValidation Loss: 1.457321 \t time: 0.2\n",
      "Epoch: 222 \tTraining Loss: 1.322616 \tValidation Loss: 1.457091 \t time: 0.3\n",
      "Validation loss decreased from 1.457098 to 1.457091. Model was saved\n",
      "Epoch: 223 \tTraining Loss: 1.321988 \tValidation Loss: 1.457149 \t time: 0.3\n",
      "Epoch: 224 \tTraining Loss: 1.321213 \tValidation Loss: 1.456923 \t time: 0.3\n",
      "Validation loss decreased from 1.457091 to 1.456923. Model was saved\n",
      "Epoch: 225 \tTraining Loss: 1.320473 \tValidation Loss: 1.456825 \t time: 0.3\n",
      "Validation loss decreased from 1.456923 to 1.456825. Model was saved\n",
      "Epoch: 226 \tTraining Loss: 1.319839 \tValidation Loss: 1.456833 \t time: 0.3\n",
      "Epoch: 227 \tTraining Loss: 1.319301 \tValidation Loss: 1.456643 \t time: 0.3\n",
      "Validation loss decreased from 1.456825 to 1.456643. Model was saved\n",
      "Epoch: 228 \tTraining Loss: 1.318772 \tValidation Loss: 1.456663 \t time: 0.3\n",
      "Epoch: 229 \tTraining Loss: 1.318147 \tValidation Loss: 1.456438 \t time: 0.3\n",
      "Validation loss decreased from 1.456643 to 1.456438. Model was saved\n",
      "Epoch: 230 \tTraining Loss: 1.317478 \tValidation Loss: 1.456312 \t time: 0.3\n",
      "Validation loss decreased from 1.456438 to 1.456312. Model was saved\n",
      "Epoch: 231 \tTraining Loss: 1.316812 \tValidation Loss: 1.456191 \t time: 0.3\n",
      "Validation loss decreased from 1.456312 to 1.456191. Model was saved\n",
      "Epoch: 232 \tTraining Loss: 1.316202 \tValidation Loss: 1.456110 \t time: 0.2\n",
      "Validation loss decreased from 1.456191 to 1.456110. Model was saved\n",
      "Epoch: 233 \tTraining Loss: 1.315643 \tValidation Loss: 1.456151 \t time: 0.3\n",
      "Epoch: 234 \tTraining Loss: 1.315089 \tValidation Loss: 1.456138 \t time: 0.3\n",
      "Epoch: 235 \tTraining Loss: 1.314506 \tValidation Loss: 1.456254 \t time: 0.3\n",
      "Epoch: 236 \tTraining Loss: 1.313880 \tValidation Loss: 1.456232 \t time: 0.3\n",
      "Epoch: 237 \tTraining Loss: 1.313239 \tValidation Loss: 1.456340 \t time: 0.3\n",
      "Epoch: 238 \tTraining Loss: 1.312599 \tValidation Loss: 1.456371 \t time: 0.3\n",
      "Epoch: 239 \tTraining Loss: 1.311990 \tValidation Loss: 1.456451 \t time: 0.3\n",
      "Epoch: 240 \tTraining Loss: 1.311405 \tValidation Loss: 1.456602 \t time: 0.3\n",
      "Epoch: 241 \tTraining Loss: 1.310835 \tValidation Loss: 1.456691 \t time: 0.3\n",
      "Epoch: 242 \tTraining Loss: 1.310288 \tValidation Loss: 1.456902 \t time: 0.3\n",
      "Epoch: 243 \tTraining Loss: 1.309748 \tValidation Loss: 1.456994 \t time: 0.3\n",
      "Epoch: 244 \tTraining Loss: 1.309242 \tValidation Loss: 1.457226 \t time: 0.3\n",
      "Epoch: 245 \tTraining Loss: 1.308762 \tValidation Loss: 1.457285 \t time: 0.3\n",
      "Epoch: 246 \tTraining Loss: 1.308388 \tValidation Loss: 1.457572 \t time: 0.3\n",
      "Epoch: 247 \tTraining Loss: 1.307970 \tValidation Loss: 1.457490 \t time: 0.3\n",
      "Epoch: 248 \tTraining Loss: 1.307636 \tValidation Loss: 1.457757 \t time: 0.3\n",
      "Epoch: 249 \tTraining Loss: 1.306864 \tValidation Loss: 1.457495 \t time: 0.3\n",
      "Epoch: 250 \tTraining Loss: 1.306032 \tValidation Loss: 1.457680 \t time: 0.3\n",
      "Epoch: 251 \tTraining Loss: 1.305240 \tValidation Loss: 1.457837 \t time: 0.3\n",
      "Epoch: 252 \tTraining Loss: 1.304786 \tValidation Loss: 1.457882 \t time: 0.3\n",
      "Epoch: 253 \tTraining Loss: 1.304534 \tValidation Loss: 1.458286 \t time: 0.3\n",
      "Epoch: 254 \tTraining Loss: 1.304124 \tValidation Loss: 1.458027 \t time: 0.3\n",
      "Epoch: 255 \tTraining Loss: 1.303562 \tValidation Loss: 1.458205 \t time: 0.3\n",
      "Epoch: 256 \tTraining Loss: 1.302699 \tValidation Loss: 1.458032 \t time: 0.3\n",
      "Epoch: 257 \tTraining Loss: 1.301963 \tValidation Loss: 1.457980 \t time: 0.3\n",
      "Epoch: 258 \tTraining Loss: 1.301466 \tValidation Loss: 1.458274 \t time: 0.3\n",
      "Epoch: 259 \tTraining Loss: 1.301020 \tValidation Loss: 1.457993 \t time: 0.3\n",
      "Epoch: 260 \tTraining Loss: 1.300499 \tValidation Loss: 1.458232 \t time: 0.3\n",
      "Epoch: 261 \tTraining Loss: 1.299751 \tValidation Loss: 1.457866 \t time: 0.3\n",
      "Epoch: 262 \tTraining Loss: 1.299027 \tValidation Loss: 1.457859 \t time: 0.3\n",
      "Epoch: 263 \tTraining Loss: 1.298411 \tValidation Loss: 1.457729 \t time: 0.3\n",
      "Epoch: 264 \tTraining Loss: 1.297907 \tValidation Loss: 1.457583 \t time: 0.3\n",
      "Epoch: 265 \tTraining Loss: 1.297388 \tValidation Loss: 1.457577 \t time: 0.3\n",
      "Epoch: 266 \tTraining Loss: 1.296756 \tValidation Loss: 1.457315 \t time: 0.3\n",
      "Epoch: 267 \tTraining Loss: 1.296097 \tValidation Loss: 1.457378 \t time: 0.3\n",
      "Epoch: 268 \tTraining Loss: 1.295437 \tValidation Loss: 1.457060 \t time: 0.3\n",
      "Epoch: 269 \tTraining Loss: 1.294841 \tValidation Loss: 1.457165 \t time: 0.3\n",
      "Epoch: 270 \tTraining Loss: 1.294278 \tValidation Loss: 1.456767 \t time: 0.3\n",
      "Epoch: 271 \tTraining Loss: 1.293728 \tValidation Loss: 1.456822 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 272 \tTraining Loss: 1.293131 \tValidation Loss: 1.456421 \t time: 0.3\n",
      "Epoch: 273 \tTraining Loss: 1.292521 \tValidation Loss: 1.456417 \t time: 0.3\n",
      "Epoch: 274 \tTraining Loss: 1.291915 \tValidation Loss: 1.456264 \t time: 0.3\n",
      "Epoch: 275 \tTraining Loss: 1.291338 \tValidation Loss: 1.456234 \t time: 0.3\n",
      "Epoch: 276 \tTraining Loss: 1.290830 \tValidation Loss: 1.456433 \t time: 0.3\n",
      "Epoch: 277 \tTraining Loss: 1.290415 \tValidation Loss: 1.456307 \t time: 0.3\n",
      "Epoch: 278 \tTraining Loss: 1.290190 \tValidation Loss: 1.456797 \t time: 0.3\n",
      "Epoch: 279 \tTraining Loss: 1.290117 \tValidation Loss: 1.456492 \t time: 0.3\n",
      "Epoch: 280 \tTraining Loss: 1.290356 \tValidation Loss: 1.456642 \t time: 0.3\n",
      "Epoch: 281 \tTraining Loss: 1.289605 \tValidation Loss: 1.456573 \t time: 0.3\n",
      "Epoch: 282 \tTraining Loss: 1.288880 \tValidation Loss: 1.455815 \t time: 0.3\n",
      "Validation loss decreased from 1.456110 to 1.455815. Model was saved\n",
      "Epoch: 283 \tTraining Loss: 1.288056 \tValidation Loss: 1.456623 \t time: 0.3\n",
      "Epoch: 284 \tTraining Loss: 1.287128 \tValidation Loss: 1.456355 \t time: 0.3\n",
      "Epoch: 285 \tTraining Loss: 1.286509 \tValidation Loss: 1.456154 \t time: 0.3\n",
      "Epoch: 286 \tTraining Loss: 1.286401 \tValidation Loss: 1.457312 \t time: 0.3\n",
      "Epoch: 287 \tTraining Loss: 1.286160 \tValidation Loss: 1.456182 \t time: 0.3\n",
      "Epoch: 288 \tTraining Loss: 1.285149 \tValidation Loss: 1.456395 \t time: 0.3\n",
      "Epoch: 289 \tTraining Loss: 1.284204 \tValidation Loss: 1.456915 \t time: 0.3\n",
      "Epoch: 290 \tTraining Loss: 1.284147 \tValidation Loss: 1.456112 \t time: 0.3\n",
      "Epoch: 291 \tTraining Loss: 1.283830 \tValidation Loss: 1.456525 \t time: 0.3\n",
      "Epoch: 292 \tTraining Loss: 1.282969 \tValidation Loss: 1.456907 \t time: 0.3\n",
      "Epoch: 293 \tTraining Loss: 1.282640 \tValidation Loss: 1.456129 \t time: 0.3\n",
      "Epoch: 294 \tTraining Loss: 1.282195 \tValidation Loss: 1.456571 \t time: 0.3\n",
      "Epoch: 295 \tTraining Loss: 1.281375 \tValidation Loss: 1.456878 \t time: 0.3\n",
      "Epoch: 296 \tTraining Loss: 1.281199 \tValidation Loss: 1.456179 \t time: 0.3\n",
      "Epoch: 297 \tTraining Loss: 1.280830 \tValidation Loss: 1.456425 \t time: 0.3\n",
      "Epoch: 298 \tTraining Loss: 1.279979 \tValidation Loss: 1.456785 \t time: 0.3\n",
      "Epoch: 299 \tTraining Loss: 1.279708 \tValidation Loss: 1.456036 \t time: 0.3\n",
      "Epoch: 300 \tTraining Loss: 1.279284 \tValidation Loss: 1.456343 \t time: 0.3\n",
      "Epoch: 301 \tTraining Loss: 1.278614 \tValidation Loss: 1.456847 \t time: 0.3\n",
      "Epoch: 302 \tTraining Loss: 1.278491 \tValidation Loss: 1.456026 \t time: 0.3\n",
      "Epoch: 303 \tTraining Loss: 1.278080 \tValidation Loss: 1.456365 \t time: 0.3\n",
      "Epoch: 304 \tTraining Loss: 1.277471 \tValidation Loss: 1.456849 \t time: 0.3\n",
      "Epoch: 305 \tTraining Loss: 1.277288 \tValidation Loss: 1.456095 \t time: 0.3\n",
      "Epoch: 306 \tTraining Loss: 1.276784 \tValidation Loss: 1.456266 \t time: 0.3\n",
      "Epoch: 307 \tTraining Loss: 1.276220 \tValidation Loss: 1.456788 \t time: 0.3\n",
      "Epoch: 308 \tTraining Loss: 1.275995 \tValidation Loss: 1.456139 \t time: 0.3\n",
      "Epoch: 309 \tTraining Loss: 1.275468 \tValidation Loss: 1.456232 \t time: 0.3\n",
      "Epoch: 310 \tTraining Loss: 1.275014 \tValidation Loss: 1.456749 \t time: 0.3\n",
      "Epoch: 311 \tTraining Loss: 1.274785 \tValidation Loss: 1.456105 \t time: 0.3\n",
      "Epoch: 312 \tTraining Loss: 1.274289 \tValidation Loss: 1.456090 \t time: 0.3\n",
      "Epoch: 313 \tTraining Loss: 1.273906 \tValidation Loss: 1.456632 \t time: 0.3\n",
      "Epoch: 314 \tTraining Loss: 1.273662 \tValidation Loss: 1.456034 \t time: 0.3\n",
      "Epoch: 315 \tTraining Loss: 1.273210 \tValidation Loss: 1.456087 \t time: 0.3\n",
      "Epoch: 316 \tTraining Loss: 1.272882 \tValidation Loss: 1.456505 \t time: 0.3\n",
      "Epoch: 317 \tTraining Loss: 1.272639 \tValidation Loss: 1.456192 \t time: 0.3\n",
      "Epoch: 318 \tTraining Loss: 1.272250 \tValidation Loss: 1.456087 \t time: 0.3\n",
      "Epoch: 319 \tTraining Loss: 1.272002 \tValidation Loss: 1.456788 \t time: 0.3\n",
      "Epoch: 320 \tTraining Loss: 1.271824 \tValidation Loss: 1.456185 \t time: 0.3\n",
      "Epoch: 321 \tTraining Loss: 1.271572 \tValidation Loss: 1.456397 \t time: 0.3\n",
      "Epoch: 322 \tTraining Loss: 1.271265 \tValidation Loss: 1.456493 \t time: 0.3\n",
      "Epoch: 323 \tTraining Loss: 1.270981 \tValidation Loss: 1.456328 \t time: 0.3\n",
      "Epoch: 324 \tTraining Loss: 1.270318 \tValidation Loss: 1.456089 \t time: 0.3\n",
      "Epoch: 325 \tTraining Loss: 1.269679 \tValidation Loss: 1.456532 \t time: 0.3\n",
      "Epoch: 326 \tTraining Loss: 1.269215 \tValidation Loss: 1.456319 \t time: 0.3\n",
      "Epoch: 327 \tTraining Loss: 1.268903 \tValidation Loss: 1.456355 \t time: 0.3\n",
      "Epoch: 328 \tTraining Loss: 1.268720 \tValidation Loss: 1.456974 \t time: 0.3\n",
      "Epoch: 329 \tTraining Loss: 1.268607 \tValidation Loss: 1.456325 \t time: 0.3\n",
      "Epoch: 330 \tTraining Loss: 1.268465 \tValidation Loss: 1.456689 \t time: 0.3\n",
      "Epoch: 331 \tTraining Loss: 1.267986 \tValidation Loss: 1.456409 \t time: 0.3\n",
      "Epoch: 332 \tTraining Loss: 1.267452 \tValidation Loss: 1.456212 \t time: 0.3\n",
      "Epoch: 333 \tTraining Loss: 1.266875 \tValidation Loss: 1.456488 \t time: 0.3\n",
      "Epoch: 334 \tTraining Loss: 1.266485 \tValidation Loss: 1.456613 \t time: 0.3\n",
      "Epoch: 335 \tTraining Loss: 1.266358 \tValidation Loss: 1.456728 \t time: 0.3\n",
      "Epoch: 336 \tTraining Loss: 1.266238 \tValidation Loss: 1.456681 \t time: 0.3\n",
      "Epoch: 337 \tTraining Loss: 1.265964 \tValidation Loss: 1.457026 \t time: 0.3\n",
      "Epoch: 338 \tTraining Loss: 1.265458 \tValidation Loss: 1.456465 \t time: 0.3\n",
      "Epoch: 339 \tTraining Loss: 1.264935 \tValidation Loss: 1.456959 \t time: 0.3\n",
      "Epoch: 340 \tTraining Loss: 1.264488 \tValidation Loss: 1.457210 \t time: 0.3\n",
      "Epoch: 341 \tTraining Loss: 1.264241 \tValidation Loss: 1.456900 \t time: 0.3\n",
      "Epoch: 342 \tTraining Loss: 1.264125 \tValidation Loss: 1.457703 \t time: 0.3\n",
      "Epoch: 343 \tTraining Loss: 1.263948 \tValidation Loss: 1.457088 \t time: 0.3\n",
      "Epoch: 344 \tTraining Loss: 1.263700 \tValidation Loss: 1.457263 \t time: 0.3\n",
      "Epoch: 345 \tTraining Loss: 1.263265 \tValidation Loss: 1.457122 \t time: 0.3\n",
      "Epoch: 346 \tTraining Loss: 1.262746 \tValidation Loss: 1.457143 \t time: 0.3\n",
      "Epoch: 347 \tTraining Loss: 1.262270 \tValidation Loss: 1.457204 \t time: 0.3\n",
      "Epoch: 348 \tTraining Loss: 1.262005 \tValidation Loss: 1.457331 \t time: 0.3\n",
      "Epoch: 349 \tTraining Loss: 1.261852 \tValidation Loss: 1.457620 \t time: 0.3\n",
      "Epoch: 350 \tTraining Loss: 1.261632 \tValidation Loss: 1.457050 \t time: 0.3\n",
      "Epoch: 351 \tTraining Loss: 1.261346 \tValidation Loss: 1.457585 \t time: 0.3\n",
      "Epoch: 352 \tTraining Loss: 1.260918 \tValidation Loss: 1.456952 \t time: 0.3\n",
      "Epoch: 353 \tTraining Loss: 1.260459 \tValidation Loss: 1.457055 \t time: 0.4\n",
      "Epoch: 354 \tTraining Loss: 1.260086 \tValidation Loss: 1.457244 \t time: 0.3\n",
      "Epoch: 355 \tTraining Loss: 1.259819 \tValidation Loss: 1.456841 \t time: 0.3\n",
      "Epoch: 356 \tTraining Loss: 1.259597 \tValidation Loss: 1.457242 \t time: 0.3\n",
      "Epoch: 357 \tTraining Loss: 1.259349 \tValidation Loss: 1.456886 \t time: 0.3\n",
      "Epoch: 358 \tTraining Loss: 1.259063 \tValidation Loss: 1.457119 \t time: 0.3\n",
      "Epoch: 359 \tTraining Loss: 1.258702 \tValidation Loss: 1.457002 \t time: 0.3\n",
      "Epoch: 360 \tTraining Loss: 1.258342 \tValidation Loss: 1.457128 \t time: 0.3\n",
      "Epoch: 361 \tTraining Loss: 1.258025 \tValidation Loss: 1.457196 \t time: 0.3\n",
      "Epoch: 362 \tTraining Loss: 1.257761 \tValidation Loss: 1.457165 \t time: 0.3\n",
      "Epoch: 363 \tTraining Loss: 1.257520 \tValidation Loss: 1.457369 \t time: 0.3\n",
      "Epoch: 364 \tTraining Loss: 1.257270 \tValidation Loss: 1.457173 \t time: 0.3\n",
      "Epoch: 365 \tTraining Loss: 1.257002 \tValidation Loss: 1.457452 \t time: 0.3\n",
      "Epoch: 366 \tTraining Loss: 1.256698 \tValidation Loss: 1.457175 \t time: 0.3\n",
      "Epoch: 367 \tTraining Loss: 1.256381 \tValidation Loss: 1.457339 \t time: 0.3\n",
      "Epoch: 368 \tTraining Loss: 1.256061 \tValidation Loss: 1.457198 \t time: 0.3\n",
      "Epoch: 369 \tTraining Loss: 1.255750 \tValidation Loss: 1.457107 \t time: 0.3\n",
      "Epoch: 370 \tTraining Loss: 1.255453 \tValidation Loss: 1.457189 \t time: 0.3\n",
      "Epoch: 371 \tTraining Loss: 1.255177 \tValidation Loss: 1.457015 \t time: 0.3\n",
      "Epoch: 372 \tTraining Loss: 1.254917 \tValidation Loss: 1.457181 \t time: 0.3\n",
      "Epoch: 373 \tTraining Loss: 1.254652 \tValidation Loss: 1.457033 \t time: 0.3\n",
      "Epoch: 374 \tTraining Loss: 1.254387 \tValidation Loss: 1.457223 \t time: 0.3\n",
      "Epoch: 375 \tTraining Loss: 1.254107 \tValidation Loss: 1.456991 \t time: 0.4\n",
      "Epoch: 376 \tTraining Loss: 1.253841 \tValidation Loss: 1.457314 \t time: 0.3\n",
      "Epoch: 377 \tTraining Loss: 1.253565 \tValidation Loss: 1.456991 \t time: 0.3\n",
      "Epoch: 378 \tTraining Loss: 1.253289 \tValidation Loss: 1.457426 \t time: 0.3\n",
      "Epoch: 379 \tTraining Loss: 1.252992 \tValidation Loss: 1.457103 \t time: 0.3\n",
      "Epoch: 380 \tTraining Loss: 1.252710 \tValidation Loss: 1.457514 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 381 \tTraining Loss: 1.252410 \tValidation Loss: 1.457151 \t time: 0.3\n",
      "Epoch: 382 \tTraining Loss: 1.252132 \tValidation Loss: 1.457543 \t time: 0.4\n",
      "Epoch: 383 \tTraining Loss: 1.251836 \tValidation Loss: 1.457063 \t time: 0.3\n",
      "Epoch: 384 \tTraining Loss: 1.251561 \tValidation Loss: 1.457524 \t time: 0.3\n",
      "Epoch: 385 \tTraining Loss: 1.251250 \tValidation Loss: 1.456928 \t time: 0.3\n",
      "Epoch: 386 \tTraining Loss: 1.250957 \tValidation Loss: 1.457468 \t time: 0.3\n",
      "Epoch: 387 \tTraining Loss: 1.250618 \tValidation Loss: 1.456795 \t time: 0.3\n",
      "Epoch: 388 \tTraining Loss: 1.250305 \tValidation Loss: 1.457350 \t time: 0.3\n",
      "Epoch: 389 \tTraining Loss: 1.249960 \tValidation Loss: 1.456669 \t time: 0.3\n",
      "Epoch: 390 \tTraining Loss: 1.249636 \tValidation Loss: 1.457166 \t time: 0.3\n",
      "Epoch: 391 \tTraining Loss: 1.249280 \tValidation Loss: 1.456585 \t time: 0.3\n",
      "Epoch: 392 \tTraining Loss: 1.248935 \tValidation Loss: 1.456973 \t time: 0.3\n",
      "Epoch: 393 \tTraining Loss: 1.248576 \tValidation Loss: 1.456607 \t time: 0.3\n",
      "Epoch: 394 \tTraining Loss: 1.248238 \tValidation Loss: 1.456826 \t time: 0.3\n",
      "Epoch: 395 \tTraining Loss: 1.247912 \tValidation Loss: 1.456732 \t time: 0.3\n",
      "Epoch: 396 \tTraining Loss: 1.247606 \tValidation Loss: 1.456713 \t time: 0.4\n",
      "Epoch: 397 \tTraining Loss: 1.247314 \tValidation Loss: 1.456900 \t time: 0.3\n",
      "Epoch: 398 \tTraining Loss: 1.247021 \tValidation Loss: 1.456663 \t time: 0.3\n",
      "Epoch: 399 \tTraining Loss: 1.246719 \tValidation Loss: 1.457167 \t time: 0.3\n",
      "Epoch: 400 \tTraining Loss: 1.246397 \tValidation Loss: 1.456801 \t time: 0.3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(400, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 199 \tTraining Loss: 1.336413 \tValidation Loss: 1.458593 \t time: 0.3\n",
    "Validation loss decreased from 1.458699 to 1.458593. Model was saved\n",
    "Epoch: 200 \tTraining Loss: 1.335772 \tValidation Loss: 1.458968 \t time: 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.437469\n",
      "\n",
      "\n",
      "Test Accuracy: 54% (236/430)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 3, 2, 3, 0, 3, 2, 0, 5, 2, 2, 0, 0, 0, 5, 5, 2, 5, 0, 0, 2,\n",
       "       5, 5, 3, 0, 0, 5, 2, 0, 3, 0, 1, 2, 0, 5, 2, 2, 3, 2, 2, 5, 0, 1,\n",
       "       5, 5, 2, 3, 2, 0, 3, 2, 1, 0, 3, 0, 5, 2, 3, 2, 3, 3, 1, 2, 0, 2,\n",
       "       3, 0, 3, 1, 5, 2, 0, 5, 5, 1, 3, 0, 3, 3, 0, 0, 2, 5, 0, 5, 2, 3,\n",
       "       1, 3, 5, 1, 2, 3, 2, 5, 5, 2, 0, 3, 5, 0, 2, 1, 2, 3, 0, 0, 3, 2,\n",
       "       0, 5, 3, 3, 2, 1, 2, 5, 4, 2, 2, 5, 0, 0, 3, 2, 1, 3, 1, 2, 2, 3,\n",
       "       1, 3, 2, 0, 2, 2, 1, 2, 2, 0, 0, 2, 3, 3, 5, 3, 2, 5, 2, 3, 2, 0,\n",
       "       2, 5, 0, 3, 5, 3, 5, 5, 5, 3, 1, 5, 5, 1, 3, 5, 0, 0, 3, 5, 0, 3,\n",
       "       3, 2, 3, 2, 5, 0, 3, 1, 2, 1, 0, 0, 0, 2, 5, 0, 2, 3, 0, 2, 3, 0,\n",
       "       5, 0, 1, 1, 2, 1, 2, 3, 2, 5, 5, 0, 1, 2, 3, 2, 1, 0, 5, 1, 1, 0,\n",
       "       5, 2, 2, 0, 2, 0, 2, 3, 3, 5, 0, 5, 3, 3, 3, 0, 3, 5, 2, 5, 2, 3,\n",
       "       2, 3, 2, 3, 0, 3, 5, 2, 0, 3, 2, 3, 2, 3, 5, 1, 0, 5, 3, 2, 3, 2,\n",
       "       3, 2, 2, 2, 2, 0, 1, 2, 5, 3, 3, 3, 0, 0, 3, 3, 3, 2, 1, 2, 0, 2,\n",
       "       5, 5, 3, 1, 0, 3, 0, 2, 1, 0, 3, 2, 2, 2, 3, 3, 3, 0, 0, 5, 5, 0,\n",
       "       3, 3, 2, 3, 5, 1, 0, 5, 3, 5, 3, 0, 0, 3, 2, 5, 0, 5, 0, 3, 3, 5,\n",
       "       5, 5, 3, 2, 0, 2, 5, 5, 3, 5, 5, 3, 0, 5, 0, 2, 0, 3, 5, 3, 0, 1,\n",
       "       5, 3, 3, 3, 3, 0, 0, 2, 3, 5, 3, 0, 5, 2, 1, 5, 3, 3, 0, 2, 2, 3,\n",
       "       3, 3, 3, 5, 5, 5, 3, 3, 3, 3, 1, 0, 5, 2, 0, 3, 2, 0, 3, 3, 5, 2,\n",
       "       3, 3, 3, 1, 0, 2, 3, 1, 2, 5, 5, 5, 2, 1, 2, 0, 3, 3, 1, 5, 1, 0,\n",
       "       3, 3, 5, 1, 2, 3, 5, 0, 3, 1, 3, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,l = next(iter(loaders['test']))\n",
    "output = model(i)\n",
    "result = output.data.max(1, keepdim=True)[1].numpy()\n",
    "result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 88.,   0.,  41.,   0.,  98.,   0., 117.,   0.,   1.,  85.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = result[:,0]\n",
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([97.,  0., 55.,  0., 89.,  0., 53.,  0., 51., 85.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(l.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = model(torch.tensor(features_test.values).type((torch.FloatTensor)))\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
