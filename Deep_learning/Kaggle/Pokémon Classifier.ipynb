{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make number of data for each class equal\n",
    "#\n",
    "# from collections import Counter\n",
    "\n",
    "# class_counter = Counter()\n",
    "\n",
    "# class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "# for class_name in class_names:\n",
    "#     class_counter[class_name] = 0\n",
    "# for i in train['class']:\n",
    "#     class_counter['class_' + str(i)] += 1\n",
    "\n",
    "# print(class_counter)\n",
    "\n",
    "# max_count = -np.Inf\n",
    "# for i in range(number_of_class):\n",
    "#     if class_counter['class_' + str(i)] > max_count:\n",
    "#         max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "# train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "# for i in range(number_of_class):\n",
    "#     num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "#     num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "#     num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "#     for j in range(num_resample_batch):\n",
    "#         add_df = train_classified[i]\n",
    "#         train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "#         train =  train.append(df_to_be_added)\n",
    "        \n",
    "\n",
    "#     df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "#     train =  train.append(df_to_be_added)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names =[i for i in range(number_of_class)]\n",
    "# for class_name in class_names:\n",
    "#     class_counter[class_name] = 0\n",
    "# for i in train['class']:\n",
    "#     class_counter[i] += 1\n",
    "\n",
    "# class_counter.most_common(number_of_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appearedTimeOfDay</th>\n",
       "      <th>appearedHour</th>\n",
       "      <th>appearedMinute</th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>city</th>\n",
       "      <th>continent</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>...</th>\n",
       "      <th>cooc_142</th>\n",
       "      <th>cooc_143</th>\n",
       "      <th>cooc_144</th>\n",
       "      <th>cooc_145</th>\n",
       "      <th>cooc_146</th>\n",
       "      <th>cooc_147</th>\n",
       "      <th>cooc_148</th>\n",
       "      <th>cooc_149</th>\n",
       "      <th>cooc_150</th>\n",
       "      <th>cooc_151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evening</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>Los_Angeles</td>\n",
       "      <td>America</td>\n",
       "      <td>PartlyCloudy</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  appearedTimeOfDay  appearedHour  appearedMinute  terrainType  closeToWater  \\\n",
       "0           evening            19              10           13         False   \n",
       "1             night             5              19           13          True   \n",
       "2           evening            19              46            0          True   \n",
       "3           morning            11              10            0          True   \n",
       "4           evening            18              32           13          True   \n",
       "\n",
       "          city  continent       weather  temperature  windSpeed    ...     \\\n",
       "0      Bangkok       Asia         Clear         27.8       9.00    ...      \n",
       "1     New_York    America         Clear         26.1       8.70    ...      \n",
       "2     New_York    America         Clear         24.7      16.82    ...      \n",
       "3       Hobart  Australia         Clear         12.7      13.25    ...      \n",
       "4  Los_Angeles    America  PartlyCloudy         19.1       5.78    ...      \n",
       "\n",
       "   cooc_142 cooc_143  cooc_144  cooc_145  cooc_146  cooc_147  cooc_148  \\\n",
       "0     False    False     False     False     False     False     False   \n",
       "1     False    False     False     False     False     False     False   \n",
       "2     False    False     False     False     False     False     False   \n",
       "3     False    False     False     False     False     False     False   \n",
       "4     False    False     False     False     False     False     False   \n",
       "\n",
       "   cooc_149  cooc_150  cooc_151  \n",
       "0     False     False     False  \n",
       "1     False     False     False  \n",
       "2     False     False     False  \n",
       "3     False     False     False  \n",
       "4     False     False     False  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1008.96</td>\n",
       "      <td>6019.04440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1018.96</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>128.89505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1011.36</td>\n",
       "      <td>4188.39100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.990268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0         13.0           0.0         27.8       9.00   1008.96   \n",
       "1         13.0           1.0         26.1       8.70   1018.96   \n",
       "2          0.0           1.0         24.7      16.82   1023.22   \n",
       "3          0.0           1.0         12.7      13.25   1014.19   \n",
       "4         13.0           1.0         19.1       5.78   1011.36   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0          6019.04440    1.0       1.0       1.0    0.0          ...            \n",
       "1             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "2             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "3           128.89505    0.0       0.0       0.0    1.0          ...            \n",
       "4          4188.39100    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                             0                      1   \n",
       "1                             0                      0   \n",
       "2                             0                      1   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                        0                   0                0   \n",
       "1                        1                   0                0   \n",
       "2                        0                   0                0   \n",
       "3                        1                   0                0   \n",
       "4                        0                   0                0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                              0                                0   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              1                                0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0                 0                 0             -0.953717  \n",
       "1                 0                 0              0.984041  \n",
       "2                 0                 0             -0.894934  \n",
       "3                 0                 0              0.216440  \n",
       "4                 0                 0             -0.990268  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631868</td>\n",
       "      <td>0.160342</td>\n",
       "      <td>0.333774</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.154997</td>\n",
       "      <td>0.598044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.710624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217033</td>\n",
       "      <td>0.236059</td>\n",
       "      <td>0.471987</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.102975</td>\n",
       "      <td>0.397199</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0       0.8125           0.0     0.631868   0.160342  0.333774   \n",
       "1       0.8125           1.0     0.585165   0.154997  0.598044   \n",
       "2       0.0000           1.0     0.546703   0.299662  0.710624   \n",
       "3       0.0000           1.0     0.217033   0.236059  0.471987   \n",
       "4       0.8125           1.0     0.392857   0.102975  0.397199   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0            0.601904    1.0       1.0       1.0    0.0          ...            \n",
       "1            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "2            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "3            0.012890    0.0       0.0       0.0    1.0          ...            \n",
       "4            0.418839    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                           0.0                    1.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    1.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                      0.0                 0.0              0.0   \n",
       "1                      1.0                 0.0              0.0   \n",
       "2                      0.0                 0.0              0.0   \n",
       "3                      1.0                 0.0              0.0   \n",
       "4                      0.0                 0.0              0.0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            1.0                              0.0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0               0.0               0.0              0.023142  \n",
       "1               0.0               0.0              0.992020  \n",
       "2               0.0               0.0              0.052533  \n",
       "3               0.0               0.0              0.608220  \n",
       "4               0.0               0.0              0.004866  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7160 entries, 0 to 7159\n",
      "Columns: 297 entries, terrainType to appearedTimeDayCycle\n",
      "dtypes: float64(272), int64(25)\n",
      "memory usage: 16.3 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7160, 297)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1611.,    0.,  920.,    0., 1478.,    0.,  889.,    0.,  851.,\n",
       "        1411.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6444, 297), (572, 297), (144, 297))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.9\n",
    "test_ratio = 0.2\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ratio = 0.98\n",
    "\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32.,  0., 19.,  0., 30.,  0., 18.,  0., 17., 28.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data per batch to load\n",
    "batch_size = 10000\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.784928 \tValidation Loss: 1.767215 \t time: 0.2\n",
      "Validation loss decreased from inf to 1.767215. Model was saved\n",
      "Epoch: 2 \tTraining Loss: 1.768289 \tValidation Loss: 1.759554 \t time: 0.2\n",
      "Validation loss decreased from 1.767215 to 1.759554. Model was saved\n",
      "Epoch: 3 \tTraining Loss: 1.761492 \tValidation Loss: 1.756852 \t time: 0.2\n",
      "Validation loss decreased from 1.759554 to 1.756852. Model was saved\n",
      "Epoch: 4 \tTraining Loss: 1.758313 \tValidation Loss: 1.756136 \t time: 0.2\n",
      "Validation loss decreased from 1.756852 to 1.756136. Model was saved\n",
      "Epoch: 5 \tTraining Loss: 1.757364 \tValidation Loss: 1.756116 \t time: 0.2\n",
      "Validation loss decreased from 1.756136 to 1.756116. Model was saved\n",
      "Epoch: 6 \tTraining Loss: 1.756996 \tValidation Loss: 1.756309 \t time: 0.2\n",
      "Epoch: 7 \tTraining Loss: 1.758409 \tValidation Loss: 1.756457 \t time: 0.2\n",
      "Epoch: 8 \tTraining Loss: 1.757243 \tValidation Loss: 1.756460 \t time: 0.2\n",
      "Epoch: 9 \tTraining Loss: 1.758671 \tValidation Loss: 1.756295 \t time: 0.2\n",
      "Epoch: 10 \tTraining Loss: 1.757186 \tValidation Loss: 1.755934 \t time: 0.2\n",
      "Validation loss decreased from 1.756116 to 1.755934. Model was saved\n",
      "Epoch: 11 \tTraining Loss: 1.757516 \tValidation Loss: 1.755354 \t time: 0.2\n",
      "Validation loss decreased from 1.755934 to 1.755354. Model was saved\n",
      "Epoch: 12 \tTraining Loss: 1.756962 \tValidation Loss: 1.754526 \t time: 0.2\n",
      "Validation loss decreased from 1.755354 to 1.754526. Model was saved\n",
      "Epoch: 13 \tTraining Loss: 1.756077 \tValidation Loss: 1.753429 \t time: 0.2\n",
      "Validation loss decreased from 1.754526 to 1.753429. Model was saved\n",
      "Epoch: 14 \tTraining Loss: 1.754603 \tValidation Loss: 1.752075 \t time: 0.2\n",
      "Validation loss decreased from 1.753429 to 1.752075. Model was saved\n",
      "Epoch: 15 \tTraining Loss: 1.753905 \tValidation Loss: 1.750498 \t time: 0.2\n",
      "Validation loss decreased from 1.752075 to 1.750498. Model was saved\n",
      "Epoch: 16 \tTraining Loss: 1.752530 \tValidation Loss: 1.748720 \t time: 0.2\n",
      "Validation loss decreased from 1.750498 to 1.748720. Model was saved\n",
      "Epoch: 17 \tTraining Loss: 1.751190 \tValidation Loss: 1.746693 \t time: 0.2\n",
      "Validation loss decreased from 1.748720 to 1.746693. Model was saved\n",
      "Epoch: 18 \tTraining Loss: 1.748276 \tValidation Loss: 1.744390 \t time: 0.2\n",
      "Validation loss decreased from 1.746693 to 1.744390. Model was saved\n",
      "Epoch: 19 \tTraining Loss: 1.746737 \tValidation Loss: 1.741774 \t time: 0.2\n",
      "Validation loss decreased from 1.744390 to 1.741774. Model was saved\n",
      "Epoch: 20 \tTraining Loss: 1.742850 \tValidation Loss: 1.738858 \t time: 0.2\n",
      "Validation loss decreased from 1.741774 to 1.738858. Model was saved\n",
      "Epoch: 21 \tTraining Loss: 1.740029 \tValidation Loss: 1.735712 \t time: 0.2\n",
      "Validation loss decreased from 1.738858 to 1.735712. Model was saved\n",
      "Epoch: 22 \tTraining Loss: 1.737703 \tValidation Loss: 1.732341 \t time: 0.2\n",
      "Validation loss decreased from 1.735712 to 1.732341. Model was saved\n",
      "Epoch: 23 \tTraining Loss: 1.735051 \tValidation Loss: 1.728670 \t time: 0.2\n",
      "Validation loss decreased from 1.732341 to 1.728670. Model was saved\n",
      "Epoch: 24 \tTraining Loss: 1.730421 \tValidation Loss: 1.724591 \t time: 0.2\n",
      "Validation loss decreased from 1.728670 to 1.724591. Model was saved\n",
      "Epoch: 25 \tTraining Loss: 1.726332 \tValidation Loss: 1.720068 \t time: 0.2\n",
      "Validation loss decreased from 1.724591 to 1.720068. Model was saved\n",
      "Epoch: 26 \tTraining Loss: 1.722121 \tValidation Loss: 1.715104 \t time: 0.2\n",
      "Validation loss decreased from 1.720068 to 1.715104. Model was saved\n",
      "Epoch: 27 \tTraining Loss: 1.716152 \tValidation Loss: 1.709727 \t time: 0.2\n",
      "Validation loss decreased from 1.715104 to 1.709727. Model was saved\n",
      "Epoch: 28 \tTraining Loss: 1.711310 \tValidation Loss: 1.703965 \t time: 0.2\n",
      "Validation loss decreased from 1.709727 to 1.703965. Model was saved\n",
      "Epoch: 29 \tTraining Loss: 1.705626 \tValidation Loss: 1.697846 \t time: 0.2\n",
      "Validation loss decreased from 1.703965 to 1.697846. Model was saved\n",
      "Epoch: 30 \tTraining Loss: 1.698478 \tValidation Loss: 1.691439 \t time: 0.2\n",
      "Validation loss decreased from 1.697846 to 1.691439. Model was saved\n",
      "Epoch: 31 \tTraining Loss: 1.691370 \tValidation Loss: 1.684806 \t time: 0.2\n",
      "Validation loss decreased from 1.691439 to 1.684806. Model was saved\n",
      "Epoch: 32 \tTraining Loss: 1.684867 \tValidation Loss: 1.677961 \t time: 0.2\n",
      "Validation loss decreased from 1.684806 to 1.677961. Model was saved\n",
      "Epoch: 33 \tTraining Loss: 1.677403 \tValidation Loss: 1.671035 \t time: 0.2\n",
      "Validation loss decreased from 1.677961 to 1.671035. Model was saved\n",
      "Epoch: 34 \tTraining Loss: 1.669699 \tValidation Loss: 1.664135 \t time: 0.2\n",
      "Validation loss decreased from 1.671035 to 1.664135. Model was saved\n",
      "Epoch: 35 \tTraining Loss: 1.662523 \tValidation Loss: 1.657245 \t time: 0.2\n",
      "Validation loss decreased from 1.664135 to 1.657245. Model was saved\n",
      "Epoch: 36 \tTraining Loss: 1.658113 \tValidation Loss: 1.650458 \t time: 0.2\n",
      "Validation loss decreased from 1.657245 to 1.650458. Model was saved\n",
      "Epoch: 37 \tTraining Loss: 1.648549 \tValidation Loss: 1.643751 \t time: 0.2\n",
      "Validation loss decreased from 1.650458 to 1.643751. Model was saved\n",
      "Epoch: 38 \tTraining Loss: 1.641801 \tValidation Loss: 1.637137 \t time: 0.2\n",
      "Validation loss decreased from 1.643751 to 1.637137. Model was saved\n",
      "Epoch: 39 \tTraining Loss: 1.636129 \tValidation Loss: 1.630611 \t time: 0.2\n",
      "Validation loss decreased from 1.637137 to 1.630611. Model was saved\n",
      "Epoch: 40 \tTraining Loss: 1.630843 \tValidation Loss: 1.624105 \t time: 0.2\n",
      "Validation loss decreased from 1.630611 to 1.624105. Model was saved\n",
      "Epoch: 41 \tTraining Loss: 1.623125 \tValidation Loss: 1.617630 \t time: 0.2\n",
      "Validation loss decreased from 1.624105 to 1.617630. Model was saved\n",
      "Epoch: 42 \tTraining Loss: 1.615032 \tValidation Loss: 1.611274 \t time: 0.2\n",
      "Validation loss decreased from 1.617630 to 1.611274. Model was saved\n",
      "Epoch: 43 \tTraining Loss: 1.608815 \tValidation Loss: 1.605071 \t time: 0.2\n",
      "Validation loss decreased from 1.611274 to 1.605071. Model was saved\n",
      "Epoch: 44 \tTraining Loss: 1.600111 \tValidation Loss: 1.599124 \t time: 0.2\n",
      "Validation loss decreased from 1.605071 to 1.599124. Model was saved\n",
      "Epoch: 45 \tTraining Loss: 1.594571 \tValidation Loss: 1.592920 \t time: 0.2\n",
      "Validation loss decreased from 1.599124 to 1.592920. Model was saved\n",
      "Epoch: 46 \tTraining Loss: 1.588385 \tValidation Loss: 1.586768 \t time: 0.2\n",
      "Validation loss decreased from 1.592920 to 1.586768. Model was saved\n",
      "Epoch: 47 \tTraining Loss: 1.582004 \tValidation Loss: 1.580840 \t time: 0.2\n",
      "Validation loss decreased from 1.586768 to 1.580840. Model was saved\n",
      "Epoch: 48 \tTraining Loss: 1.573515 \tValidation Loss: 1.574928 \t time: 0.2\n",
      "Validation loss decreased from 1.580840 to 1.574928. Model was saved\n",
      "Epoch: 49 \tTraining Loss: 1.572828 \tValidation Loss: 1.569116 \t time: 0.2\n",
      "Validation loss decreased from 1.574928 to 1.569116. Model was saved\n",
      "Epoch: 50 \tTraining Loss: 1.562449 \tValidation Loss: 1.563162 \t time: 0.2\n",
      "Validation loss decreased from 1.569116 to 1.563162. Model was saved\n",
      "Epoch: 51 \tTraining Loss: 1.559417 \tValidation Loss: 1.557530 \t time: 0.2\n",
      "Validation loss decreased from 1.563162 to 1.557530. Model was saved\n",
      "Epoch: 52 \tTraining Loss: 1.552632 \tValidation Loss: 1.552101 \t time: 0.2\n",
      "Validation loss decreased from 1.557530 to 1.552101. Model was saved\n",
      "Epoch: 53 \tTraining Loss: 1.548910 \tValidation Loss: 1.546976 \t time: 0.2\n",
      "Validation loss decreased from 1.552101 to 1.546976. Model was saved\n",
      "Epoch: 54 \tTraining Loss: 1.544949 \tValidation Loss: 1.541845 \t time: 0.2\n",
      "Validation loss decreased from 1.546976 to 1.541845. Model was saved\n",
      "Epoch: 55 \tTraining Loss: 1.539600 \tValidation Loss: 1.536913 \t time: 0.2\n",
      "Validation loss decreased from 1.541845 to 1.536913. Model was saved\n",
      "Epoch: 56 \tTraining Loss: 1.533928 \tValidation Loss: 1.532287 \t time: 0.2\n",
      "Validation loss decreased from 1.536913 to 1.532287. Model was saved\n",
      "Epoch: 57 \tTraining Loss: 1.530702 \tValidation Loss: 1.528001 \t time: 0.2\n",
      "Validation loss decreased from 1.532287 to 1.528001. Model was saved\n",
      "Epoch: 58 \tTraining Loss: 1.526123 \tValidation Loss: 1.523618 \t time: 0.2\n",
      "Validation loss decreased from 1.528001 to 1.523618. Model was saved\n",
      "Epoch: 59 \tTraining Loss: 1.523211 \tValidation Loss: 1.519158 \t time: 0.2\n",
      "Validation loss decreased from 1.523618 to 1.519158. Model was saved\n",
      "Epoch: 60 \tTraining Loss: 1.519476 \tValidation Loss: 1.514897 \t time: 0.2\n",
      "Validation loss decreased from 1.519158 to 1.514897. Model was saved\n",
      "Epoch: 61 \tTraining Loss: 1.517904 \tValidation Loss: 1.511187 \t time: 0.2\n",
      "Validation loss decreased from 1.514897 to 1.511187. Model was saved\n",
      "Epoch: 62 \tTraining Loss: 1.513335 \tValidation Loss: 1.508069 \t time: 0.2\n",
      "Validation loss decreased from 1.511187 to 1.508069. Model was saved\n",
      "Epoch: 63 \tTraining Loss: 1.509503 \tValidation Loss: 1.504928 \t time: 0.2\n",
      "Validation loss decreased from 1.508069 to 1.504928. Model was saved\n",
      "Epoch: 64 \tTraining Loss: 1.509371 \tValidation Loss: 1.502039 \t time: 0.2\n",
      "Validation loss decreased from 1.504928 to 1.502039. Model was saved\n",
      "Epoch: 65 \tTraining Loss: 1.503502 \tValidation Loss: 1.498625 \t time: 0.2\n",
      "Validation loss decreased from 1.502039 to 1.498625. Model was saved\n",
      "Epoch: 66 \tTraining Loss: 1.503106 \tValidation Loss: 1.495421 \t time: 0.2\n",
      "Validation loss decreased from 1.498625 to 1.495421. Model was saved\n",
      "Epoch: 67 \tTraining Loss: 1.497788 \tValidation Loss: 1.493224 \t time: 0.2\n",
      "Validation loss decreased from 1.495421 to 1.493224. Model was saved\n",
      "Epoch: 68 \tTraining Loss: 1.495892 \tValidation Loss: 1.491083 \t time: 0.2\n",
      "Validation loss decreased from 1.493224 to 1.491083. Model was saved\n",
      "Epoch: 69 \tTraining Loss: 1.493022 \tValidation Loss: 1.489124 \t time: 0.2\n",
      "Validation loss decreased from 1.491083 to 1.489124. Model was saved\n",
      "Epoch: 70 \tTraining Loss: 1.489391 \tValidation Loss: 1.487240 \t time: 0.2\n",
      "Validation loss decreased from 1.489124 to 1.487240. Model was saved\n",
      "Epoch: 71 \tTraining Loss: 1.489020 \tValidation Loss: 1.486129 \t time: 0.2\n",
      "Validation loss decreased from 1.487240 to 1.486129. Model was saved\n",
      "Epoch: 72 \tTraining Loss: 1.487648 \tValidation Loss: 1.484529 \t time: 0.2\n",
      "Validation loss decreased from 1.486129 to 1.484529. Model was saved\n",
      "Epoch: 73 \tTraining Loss: 1.485860 \tValidation Loss: 1.482768 \t time: 0.2\n",
      "Validation loss decreased from 1.484529 to 1.482768. Model was saved\n",
      "Epoch: 74 \tTraining Loss: 1.483100 \tValidation Loss: 1.481209 \t time: 0.2\n",
      "Validation loss decreased from 1.482768 to 1.481209. Model was saved\n",
      "Epoch: 75 \tTraining Loss: 1.480842 \tValidation Loss: 1.480171 \t time: 0.2\n",
      "Validation loss decreased from 1.481209 to 1.480171. Model was saved\n",
      "Epoch: 76 \tTraining Loss: 1.480794 \tValidation Loss: 1.479674 \t time: 0.2\n",
      "Validation loss decreased from 1.480171 to 1.479674. Model was saved\n",
      "Epoch: 77 \tTraining Loss: 1.477554 \tValidation Loss: 1.479632 \t time: 0.2\n",
      "Validation loss decreased from 1.479674 to 1.479632. Model was saved\n",
      "Epoch: 78 \tTraining Loss: 1.475267 \tValidation Loss: 1.478222 \t time: 0.2\n",
      "Validation loss decreased from 1.479632 to 1.478222. Model was saved\n",
      "Epoch: 79 \tTraining Loss: 1.473154 \tValidation Loss: 1.475526 \t time: 0.2\n",
      "Validation loss decreased from 1.478222 to 1.475526. Model was saved\n",
      "Epoch: 80 \tTraining Loss: 1.472497 \tValidation Loss: 1.473611 \t time: 0.2\n",
      "Validation loss decreased from 1.475526 to 1.473611. Model was saved\n",
      "Epoch: 81 \tTraining Loss: 1.470506 \tValidation Loss: 1.472425 \t time: 0.2\n",
      "Validation loss decreased from 1.473611 to 1.472425. Model was saved\n",
      "Epoch: 82 \tTraining Loss: 1.469757 \tValidation Loss: 1.472346 \t time: 0.2\n",
      "Validation loss decreased from 1.472425 to 1.472346. Model was saved\n",
      "Epoch: 83 \tTraining Loss: 1.468977 \tValidation Loss: 1.472564 \t time: 0.2\n",
      "Epoch: 84 \tTraining Loss: 1.467677 \tValidation Loss: 1.471238 \t time: 0.2\n",
      "Validation loss decreased from 1.472346 to 1.471238. Model was saved\n",
      "Epoch: 85 \tTraining Loss: 1.465649 \tValidation Loss: 1.468648 \t time: 0.2\n",
      "Validation loss decreased from 1.471238 to 1.468648. Model was saved\n",
      "Epoch: 86 \tTraining Loss: 1.465490 \tValidation Loss: 1.466819 \t time: 0.2\n",
      "Validation loss decreased from 1.468648 to 1.466819. Model was saved\n",
      "Epoch: 87 \tTraining Loss: 1.463069 \tValidation Loss: 1.465997 \t time: 0.2\n",
      "Validation loss decreased from 1.466819 to 1.465997. Model was saved\n",
      "Epoch: 88 \tTraining Loss: 1.463480 \tValidation Loss: 1.465775 \t time: 0.2\n",
      "Validation loss decreased from 1.465997 to 1.465775. Model was saved\n",
      "Epoch: 89 \tTraining Loss: 1.460270 \tValidation Loss: 1.465977 \t time: 0.2\n",
      "Epoch: 90 \tTraining Loss: 1.461476 \tValidation Loss: 1.465672 \t time: 0.2\n",
      "Validation loss decreased from 1.465775 to 1.465672. Model was saved\n",
      "Epoch: 91 \tTraining Loss: 1.459963 \tValidation Loss: 1.464439 \t time: 0.2\n",
      "Validation loss decreased from 1.465672 to 1.464439. Model was saved\n",
      "Epoch: 92 \tTraining Loss: 1.456943 \tValidation Loss: 1.462027 \t time: 0.2\n",
      "Validation loss decreased from 1.464439 to 1.462027. Model was saved\n",
      "Epoch: 93 \tTraining Loss: 1.456181 \tValidation Loss: 1.460753 \t time: 0.2\n",
      "Validation loss decreased from 1.462027 to 1.460753. Model was saved\n",
      "Epoch: 94 \tTraining Loss: 1.454853 \tValidation Loss: 1.460344 \t time: 0.2\n",
      "Validation loss decreased from 1.460753 to 1.460344. Model was saved\n",
      "Epoch: 95 \tTraining Loss: 1.453360 \tValidation Loss: 1.460492 \t time: 0.2\n",
      "Epoch: 96 \tTraining Loss: 1.452694 \tValidation Loss: 1.460631 \t time: 0.2\n",
      "Epoch: 97 \tTraining Loss: 1.451675 \tValidation Loss: 1.460499 \t time: 0.2\n",
      "Epoch: 98 \tTraining Loss: 1.451198 \tValidation Loss: 1.459606 \t time: 0.2\n",
      "Validation loss decreased from 1.460344 to 1.459606. Model was saved\n",
      "Epoch: 99 \tTraining Loss: 1.450856 \tValidation Loss: 1.458590 \t time: 0.2\n",
      "Validation loss decreased from 1.459606 to 1.458590. Model was saved\n",
      "Epoch: 100 \tTraining Loss: 1.451868 \tValidation Loss: 1.458354 \t time: 0.2\n",
      "Validation loss decreased from 1.458590 to 1.458354. Model was saved\n",
      "Epoch: 101 \tTraining Loss: 1.447517 \tValidation Loss: 1.458249 \t time: 0.2\n",
      "Validation loss decreased from 1.458354 to 1.458249. Model was saved\n",
      "Epoch: 102 \tTraining Loss: 1.448372 \tValidation Loss: 1.457913 \t time: 0.2\n",
      "Validation loss decreased from 1.458249 to 1.457913. Model was saved\n",
      "Epoch: 103 \tTraining Loss: 1.449001 \tValidation Loss: 1.457977 \t time: 0.2\n",
      "Epoch: 104 \tTraining Loss: 1.448626 \tValidation Loss: 1.458354 \t time: 0.2\n",
      "Epoch: 105 \tTraining Loss: 1.447302 \tValidation Loss: 1.458496 \t time: 0.2\n",
      "Epoch: 106 \tTraining Loss: 1.444994 \tValidation Loss: 1.457767 \t time: 0.2\n",
      "Validation loss decreased from 1.457913 to 1.457767. Model was saved\n",
      "Epoch: 107 \tTraining Loss: 1.444342 \tValidation Loss: 1.457130 \t time: 0.2\n",
      "Validation loss decreased from 1.457767 to 1.457130. Model was saved\n",
      "Epoch: 108 \tTraining Loss: 1.443176 \tValidation Loss: 1.456911 \t time: 0.2\n",
      "Validation loss decreased from 1.457130 to 1.456911. Model was saved\n",
      "Epoch: 109 \tTraining Loss: 1.443819 \tValidation Loss: 1.456893 \t time: 0.2\n",
      "Validation loss decreased from 1.456911 to 1.456893. Model was saved\n",
      "Epoch: 110 \tTraining Loss: 1.443322 \tValidation Loss: 1.456643 \t time: 0.2\n",
      "Validation loss decreased from 1.456893 to 1.456643. Model was saved\n",
      "Epoch: 111 \tTraining Loss: 1.444612 \tValidation Loss: 1.456493 \t time: 0.2\n",
      "Validation loss decreased from 1.456643 to 1.456493. Model was saved\n",
      "Epoch: 112 \tTraining Loss: 1.442502 \tValidation Loss: 1.456100 \t time: 0.2\n",
      "Validation loss decreased from 1.456493 to 1.456100. Model was saved\n",
      "Epoch: 113 \tTraining Loss: 1.441564 \tValidation Loss: 1.455655 \t time: 0.2\n",
      "Validation loss decreased from 1.456100 to 1.455655. Model was saved\n",
      "Epoch: 114 \tTraining Loss: 1.440650 \tValidation Loss: 1.455235 \t time: 0.2\n",
      "Validation loss decreased from 1.455655 to 1.455235. Model was saved\n",
      "Epoch: 115 \tTraining Loss: 1.442284 \tValidation Loss: 1.455010 \t time: 0.2\n",
      "Validation loss decreased from 1.455235 to 1.455010. Model was saved\n",
      "Epoch: 116 \tTraining Loss: 1.441182 \tValidation Loss: 1.454062 \t time: 0.2\n",
      "Validation loss decreased from 1.455010 to 1.454062. Model was saved\n",
      "Epoch: 117 \tTraining Loss: 1.439722 \tValidation Loss: 1.452986 \t time: 0.2\n",
      "Validation loss decreased from 1.454062 to 1.452986. Model was saved\n",
      "Epoch: 118 \tTraining Loss: 1.438057 \tValidation Loss: 1.451989 \t time: 0.2\n",
      "Validation loss decreased from 1.452986 to 1.451989. Model was saved\n",
      "Epoch: 119 \tTraining Loss: 1.440091 \tValidation Loss: 1.451423 \t time: 0.2\n",
      "Validation loss decreased from 1.451989 to 1.451423. Model was saved\n",
      "Epoch: 120 \tTraining Loss: 1.439233 \tValidation Loss: 1.451418 \t time: 0.2\n",
      "Validation loss decreased from 1.451423 to 1.451418. Model was saved\n",
      "Epoch: 121 \tTraining Loss: 1.437452 \tValidation Loss: 1.451370 \t time: 0.2\n",
      "Validation loss decreased from 1.451418 to 1.451370. Model was saved\n",
      "Epoch: 122 \tTraining Loss: 1.437117 \tValidation Loss: 1.451018 \t time: 0.2\n",
      "Validation loss decreased from 1.451370 to 1.451018. Model was saved\n",
      "Epoch: 123 \tTraining Loss: 1.436777 \tValidation Loss: 1.450193 \t time: 0.2\n",
      "Validation loss decreased from 1.451018 to 1.450193. Model was saved\n",
      "Epoch: 124 \tTraining Loss: 1.432773 \tValidation Loss: 1.449468 \t time: 0.2\n",
      "Validation loss decreased from 1.450193 to 1.449468. Model was saved\n",
      "Epoch: 125 \tTraining Loss: 1.433818 \tValidation Loss: 1.448697 \t time: 0.2\n",
      "Validation loss decreased from 1.449468 to 1.448697. Model was saved\n",
      "Epoch: 126 \tTraining Loss: 1.434295 \tValidation Loss: 1.448193 \t time: 0.2\n",
      "Validation loss decreased from 1.448697 to 1.448193. Model was saved\n",
      "Epoch: 127 \tTraining Loss: 1.434307 \tValidation Loss: 1.448314 \t time: 0.2\n",
      "Epoch: 128 \tTraining Loss: 1.432660 \tValidation Loss: 1.448797 \t time: 0.2\n",
      "Epoch: 129 \tTraining Loss: 1.434672 \tValidation Loss: 1.448910 \t time: 0.2\n",
      "Epoch: 130 \tTraining Loss: 1.433537 \tValidation Loss: 1.448872 \t time: 0.2\n",
      "Epoch: 131 \tTraining Loss: 1.432678 \tValidation Loss: 1.448771 \t time: 0.2\n",
      "Epoch: 132 \tTraining Loss: 1.430394 \tValidation Loss: 1.448096 \t time: 0.2\n",
      "Validation loss decreased from 1.448193 to 1.448096. Model was saved\n",
      "Epoch: 133 \tTraining Loss: 1.430736 \tValidation Loss: 1.447490 \t time: 0.2\n",
      "Validation loss decreased from 1.448096 to 1.447490. Model was saved\n",
      "Epoch: 134 \tTraining Loss: 1.430403 \tValidation Loss: 1.447349 \t time: 0.2\n",
      "Validation loss decreased from 1.447490 to 1.447349. Model was saved\n",
      "Epoch: 135 \tTraining Loss: 1.430539 \tValidation Loss: 1.447468 \t time: 0.2\n",
      "Epoch: 136 \tTraining Loss: 1.429237 \tValidation Loss: 1.447387 \t time: 0.2\n",
      "Epoch: 137 \tTraining Loss: 1.429300 \tValidation Loss: 1.447300 \t time: 0.2\n",
      "Validation loss decreased from 1.447349 to 1.447300. Model was saved\n",
      "Epoch: 138 \tTraining Loss: 1.430065 \tValidation Loss: 1.447055 \t time: 0.2\n",
      "Validation loss decreased from 1.447300 to 1.447055. Model was saved\n",
      "Epoch: 139 \tTraining Loss: 1.426690 \tValidation Loss: 1.446868 \t time: 0.2\n",
      "Validation loss decreased from 1.447055 to 1.446868. Model was saved\n",
      "Epoch: 140 \tTraining Loss: 1.427909 \tValidation Loss: 1.446801 \t time: 0.2\n",
      "Validation loss decreased from 1.446868 to 1.446801. Model was saved\n",
      "Epoch: 141 \tTraining Loss: 1.427125 \tValidation Loss: 1.446729 \t time: 0.2\n",
      "Validation loss decreased from 1.446801 to 1.446729. Model was saved\n",
      "Epoch: 142 \tTraining Loss: 1.427494 \tValidation Loss: 1.446706 \t time: 0.2\n",
      "Validation loss decreased from 1.446729 to 1.446706. Model was saved\n",
      "Epoch: 143 \tTraining Loss: 1.425756 \tValidation Loss: 1.446375 \t time: 0.2\n",
      "Validation loss decreased from 1.446706 to 1.446375. Model was saved\n",
      "Epoch: 144 \tTraining Loss: 1.425471 \tValidation Loss: 1.445701 \t time: 0.2\n",
      "Validation loss decreased from 1.446375 to 1.445701. Model was saved\n",
      "Epoch: 145 \tTraining Loss: 1.425097 \tValidation Loss: 1.445061 \t time: 0.2\n",
      "Validation loss decreased from 1.445701 to 1.445061. Model was saved\n",
      "Epoch: 146 \tTraining Loss: 1.426353 \tValidation Loss: 1.444583 \t time: 0.2\n",
      "Validation loss decreased from 1.445061 to 1.444583. Model was saved\n",
      "Epoch: 147 \tTraining Loss: 1.425236 \tValidation Loss: 1.444487 \t time: 0.2\n",
      "Validation loss decreased from 1.444583 to 1.444487. Model was saved\n",
      "Epoch: 148 \tTraining Loss: 1.423143 \tValidation Loss: 1.444661 \t time: 0.2\n",
      "Epoch: 149 \tTraining Loss: 1.427238 \tValidation Loss: 1.444622 \t time: 0.2\n",
      "Epoch: 150 \tTraining Loss: 1.421747 \tValidation Loss: 1.444721 \t time: 0.2\n",
      "Epoch: 151 \tTraining Loss: 1.423421 \tValidation Loss: 1.444659 \t time: 0.2\n",
      "Epoch: 152 \tTraining Loss: 1.421510 \tValidation Loss: 1.444409 \t time: 0.2\n",
      "Validation loss decreased from 1.444487 to 1.444409. Model was saved\n",
      "Epoch: 153 \tTraining Loss: 1.422262 \tValidation Loss: 1.444058 \t time: 0.2\n",
      "Validation loss decreased from 1.444409 to 1.444058. Model was saved\n",
      "Epoch: 154 \tTraining Loss: 1.420840 \tValidation Loss: 1.443797 \t time: 0.2\n",
      "Validation loss decreased from 1.444058 to 1.443797. Model was saved\n",
      "Epoch: 155 \tTraining Loss: 1.420762 \tValidation Loss: 1.443727 \t time: 0.2\n",
      "Validation loss decreased from 1.443797 to 1.443727. Model was saved\n",
      "Epoch: 156 \tTraining Loss: 1.424247 \tValidation Loss: 1.443736 \t time: 0.2\n",
      "Epoch: 157 \tTraining Loss: 1.421007 \tValidation Loss: 1.443971 \t time: 0.2\n",
      "Epoch: 158 \tTraining Loss: 1.421013 \tValidation Loss: 1.444315 \t time: 0.2\n",
      "Epoch: 159 \tTraining Loss: 1.422491 \tValidation Loss: 1.444371 \t time: 0.2\n",
      "Epoch: 160 \tTraining Loss: 1.419626 \tValidation Loss: 1.444511 \t time: 0.2\n",
      "Epoch: 161 \tTraining Loss: 1.419560 \tValidation Loss: 1.444508 \t time: 0.2\n",
      "Epoch: 162 \tTraining Loss: 1.422670 \tValidation Loss: 1.444500 \t time: 0.2\n",
      "Epoch: 163 \tTraining Loss: 1.418310 \tValidation Loss: 1.444216 \t time: 0.2\n",
      "Epoch: 164 \tTraining Loss: 1.419275 \tValidation Loss: 1.443912 \t time: 0.2\n",
      "Epoch: 165 \tTraining Loss: 1.417515 \tValidation Loss: 1.443883 \t time: 0.2\n",
      "Epoch: 166 \tTraining Loss: 1.418685 \tValidation Loss: 1.443782 \t time: 0.2\n",
      "Epoch: 167 \tTraining Loss: 1.418030 \tValidation Loss: 1.443682 \t time: 0.2\n",
      "Validation loss decreased from 1.443727 to 1.443682. Model was saved\n",
      "Epoch: 168 \tTraining Loss: 1.413769 \tValidation Loss: 1.443779 \t time: 0.2\n",
      "Epoch: 169 \tTraining Loss: 1.415956 \tValidation Loss: 1.444011 \t time: 0.2\n",
      "Epoch: 170 \tTraining Loss: 1.415486 \tValidation Loss: 1.443879 \t time: 0.2\n",
      "Epoch: 171 \tTraining Loss: 1.414671 \tValidation Loss: 1.443503 \t time: 0.2\n",
      "Validation loss decreased from 1.443682 to 1.443503. Model was saved\n",
      "Epoch: 172 \tTraining Loss: 1.413190 \tValidation Loss: 1.443051 \t time: 0.2\n",
      "Validation loss decreased from 1.443503 to 1.443051. Model was saved\n",
      "Epoch: 173 \tTraining Loss: 1.410808 \tValidation Loss: 1.442867 \t time: 0.2\n",
      "Validation loss decreased from 1.443051 to 1.442867. Model was saved\n",
      "Epoch: 174 \tTraining Loss: 1.416350 \tValidation Loss: 1.442818 \t time: 0.2\n",
      "Validation loss decreased from 1.442867 to 1.442818. Model was saved\n",
      "Epoch: 175 \tTraining Loss: 1.414255 \tValidation Loss: 1.442938 \t time: 0.2\n",
      "Epoch: 176 \tTraining Loss: 1.411594 \tValidation Loss: 1.443090 \t time: 0.2\n",
      "Epoch: 177 \tTraining Loss: 1.411687 \tValidation Loss: 1.443109 \t time: 0.2\n",
      "Epoch: 178 \tTraining Loss: 1.412663 \tValidation Loss: 1.442873 \t time: 0.2\n",
      "Epoch: 179 \tTraining Loss: 1.413180 \tValidation Loss: 1.442334 \t time: 0.2\n",
      "Validation loss decreased from 1.442818 to 1.442334. Model was saved\n",
      "Epoch: 180 \tTraining Loss: 1.414865 \tValidation Loss: 1.441854 \t time: 0.2\n",
      "Validation loss decreased from 1.442334 to 1.441854. Model was saved\n",
      "Epoch: 181 \tTraining Loss: 1.411465 \tValidation Loss: 1.441413 \t time: 0.2\n",
      "Validation loss decreased from 1.441854 to 1.441413. Model was saved\n",
      "Epoch: 182 \tTraining Loss: 1.411362 \tValidation Loss: 1.441352 \t time: 0.2\n",
      "Validation loss decreased from 1.441413 to 1.441352. Model was saved\n",
      "Epoch: 183 \tTraining Loss: 1.411838 \tValidation Loss: 1.441277 \t time: 0.2\n",
      "Validation loss decreased from 1.441352 to 1.441277. Model was saved\n",
      "Epoch: 184 \tTraining Loss: 1.410479 \tValidation Loss: 1.441252 \t time: 0.2\n",
      "Validation loss decreased from 1.441277 to 1.441252. Model was saved\n",
      "Epoch: 185 \tTraining Loss: 1.409097 \tValidation Loss: 1.441086 \t time: 0.2\n",
      "Validation loss decreased from 1.441252 to 1.441086. Model was saved\n",
      "Epoch: 186 \tTraining Loss: 1.409036 \tValidation Loss: 1.440961 \t time: 0.2\n",
      "Validation loss decreased from 1.441086 to 1.440961. Model was saved\n",
      "Epoch: 187 \tTraining Loss: 1.408517 \tValidation Loss: 1.440705 \t time: 0.2\n",
      "Validation loss decreased from 1.440961 to 1.440705. Model was saved\n",
      "Epoch: 188 \tTraining Loss: 1.410537 \tValidation Loss: 1.440592 \t time: 0.2\n",
      "Validation loss decreased from 1.440705 to 1.440592. Model was saved\n",
      "Epoch: 189 \tTraining Loss: 1.408008 \tValidation Loss: 1.440576 \t time: 0.2\n",
      "Validation loss decreased from 1.440592 to 1.440576. Model was saved\n",
      "Epoch: 190 \tTraining Loss: 1.407154 \tValidation Loss: 1.440513 \t time: 0.2\n",
      "Validation loss decreased from 1.440576 to 1.440513. Model was saved\n",
      "Epoch: 191 \tTraining Loss: 1.408209 \tValidation Loss: 1.440261 \t time: 0.2\n",
      "Validation loss decreased from 1.440513 to 1.440261. Model was saved\n",
      "Epoch: 192 \tTraining Loss: 1.408114 \tValidation Loss: 1.439916 \t time: 0.2\n",
      "Validation loss decreased from 1.440261 to 1.439916. Model was saved\n",
      "Epoch: 193 \tTraining Loss: 1.405941 \tValidation Loss: 1.439422 \t time: 0.2\n",
      "Validation loss decreased from 1.439916 to 1.439422. Model was saved\n",
      "Epoch: 194 \tTraining Loss: 1.408983 \tValidation Loss: 1.439089 \t time: 0.2\n",
      "Validation loss decreased from 1.439422 to 1.439089. Model was saved\n",
      "Epoch: 195 \tTraining Loss: 1.407640 \tValidation Loss: 1.438859 \t time: 0.2\n",
      "Validation loss decreased from 1.439089 to 1.438859. Model was saved\n",
      "Epoch: 196 \tTraining Loss: 1.406643 \tValidation Loss: 1.438729 \t time: 0.2\n",
      "Validation loss decreased from 1.438859 to 1.438729. Model was saved\n",
      "Epoch: 197 \tTraining Loss: 1.405970 \tValidation Loss: 1.438382 \t time: 0.2\n",
      "Validation loss decreased from 1.438729 to 1.438382. Model was saved\n",
      "Epoch: 198 \tTraining Loss: 1.407923 \tValidation Loss: 1.438174 \t time: 0.2\n",
      "Validation loss decreased from 1.438382 to 1.438174. Model was saved\n",
      "Epoch: 199 \tTraining Loss: 1.405284 \tValidation Loss: 1.437977 \t time: 0.2\n",
      "Validation loss decreased from 1.438174 to 1.437977. Model was saved\n",
      "Epoch: 200 \tTraining Loss: 1.406385 \tValidation Loss: 1.437836 \t time: 0.2\n",
      "Validation loss decreased from 1.437977 to 1.437836. Model was saved\n",
      "Epoch: 201 \tTraining Loss: 1.404547 \tValidation Loss: 1.437626 \t time: 0.2\n",
      "Validation loss decreased from 1.437836 to 1.437626. Model was saved\n",
      "Epoch: 202 \tTraining Loss: 1.404361 \tValidation Loss: 1.437310 \t time: 0.2\n",
      "Validation loss decreased from 1.437626 to 1.437310. Model was saved\n",
      "Epoch: 203 \tTraining Loss: 1.403995 \tValidation Loss: 1.437023 \t time: 0.2\n",
      "Validation loss decreased from 1.437310 to 1.437023. Model was saved\n",
      "Epoch: 204 \tTraining Loss: 1.405486 \tValidation Loss: 1.437039 \t time: 0.2\n",
      "Epoch: 205 \tTraining Loss: 1.404990 \tValidation Loss: 1.436958 \t time: 0.2\n",
      "Validation loss decreased from 1.437023 to 1.436958. Model was saved\n",
      "Epoch: 206 \tTraining Loss: 1.402700 \tValidation Loss: 1.436875 \t time: 0.2\n",
      "Validation loss decreased from 1.436958 to 1.436875. Model was saved\n",
      "Epoch: 207 \tTraining Loss: 1.399584 \tValidation Loss: 1.437078 \t time: 0.2\n",
      "Epoch: 208 \tTraining Loss: 1.400240 \tValidation Loss: 1.436977 \t time: 0.2\n",
      "Epoch: 209 \tTraining Loss: 1.400973 \tValidation Loss: 1.436731 \t time: 0.2\n",
      "Validation loss decreased from 1.436875 to 1.436731. Model was saved\n",
      "Epoch: 210 \tTraining Loss: 1.403785 \tValidation Loss: 1.436643 \t time: 0.2\n",
      "Validation loss decreased from 1.436731 to 1.436643. Model was saved\n",
      "Epoch: 211 \tTraining Loss: 1.401950 \tValidation Loss: 1.436771 \t time: 0.2\n",
      "Epoch: 212 \tTraining Loss: 1.399288 \tValidation Loss: 1.436730 \t time: 0.2\n",
      "Epoch: 213 \tTraining Loss: 1.402729 \tValidation Loss: 1.436833 \t time: 0.2\n",
      "Epoch: 214 \tTraining Loss: 1.398957 \tValidation Loss: 1.437067 \t time: 0.2\n",
      "Epoch: 215 \tTraining Loss: 1.401161 \tValidation Loss: 1.437073 \t time: 0.2\n",
      "Epoch: 216 \tTraining Loss: 1.398111 \tValidation Loss: 1.436864 \t time: 0.2\n",
      "Epoch: 217 \tTraining Loss: 1.398940 \tValidation Loss: 1.436643 \t time: 0.2\n",
      "Epoch: 218 \tTraining Loss: 1.398214 \tValidation Loss: 1.436455 \t time: 0.2\n",
      "Validation loss decreased from 1.436643 to 1.436455. Model was saved\n",
      "Epoch: 219 \tTraining Loss: 1.396618 \tValidation Loss: 1.436386 \t time: 0.2\n",
      "Validation loss decreased from 1.436455 to 1.436386. Model was saved\n",
      "Epoch: 220 \tTraining Loss: 1.398645 \tValidation Loss: 1.436327 \t time: 0.2\n",
      "Validation loss decreased from 1.436386 to 1.436327. Model was saved\n",
      "Epoch: 221 \tTraining Loss: 1.397613 \tValidation Loss: 1.436143 \t time: 0.2\n",
      "Validation loss decreased from 1.436327 to 1.436143. Model was saved\n",
      "Epoch: 222 \tTraining Loss: 1.395064 \tValidation Loss: 1.435902 \t time: 0.2\n",
      "Validation loss decreased from 1.436143 to 1.435902. Model was saved\n",
      "Epoch: 223 \tTraining Loss: 1.395721 \tValidation Loss: 1.435580 \t time: 0.2\n",
      "Validation loss decreased from 1.435902 to 1.435580. Model was saved\n",
      "Epoch: 224 \tTraining Loss: 1.394485 \tValidation Loss: 1.435002 \t time: 0.2\n",
      "Validation loss decreased from 1.435580 to 1.435002. Model was saved\n",
      "Epoch: 225 \tTraining Loss: 1.394293 \tValidation Loss: 1.434499 \t time: 0.2\n",
      "Validation loss decreased from 1.435002 to 1.434499. Model was saved\n",
      "Epoch: 226 \tTraining Loss: 1.396082 \tValidation Loss: 1.434232 \t time: 0.2\n",
      "Validation loss decreased from 1.434499 to 1.434232. Model was saved\n",
      "Epoch: 227 \tTraining Loss: 1.394833 \tValidation Loss: 1.434274 \t time: 0.2\n",
      "Epoch: 228 \tTraining Loss: 1.396164 \tValidation Loss: 1.434534 \t time: 0.2\n",
      "Epoch: 229 \tTraining Loss: 1.394126 \tValidation Loss: 1.434880 \t time: 0.2\n",
      "Epoch: 230 \tTraining Loss: 1.393072 \tValidation Loss: 1.434857 \t time: 0.2\n",
      "Epoch: 231 \tTraining Loss: 1.393494 \tValidation Loss: 1.434496 \t time: 0.2\n",
      "Epoch: 232 \tTraining Loss: 1.392661 \tValidation Loss: 1.434107 \t time: 0.2\n",
      "Validation loss decreased from 1.434232 to 1.434107. Model was saved\n",
      "Epoch: 233 \tTraining Loss: 1.393387 \tValidation Loss: 1.433759 \t time: 0.2\n",
      "Validation loss decreased from 1.434107 to 1.433759. Model was saved\n",
      "Epoch: 234 \tTraining Loss: 1.389823 \tValidation Loss: 1.433478 \t time: 0.2\n",
      "Validation loss decreased from 1.433759 to 1.433478. Model was saved\n",
      "Epoch: 235 \tTraining Loss: 1.391851 \tValidation Loss: 1.433200 \t time: 0.2\n",
      "Validation loss decreased from 1.433478 to 1.433200. Model was saved\n",
      "Epoch: 236 \tTraining Loss: 1.392917 \tValidation Loss: 1.433105 \t time: 0.2\n",
      "Validation loss decreased from 1.433200 to 1.433105. Model was saved\n",
      "Epoch: 237 \tTraining Loss: 1.393310 \tValidation Loss: 1.433261 \t time: 0.2\n",
      "Epoch: 238 \tTraining Loss: 1.392857 \tValidation Loss: 1.433553 \t time: 0.2\n",
      "Epoch: 239 \tTraining Loss: 1.390656 \tValidation Loss: 1.433168 \t time: 0.2\n",
      "Epoch: 240 \tTraining Loss: 1.389677 \tValidation Loss: 1.432763 \t time: 0.2\n",
      "Validation loss decreased from 1.433105 to 1.432763. Model was saved\n",
      "Epoch: 241 \tTraining Loss: 1.391120 \tValidation Loss: 1.432221 \t time: 0.2\n",
      "Validation loss decreased from 1.432763 to 1.432221. Model was saved\n",
      "Epoch: 242 \tTraining Loss: 1.388596 \tValidation Loss: 1.431727 \t time: 0.2\n",
      "Validation loss decreased from 1.432221 to 1.431727. Model was saved\n",
      "Epoch: 243 \tTraining Loss: 1.387971 \tValidation Loss: 1.431424 \t time: 0.2\n",
      "Validation loss decreased from 1.431727 to 1.431424. Model was saved\n",
      "Epoch: 244 \tTraining Loss: 1.390175 \tValidation Loss: 1.431540 \t time: 0.2\n",
      "Epoch: 245 \tTraining Loss: 1.388632 \tValidation Loss: 1.431903 \t time: 0.2\n",
      "Epoch: 246 \tTraining Loss: 1.388950 \tValidation Loss: 1.432368 \t time: 0.2\n",
      "Epoch: 247 \tTraining Loss: 1.391629 \tValidation Loss: 1.432477 \t time: 0.2\n",
      "Epoch: 248 \tTraining Loss: 1.389111 \tValidation Loss: 1.431960 \t time: 0.2\n",
      "Epoch: 249 \tTraining Loss: 1.386662 \tValidation Loss: 1.431239 \t time: 0.2\n",
      "Validation loss decreased from 1.431424 to 1.431239. Model was saved\n",
      "Epoch: 250 \tTraining Loss: 1.384718 \tValidation Loss: 1.430691 \t time: 0.2\n",
      "Validation loss decreased from 1.431239 to 1.430691. Model was saved\n",
      "Epoch: 251 \tTraining Loss: 1.387892 \tValidation Loss: 1.430670 \t time: 0.2\n",
      "Validation loss decreased from 1.430691 to 1.430670. Model was saved\n",
      "Epoch: 252 \tTraining Loss: 1.388531 \tValidation Loss: 1.430910 \t time: 0.2\n",
      "Epoch: 253 \tTraining Loss: 1.386876 \tValidation Loss: 1.431520 \t time: 0.2\n",
      "Epoch: 254 \tTraining Loss: 1.386346 \tValidation Loss: 1.431920 \t time: 0.2\n",
      "Epoch: 255 \tTraining Loss: 1.385443 \tValidation Loss: 1.431623 \t time: 0.2\n",
      "Epoch: 256 \tTraining Loss: 1.386978 \tValidation Loss: 1.430956 \t time: 0.2\n",
      "Epoch: 257 \tTraining Loss: 1.386251 \tValidation Loss: 1.430546 \t time: 0.2\n",
      "Validation loss decreased from 1.430670 to 1.430546. Model was saved\n",
      "Epoch: 258 \tTraining Loss: 1.386636 \tValidation Loss: 1.430312 \t time: 0.2\n",
      "Validation loss decreased from 1.430546 to 1.430312. Model was saved\n",
      "Epoch: 259 \tTraining Loss: 1.385799 \tValidation Loss: 1.430285 \t time: 0.2\n",
      "Validation loss decreased from 1.430312 to 1.430285. Model was saved\n",
      "Epoch: 260 \tTraining Loss: 1.384262 \tValidation Loss: 1.430338 \t time: 0.2\n",
      "Epoch: 261 \tTraining Loss: 1.385460 \tValidation Loss: 1.430415 \t time: 0.2\n",
      "Epoch: 262 \tTraining Loss: 1.383661 \tValidation Loss: 1.430619 \t time: 0.2\n",
      "Epoch: 263 \tTraining Loss: 1.382485 \tValidation Loss: 1.430443 \t time: 0.2\n",
      "Epoch: 264 \tTraining Loss: 1.383014 \tValidation Loss: 1.430145 \t time: 0.2\n",
      "Validation loss decreased from 1.430285 to 1.430145. Model was saved\n",
      "Epoch: 265 \tTraining Loss: 1.381382 \tValidation Loss: 1.430026 \t time: 0.2\n",
      "Validation loss decreased from 1.430145 to 1.430026. Model was saved\n",
      "Epoch: 266 \tTraining Loss: 1.383139 \tValidation Loss: 1.430072 \t time: 0.2\n",
      "Epoch: 267 \tTraining Loss: 1.381183 \tValidation Loss: 1.430281 \t time: 0.2\n",
      "Epoch: 268 \tTraining Loss: 1.385288 \tValidation Loss: 1.430520 \t time: 0.2\n",
      "Epoch: 269 \tTraining Loss: 1.380484 \tValidation Loss: 1.430774 \t time: 0.2\n",
      "Epoch: 270 \tTraining Loss: 1.381090 \tValidation Loss: 1.431122 \t time: 0.2\n",
      "Epoch: 271 \tTraining Loss: 1.380081 \tValidation Loss: 1.431339 \t time: 0.2\n",
      "Epoch: 272 \tTraining Loss: 1.381638 \tValidation Loss: 1.431251 \t time: 0.2\n",
      "Epoch: 273 \tTraining Loss: 1.379094 \tValidation Loss: 1.431051 \t time: 0.2\n",
      "Epoch: 274 \tTraining Loss: 1.382064 \tValidation Loss: 1.431036 \t time: 0.2\n",
      "Epoch: 275 \tTraining Loss: 1.381234 \tValidation Loss: 1.431034 \t time: 0.2\n",
      "Epoch: 276 \tTraining Loss: 1.379314 \tValidation Loss: 1.430840 \t time: 0.2\n",
      "Epoch: 277 \tTraining Loss: 1.379774 \tValidation Loss: 1.430579 \t time: 0.2\n",
      "Epoch: 278 \tTraining Loss: 1.378672 \tValidation Loss: 1.430249 \t time: 0.2\n",
      "Epoch: 279 \tTraining Loss: 1.379215 \tValidation Loss: 1.429715 \t time: 0.2\n",
      "Validation loss decreased from 1.430026 to 1.429715. Model was saved\n",
      "Epoch: 280 \tTraining Loss: 1.382132 \tValidation Loss: 1.429145 \t time: 0.2\n",
      "Validation loss decreased from 1.429715 to 1.429145. Model was saved\n",
      "Epoch: 281 \tTraining Loss: 1.381271 \tValidation Loss: 1.428746 \t time: 0.2\n",
      "Validation loss decreased from 1.429145 to 1.428746. Model was saved\n",
      "Epoch: 282 \tTraining Loss: 1.382042 \tValidation Loss: 1.428401 \t time: 0.2\n",
      "Validation loss decreased from 1.428746 to 1.428401. Model was saved\n",
      "Epoch: 283 \tTraining Loss: 1.378978 \tValidation Loss: 1.428182 \t time: 0.2\n",
      "Validation loss decreased from 1.428401 to 1.428182. Model was saved\n",
      "Epoch: 284 \tTraining Loss: 1.377995 \tValidation Loss: 1.427989 \t time: 0.2\n",
      "Validation loss decreased from 1.428182 to 1.427989. Model was saved\n",
      "Epoch: 285 \tTraining Loss: 1.374980 \tValidation Loss: 1.427857 \t time: 0.2\n",
      "Validation loss decreased from 1.427989 to 1.427857. Model was saved\n",
      "Epoch: 286 \tTraining Loss: 1.378046 \tValidation Loss: 1.427647 \t time: 0.2\n",
      "Validation loss decreased from 1.427857 to 1.427647. Model was saved\n",
      "Epoch: 287 \tTraining Loss: 1.377466 \tValidation Loss: 1.427515 \t time: 0.2\n",
      "Validation loss decreased from 1.427647 to 1.427515. Model was saved\n",
      "Epoch: 288 \tTraining Loss: 1.375633 \tValidation Loss: 1.427689 \t time: 0.2\n",
      "Epoch: 289 \tTraining Loss: 1.376178 \tValidation Loss: 1.427795 \t time: 0.2\n",
      "Epoch: 290 \tTraining Loss: 1.374269 \tValidation Loss: 1.427837 \t time: 0.2\n",
      "Epoch: 291 \tTraining Loss: 1.375405 \tValidation Loss: 1.428025 \t time: 0.2\n",
      "Epoch: 292 \tTraining Loss: 1.375168 \tValidation Loss: 1.428449 \t time: 0.2\n",
      "Epoch: 293 \tTraining Loss: 1.372602 \tValidation Loss: 1.428366 \t time: 0.2\n",
      "Epoch: 294 \tTraining Loss: 1.375580 \tValidation Loss: 1.428108 \t time: 0.2\n",
      "Epoch: 295 \tTraining Loss: 1.377269 \tValidation Loss: 1.427989 \t time: 0.2\n",
      "Epoch: 296 \tTraining Loss: 1.376722 \tValidation Loss: 1.427963 \t time: 0.2\n",
      "Epoch: 297 \tTraining Loss: 1.375613 \tValidation Loss: 1.427702 \t time: 0.2\n",
      "Epoch: 298 \tTraining Loss: 1.372684 \tValidation Loss: 1.427258 \t time: 0.2\n",
      "Validation loss decreased from 1.427515 to 1.427258. Model was saved\n",
      "Epoch: 299 \tTraining Loss: 1.371622 \tValidation Loss: 1.426978 \t time: 0.2\n",
      "Validation loss decreased from 1.427258 to 1.426978. Model was saved\n",
      "Epoch: 300 \tTraining Loss: 1.377824 \tValidation Loss: 1.426883 \t time: 0.2\n",
      "Validation loss decreased from 1.426978 to 1.426883. Model was saved\n",
      "Epoch: 301 \tTraining Loss: 1.375622 \tValidation Loss: 1.426663 \t time: 0.2\n",
      "Validation loss decreased from 1.426883 to 1.426663. Model was saved\n",
      "Epoch: 302 \tTraining Loss: 1.375303 \tValidation Loss: 1.426298 \t time: 0.2\n",
      "Validation loss decreased from 1.426663 to 1.426298. Model was saved\n",
      "Epoch: 303 \tTraining Loss: 1.373981 \tValidation Loss: 1.426198 \t time: 0.2\n",
      "Validation loss decreased from 1.426298 to 1.426198. Model was saved\n",
      "Epoch: 304 \tTraining Loss: 1.371950 \tValidation Loss: 1.426208 \t time: 0.2\n",
      "Epoch: 305 \tTraining Loss: 1.372271 \tValidation Loss: 1.426175 \t time: 0.2\n",
      "Validation loss decreased from 1.426198 to 1.426175. Model was saved\n",
      "Epoch: 306 \tTraining Loss: 1.374068 \tValidation Loss: 1.426145 \t time: 0.2\n",
      "Validation loss decreased from 1.426175 to 1.426145. Model was saved\n",
      "Epoch: 307 \tTraining Loss: 1.372694 \tValidation Loss: 1.426169 \t time: 0.2\n",
      "Epoch: 308 \tTraining Loss: 1.371145 \tValidation Loss: 1.426286 \t time: 0.2\n",
      "Epoch: 309 \tTraining Loss: 1.370444 \tValidation Loss: 1.426610 \t time: 0.2\n",
      "Epoch: 310 \tTraining Loss: 1.371363 \tValidation Loss: 1.426873 \t time: 0.2\n",
      "Epoch: 311 \tTraining Loss: 1.371075 \tValidation Loss: 1.426988 \t time: 0.2\n",
      "Epoch: 312 \tTraining Loss: 1.369698 \tValidation Loss: 1.426850 \t time: 0.2\n",
      "Epoch: 313 \tTraining Loss: 1.371140 \tValidation Loss: 1.426643 \t time: 0.2\n",
      "Epoch: 314 \tTraining Loss: 1.370144 \tValidation Loss: 1.426446 \t time: 0.2\n",
      "Epoch: 315 \tTraining Loss: 1.369855 \tValidation Loss: 1.426134 \t time: 0.2\n",
      "Validation loss decreased from 1.426145 to 1.426134. Model was saved\n",
      "Epoch: 316 \tTraining Loss: 1.369094 \tValidation Loss: 1.425646 \t time: 0.2\n",
      "Validation loss decreased from 1.426134 to 1.425646. Model was saved\n",
      "Epoch: 317 \tTraining Loss: 1.371436 \tValidation Loss: 1.425203 \t time: 0.2\n",
      "Validation loss decreased from 1.425646 to 1.425203. Model was saved\n",
      "Epoch: 318 \tTraining Loss: 1.371627 \tValidation Loss: 1.424915 \t time: 0.2\n",
      "Validation loss decreased from 1.425203 to 1.424915. Model was saved\n",
      "Epoch: 319 \tTraining Loss: 1.370219 \tValidation Loss: 1.424819 \t time: 0.2\n",
      "Validation loss decreased from 1.424915 to 1.424819. Model was saved\n",
      "Epoch: 320 \tTraining Loss: 1.368513 \tValidation Loss: 1.424569 \t time: 0.2\n",
      "Validation loss decreased from 1.424819 to 1.424569. Model was saved\n",
      "Epoch: 321 \tTraining Loss: 1.368785 \tValidation Loss: 1.424139 \t time: 0.2\n",
      "Validation loss decreased from 1.424569 to 1.424139. Model was saved\n",
      "Epoch: 322 \tTraining Loss: 1.367011 \tValidation Loss: 1.423528 \t time: 0.2\n",
      "Validation loss decreased from 1.424139 to 1.423528. Model was saved\n",
      "Epoch: 323 \tTraining Loss: 1.370289 \tValidation Loss: 1.423224 \t time: 0.2\n",
      "Validation loss decreased from 1.423528 to 1.423224. Model was saved\n",
      "Epoch: 324 \tTraining Loss: 1.367741 \tValidation Loss: 1.422975 \t time: 0.2\n",
      "Validation loss decreased from 1.423224 to 1.422975. Model was saved\n",
      "Epoch: 325 \tTraining Loss: 1.368140 \tValidation Loss: 1.422778 \t time: 0.2\n",
      "Validation loss decreased from 1.422975 to 1.422778. Model was saved\n",
      "Epoch: 326 \tTraining Loss: 1.368028 \tValidation Loss: 1.422660 \t time: 0.2\n",
      "Validation loss decreased from 1.422778 to 1.422660. Model was saved\n",
      "Epoch: 327 \tTraining Loss: 1.365775 \tValidation Loss: 1.422654 \t time: 0.2\n",
      "Validation loss decreased from 1.422660 to 1.422654. Model was saved\n",
      "Epoch: 328 \tTraining Loss: 1.366181 \tValidation Loss: 1.422647 \t time: 0.2\n",
      "Validation loss decreased from 1.422654 to 1.422647. Model was saved\n",
      "Epoch: 329 \tTraining Loss: 1.364506 \tValidation Loss: 1.422706 \t time: 0.2\n",
      "Epoch: 330 \tTraining Loss: 1.367339 \tValidation Loss: 1.422578 \t time: 0.2\n",
      "Validation loss decreased from 1.422647 to 1.422578. Model was saved\n",
      "Epoch: 331 \tTraining Loss: 1.364441 \tValidation Loss: 1.422452 \t time: 0.2\n",
      "Validation loss decreased from 1.422578 to 1.422452. Model was saved\n",
      "Epoch: 332 \tTraining Loss: 1.365452 \tValidation Loss: 1.422319 \t time: 0.2\n",
      "Validation loss decreased from 1.422452 to 1.422319. Model was saved\n",
      "Epoch: 333 \tTraining Loss: 1.366147 \tValidation Loss: 1.422417 \t time: 0.2\n",
      "Epoch: 334 \tTraining Loss: 1.365033 \tValidation Loss: 1.422650 \t time: 0.2\n",
      "Epoch: 335 \tTraining Loss: 1.364689 \tValidation Loss: 1.422958 \t time: 0.2\n",
      "Epoch: 336 \tTraining Loss: 1.364326 \tValidation Loss: 1.423181 \t time: 0.2\n",
      "Epoch: 337 \tTraining Loss: 1.366227 \tValidation Loss: 1.423451 \t time: 0.2\n",
      "Epoch: 338 \tTraining Loss: 1.365008 \tValidation Loss: 1.423797 \t time: 0.2\n",
      "Epoch: 339 \tTraining Loss: 1.364911 \tValidation Loss: 1.423783 \t time: 0.2\n",
      "Epoch: 340 \tTraining Loss: 1.365360 \tValidation Loss: 1.423655 \t time: 0.2\n",
      "Epoch: 341 \tTraining Loss: 1.365445 \tValidation Loss: 1.423280 \t time: 0.2\n",
      "Epoch: 342 \tTraining Loss: 1.361282 \tValidation Loss: 1.422945 \t time: 0.2\n",
      "Epoch: 343 \tTraining Loss: 1.363162 \tValidation Loss: 1.422589 \t time: 0.2\n",
      "Epoch: 344 \tTraining Loss: 1.364328 \tValidation Loss: 1.422245 \t time: 0.2\n",
      "Validation loss decreased from 1.422319 to 1.422245. Model was saved\n",
      "Epoch: 345 \tTraining Loss: 1.362375 \tValidation Loss: 1.421978 \t time: 0.2\n",
      "Validation loss decreased from 1.422245 to 1.421978. Model was saved\n",
      "Epoch: 346 \tTraining Loss: 1.365305 \tValidation Loss: 1.421868 \t time: 0.2\n",
      "Validation loss decreased from 1.421978 to 1.421868. Model was saved\n",
      "Epoch: 347 \tTraining Loss: 1.365795 \tValidation Loss: 1.421982 \t time: 0.2\n",
      "Epoch: 348 \tTraining Loss: 1.362166 \tValidation Loss: 1.422139 \t time: 0.2\n",
      "Epoch: 349 \tTraining Loss: 1.361047 \tValidation Loss: 1.422263 \t time: 0.2\n",
      "Epoch: 350 \tTraining Loss: 1.361671 \tValidation Loss: 1.422139 \t time: 0.2\n",
      "Epoch: 351 \tTraining Loss: 1.360125 \tValidation Loss: 1.422070 \t time: 0.2\n",
      "Epoch: 352 \tTraining Loss: 1.362632 \tValidation Loss: 1.422128 \t time: 0.2\n",
      "Epoch: 353 \tTraining Loss: 1.363876 \tValidation Loss: 1.422323 \t time: 0.2\n",
      "Epoch: 354 \tTraining Loss: 1.361269 \tValidation Loss: 1.422512 \t time: 0.2\n",
      "Epoch: 355 \tTraining Loss: 1.360591 \tValidation Loss: 1.422430 \t time: 0.2\n",
      "Epoch: 356 \tTraining Loss: 1.361258 \tValidation Loss: 1.422366 \t time: 0.2\n",
      "Epoch: 357 \tTraining Loss: 1.361551 \tValidation Loss: 1.422422 \t time: 0.2\n",
      "Epoch: 358 \tTraining Loss: 1.360417 \tValidation Loss: 1.422442 \t time: 0.2\n",
      "Epoch: 359 \tTraining Loss: 1.360058 \tValidation Loss: 1.422248 \t time: 0.2\n",
      "Epoch: 360 \tTraining Loss: 1.360453 \tValidation Loss: 1.422070 \t time: 0.2\n",
      "Epoch: 361 \tTraining Loss: 1.360852 \tValidation Loss: 1.421921 \t time: 0.2\n",
      "Epoch: 362 \tTraining Loss: 1.360965 \tValidation Loss: 1.421824 \t time: 0.2\n",
      "Validation loss decreased from 1.421868 to 1.421824. Model was saved\n",
      "Epoch: 363 \tTraining Loss: 1.357528 \tValidation Loss: 1.421608 \t time: 0.2\n",
      "Validation loss decreased from 1.421824 to 1.421608. Model was saved\n",
      "Epoch: 364 \tTraining Loss: 1.357187 \tValidation Loss: 1.421370 \t time: 0.2\n",
      "Validation loss decreased from 1.421608 to 1.421370. Model was saved\n",
      "Epoch: 365 \tTraining Loss: 1.357433 \tValidation Loss: 1.421126 \t time: 0.2\n",
      "Validation loss decreased from 1.421370 to 1.421126. Model was saved\n",
      "Epoch: 366 \tTraining Loss: 1.358076 \tValidation Loss: 1.420987 \t time: 0.2\n",
      "Validation loss decreased from 1.421126 to 1.420987. Model was saved\n",
      "Epoch: 367 \tTraining Loss: 1.358434 \tValidation Loss: 1.420948 \t time: 0.2\n",
      "Validation loss decreased from 1.420987 to 1.420948. Model was saved\n",
      "Epoch: 368 \tTraining Loss: 1.357031 \tValidation Loss: 1.421132 \t time: 0.2\n",
      "Epoch: 369 \tTraining Loss: 1.356738 \tValidation Loss: 1.421311 \t time: 0.2\n",
      "Epoch: 370 \tTraining Loss: 1.358950 \tValidation Loss: 1.421066 \t time: 0.2\n",
      "Epoch: 371 \tTraining Loss: 1.358104 \tValidation Loss: 1.420798 \t time: 0.2\n",
      "Validation loss decreased from 1.420948 to 1.420798. Model was saved\n",
      "Epoch: 372 \tTraining Loss: 1.358533 \tValidation Loss: 1.420694 \t time: 0.2\n",
      "Validation loss decreased from 1.420798 to 1.420694. Model was saved\n",
      "Epoch: 373 \tTraining Loss: 1.355825 \tValidation Loss: 1.420432 \t time: 0.2\n",
      "Validation loss decreased from 1.420694 to 1.420432. Model was saved\n",
      "Epoch: 374 \tTraining Loss: 1.356634 \tValidation Loss: 1.420254 \t time: 0.2\n",
      "Validation loss decreased from 1.420432 to 1.420254. Model was saved\n",
      "Epoch: 375 \tTraining Loss: 1.356857 \tValidation Loss: 1.420426 \t time: 0.2\n",
      "Epoch: 376 \tTraining Loss: 1.356447 \tValidation Loss: 1.420714 \t time: 0.2\n",
      "Epoch: 377 \tTraining Loss: 1.355526 \tValidation Loss: 1.420723 \t time: 0.2\n",
      "Epoch: 378 \tTraining Loss: 1.357413 \tValidation Loss: 1.420574 \t time: 0.2\n",
      "Epoch: 379 \tTraining Loss: 1.355778 \tValidation Loss: 1.420273 \t time: 0.2\n",
      "Epoch: 380 \tTraining Loss: 1.355839 \tValidation Loss: 1.419972 \t time: 0.2\n",
      "Validation loss decreased from 1.420254 to 1.419972. Model was saved\n",
      "Epoch: 381 \tTraining Loss: 1.354007 \tValidation Loss: 1.419773 \t time: 0.2\n",
      "Validation loss decreased from 1.419972 to 1.419773. Model was saved\n",
      "Epoch: 382 \tTraining Loss: 1.355331 \tValidation Loss: 1.419775 \t time: 0.2\n",
      "Epoch: 383 \tTraining Loss: 1.352847 \tValidation Loss: 1.420076 \t time: 0.2\n",
      "Epoch: 384 \tTraining Loss: 1.354775 \tValidation Loss: 1.420627 \t time: 0.2\n",
      "Epoch: 385 \tTraining Loss: 1.356804 \tValidation Loss: 1.421089 \t time: 0.2\n",
      "Epoch: 386 \tTraining Loss: 1.353848 \tValidation Loss: 1.421249 \t time: 0.2\n",
      "Epoch: 387 \tTraining Loss: 1.353706 \tValidation Loss: 1.420941 \t time: 0.2\n",
      "Epoch: 388 \tTraining Loss: 1.355786 \tValidation Loss: 1.420333 \t time: 0.2\n",
      "Epoch: 389 \tTraining Loss: 1.353274 \tValidation Loss: 1.419773 \t time: 0.2\n",
      "Epoch: 390 \tTraining Loss: 1.353277 \tValidation Loss: 1.419409 \t time: 0.2\n",
      "Validation loss decreased from 1.419773 to 1.419409. Model was saved\n",
      "Epoch: 391 \tTraining Loss: 1.352229 \tValidation Loss: 1.419441 \t time: 0.2\n",
      "Epoch: 392 \tTraining Loss: 1.353447 \tValidation Loss: 1.419858 \t time: 0.2\n",
      "Epoch: 393 \tTraining Loss: 1.353168 \tValidation Loss: 1.420693 \t time: 0.2\n",
      "Epoch: 394 \tTraining Loss: 1.353048 \tValidation Loss: 1.421090 \t time: 0.2\n",
      "Epoch: 395 \tTraining Loss: 1.352498 \tValidation Loss: 1.420647 \t time: 0.2\n",
      "Epoch: 396 \tTraining Loss: 1.352252 \tValidation Loss: 1.420010 \t time: 0.2\n",
      "Epoch: 397 \tTraining Loss: 1.351783 \tValidation Loss: 1.419593 \t time: 0.2\n",
      "Epoch: 398 \tTraining Loss: 1.351848 \tValidation Loss: 1.419437 \t time: 0.2\n",
      "Epoch: 399 \tTraining Loss: 1.351447 \tValidation Loss: 1.419342 \t time: 0.2\n",
      "Validation loss decreased from 1.419409 to 1.419342. Model was saved\n",
      "Epoch: 400 \tTraining Loss: 1.351165 \tValidation Loss: 1.419581 \t time: 0.2\n",
      "Epoch: 401 \tTraining Loss: 1.351393 \tValidation Loss: 1.419801 \t time: 0.2\n",
      "Epoch: 402 \tTraining Loss: 1.350851 \tValidation Loss: 1.420023 \t time: 0.2\n",
      "Epoch: 403 \tTraining Loss: 1.349895 \tValidation Loss: 1.419944 \t time: 0.2\n",
      "Epoch: 404 \tTraining Loss: 1.351963 \tValidation Loss: 1.419532 \t time: 0.2\n",
      "Epoch: 405 \tTraining Loss: 1.351467 \tValidation Loss: 1.419318 \t time: 0.2\n",
      "Validation loss decreased from 1.419342 to 1.419318. Model was saved\n",
      "Epoch: 406 \tTraining Loss: 1.350189 \tValidation Loss: 1.419383 \t time: 0.2\n",
      "Epoch: 407 \tTraining Loss: 1.350052 \tValidation Loss: 1.419476 \t time: 0.2\n",
      "Epoch: 408 \tTraining Loss: 1.350264 \tValidation Loss: 1.419236 \t time: 0.2\n",
      "Validation loss decreased from 1.419318 to 1.419236. Model was saved\n",
      "Epoch: 409 \tTraining Loss: 1.350949 \tValidation Loss: 1.419368 \t time: 0.2\n",
      "Epoch: 410 \tTraining Loss: 1.348529 \tValidation Loss: 1.420081 \t time: 0.2\n",
      "Epoch: 411 \tTraining Loss: 1.349567 \tValidation Loss: 1.420295 \t time: 0.2\n",
      "Epoch: 412 \tTraining Loss: 1.350778 \tValidation Loss: 1.419703 \t time: 0.2\n",
      "Epoch: 413 \tTraining Loss: 1.350254 \tValidation Loss: 1.419417 \t time: 0.2\n",
      "Epoch: 414 \tTraining Loss: 1.350479 \tValidation Loss: 1.419501 \t time: 0.2\n",
      "Epoch: 415 \tTraining Loss: 1.348475 \tValidation Loss: 1.419374 \t time: 0.2\n",
      "Epoch: 416 \tTraining Loss: 1.349522 \tValidation Loss: 1.419133 \t time: 0.2\n",
      "Validation loss decreased from 1.419236 to 1.419133. Model was saved\n",
      "Epoch: 417 \tTraining Loss: 1.348533 \tValidation Loss: 1.419403 \t time: 0.2\n",
      "Epoch: 418 \tTraining Loss: 1.348142 \tValidation Loss: 1.419837 \t time: 0.2\n",
      "Epoch: 419 \tTraining Loss: 1.349431 \tValidation Loss: 1.419746 \t time: 0.2\n",
      "Epoch: 420 \tTraining Loss: 1.348106 \tValidation Loss: 1.419279 \t time: 0.2\n",
      "Epoch: 421 \tTraining Loss: 1.346623 \tValidation Loss: 1.418781 \t time: 0.2\n",
      "Validation loss decreased from 1.419133 to 1.418781. Model was saved\n",
      "Epoch: 422 \tTraining Loss: 1.347287 \tValidation Loss: 1.418714 \t time: 0.2\n",
      "Validation loss decreased from 1.418781 to 1.418714. Model was saved\n",
      "Epoch: 423 \tTraining Loss: 1.347487 \tValidation Loss: 1.418560 \t time: 0.2\n",
      "Validation loss decreased from 1.418714 to 1.418560. Model was saved\n",
      "Epoch: 424 \tTraining Loss: 1.347492 \tValidation Loss: 1.418307 \t time: 0.2\n",
      "Validation loss decreased from 1.418560 to 1.418307. Model was saved\n",
      "Epoch: 425 \tTraining Loss: 1.346231 \tValidation Loss: 1.418286 \t time: 0.2\n",
      "Validation loss decreased from 1.418307 to 1.418286. Model was saved\n",
      "Epoch: 426 \tTraining Loss: 1.346814 \tValidation Loss: 1.418424 \t time: 0.2\n",
      "Epoch: 427 \tTraining Loss: 1.342729 \tValidation Loss: 1.418607 \t time: 0.2\n",
      "Epoch: 428 \tTraining Loss: 1.345835 \tValidation Loss: 1.418688 \t time: 0.2\n",
      "Epoch: 429 \tTraining Loss: 1.345880 \tValidation Loss: 1.418550 \t time: 0.2\n",
      "Epoch: 430 \tTraining Loss: 1.346784 \tValidation Loss: 1.418157 \t time: 0.2\n",
      "Validation loss decreased from 1.418286 to 1.418157. Model was saved\n",
      "Epoch: 431 \tTraining Loss: 1.344626 \tValidation Loss: 1.417826 \t time: 0.2\n",
      "Validation loss decreased from 1.418157 to 1.417826. Model was saved\n",
      "Epoch: 432 \tTraining Loss: 1.344540 \tValidation Loss: 1.417725 \t time: 0.2\n",
      "Validation loss decreased from 1.417826 to 1.417725. Model was saved\n",
      "Epoch: 433 \tTraining Loss: 1.344440 \tValidation Loss: 1.417711 \t time: 0.2\n",
      "Validation loss decreased from 1.417725 to 1.417711. Model was saved\n",
      "Epoch: 434 \tTraining Loss: 1.345139 \tValidation Loss: 1.417958 \t time: 0.2\n",
      "Epoch: 435 \tTraining Loss: 1.345127 \tValidation Loss: 1.418349 \t time: 0.2\n",
      "Epoch: 436 \tTraining Loss: 1.343794 \tValidation Loss: 1.418171 \t time: 0.2\n",
      "Epoch: 437 \tTraining Loss: 1.345033 \tValidation Loss: 1.417796 \t time: 0.2\n",
      "Epoch: 438 \tTraining Loss: 1.343153 \tValidation Loss: 1.417591 \t time: 0.2\n",
      "Validation loss decreased from 1.417711 to 1.417591. Model was saved\n",
      "Epoch: 439 \tTraining Loss: 1.344231 \tValidation Loss: 1.417562 \t time: 0.2\n",
      "Validation loss decreased from 1.417591 to 1.417562. Model was saved\n",
      "Epoch: 440 \tTraining Loss: 1.345133 \tValidation Loss: 1.417760 \t time: 0.2\n",
      "Epoch: 441 \tTraining Loss: 1.345018 \tValidation Loss: 1.417989 \t time: 0.2\n",
      "Epoch: 442 \tTraining Loss: 1.346926 \tValidation Loss: 1.418140 \t time: 0.2\n",
      "Epoch: 443 \tTraining Loss: 1.341015 \tValidation Loss: 1.418000 \t time: 0.2\n",
      "Epoch: 444 \tTraining Loss: 1.344108 \tValidation Loss: 1.417643 \t time: 0.2\n",
      "Epoch: 445 \tTraining Loss: 1.342704 \tValidation Loss: 1.417234 \t time: 0.2\n",
      "Validation loss decreased from 1.417562 to 1.417234. Model was saved\n",
      "Epoch: 446 \tTraining Loss: 1.341462 \tValidation Loss: 1.416916 \t time: 0.2\n",
      "Validation loss decreased from 1.417234 to 1.416916. Model was saved\n",
      "Epoch: 447 \tTraining Loss: 1.341684 \tValidation Loss: 1.416533 \t time: 0.2\n",
      "Validation loss decreased from 1.416916 to 1.416533. Model was saved\n",
      "Epoch: 448 \tTraining Loss: 1.343024 \tValidation Loss: 1.416225 \t time: 0.2\n",
      "Validation loss decreased from 1.416533 to 1.416225. Model was saved\n",
      "Epoch: 449 \tTraining Loss: 1.341652 \tValidation Loss: 1.416133 \t time: 0.2\n",
      "Validation loss decreased from 1.416225 to 1.416133. Model was saved\n",
      "Epoch: 450 \tTraining Loss: 1.343219 \tValidation Loss: 1.416232 \t time: 0.2\n",
      "Epoch: 451 \tTraining Loss: 1.340933 \tValidation Loss: 1.416451 \t time: 0.2\n",
      "Epoch: 452 \tTraining Loss: 1.340802 \tValidation Loss: 1.416661 \t time: 0.2\n",
      "Epoch: 453 \tTraining Loss: 1.339319 \tValidation Loss: 1.416618 \t time: 0.2\n",
      "Epoch: 454 \tTraining Loss: 1.342062 \tValidation Loss: 1.416585 \t time: 0.2\n",
      "Epoch: 455 \tTraining Loss: 1.342906 \tValidation Loss: 1.416593 \t time: 0.2\n",
      "Epoch: 456 \tTraining Loss: 1.340477 \tValidation Loss: 1.416624 \t time: 0.2\n",
      "Epoch: 457 \tTraining Loss: 1.343595 \tValidation Loss: 1.416633 \t time: 0.2\n",
      "Epoch: 458 \tTraining Loss: 1.341080 \tValidation Loss: 1.416502 \t time: 0.2\n",
      "Epoch: 459 \tTraining Loss: 1.341096 \tValidation Loss: 1.416566 \t time: 0.2\n",
      "Epoch: 460 \tTraining Loss: 1.342575 \tValidation Loss: 1.416957 \t time: 0.2\n",
      "Epoch: 461 \tTraining Loss: 1.341252 \tValidation Loss: 1.417251 \t time: 0.2\n",
      "Epoch: 462 \tTraining Loss: 1.340795 \tValidation Loss: 1.417492 \t time: 0.2\n",
      "Epoch: 463 \tTraining Loss: 1.342134 \tValidation Loss: 1.417401 \t time: 0.2\n",
      "Epoch: 464 \tTraining Loss: 1.339000 \tValidation Loss: 1.417075 \t time: 0.2\n",
      "Epoch: 465 \tTraining Loss: 1.340285 \tValidation Loss: 1.416739 \t time: 0.2\n",
      "Epoch: 466 \tTraining Loss: 1.338840 \tValidation Loss: 1.416473 \t time: 0.2\n",
      "Epoch: 467 \tTraining Loss: 1.337636 \tValidation Loss: 1.416395 \t time: 0.2\n",
      "Epoch: 468 \tTraining Loss: 1.340023 \tValidation Loss: 1.416344 \t time: 0.2\n",
      "Epoch: 469 \tTraining Loss: 1.337770 \tValidation Loss: 1.416172 \t time: 0.2\n",
      "Epoch: 470 \tTraining Loss: 1.336006 \tValidation Loss: 1.416140 \t time: 0.2\n",
      "Epoch: 471 \tTraining Loss: 1.337725 \tValidation Loss: 1.416178 \t time: 0.2\n",
      "Epoch: 472 \tTraining Loss: 1.338382 \tValidation Loss: 1.416277 \t time: 0.2\n",
      "Epoch: 473 \tTraining Loss: 1.336653 \tValidation Loss: 1.416311 \t time: 0.2\n",
      "Epoch: 474 \tTraining Loss: 1.340137 \tValidation Loss: 1.416055 \t time: 0.2\n",
      "Validation loss decreased from 1.416133 to 1.416055. Model was saved\n",
      "Epoch: 475 \tTraining Loss: 1.338145 \tValidation Loss: 1.415909 \t time: 0.2\n",
      "Validation loss decreased from 1.416055 to 1.415909. Model was saved\n",
      "Epoch: 476 \tTraining Loss: 1.338055 \tValidation Loss: 1.415721 \t time: 0.2\n",
      "Validation loss decreased from 1.415909 to 1.415721. Model was saved\n",
      "Epoch: 477 \tTraining Loss: 1.336190 \tValidation Loss: 1.415418 \t time: 0.2\n",
      "Validation loss decreased from 1.415721 to 1.415418. Model was saved\n",
      "Epoch: 478 \tTraining Loss: 1.340458 \tValidation Loss: 1.415413 \t time: 0.2\n",
      "Validation loss decreased from 1.415418 to 1.415413. Model was saved\n",
      "Epoch: 479 \tTraining Loss: 1.339666 \tValidation Loss: 1.415545 \t time: 0.2\n",
      "Epoch: 480 \tTraining Loss: 1.337878 \tValidation Loss: 1.415985 \t time: 0.2\n",
      "Epoch: 481 \tTraining Loss: 1.338783 \tValidation Loss: 1.416439 \t time: 0.2\n",
      "Epoch: 482 \tTraining Loss: 1.336717 \tValidation Loss: 1.416746 \t time: 0.2\n",
      "Epoch: 483 \tTraining Loss: 1.336599 \tValidation Loss: 1.416919 \t time: 0.2\n",
      "Epoch: 484 \tTraining Loss: 1.334464 \tValidation Loss: 1.417209 \t time: 0.2\n",
      "Epoch: 485 \tTraining Loss: 1.335555 \tValidation Loss: 1.417502 \t time: 0.2\n",
      "Epoch: 486 \tTraining Loss: 1.335408 \tValidation Loss: 1.417843 \t time: 0.2\n",
      "Epoch: 487 \tTraining Loss: 1.336640 \tValidation Loss: 1.418072 \t time: 0.2\n",
      "Epoch: 488 \tTraining Loss: 1.334975 \tValidation Loss: 1.418012 \t time: 0.2\n",
      "Epoch: 489 \tTraining Loss: 1.338074 \tValidation Loss: 1.417850 \t time: 0.2\n",
      "Epoch: 490 \tTraining Loss: 1.335681 \tValidation Loss: 1.417706 \t time: 0.2\n",
      "Epoch: 491 \tTraining Loss: 1.335058 \tValidation Loss: 1.417808 \t time: 0.2\n",
      "Epoch: 492 \tTraining Loss: 1.335693 \tValidation Loss: 1.418020 \t time: 0.2\n",
      "Epoch: 493 \tTraining Loss: 1.337095 \tValidation Loss: 1.417742 \t time: 0.2\n",
      "Epoch: 494 \tTraining Loss: 1.336051 \tValidation Loss: 1.417102 \t time: 0.2\n",
      "Epoch: 495 \tTraining Loss: 1.336036 \tValidation Loss: 1.416569 \t time: 0.2\n",
      "Epoch: 496 \tTraining Loss: 1.333617 \tValidation Loss: 1.416166 \t time: 0.2\n",
      "Epoch: 497 \tTraining Loss: 1.332146 \tValidation Loss: 1.416170 \t time: 0.2\n",
      "Epoch: 498 \tTraining Loss: 1.333183 \tValidation Loss: 1.416193 \t time: 0.2\n",
      "Epoch: 499 \tTraining Loss: 1.335622 \tValidation Loss: 1.416235 \t time: 0.2\n",
      "Epoch: 500 \tTraining Loss: 1.333915 \tValidation Loss: 1.416246 \t time: 0.2\n",
      "Epoch: 501 \tTraining Loss: 1.332593 \tValidation Loss: 1.416097 \t time: 0.2\n",
      "Epoch: 502 \tTraining Loss: 1.334791 \tValidation Loss: 1.415803 \t time: 0.2\n",
      "Epoch: 503 \tTraining Loss: 1.329589 \tValidation Loss: 1.415579 \t time: 0.2\n",
      "Epoch: 504 \tTraining Loss: 1.334704 \tValidation Loss: 1.415361 \t time: 0.2\n",
      "Validation loss decreased from 1.415413 to 1.415361. Model was saved\n",
      "Epoch: 505 \tTraining Loss: 1.336286 \tValidation Loss: 1.415281 \t time: 0.2\n",
      "Validation loss decreased from 1.415361 to 1.415281. Model was saved\n",
      "Epoch: 506 \tTraining Loss: 1.333722 \tValidation Loss: 1.415520 \t time: 0.2\n",
      "Epoch: 507 \tTraining Loss: 1.333543 \tValidation Loss: 1.415768 \t time: 0.2\n",
      "Epoch: 508 \tTraining Loss: 1.335185 \tValidation Loss: 1.415879 \t time: 0.2\n",
      "Epoch: 509 \tTraining Loss: 1.329024 \tValidation Loss: 1.415820 \t time: 0.2\n",
      "Epoch: 510 \tTraining Loss: 1.330574 \tValidation Loss: 1.415564 \t time: 0.2\n",
      "Epoch: 511 \tTraining Loss: 1.331893 \tValidation Loss: 1.415241 \t time: 0.2\n",
      "Validation loss decreased from 1.415281 to 1.415241. Model was saved\n",
      "Epoch: 512 \tTraining Loss: 1.332643 \tValidation Loss: 1.414866 \t time: 0.2\n",
      "Validation loss decreased from 1.415241 to 1.414866. Model was saved\n",
      "Epoch: 513 \tTraining Loss: 1.331640 \tValidation Loss: 1.414709 \t time: 0.2\n",
      "Validation loss decreased from 1.414866 to 1.414709. Model was saved\n",
      "Epoch: 514 \tTraining Loss: 1.330290 \tValidation Loss: 1.414855 \t time: 0.2\n",
      "Epoch: 515 \tTraining Loss: 1.330496 \tValidation Loss: 1.415187 \t time: 0.2\n",
      "Epoch: 516 \tTraining Loss: 1.333313 \tValidation Loss: 1.415819 \t time: 0.2\n",
      "Epoch: 517 \tTraining Loss: 1.329441 \tValidation Loss: 1.416208 \t time: 0.2\n",
      "Epoch: 518 \tTraining Loss: 1.330320 \tValidation Loss: 1.416218 \t time: 0.2\n",
      "Epoch: 519 \tTraining Loss: 1.329070 \tValidation Loss: 1.415613 \t time: 0.2\n",
      "Epoch: 520 \tTraining Loss: 1.332853 \tValidation Loss: 1.414946 \t time: 0.2\n",
      "Epoch: 521 \tTraining Loss: 1.329917 \tValidation Loss: 1.414663 \t time: 0.2\n",
      "Validation loss decreased from 1.414709 to 1.414663. Model was saved\n",
      "Epoch: 522 \tTraining Loss: 1.330798 \tValidation Loss: 1.415204 \t time: 0.2\n",
      "Epoch: 523 \tTraining Loss: 1.331189 \tValidation Loss: 1.415917 \t time: 0.2\n",
      "Epoch: 524 \tTraining Loss: 1.331970 \tValidation Loss: 1.416725 \t time: 0.2\n",
      "Epoch: 525 \tTraining Loss: 1.329044 \tValidation Loss: 1.416997 \t time: 0.2\n",
      "Epoch: 526 \tTraining Loss: 1.329033 \tValidation Loss: 1.416770 \t time: 0.2\n",
      "Epoch: 527 \tTraining Loss: 1.328135 \tValidation Loss: 1.416149 \t time: 0.2\n",
      "Epoch: 528 \tTraining Loss: 1.330872 \tValidation Loss: 1.415648 \t time: 0.2\n",
      "Epoch: 529 \tTraining Loss: 1.328697 \tValidation Loss: 1.415378 \t time: 0.2\n",
      "Epoch: 530 \tTraining Loss: 1.329624 \tValidation Loss: 1.415344 \t time: 0.2\n",
      "Epoch: 531 \tTraining Loss: 1.328402 \tValidation Loss: 1.415593 \t time: 0.2\n",
      "Epoch: 532 \tTraining Loss: 1.328556 \tValidation Loss: 1.416021 \t time: 0.2\n",
      "Epoch: 533 \tTraining Loss: 1.328452 \tValidation Loss: 1.416386 \t time: 0.2\n",
      "Epoch: 534 \tTraining Loss: 1.330198 \tValidation Loss: 1.416704 \t time: 0.2\n",
      "Epoch: 535 \tTraining Loss: 1.328257 \tValidation Loss: 1.416669 \t time: 0.2\n",
      "Epoch: 536 \tTraining Loss: 1.327212 \tValidation Loss: 1.416355 \t time: 0.2\n",
      "Epoch: 537 \tTraining Loss: 1.328896 \tValidation Loss: 1.415621 \t time: 0.2\n",
      "Epoch: 538 \tTraining Loss: 1.326217 \tValidation Loss: 1.414916 \t time: 0.2\n",
      "Epoch: 539 \tTraining Loss: 1.328475 \tValidation Loss: 1.414268 \t time: 0.2\n",
      "Validation loss decreased from 1.414663 to 1.414268. Model was saved\n",
      "Epoch: 540 \tTraining Loss: 1.329621 \tValidation Loss: 1.413830 \t time: 0.2\n",
      "Validation loss decreased from 1.414268 to 1.413830. Model was saved\n",
      "Epoch: 541 \tTraining Loss: 1.324874 \tValidation Loss: 1.413372 \t time: 0.2\n",
      "Validation loss decreased from 1.413830 to 1.413372. Model was saved\n",
      "Epoch: 542 \tTraining Loss: 1.324712 \tValidation Loss: 1.413175 \t time: 0.2\n",
      "Validation loss decreased from 1.413372 to 1.413175. Model was saved\n",
      "Epoch: 543 \tTraining Loss: 1.329071 \tValidation Loss: 1.412902 \t time: 0.2\n",
      "Validation loss decreased from 1.413175 to 1.412902. Model was saved\n",
      "Epoch: 544 \tTraining Loss: 1.326104 \tValidation Loss: 1.412954 \t time: 0.2\n",
      "Epoch: 545 \tTraining Loss: 1.325221 \tValidation Loss: 1.412969 \t time: 0.2\n",
      "Epoch: 546 \tTraining Loss: 1.328479 \tValidation Loss: 1.413082 \t time: 0.2\n",
      "Epoch: 547 \tTraining Loss: 1.327271 \tValidation Loss: 1.412900 \t time: 0.2\n",
      "Validation loss decreased from 1.412902 to 1.412900. Model was saved\n",
      "Epoch: 548 \tTraining Loss: 1.328876 \tValidation Loss: 1.412738 \t time: 0.2\n",
      "Validation loss decreased from 1.412900 to 1.412738. Model was saved\n",
      "Epoch: 549 \tTraining Loss: 1.324721 \tValidation Loss: 1.412453 \t time: 0.2\n",
      "Validation loss decreased from 1.412738 to 1.412453. Model was saved\n",
      "Epoch: 550 \tTraining Loss: 1.326494 \tValidation Loss: 1.412196 \t time: 0.2\n",
      "Validation loss decreased from 1.412453 to 1.412196. Model was saved\n",
      "Epoch: 551 \tTraining Loss: 1.323971 \tValidation Loss: 1.412032 \t time: 0.2\n",
      "Validation loss decreased from 1.412196 to 1.412032. Model was saved\n",
      "Epoch: 552 \tTraining Loss: 1.325134 \tValidation Loss: 1.412117 \t time: 0.2\n",
      "Epoch: 553 \tTraining Loss: 1.324064 \tValidation Loss: 1.412529 \t time: 0.2\n",
      "Epoch: 554 \tTraining Loss: 1.325543 \tValidation Loss: 1.413191 \t time: 0.2\n",
      "Epoch: 555 \tTraining Loss: 1.323866 \tValidation Loss: 1.413578 \t time: 0.2\n",
      "Epoch: 556 \tTraining Loss: 1.324042 \tValidation Loss: 1.413725 \t time: 0.2\n",
      "Epoch: 557 \tTraining Loss: 1.326629 \tValidation Loss: 1.413591 \t time: 0.2\n",
      "Epoch: 558 \tTraining Loss: 1.326199 \tValidation Loss: 1.413164 \t time: 0.2\n",
      "Epoch: 559 \tTraining Loss: 1.322972 \tValidation Loss: 1.412956 \t time: 0.2\n",
      "Epoch: 560 \tTraining Loss: 1.323962 \tValidation Loss: 1.412818 \t time: 0.2\n",
      "Epoch: 561 \tTraining Loss: 1.321942 \tValidation Loss: 1.412895 \t time: 0.2\n",
      "Epoch: 562 \tTraining Loss: 1.324340 \tValidation Loss: 1.413285 \t time: 0.2\n",
      "Epoch: 563 \tTraining Loss: 1.324926 \tValidation Loss: 1.413638 \t time: 0.2\n",
      "Epoch: 564 \tTraining Loss: 1.323478 \tValidation Loss: 1.413918 \t time: 0.2\n",
      "Epoch: 565 \tTraining Loss: 1.323180 \tValidation Loss: 1.413738 \t time: 0.2\n",
      "Epoch: 566 \tTraining Loss: 1.322785 \tValidation Loss: 1.413418 \t time: 0.2\n",
      "Epoch: 567 \tTraining Loss: 1.323210 \tValidation Loss: 1.413078 \t time: 0.2\n",
      "Epoch: 568 \tTraining Loss: 1.321826 \tValidation Loss: 1.412740 \t time: 0.2\n",
      "Epoch: 569 \tTraining Loss: 1.322200 \tValidation Loss: 1.412753 \t time: 0.2\n",
      "Epoch: 570 \tTraining Loss: 1.321625 \tValidation Loss: 1.412879 \t time: 0.2\n",
      "Epoch: 571 \tTraining Loss: 1.323710 \tValidation Loss: 1.412930 \t time: 0.2\n",
      "Epoch: 572 \tTraining Loss: 1.321092 \tValidation Loss: 1.412632 \t time: 0.2\n",
      "Epoch: 573 \tTraining Loss: 1.321886 \tValidation Loss: 1.412060 \t time: 0.2\n",
      "Epoch: 574 \tTraining Loss: 1.322699 \tValidation Loss: 1.411505 \t time: 0.2\n",
      "Validation loss decreased from 1.412032 to 1.411505. Model was saved\n",
      "Epoch: 575 \tTraining Loss: 1.320319 \tValidation Loss: 1.411276 \t time: 0.2\n",
      "Validation loss decreased from 1.411505 to 1.411276. Model was saved\n",
      "Epoch: 576 \tTraining Loss: 1.321865 \tValidation Loss: 1.411605 \t time: 0.2\n",
      "Epoch: 577 \tTraining Loss: 1.323585 \tValidation Loss: 1.412443 \t time: 0.2\n",
      "Epoch: 578 \tTraining Loss: 1.319968 \tValidation Loss: 1.413160 \t time: 0.2\n",
      "Epoch: 579 \tTraining Loss: 1.319558 \tValidation Loss: 1.413420 \t time: 0.2\n",
      "Epoch: 580 \tTraining Loss: 1.322290 \tValidation Loss: 1.413039 \t time: 0.2\n",
      "Epoch: 581 \tTraining Loss: 1.320310 \tValidation Loss: 1.412057 \t time: 0.2\n",
      "Epoch: 582 \tTraining Loss: 1.323968 \tValidation Loss: 1.411974 \t time: 0.2\n",
      "Epoch: 583 \tTraining Loss: 1.319273 \tValidation Loss: 1.412110 \t time: 0.2\n",
      "Epoch: 584 \tTraining Loss: 1.323626 \tValidation Loss: 1.412486 \t time: 0.2\n",
      "Epoch: 585 \tTraining Loss: 1.319237 \tValidation Loss: 1.413053 \t time: 0.2\n",
      "Epoch: 586 \tTraining Loss: 1.320626 \tValidation Loss: 1.413083 \t time: 0.2\n",
      "Epoch: 587 \tTraining Loss: 1.322914 \tValidation Loss: 1.413042 \t time: 0.2\n",
      "Epoch: 588 \tTraining Loss: 1.319957 \tValidation Loss: 1.412356 \t time: 0.2\n",
      "Epoch: 589 \tTraining Loss: 1.318005 \tValidation Loss: 1.411563 \t time: 0.2\n",
      "Epoch: 590 \tTraining Loss: 1.320644 \tValidation Loss: 1.411071 \t time: 0.2\n",
      "Validation loss decreased from 1.411276 to 1.411071. Model was saved\n",
      "Epoch: 591 \tTraining Loss: 1.320528 \tValidation Loss: 1.410994 \t time: 0.2\n",
      "Validation loss decreased from 1.411071 to 1.410994. Model was saved\n",
      "Epoch: 592 \tTraining Loss: 1.317832 \tValidation Loss: 1.411174 \t time: 0.2\n",
      "Epoch: 593 \tTraining Loss: 1.318347 \tValidation Loss: 1.411544 \t time: 0.2\n",
      "Epoch: 594 \tTraining Loss: 1.319574 \tValidation Loss: 1.412204 \t time: 0.2\n",
      "Epoch: 595 \tTraining Loss: 1.317977 \tValidation Loss: 1.412766 \t time: 0.2\n",
      "Epoch: 596 \tTraining Loss: 1.317903 \tValidation Loss: 1.413010 \t time: 0.2\n",
      "Epoch: 597 \tTraining Loss: 1.319290 \tValidation Loss: 1.413262 \t time: 0.2\n",
      "Epoch: 598 \tTraining Loss: 1.319793 \tValidation Loss: 1.413259 \t time: 0.2\n",
      "Epoch: 599 \tTraining Loss: 1.321553 \tValidation Loss: 1.413186 \t time: 0.2\n",
      "Epoch: 600 \tTraining Loss: 1.319110 \tValidation Loss: 1.413133 \t time: 0.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(600, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.472939\n",
      "\n",
      "\n",
      "Test Accuracy: 52% (76/144)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 5, 3, 2, 0, 5, 3, 1, 1, 5, 2, 5, 0, 1, 5, 5, 1, 2, 3, 0,\n",
       "       3, 1, 5, 0, 3, 5, 2, 0, 5, 5, 0, 5, 0, 3, 3, 2, 3, 0, 2, 5, 5, 2,\n",
       "       5, 2, 0, 0, 2, 1, 0, 0, 0, 2, 3, 1, 5, 1, 0, 0, 3, 1, 5, 0, 3, 3,\n",
       "       3, 2, 3, 1, 5, 0, 3, 3, 3, 0, 5, 5, 0, 5, 5, 1, 5, 3, 3, 2, 0, 5,\n",
       "       5, 1, 3, 0, 2, 3, 0, 5, 3, 2, 3, 2, 3, 0, 0, 2, 3, 2, 2, 0, 3, 1,\n",
       "       3, 0, 5, 5, 2, 0, 5, 3, 3, 5, 0, 0, 3, 2, 5, 2, 0, 3, 0, 5, 3, 0,\n",
       "       0, 5, 3, 5, 3, 2, 1, 3, 3, 2, 5, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,l = next(iter(loaders['test']))\n",
    "if use_cuda:\n",
    "    i, l = i.cuda(), l.cuda()\n",
    "\n",
    "output = model(i)\n",
    "\n",
    "result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([34.,  0., 14.,  0., 26.,  0., 36.,  0.,  0., 34.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = result[:,0]\n",
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32.,  0., 19.,  0., 30.,  0., 18.,  0., 17., 28.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
