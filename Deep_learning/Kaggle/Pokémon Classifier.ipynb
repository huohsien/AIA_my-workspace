{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appearedTimeOfDay</th>\n",
       "      <th>appearedHour</th>\n",
       "      <th>appearedMinute</th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>city</th>\n",
       "      <th>continent</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>...</th>\n",
       "      <th>cooc_142</th>\n",
       "      <th>cooc_143</th>\n",
       "      <th>cooc_144</th>\n",
       "      <th>cooc_145</th>\n",
       "      <th>cooc_146</th>\n",
       "      <th>cooc_147</th>\n",
       "      <th>cooc_148</th>\n",
       "      <th>cooc_149</th>\n",
       "      <th>cooc_150</th>\n",
       "      <th>cooc_151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evening</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>Los_Angeles</td>\n",
       "      <td>America</td>\n",
       "      <td>PartlyCloudy</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  appearedTimeOfDay  appearedHour  appearedMinute  terrainType  closeToWater  \\\n",
       "0           evening            19              10           13         False   \n",
       "1             night             5              19           13          True   \n",
       "2           evening            19              46            0          True   \n",
       "3           morning            11              10            0          True   \n",
       "4           evening            18              32           13          True   \n",
       "\n",
       "          city  continent       weather  temperature  windSpeed  ...  \\\n",
       "0      Bangkok       Asia         Clear         27.8       9.00  ...   \n",
       "1     New_York    America         Clear         26.1       8.70  ...   \n",
       "2     New_York    America         Clear         24.7      16.82  ...   \n",
       "3       Hobart  Australia         Clear         12.7      13.25  ...   \n",
       "4  Los_Angeles    America  PartlyCloudy         19.1       5.78  ...   \n",
       "\n",
       "   cooc_142 cooc_143  cooc_144  cooc_145  cooc_146  cooc_147  cooc_148  \\\n",
       "0     False    False     False     False     False     False     False   \n",
       "1     False    False     False     False     False     False     False   \n",
       "2     False    False     False     False     False     False     False   \n",
       "3     False    False     False     False     False     False     False   \n",
       "4     False    False     False     False     False     False     False   \n",
       "\n",
       "   cooc_149  cooc_150  cooc_151  \n",
       "0     False     False     False  \n",
       "1     False     False     False  \n",
       "2     False     False     False  \n",
       "3     False     False     False  \n",
       "4     False     False     False  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1008.96</td>\n",
       "      <td>6019.04440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1018.96</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>128.89505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1011.36</td>\n",
       "      <td>4188.39100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.990268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0         13.0           0.0         27.8       9.00   1008.96   \n",
       "1         13.0           1.0         26.1       8.70   1018.96   \n",
       "2          0.0           1.0         24.7      16.82   1023.22   \n",
       "3          0.0           1.0         12.7      13.25   1014.19   \n",
       "4         13.0           1.0         19.1       5.78   1011.36   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural  ...  \\\n",
       "0          6019.04440    1.0       1.0       1.0    0.0  ...   \n",
       "1             0.00000    0.0       0.0       0.0    1.0  ...   \n",
       "2             0.00000    0.0       0.0       0.0    1.0  ...   \n",
       "3           128.89505    0.0       0.0       0.0    1.0  ...   \n",
       "4          4188.39100    1.0       1.0       1.0    0.0  ...   \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                             0                      1   \n",
       "1                             0                      0   \n",
       "2                             0                      1   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                        0                   0                0   \n",
       "1                        1                   0                0   \n",
       "2                        0                   0                0   \n",
       "3                        1                   0                0   \n",
       "4                        0                   0                0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                              0                                0   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              1                                0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0                 0                 0             -0.953717  \n",
       "1                 0                 0              0.984041  \n",
       "2                 0                 0             -0.894934  \n",
       "3                 0                 0              0.216440  \n",
       "4                 0                 0             -0.990268  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terrainType',\n",
       " 'closeToWater',\n",
       " 'temperature',\n",
       " 'windSpeed',\n",
       " 'pressure',\n",
       " 'population_density',\n",
       " 'urban',\n",
       " 'suburban',\n",
       " 'midurban',\n",
       " 'rural',\n",
       " 'gymDistanceKm',\n",
       " 'gymIn100m',\n",
       " 'gymIn250m',\n",
       " 'gymIn500m',\n",
       " 'gymIn1000m',\n",
       " 'gymIn2500m',\n",
       " 'gymIn5000m',\n",
       " 'pokestopDistanceKm',\n",
       " 'pokestopIn100m',\n",
       " 'pokestopIn250m',\n",
       " 'pokestopIn500m',\n",
       " 'pokestopIn1000m',\n",
       " 'pokestopIn2500m',\n",
       " 'pokestopIn5000m',\n",
       " 'cooc_1',\n",
       " 'cooc_2',\n",
       " 'cooc_3',\n",
       " 'cooc_4',\n",
       " 'cooc_5',\n",
       " 'cooc_6',\n",
       " 'cooc_7',\n",
       " 'cooc_8',\n",
       " 'cooc_9',\n",
       " 'cooc_10',\n",
       " 'cooc_11',\n",
       " 'cooc_12',\n",
       " 'cooc_13',\n",
       " 'cooc_14',\n",
       " 'cooc_15',\n",
       " 'cooc_16',\n",
       " 'cooc_17',\n",
       " 'cooc_18',\n",
       " 'cooc_19',\n",
       " 'cooc_20',\n",
       " 'cooc_21',\n",
       " 'cooc_22',\n",
       " 'cooc_23',\n",
       " 'cooc_24',\n",
       " 'cooc_25',\n",
       " 'cooc_26',\n",
       " 'cooc_27',\n",
       " 'cooc_28',\n",
       " 'cooc_29',\n",
       " 'cooc_30',\n",
       " 'cooc_31',\n",
       " 'cooc_32',\n",
       " 'cooc_33',\n",
       " 'cooc_34',\n",
       " 'cooc_35',\n",
       " 'cooc_36',\n",
       " 'cooc_37',\n",
       " 'cooc_38',\n",
       " 'cooc_39',\n",
       " 'cooc_40',\n",
       " 'cooc_41',\n",
       " 'cooc_42',\n",
       " 'cooc_43',\n",
       " 'cooc_44',\n",
       " 'cooc_45',\n",
       " 'cooc_46',\n",
       " 'cooc_47',\n",
       " 'cooc_48',\n",
       " 'cooc_49',\n",
       " 'cooc_50',\n",
       " 'cooc_51',\n",
       " 'cooc_52',\n",
       " 'cooc_53',\n",
       " 'cooc_54',\n",
       " 'cooc_55',\n",
       " 'cooc_56',\n",
       " 'cooc_57',\n",
       " 'cooc_58',\n",
       " 'cooc_59',\n",
       " 'cooc_60',\n",
       " 'cooc_61',\n",
       " 'cooc_62',\n",
       " 'cooc_63',\n",
       " 'cooc_64',\n",
       " 'cooc_65',\n",
       " 'cooc_66',\n",
       " 'cooc_67',\n",
       " 'cooc_68',\n",
       " 'cooc_69',\n",
       " 'cooc_70',\n",
       " 'cooc_71',\n",
       " 'cooc_72',\n",
       " 'cooc_73',\n",
       " 'cooc_74',\n",
       " 'cooc_75',\n",
       " 'cooc_76',\n",
       " 'cooc_77',\n",
       " 'cooc_78',\n",
       " 'cooc_79',\n",
       " 'cooc_80',\n",
       " 'cooc_81',\n",
       " 'cooc_82',\n",
       " 'cooc_83',\n",
       " 'cooc_84',\n",
       " 'cooc_85',\n",
       " 'cooc_86',\n",
       " 'cooc_87',\n",
       " 'cooc_88',\n",
       " 'cooc_89',\n",
       " 'cooc_90',\n",
       " 'cooc_91',\n",
       " 'cooc_92',\n",
       " 'cooc_93',\n",
       " 'cooc_94',\n",
       " 'cooc_95',\n",
       " 'cooc_96',\n",
       " 'cooc_97',\n",
       " 'cooc_98',\n",
       " 'cooc_99',\n",
       " 'cooc_100',\n",
       " 'cooc_101',\n",
       " 'cooc_102',\n",
       " 'cooc_103',\n",
       " 'cooc_104',\n",
       " 'cooc_105',\n",
       " 'cooc_106',\n",
       " 'cooc_107',\n",
       " 'cooc_108',\n",
       " 'cooc_109',\n",
       " 'cooc_110',\n",
       " 'cooc_111',\n",
       " 'cooc_112',\n",
       " 'cooc_113',\n",
       " 'cooc_114',\n",
       " 'cooc_115',\n",
       " 'cooc_116',\n",
       " 'cooc_117',\n",
       " 'cooc_118',\n",
       " 'cooc_119',\n",
       " 'cooc_120',\n",
       " 'cooc_121',\n",
       " 'cooc_122',\n",
       " 'cooc_123',\n",
       " 'cooc_124',\n",
       " 'cooc_125',\n",
       " 'cooc_126',\n",
       " 'cooc_127',\n",
       " 'cooc_128',\n",
       " 'cooc_129',\n",
       " 'cooc_130',\n",
       " 'cooc_131',\n",
       " 'cooc_132',\n",
       " 'cooc_133',\n",
       " 'cooc_134',\n",
       " 'cooc_135',\n",
       " 'cooc_136',\n",
       " 'cooc_137',\n",
       " 'cooc_138',\n",
       " 'cooc_139',\n",
       " 'cooc_140',\n",
       " 'cooc_141',\n",
       " 'cooc_142',\n",
       " 'cooc_143',\n",
       " 'cooc_144',\n",
       " 'cooc_145',\n",
       " 'cooc_146',\n",
       " 'cooc_147',\n",
       " 'cooc_148',\n",
       " 'cooc_149',\n",
       " 'cooc_150',\n",
       " 'cooc_151',\n",
       " 'appearedTimeOfDay_afternoon',\n",
       " 'appearedTimeOfDay_evening',\n",
       " 'appearedTimeOfDay_morning',\n",
       " 'appearedTimeOfDay_night',\n",
       " 'city_Adelaide',\n",
       " 'city_Amsterdam',\n",
       " 'city_Athens',\n",
       " 'city_Auckland',\n",
       " 'city_Bahia',\n",
       " 'city_Bangkok',\n",
       " 'city_Belem',\n",
       " 'city_Berlin',\n",
       " 'city_Boise',\n",
       " 'city_Brisbane',\n",
       " 'city_Brunei',\n",
       " 'city_Brussels',\n",
       " 'city_Bucharest',\n",
       " 'city_Buenos_Aires',\n",
       " 'city_Casablanca',\n",
       " 'city_Chicago',\n",
       " 'city_Copenhagen',\n",
       " 'city_Denver',\n",
       " 'city_Detroit',\n",
       " 'city_Dubai',\n",
       " 'city_Dublin',\n",
       " 'city_Edmonton',\n",
       " 'city_Guam',\n",
       " 'city_Halifax',\n",
       " 'city_Helsinki',\n",
       " 'city_Ho_Chi_Minh',\n",
       " 'city_Hobart',\n",
       " 'city_Hong_Kong',\n",
       " 'city_Honolulu',\n",
       " 'city_Indianapolis',\n",
       " 'city_Jakarta',\n",
       " 'city_Karachi',\n",
       " 'city_Kolkata',\n",
       " 'city_Kuala_Lumpur',\n",
       " 'city_Kuching',\n",
       " 'city_Lisbon',\n",
       " 'city_Ljubljana',\n",
       " 'city_London',\n",
       " 'city_Los_Angeles',\n",
       " 'city_Louisville',\n",
       " 'city_Luanda',\n",
       " 'city_Madrid',\n",
       " 'city_Manila',\n",
       " 'city_Melbourne',\n",
       " 'city_Mexico_City',\n",
       " 'city_Monterrey',\n",
       " 'city_Montreal',\n",
       " 'city_New_York',\n",
       " 'city_Nicosia',\n",
       " 'city_Noumea',\n",
       " 'city_Oslo',\n",
       " 'city_Paris',\n",
       " 'city_Perth',\n",
       " 'city_Phoenix',\n",
       " 'city_Prague',\n",
       " 'city_Puerto_Rico',\n",
       " 'city_Regina',\n",
       " 'city_Rome',\n",
       " 'city_Santiago',\n",
       " 'city_Sao_Paulo',\n",
       " 'city_Singapore',\n",
       " 'city_Stockholm',\n",
       " 'city_Sydney',\n",
       " 'city_Tahiti',\n",
       " 'city_Taipei',\n",
       " 'city_Tokyo',\n",
       " 'city_Toronto',\n",
       " 'city_Tripoli',\n",
       " 'city_Tunis',\n",
       " 'city_Vancouver',\n",
       " 'city_Vienna',\n",
       " 'city_Vilnius',\n",
       " 'city_Warsaw',\n",
       " 'city_Zagreb',\n",
       " 'city_Zurich',\n",
       " 'continent_Africa',\n",
       " 'continent_America',\n",
       " 'continent_America/Argentina',\n",
       " 'continent_America/Indiana',\n",
       " 'continent_America/Kentucky',\n",
       " 'continent_Asia',\n",
       " 'continent_Australia',\n",
       " 'continent_Europe',\n",
       " 'continent_Pacific',\n",
       " 'weather_Breezy',\n",
       " 'weather_BreezyandMostlyCloudy',\n",
       " 'weather_BreezyandOvercast',\n",
       " 'weather_BreezyandPartlyCloudy',\n",
       " 'weather_Clear',\n",
       " 'weather_DangerouslyWindy',\n",
       " 'weather_Drizzle',\n",
       " 'weather_DrizzleandBreezy',\n",
       " 'weather_Dry',\n",
       " 'weather_DryandPartlyCloudy',\n",
       " 'weather_Foggy',\n",
       " 'weather_HeavyRain',\n",
       " 'weather_Humid',\n",
       " 'weather_HumidandOvercast',\n",
       " 'weather_HumidandPartlyCloudy',\n",
       " 'weather_LightRain',\n",
       " 'weather_LightRainandBreezy',\n",
       " 'weather_MostlyCloudy',\n",
       " 'weather_Overcast',\n",
       " 'weather_PartlyCloudy',\n",
       " 'weather_Rain',\n",
       " 'weather_RainandWindy',\n",
       " 'weather_Windy',\n",
       " 'weather_WindyandFoggy',\n",
       " 'weather_WindyandPartlyCloudy',\n",
       " 'weatherIcon_clear-day',\n",
       " 'weatherIcon_clear-night',\n",
       " 'weatherIcon_cloudy',\n",
       " 'weatherIcon_fog',\n",
       " 'weatherIcon_partly-cloudy-day',\n",
       " 'weatherIcon_partly-cloudy-night',\n",
       " 'weatherIcon_rain',\n",
       " 'weatherIcon_wind',\n",
       " 'appearedTimeDayCycle']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631868</td>\n",
       "      <td>0.160342</td>\n",
       "      <td>0.333774</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.154997</td>\n",
       "      <td>0.598044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.710624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217033</td>\n",
       "      <td>0.236059</td>\n",
       "      <td>0.471987</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.102975</td>\n",
       "      <td>0.397199</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0       0.8125           0.0     0.631868   0.160342  0.333774   \n",
       "1       0.8125           1.0     0.585165   0.154997  0.598044   \n",
       "2       0.0000           1.0     0.546703   0.299662  0.710624   \n",
       "3       0.0000           1.0     0.217033   0.236059  0.471987   \n",
       "4       0.8125           1.0     0.392857   0.102975  0.397199   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural  ...  \\\n",
       "0            0.601904    1.0       1.0       1.0    0.0  ...   \n",
       "1            0.000000    0.0       0.0       0.0    1.0  ...   \n",
       "2            0.000000    0.0       0.0       0.0    1.0  ...   \n",
       "3            0.012890    0.0       0.0       0.0    1.0  ...   \n",
       "4            0.418839    1.0       1.0       1.0    0.0  ...   \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                           0.0                    1.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    1.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                      0.0                 0.0              0.0   \n",
       "1                      1.0                 0.0              0.0   \n",
       "2                      0.0                 0.0              0.0   \n",
       "3                      1.0                 0.0              0.0   \n",
       "4                      0.0                 0.0              0.0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            1.0                              0.0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0               0.0               0.0              0.023142  \n",
       "1               0.0               0.0              0.992020  \n",
       "2               0.0               0.0              0.052533  \n",
       "3               0.0               0.0              0.608220  \n",
       "4               0.0               0.0              0.004866  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7160 entries, 0 to 7159\n",
      "Columns: 297 entries, terrainType to appearedTimeDayCycle\n",
      "dtypes: float64(272), int64(25)\n",
      "memory usage: 16.3 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7160, 297)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7088, 297), (64, 297), (8, 297))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.99\n",
    "test_ratio = 0.1\n",
    "# split the data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ratio = 0.7\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data per batch to load\n",
    "batch_size = 10000\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huohsien/anaconda2/envs/ai/lib/python3.7/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.783974 \tValidation Loss: 1.763391 \t time: 0.2\n",
      "Validation loss decreased from inf to 1.763391. Model was saved\n",
      "Epoch: 2 \tTraining Loss: 1.760770 \tValidation Loss: 1.766530 \t time: 0.2\n",
      "Epoch: 3 \tTraining Loss: 1.762679 \tValidation Loss: 1.768334 \t time: 0.2\n",
      "Epoch: 4 \tTraining Loss: 1.763395 \tValidation Loss: 1.768375 \t time: 0.2\n",
      "Epoch: 5 \tTraining Loss: 1.763111 \tValidation Loss: 1.765213 \t time: 0.2\n",
      "Epoch: 6 \tTraining Loss: 1.760341 \tValidation Loss: 1.761982 \t time: 0.2\n",
      "Validation loss decreased from 1.763391 to 1.761982. Model was saved\n",
      "Epoch: 7 \tTraining Loss: 1.757662 \tValidation Loss: 1.760509 \t time: 0.2\n",
      "Validation loss decreased from 1.761982 to 1.760509. Model was saved\n",
      "Epoch: 8 \tTraining Loss: 1.756564 \tValidation Loss: 1.758973 \t time: 0.2\n",
      "Validation loss decreased from 1.760509 to 1.758973. Model was saved\n",
      "Epoch: 9 \tTraining Loss: 1.755211 \tValidation Loss: 1.756217 \t time: 0.2\n",
      "Validation loss decreased from 1.758973 to 1.756217. Model was saved\n",
      "Epoch: 10 \tTraining Loss: 1.752754 \tValidation Loss: 1.752830 \t time: 0.2\n",
      "Validation loss decreased from 1.756217 to 1.752830. Model was saved\n",
      "Epoch: 11 \tTraining Loss: 1.749824 \tValidation Loss: 1.749365 \t time: 0.2\n",
      "Validation loss decreased from 1.752830 to 1.749365. Model was saved\n",
      "Epoch: 12 \tTraining Loss: 1.746462 \tValidation Loss: 1.747032 \t time: 0.2\n",
      "Validation loss decreased from 1.749365 to 1.747032. Model was saved\n",
      "Epoch: 13 \tTraining Loss: 1.743145 \tValidation Loss: 1.741935 \t time: 0.2\n",
      "Validation loss decreased from 1.747032 to 1.741935. Model was saved\n",
      "Epoch: 14 \tTraining Loss: 1.737636 \tValidation Loss: 1.735257 \t time: 0.2\n",
      "Validation loss decreased from 1.741935 to 1.735257. Model was saved\n",
      "Epoch: 15 \tTraining Loss: 1.731260 \tValidation Loss: 1.729965 \t time: 0.2\n",
      "Validation loss decreased from 1.735257 to 1.729965. Model was saved\n",
      "Epoch: 16 \tTraining Loss: 1.725219 \tValidation Loss: 1.724966 \t time: 0.3\n",
      "Validation loss decreased from 1.729965 to 1.724966. Model was saved\n",
      "Epoch: 17 \tTraining Loss: 1.718396 \tValidation Loss: 1.716956 \t time: 0.3\n",
      "Validation loss decreased from 1.724966 to 1.716956. Model was saved\n",
      "Epoch: 18 \tTraining Loss: 1.709827 \tValidation Loss: 1.706180 \t time: 0.3\n",
      "Validation loss decreased from 1.716956 to 1.706180. Model was saved\n",
      "Epoch: 19 \tTraining Loss: 1.700457 \tValidation Loss: 1.695981 \t time: 0.3\n",
      "Validation loss decreased from 1.706180 to 1.695981. Model was saved\n",
      "Epoch: 20 \tTraining Loss: 1.691237 \tValidation Loss: 1.683933 \t time: 0.3\n",
      "Validation loss decreased from 1.695981 to 1.683933. Model was saved\n",
      "Epoch: 21 \tTraining Loss: 1.682436 \tValidation Loss: 1.673497 \t time: 0.3\n",
      "Validation loss decreased from 1.683933 to 1.673497. Model was saved\n",
      "Epoch: 22 \tTraining Loss: 1.673591 \tValidation Loss: 1.664751 \t time: 0.3\n",
      "Validation loss decreased from 1.673497 to 1.664751. Model was saved\n",
      "Epoch: 23 \tTraining Loss: 1.664510 \tValidation Loss: 1.654169 \t time: 0.3\n",
      "Validation loss decreased from 1.664751 to 1.654169. Model was saved\n",
      "Epoch: 24 \tTraining Loss: 1.656017 \tValidation Loss: 1.647254 \t time: 0.2\n",
      "Validation loss decreased from 1.654169 to 1.647254. Model was saved\n",
      "Epoch: 25 \tTraining Loss: 1.648946 \tValidation Loss: 1.643071 \t time: 0.3\n",
      "Validation loss decreased from 1.647254 to 1.643071. Model was saved\n",
      "Epoch: 26 \tTraining Loss: 1.642584 \tValidation Loss: 1.634715 \t time: 0.3\n",
      "Validation loss decreased from 1.643071 to 1.634715. Model was saved\n",
      "Epoch: 27 \tTraining Loss: 1.635088 \tValidation Loss: 1.628845 \t time: 0.3\n",
      "Validation loss decreased from 1.634715 to 1.628845. Model was saved\n",
      "Epoch: 28 \tTraining Loss: 1.629005 \tValidation Loss: 1.627873 \t time: 0.3\n",
      "Validation loss decreased from 1.628845 to 1.627873. Model was saved\n",
      "Epoch: 29 \tTraining Loss: 1.623506 \tValidation Loss: 1.620103 \t time: 0.2\n",
      "Validation loss decreased from 1.627873 to 1.620103. Model was saved\n",
      "Epoch: 30 \tTraining Loss: 1.617593 \tValidation Loss: 1.613637 \t time: 0.3\n",
      "Validation loss decreased from 1.620103 to 1.613637. Model was saved\n",
      "Epoch: 31 \tTraining Loss: 1.613717 \tValidation Loss: 1.619534 \t time: 0.3\n",
      "Epoch: 32 \tTraining Loss: 1.608992 \tValidation Loss: 1.611566 \t time: 0.3\n",
      "Validation loss decreased from 1.613637 to 1.611566. Model was saved\n",
      "Epoch: 33 \tTraining Loss: 1.603681 \tValidation Loss: 1.606161 \t time: 0.3\n",
      "Validation loss decreased from 1.611566 to 1.606161. Model was saved\n",
      "Epoch: 34 \tTraining Loss: 1.600348 \tValidation Loss: 1.613041 \t time: 0.2\n",
      "Epoch: 35 \tTraining Loss: 1.596322 \tValidation Loss: 1.607846 \t time: 0.3\n",
      "Epoch: 36 \tTraining Loss: 1.592033 \tValidation Loss: 1.604221 \t time: 0.3\n",
      "Validation loss decreased from 1.606161 to 1.604221. Model was saved\n",
      "Epoch: 37 \tTraining Loss: 1.589126 \tValidation Loss: 1.606537 \t time: 0.3\n",
      "Epoch: 38 \tTraining Loss: 1.586094 \tValidation Loss: 1.599490 \t time: 0.3\n",
      "Validation loss decreased from 1.604221 to 1.599490. Model was saved\n",
      "Epoch: 39 \tTraining Loss: 1.582135 \tValidation Loss: 1.596656 \t time: 0.2\n",
      "Validation loss decreased from 1.599490 to 1.596656. Model was saved\n",
      "Epoch: 40 \tTraining Loss: 1.578986 \tValidation Loss: 1.597068 \t time: 0.3\n",
      "Epoch: 41 \tTraining Loss: 1.576495 \tValidation Loss: 1.593738 \t time: 0.3\n",
      "Validation loss decreased from 1.596656 to 1.593738. Model was saved\n",
      "Epoch: 42 \tTraining Loss: 1.573466 \tValidation Loss: 1.591864 \t time: 0.3\n",
      "Validation loss decreased from 1.593738 to 1.591864. Model was saved\n",
      "Epoch: 43 \tTraining Loss: 1.569877 \tValidation Loss: 1.589604 \t time: 0.3\n",
      "Validation loss decreased from 1.591864 to 1.589604. Model was saved\n",
      "Epoch: 44 \tTraining Loss: 1.566628 \tValidation Loss: 1.588891 \t time: 0.3\n",
      "Validation loss decreased from 1.589604 to 1.588891. Model was saved\n",
      "Epoch: 45 \tTraining Loss: 1.563980 \tValidation Loss: 1.583706 \t time: 0.3\n",
      "Validation loss decreased from 1.588891 to 1.583706. Model was saved\n",
      "Epoch: 46 \tTraining Loss: 1.561896 \tValidation Loss: 1.588040 \t time: 0.3\n",
      "Epoch: 47 \tTraining Loss: 1.559442 \tValidation Loss: 1.580401 \t time: 0.3\n",
      "Validation loss decreased from 1.583706 to 1.580401. Model was saved\n",
      "Epoch: 48 \tTraining Loss: 1.555905 \tValidation Loss: 1.580079 \t time: 0.3\n",
      "Validation loss decreased from 1.580401 to 1.580079. Model was saved\n",
      "Epoch: 49 \tTraining Loss: 1.552550 \tValidation Loss: 1.582363 \t time: 0.3\n",
      "Epoch: 50 \tTraining Loss: 1.550903 \tValidation Loss: 1.575906 \t time: 0.2\n",
      "Validation loss decreased from 1.580079 to 1.575906. Model was saved\n",
      "Epoch: 51 \tTraining Loss: 1.548484 \tValidation Loss: 1.576169 \t time: 0.2\n",
      "Epoch: 52 \tTraining Loss: 1.544706 \tValidation Loss: 1.577341 \t time: 0.3\n",
      "Epoch: 53 \tTraining Loss: 1.542718 \tValidation Loss: 1.571969 \t time: 0.3\n",
      "Validation loss decreased from 1.575906 to 1.571969. Model was saved\n",
      "Epoch: 54 \tTraining Loss: 1.541409 \tValidation Loss: 1.576214 \t time: 0.3\n",
      "Epoch: 55 \tTraining Loss: 1.538474 \tValidation Loss: 1.570263 \t time: 0.3\n",
      "Validation loss decreased from 1.571969 to 1.570263. Model was saved\n",
      "Epoch: 56 \tTraining Loss: 1.534638 \tValidation Loss: 1.569366 \t time: 0.3\n",
      "Validation loss decreased from 1.570263 to 1.569366. Model was saved\n",
      "Epoch: 57 \tTraining Loss: 1.532485 \tValidation Loss: 1.570436 \t time: 0.3\n",
      "Epoch: 58 \tTraining Loss: 1.531266 \tValidation Loss: 1.568858 \t time: 0.3\n",
      "Validation loss decreased from 1.569366 to 1.568858. Model was saved\n",
      "Epoch: 59 \tTraining Loss: 1.528660 \tValidation Loss: 1.567446 \t time: 0.3\n",
      "Validation loss decreased from 1.568858 to 1.567446. Model was saved\n",
      "Epoch: 60 \tTraining Loss: 1.525170 \tValidation Loss: 1.567145 \t time: 0.3\n",
      "Validation loss decreased from 1.567446 to 1.567145. Model was saved\n",
      "Epoch: 61 \tTraining Loss: 1.522665 \tValidation Loss: 1.567945 \t time: 0.3\n",
      "Epoch: 62 \tTraining Loss: 1.521151 \tValidation Loss: 1.567138 \t time: 0.2\n",
      "Validation loss decreased from 1.567145 to 1.567138. Model was saved\n",
      "Epoch: 63 \tTraining Loss: 1.519759 \tValidation Loss: 1.567042 \t time: 0.3\n",
      "Validation loss decreased from 1.567138 to 1.567042. Model was saved\n",
      "Epoch: 64 \tTraining Loss: 1.516820 \tValidation Loss: 1.565489 \t time: 0.3\n",
      "Validation loss decreased from 1.567042 to 1.565489. Model was saved\n",
      "Epoch: 65 \tTraining Loss: 1.513498 \tValidation Loss: 1.565441 \t time: 0.3\n",
      "Validation loss decreased from 1.565489 to 1.565441. Model was saved\n",
      "Epoch: 66 \tTraining Loss: 1.510858 \tValidation Loss: 1.566082 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67 \tTraining Loss: 1.509032 \tValidation Loss: 1.564916 \t time: 0.3\n",
      "Validation loss decreased from 1.565441 to 1.564916. Model was saved\n",
      "Epoch: 68 \tTraining Loss: 1.507272 \tValidation Loss: 1.564426 \t time: 0.3\n",
      "Validation loss decreased from 1.564916 to 1.564426. Model was saved\n",
      "Epoch: 69 \tTraining Loss: 1.505005 \tValidation Loss: 1.560093 \t time: 0.3\n",
      "Validation loss decreased from 1.564426 to 1.560093. Model was saved\n",
      "Epoch: 70 \tTraining Loss: 1.501881 \tValidation Loss: 1.559294 \t time: 0.3\n",
      "Validation loss decreased from 1.560093 to 1.559294. Model was saved\n",
      "Epoch: 71 \tTraining Loss: 1.498625 \tValidation Loss: 1.557686 \t time: 0.3\n",
      "Validation loss decreased from 1.559294 to 1.557686. Model was saved\n",
      "Epoch: 72 \tTraining Loss: 1.495926 \tValidation Loss: 1.555763 \t time: 0.3\n",
      "Validation loss decreased from 1.557686 to 1.555763. Model was saved\n",
      "Epoch: 73 \tTraining Loss: 1.493840 \tValidation Loss: 1.555570 \t time: 0.3\n",
      "Validation loss decreased from 1.555763 to 1.555570. Model was saved\n",
      "Epoch: 74 \tTraining Loss: 1.492362 \tValidation Loss: 1.552651 \t time: 0.3\n",
      "Validation loss decreased from 1.555570 to 1.552651. Model was saved\n",
      "Epoch: 75 \tTraining Loss: 1.491403 \tValidation Loss: 1.552809 \t time: 0.3\n",
      "Epoch: 76 \tTraining Loss: 1.490126 \tValidation Loss: 1.546942 \t time: 0.3\n",
      "Validation loss decreased from 1.552651 to 1.546942. Model was saved\n",
      "Epoch: 77 \tTraining Loss: 1.485322 \tValidation Loss: 1.545729 \t time: 0.3\n",
      "Validation loss decreased from 1.546942 to 1.545729. Model was saved\n",
      "Epoch: 78 \tTraining Loss: 1.480594 \tValidation Loss: 1.544142 \t time: 0.3\n",
      "Validation loss decreased from 1.545729 to 1.544142. Model was saved\n",
      "Epoch: 79 \tTraining Loss: 1.479513 \tValidation Loss: 1.539136 \t time: 0.3\n",
      "Validation loss decreased from 1.544142 to 1.539136. Model was saved\n",
      "Epoch: 80 \tTraining Loss: 1.478970 \tValidation Loss: 1.537439 \t time: 0.3\n",
      "Validation loss decreased from 1.539136 to 1.537439. Model was saved\n",
      "Epoch: 81 \tTraining Loss: 1.475450 \tValidation Loss: 1.533931 \t time: 0.3\n",
      "Validation loss decreased from 1.537439 to 1.533931. Model was saved\n",
      "Epoch: 82 \tTraining Loss: 1.471208 \tValidation Loss: 1.531265 \t time: 0.3\n",
      "Validation loss decreased from 1.533931 to 1.531265. Model was saved\n",
      "Epoch: 83 \tTraining Loss: 1.469819 \tValidation Loss: 1.530803 \t time: 0.3\n",
      "Validation loss decreased from 1.531265 to 1.530803. Model was saved\n",
      "Epoch: 84 \tTraining Loss: 1.469378 \tValidation Loss: 1.527219 \t time: 0.3\n",
      "Validation loss decreased from 1.530803 to 1.527219. Model was saved\n",
      "Epoch: 85 \tTraining Loss: 1.466395 \tValidation Loss: 1.528041 \t time: 0.3\n",
      "Epoch: 86 \tTraining Loss: 1.462562 \tValidation Loss: 1.526837 \t time: 0.3\n",
      "Validation loss decreased from 1.527219 to 1.526837. Model was saved\n",
      "Epoch: 87 \tTraining Loss: 1.460348 \tValidation Loss: 1.523257 \t time: 0.3\n",
      "Validation loss decreased from 1.526837 to 1.523257. Model was saved\n",
      "Epoch: 88 \tTraining Loss: 1.459538 \tValidation Loss: 1.526653 \t time: 0.3\n",
      "Epoch: 89 \tTraining Loss: 1.457898 \tValidation Loss: 1.520990 \t time: 0.3\n",
      "Validation loss decreased from 1.523257 to 1.520990. Model was saved\n",
      "Epoch: 90 \tTraining Loss: 1.455056 \tValidation Loss: 1.521033 \t time: 0.3\n",
      "Epoch: 91 \tTraining Loss: 1.452055 \tValidation Loss: 1.518079 \t time: 0.3\n",
      "Validation loss decreased from 1.520990 to 1.518079. Model was saved\n",
      "Epoch: 92 \tTraining Loss: 1.449566 \tValidation Loss: 1.515218 \t time: 0.3\n",
      "Validation loss decreased from 1.518079 to 1.515218. Model was saved\n",
      "Epoch: 93 \tTraining Loss: 1.448005 \tValidation Loss: 1.517443 \t time: 0.3\n",
      "Epoch: 94 \tTraining Loss: 1.447057 \tValidation Loss: 1.509605 \t time: 0.3\n",
      "Validation loss decreased from 1.515218 to 1.509605. Model was saved\n",
      "Epoch: 95 \tTraining Loss: 1.446468 \tValidation Loss: 1.519125 \t time: 0.3\n",
      "Epoch: 96 \tTraining Loss: 1.445395 \tValidation Loss: 1.505826 \t time: 0.4\n",
      "Validation loss decreased from 1.509605 to 1.505826. Model was saved\n",
      "Epoch: 97 \tTraining Loss: 1.442856 \tValidation Loss: 1.509365 \t time: 0.3\n",
      "Epoch: 98 \tTraining Loss: 1.438576 \tValidation Loss: 1.510710 \t time: 0.3\n",
      "Epoch: 99 \tTraining Loss: 1.436546 \tValidation Loss: 1.502939 \t time: 0.3\n",
      "Validation loss decreased from 1.505826 to 1.502939. Model was saved\n",
      "Epoch: 100 \tTraining Loss: 1.436298 \tValidation Loss: 1.510985 \t time: 0.3\n",
      "Epoch: 101 \tTraining Loss: 1.435167 \tValidation Loss: 1.502770 \t time: 0.3\n",
      "Validation loss decreased from 1.502939 to 1.502770. Model was saved\n",
      "Epoch: 102 \tTraining Loss: 1.431390 \tValidation Loss: 1.505919 \t time: 0.3\n",
      "Epoch: 103 \tTraining Loss: 1.428212 \tValidation Loss: 1.501505 \t time: 0.3\n",
      "Validation loss decreased from 1.502770 to 1.501505. Model was saved\n",
      "Epoch: 104 \tTraining Loss: 1.426591 \tValidation Loss: 1.498273 \t time: 0.3\n",
      "Validation loss decreased from 1.501505 to 1.498273. Model was saved\n",
      "Epoch: 105 \tTraining Loss: 1.425141 \tValidation Loss: 1.507648 \t time: 0.3\n",
      "Epoch: 106 \tTraining Loss: 1.424299 \tValidation Loss: 1.493725 \t time: 0.3\n",
      "Validation loss decreased from 1.498273 to 1.493725. Model was saved\n",
      "Epoch: 107 \tTraining Loss: 1.423933 \tValidation Loss: 1.503417 \t time: 0.3\n",
      "Epoch: 108 \tTraining Loss: 1.421209 \tValidation Loss: 1.494101 \t time: 0.3\n",
      "Epoch: 109 \tTraining Loss: 1.418521 \tValidation Loss: 1.495051 \t time: 0.3\n",
      "Epoch: 110 \tTraining Loss: 1.415250 \tValidation Loss: 1.491494 \t time: 0.3\n",
      "Validation loss decreased from 1.493725 to 1.491494. Model was saved\n",
      "Epoch: 111 \tTraining Loss: 1.412830 \tValidation Loss: 1.491321 \t time: 0.3\n",
      "Validation loss decreased from 1.491494 to 1.491321. Model was saved\n",
      "Epoch: 112 \tTraining Loss: 1.411727 \tValidation Loss: 1.496474 \t time: 0.3\n",
      "Epoch: 113 \tTraining Loss: 1.410556 \tValidation Loss: 1.482240 \t time: 0.3\n",
      "Validation loss decreased from 1.491321 to 1.482240. Model was saved\n",
      "Epoch: 114 \tTraining Loss: 1.411379 \tValidation Loss: 1.499046 \t time: 0.3\n",
      "Epoch: 115 \tTraining Loss: 1.410567 \tValidation Loss: 1.479172 \t time: 0.3\n",
      "Validation loss decreased from 1.482240 to 1.479172. Model was saved\n",
      "Epoch: 116 \tTraining Loss: 1.410107 \tValidation Loss: 1.491046 \t time: 0.3\n",
      "Epoch: 117 \tTraining Loss: 1.405763 \tValidation Loss: 1.484124 \t time: 0.3\n",
      "Epoch: 118 \tTraining Loss: 1.400318 \tValidation Loss: 1.474934 \t time: 0.3\n",
      "Validation loss decreased from 1.479172 to 1.474934. Model was saved\n",
      "Epoch: 119 \tTraining Loss: 1.401725 \tValidation Loss: 1.491251 \t time: 0.4\n",
      "Epoch: 120 \tTraining Loss: 1.401445 \tValidation Loss: 1.471687 \t time: 0.3\n",
      "Validation loss decreased from 1.474934 to 1.471687. Model was saved\n",
      "Epoch: 121 \tTraining Loss: 1.397466 \tValidation Loss: 1.478492 \t time: 0.3\n",
      "Epoch: 122 \tTraining Loss: 1.393199 \tValidation Loss: 1.487907 \t time: 0.3\n",
      "Epoch: 123 \tTraining Loss: 1.394167 \tValidation Loss: 1.467300 \t time: 0.3\n",
      "Validation loss decreased from 1.471687 to 1.467300. Model was saved\n",
      "Epoch: 124 \tTraining Loss: 1.396764 \tValidation Loss: 1.477756 \t time: 0.3\n",
      "Epoch: 125 \tTraining Loss: 1.389136 \tValidation Loss: 1.480739 \t time: 0.3\n",
      "Epoch: 126 \tTraining Loss: 1.388464 \tValidation Loss: 1.465320 \t time: 0.3\n",
      "Validation loss decreased from 1.467300 to 1.465320. Model was saved\n",
      "Epoch: 127 \tTraining Loss: 1.390264 \tValidation Loss: 1.474715 \t time: 0.3\n",
      "Epoch: 128 \tTraining Loss: 1.390246 \tValidation Loss: 1.471329 \t time: 0.4\n",
      "Epoch: 129 \tTraining Loss: 1.380370 \tValidation Loss: 1.475700 \t time: 0.3\n",
      "Epoch: 130 \tTraining Loss: 1.386087 \tValidation Loss: 1.482048 \t time: 0.3\n",
      "Epoch: 131 \tTraining Loss: 1.385144 \tValidation Loss: 1.464271 \t time: 0.3\n",
      "Validation loss decreased from 1.465320 to 1.464271. Model was saved\n",
      "Epoch: 132 \tTraining Loss: 1.384201 \tValidation Loss: 1.469421 \t time: 0.3\n",
      "Epoch: 133 \tTraining Loss: 1.376127 \tValidation Loss: 1.493347 \t time: 0.3\n",
      "Epoch: 134 \tTraining Loss: 1.385388 \tValidation Loss: 1.468120 \t time: 0.3\n",
      "Epoch: 135 \tTraining Loss: 1.375942 \tValidation Loss: 1.464475 \t time: 0.3\n",
      "Epoch: 136 \tTraining Loss: 1.373983 \tValidation Loss: 1.474445 \t time: 0.3\n",
      "Epoch: 137 \tTraining Loss: 1.373727 \tValidation Loss: 1.472602 \t time: 0.3\n",
      "Epoch: 138 \tTraining Loss: 1.368920 \tValidation Loss: 1.470536 \t time: 0.3\n",
      "Epoch: 139 \tTraining Loss: 1.369151 \tValidation Loss: 1.473414 \t time: 0.3\n",
      "Epoch: 140 \tTraining Loss: 1.367790 \tValidation Loss: 1.466544 \t time: 0.3\n",
      "Epoch: 141 \tTraining Loss: 1.365414 \tValidation Loss: 1.472332 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 142 \tTraining Loss: 1.362772 \tValidation Loss: 1.481909 \t time: 0.3\n",
      "Epoch: 143 \tTraining Loss: 1.364722 \tValidation Loss: 1.472250 \t time: 0.3\n",
      "Epoch: 144 \tTraining Loss: 1.358216 \tValidation Loss: 1.467608 \t time: 0.3\n",
      "Epoch: 145 \tTraining Loss: 1.359370 \tValidation Loss: 1.469861 \t time: 0.3\n",
      "Epoch: 146 \tTraining Loss: 1.356497 \tValidation Loss: 1.470646 \t time: 0.3\n",
      "Epoch: 147 \tTraining Loss: 1.354594 \tValidation Loss: 1.464895 \t time: 0.3\n",
      "Epoch: 148 \tTraining Loss: 1.353894 \tValidation Loss: 1.463673 \t time: 0.3\n",
      "Validation loss decreased from 1.464271 to 1.463673. Model was saved\n",
      "Epoch: 149 \tTraining Loss: 1.352174 \tValidation Loss: 1.460517 \t time: 0.3\n",
      "Validation loss decreased from 1.463673 to 1.460517. Model was saved\n",
      "Epoch: 150 \tTraining Loss: 1.350317 \tValidation Loss: 1.462460 \t time: 0.3\n",
      "Epoch: 151 \tTraining Loss: 1.348418 \tValidation Loss: 1.467196 \t time: 0.3\n",
      "Epoch: 152 \tTraining Loss: 1.348910 \tValidation Loss: 1.461651 \t time: 0.3\n",
      "Epoch: 153 \tTraining Loss: 1.346331 \tValidation Loss: 1.457925 \t time: 0.3\n",
      "Validation loss decreased from 1.460517 to 1.457925. Model was saved\n",
      "Epoch: 154 \tTraining Loss: 1.344890 \tValidation Loss: 1.460212 \t time: 0.3\n",
      "Epoch: 155 \tTraining Loss: 1.342843 \tValidation Loss: 1.456323 \t time: 0.3\n",
      "Validation loss decreased from 1.457925 to 1.456323. Model was saved\n",
      "Epoch: 156 \tTraining Loss: 1.343408 \tValidation Loss: 1.457557 \t time: 0.3\n",
      "Epoch: 157 \tTraining Loss: 1.341016 \tValidation Loss: 1.455594 \t time: 0.3\n",
      "Validation loss decreased from 1.456323 to 1.455594. Model was saved\n",
      "Epoch: 158 \tTraining Loss: 1.339660 \tValidation Loss: 1.456519 \t time: 0.3\n",
      "Epoch: 159 \tTraining Loss: 1.337825 \tValidation Loss: 1.457958 \t time: 0.3\n",
      "Epoch: 160 \tTraining Loss: 1.338182 \tValidation Loss: 1.453821 \t time: 0.3\n",
      "Validation loss decreased from 1.455594 to 1.453821. Model was saved\n",
      "Epoch: 161 \tTraining Loss: 1.336780 \tValidation Loss: 1.451851 \t time: 0.3\n",
      "Validation loss decreased from 1.453821 to 1.451851. Model was saved\n",
      "Epoch: 162 \tTraining Loss: 1.335330 \tValidation Loss: 1.452577 \t time: 0.3\n",
      "Epoch: 163 \tTraining Loss: 1.332800 \tValidation Loss: 1.451162 \t time: 0.3\n",
      "Validation loss decreased from 1.451851 to 1.451162. Model was saved\n",
      "Epoch: 164 \tTraining Loss: 1.332438 \tValidation Loss: 1.455657 \t time: 0.3\n",
      "Epoch: 165 \tTraining Loss: 1.331644 \tValidation Loss: 1.452842 \t time: 0.3\n",
      "Epoch: 166 \tTraining Loss: 1.331079 \tValidation Loss: 1.456401 \t time: 0.3\n",
      "Epoch: 167 \tTraining Loss: 1.328733 \tValidation Loss: 1.451852 \t time: 0.3\n",
      "Epoch: 168 \tTraining Loss: 1.327306 \tValidation Loss: 1.451190 \t time: 0.3\n",
      "Epoch: 169 \tTraining Loss: 1.325998 \tValidation Loss: 1.450136 \t time: 0.3\n",
      "Validation loss decreased from 1.451162 to 1.450136. Model was saved\n",
      "Epoch: 170 \tTraining Loss: 1.325275 \tValidation Loss: 1.444432 \t time: 0.3\n",
      "Validation loss decreased from 1.450136 to 1.444432. Model was saved\n",
      "Epoch: 171 \tTraining Loss: 1.324513 \tValidation Loss: 1.449932 \t time: 0.3\n",
      "Epoch: 172 \tTraining Loss: 1.323678 \tValidation Loss: 1.445411 \t time: 0.3\n",
      "Epoch: 173 \tTraining Loss: 1.323058 \tValidation Loss: 1.449651 \t time: 0.3\n",
      "Epoch: 174 \tTraining Loss: 1.321683 \tValidation Loss: 1.444554 \t time: 0.3\n",
      "Epoch: 175 \tTraining Loss: 1.320599 \tValidation Loss: 1.449063 \t time: 0.3\n",
      "Epoch: 176 \tTraining Loss: 1.319245 \tValidation Loss: 1.445602 \t time: 0.3\n",
      "Epoch: 177 \tTraining Loss: 1.318329 \tValidation Loss: 1.446978 \t time: 0.3\n",
      "Epoch: 178 \tTraining Loss: 1.317101 \tValidation Loss: 1.443398 \t time: 0.3\n",
      "Validation loss decreased from 1.444432 to 1.443398. Model was saved\n",
      "Epoch: 179 \tTraining Loss: 1.316181 \tValidation Loss: 1.443239 \t time: 0.3\n",
      "Validation loss decreased from 1.443398 to 1.443239. Model was saved\n",
      "Epoch: 180 \tTraining Loss: 1.315159 \tValidation Loss: 1.439903 \t time: 0.3\n",
      "Validation loss decreased from 1.443239 to 1.439903. Model was saved\n",
      "Epoch: 181 \tTraining Loss: 1.314222 \tValidation Loss: 1.439214 \t time: 0.3\n",
      "Validation loss decreased from 1.439903 to 1.439214. Model was saved\n",
      "Epoch: 182 \tTraining Loss: 1.313378 \tValidation Loss: 1.435611 \t time: 0.3\n",
      "Validation loss decreased from 1.439214 to 1.435611. Model was saved\n",
      "Epoch: 183 \tTraining Loss: 1.312455 \tValidation Loss: 1.435922 \t time: 0.3\n",
      "Epoch: 184 \tTraining Loss: 1.311875 \tValidation Loss: 1.432537 \t time: 0.3\n",
      "Validation loss decreased from 1.435611 to 1.432537. Model was saved\n",
      "Epoch: 185 \tTraining Loss: 1.311333 \tValidation Loss: 1.437836 \t time: 0.3\n",
      "Epoch: 186 \tTraining Loss: 1.311585 \tValidation Loss: 1.427854 \t time: 0.3\n",
      "Validation loss decreased from 1.432537 to 1.427854. Model was saved\n",
      "Epoch: 187 \tTraining Loss: 1.314212 \tValidation Loss: 1.445246 \t time: 0.3\n",
      "Epoch: 188 \tTraining Loss: 1.320026 \tValidation Loss: 1.425119 \t time: 0.3\n",
      "Validation loss decreased from 1.427854 to 1.425119. Model was saved\n",
      "Epoch: 189 \tTraining Loss: 1.329278 \tValidation Loss: 1.443475 \t time: 0.3\n",
      "Epoch: 190 \tTraining Loss: 1.324245 \tValidation Loss: 1.428582 \t time: 0.3\n",
      "Epoch: 191 \tTraining Loss: 1.309064 \tValidation Loss: 1.428694 \t time: 0.3\n",
      "Epoch: 192 \tTraining Loss: 1.317314 \tValidation Loss: 1.443966 \t time: 0.3\n",
      "Epoch: 193 \tTraining Loss: 1.315338 \tValidation Loss: 1.433716 \t time: 0.3\n",
      "Epoch: 194 \tTraining Loss: 1.308127 \tValidation Loss: 1.427103 \t time: 0.3\n",
      "Epoch: 195 \tTraining Loss: 1.311988 \tValidation Loss: 1.447358 \t time: 0.3\n",
      "Epoch: 196 \tTraining Loss: 1.307333 \tValidation Loss: 1.444029 \t time: 0.3\n",
      "Epoch: 197 \tTraining Loss: 1.306255 \tValidation Loss: 1.431140 \t time: 0.3\n",
      "Epoch: 198 \tTraining Loss: 1.308509 \tValidation Loss: 1.435810 \t time: 0.3\n",
      "Epoch: 199 \tTraining Loss: 1.303055 \tValidation Loss: 1.450336 \t time: 0.3\n",
      "Epoch: 200 \tTraining Loss: 1.306244 \tValidation Loss: 1.435264 \t time: 0.3\n",
      "Epoch: 201 \tTraining Loss: 1.303268 \tValidation Loss: 1.432469 \t time: 0.3\n",
      "Epoch: 202 \tTraining Loss: 1.302159 \tValidation Loss: 1.439221 \t time: 0.3\n",
      "Epoch: 203 \tTraining Loss: 1.302598 \tValidation Loss: 1.437736 \t time: 0.3\n",
      "Epoch: 204 \tTraining Loss: 1.299384 \tValidation Loss: 1.430161 \t time: 0.3\n",
      "Epoch: 205 \tTraining Loss: 1.301436 \tValidation Loss: 1.438467 \t time: 0.3\n",
      "Epoch: 206 \tTraining Loss: 1.298588 \tValidation Loss: 1.436403 \t time: 0.3\n",
      "Epoch: 207 \tTraining Loss: 1.298568 \tValidation Loss: 1.431670 \t time: 0.3\n",
      "Epoch: 208 \tTraining Loss: 1.297904 \tValidation Loss: 1.440676 \t time: 0.3\n",
      "Epoch: 209 \tTraining Loss: 1.296855 \tValidation Loss: 1.443720 \t time: 0.3\n",
      "Epoch: 210 \tTraining Loss: 1.296010 \tValidation Loss: 1.434746 \t time: 0.3\n",
      "Epoch: 211 \tTraining Loss: 1.296373 \tValidation Loss: 1.439850 \t time: 0.3\n",
      "Epoch: 212 \tTraining Loss: 1.294043 \tValidation Loss: 1.445150 \t time: 0.3\n",
      "Epoch: 213 \tTraining Loss: 1.294704 \tValidation Loss: 1.435581 \t time: 0.3\n",
      "Epoch: 214 \tTraining Loss: 1.293652 \tValidation Loss: 1.440507 \t time: 0.3\n",
      "Epoch: 215 \tTraining Loss: 1.292805 \tValidation Loss: 1.443715 \t time: 0.3\n",
      "Epoch: 216 \tTraining Loss: 1.291940 \tValidation Loss: 1.437474 \t time: 0.3\n",
      "Epoch: 217 \tTraining Loss: 1.292054 \tValidation Loss: 1.442748 \t time: 0.3\n",
      "Epoch: 218 \tTraining Loss: 1.290430 \tValidation Loss: 1.438903 \t time: 0.3\n",
      "Epoch: 219 \tTraining Loss: 1.290036 \tValidation Loss: 1.437084 \t time: 0.3\n",
      "Epoch: 220 \tTraining Loss: 1.289197 \tValidation Loss: 1.443138 \t time: 0.3\n",
      "Epoch: 221 \tTraining Loss: 1.289071 \tValidation Loss: 1.436520 \t time: 0.3\n",
      "Epoch: 222 \tTraining Loss: 1.288001 \tValidation Loss: 1.437540 \t time: 0.3\n",
      "Epoch: 223 \tTraining Loss: 1.287423 \tValidation Loss: 1.437298 \t time: 0.3\n",
      "Epoch: 224 \tTraining Loss: 1.286505 \tValidation Loss: 1.432963 \t time: 0.3\n",
      "Epoch: 225 \tTraining Loss: 1.286466 \tValidation Loss: 1.436806 \t time: 0.3\n",
      "Epoch: 226 \tTraining Loss: 1.285684 \tValidation Loss: 1.429420 \t time: 0.3\n",
      "Epoch: 227 \tTraining Loss: 1.285153 \tValidation Loss: 1.432595 \t time: 0.3\n",
      "Epoch: 228 \tTraining Loss: 1.284210 \tValidation Loss: 1.430642 \t time: 0.3\n",
      "Epoch: 229 \tTraining Loss: 1.283764 \tValidation Loss: 1.424088 \t time: 0.3\n",
      "Validation loss decreased from 1.425119 to 1.424088. Model was saved\n",
      "Epoch: 230 \tTraining Loss: 1.283296 \tValidation Loss: 1.428290 \t time: 0.3\n",
      "Epoch: 231 \tTraining Loss: 1.283035 \tValidation Loss: 1.422959 \t time: 0.3\n",
      "Validation loss decreased from 1.424088 to 1.422959. Model was saved\n",
      "Epoch: 232 \tTraining Loss: 1.282441 \tValidation Loss: 1.429728 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 233 \tTraining Loss: 1.281892 \tValidation Loss: 1.425018 \t time: 0.3\n",
      "Epoch: 234 \tTraining Loss: 1.281165 \tValidation Loss: 1.425840 \t time: 0.3\n",
      "Epoch: 235 \tTraining Loss: 1.280550 \tValidation Loss: 1.425176 \t time: 0.3\n",
      "Epoch: 236 \tTraining Loss: 1.280067 \tValidation Loss: 1.422057 \t time: 0.3\n",
      "Validation loss decreased from 1.422959 to 1.422057. Model was saved\n",
      "Epoch: 237 \tTraining Loss: 1.279710 \tValidation Loss: 1.425727 \t time: 0.3\n",
      "Epoch: 238 \tTraining Loss: 1.279319 \tValidation Loss: 1.421120 \t time: 0.3\n",
      "Validation loss decreased from 1.422057 to 1.421120. Model was saved\n",
      "Epoch: 239 \tTraining Loss: 1.278930 \tValidation Loss: 1.426385 \t time: 0.3\n",
      "Epoch: 240 \tTraining Loss: 1.278454 \tValidation Loss: 1.419211 \t time: 0.3\n",
      "Validation loss decreased from 1.421120 to 1.419211. Model was saved\n",
      "Epoch: 241 \tTraining Loss: 1.277963 \tValidation Loss: 1.423592 \t time: 0.3\n",
      "Epoch: 242 \tTraining Loss: 1.277519 \tValidation Loss: 1.416599 \t time: 0.3\n",
      "Validation loss decreased from 1.419211 to 1.416599. Model was saved\n",
      "Epoch: 243 \tTraining Loss: 1.277143 \tValidation Loss: 1.426300 \t time: 0.3\n",
      "Epoch: 244 \tTraining Loss: 1.276878 \tValidation Loss: 1.415576 \t time: 0.3\n",
      "Validation loss decreased from 1.416599 to 1.415576. Model was saved\n",
      "Epoch: 245 \tTraining Loss: 1.277079 \tValidation Loss: 1.429481 \t time: 0.3\n",
      "Epoch: 246 \tTraining Loss: 1.277532 \tValidation Loss: 1.410342 \t time: 0.3\n",
      "Validation loss decreased from 1.415576 to 1.410342. Model was saved\n",
      "Epoch: 247 \tTraining Loss: 1.279082 \tValidation Loss: 1.431526 \t time: 0.3\n",
      "Epoch: 248 \tTraining Loss: 1.278805 \tValidation Loss: 1.411229 \t time: 0.3\n",
      "Epoch: 249 \tTraining Loss: 1.278451 \tValidation Loss: 1.427348 \t time: 0.3\n",
      "Epoch: 250 \tTraining Loss: 1.274701 \tValidation Loss: 1.426753 \t time: 0.3\n",
      "Epoch: 251 \tTraining Loss: 1.273800 \tValidation Loss: 1.414985 \t time: 0.3\n",
      "Epoch: 252 \tTraining Loss: 1.275895 \tValidation Loss: 1.428272 \t time: 0.3\n",
      "Epoch: 253 \tTraining Loss: 1.275148 \tValidation Loss: 1.419034 \t time: 0.3\n",
      "Epoch: 254 \tTraining Loss: 1.273102 \tValidation Loss: 1.424006 \t time: 0.3\n",
      "Epoch: 255 \tTraining Loss: 1.272094 \tValidation Loss: 1.433156 \t time: 0.3\n",
      "Epoch: 256 \tTraining Loss: 1.273281 \tValidation Loss: 1.418314 \t time: 0.3\n",
      "Epoch: 257 \tTraining Loss: 1.274099 \tValidation Loss: 1.431880 \t time: 0.3\n",
      "Epoch: 258 \tTraining Loss: 1.271620 \tValidation Loss: 1.428852 \t time: 0.3\n",
      "Epoch: 259 \tTraining Loss: 1.270123 \tValidation Loss: 1.422752 \t time: 0.3\n",
      "Epoch: 260 \tTraining Loss: 1.270683 \tValidation Loss: 1.434382 \t time: 0.3\n",
      "Epoch: 261 \tTraining Loss: 1.270799 \tValidation Loss: 1.424404 \t time: 0.3\n",
      "Epoch: 262 \tTraining Loss: 1.269533 \tValidation Loss: 1.428196 \t time: 0.3\n",
      "Epoch: 263 \tTraining Loss: 1.268406 \tValidation Loss: 1.431064 \t time: 0.3\n",
      "Epoch: 264 \tTraining Loss: 1.268475 \tValidation Loss: 1.420728 \t time: 0.3\n",
      "Epoch: 265 \tTraining Loss: 1.268800 \tValidation Loss: 1.430246 \t time: 0.3\n",
      "Epoch: 266 \tTraining Loss: 1.267721 \tValidation Loss: 1.423957 \t time: 0.3\n",
      "Epoch: 267 \tTraining Loss: 1.266504 \tValidation Loss: 1.422502 \t time: 0.3\n",
      "Epoch: 268 \tTraining Loss: 1.265948 \tValidation Loss: 1.425536 \t time: 0.3\n",
      "Epoch: 269 \tTraining Loss: 1.265980 \tValidation Loss: 1.417034 \t time: 0.3\n",
      "Epoch: 270 \tTraining Loss: 1.265655 \tValidation Loss: 1.422882 \t time: 0.3\n",
      "Epoch: 271 \tTraining Loss: 1.264737 \tValidation Loss: 1.417049 \t time: 0.3\n",
      "Epoch: 272 \tTraining Loss: 1.263738 \tValidation Loss: 1.415734 \t time: 0.3\n",
      "Epoch: 273 \tTraining Loss: 1.263238 \tValidation Loss: 1.418758 \t time: 0.3\n",
      "Epoch: 274 \tTraining Loss: 1.262965 \tValidation Loss: 1.412517 \t time: 0.3\n",
      "Epoch: 275 \tTraining Loss: 1.262594 \tValidation Loss: 1.416941 \t time: 0.3\n",
      "Epoch: 276 \tTraining Loss: 1.261847 \tValidation Loss: 1.410592 \t time: 0.3\n",
      "Epoch: 277 \tTraining Loss: 1.260733 \tValidation Loss: 1.411404 \t time: 0.4\n",
      "Epoch: 278 \tTraining Loss: 1.259826 \tValidation Loss: 1.411327 \t time: 0.3\n",
      "Epoch: 279 \tTraining Loss: 1.259078 \tValidation Loss: 1.408652 \t time: 0.3\n",
      "Validation loss decreased from 1.410342 to 1.408652. Model was saved\n",
      "Epoch: 280 \tTraining Loss: 1.258578 \tValidation Loss: 1.411919 \t time: 0.3\n",
      "Epoch: 281 \tTraining Loss: 1.257937 \tValidation Loss: 1.406990 \t time: 0.3\n",
      "Validation loss decreased from 1.408652 to 1.406990. Model was saved\n",
      "Epoch: 282 \tTraining Loss: 1.257164 \tValidation Loss: 1.409569 \t time: 0.3\n",
      "Epoch: 283 \tTraining Loss: 1.256357 \tValidation Loss: 1.406071 \t time: 0.3\n",
      "Validation loss decreased from 1.406990 to 1.406071. Model was saved\n",
      "Epoch: 284 \tTraining Loss: 1.255491 \tValidation Loss: 1.407904 \t time: 0.3\n",
      "Epoch: 285 \tTraining Loss: 1.254625 \tValidation Loss: 1.405231 \t time: 0.3\n",
      "Validation loss decreased from 1.406071 to 1.405231. Model was saved\n",
      "Epoch: 286 \tTraining Loss: 1.253737 \tValidation Loss: 1.403636 \t time: 0.3\n",
      "Validation loss decreased from 1.405231 to 1.403636. Model was saved\n",
      "Epoch: 287 \tTraining Loss: 1.252993 \tValidation Loss: 1.403659 \t time: 0.3\n",
      "Epoch: 288 \tTraining Loss: 1.252280 \tValidation Loss: 1.399754 \t time: 0.3\n",
      "Validation loss decreased from 1.403636 to 1.399754. Model was saved\n",
      "Epoch: 289 \tTraining Loss: 1.251667 \tValidation Loss: 1.401800 \t time: 0.3\n",
      "Epoch: 290 \tTraining Loss: 1.251022 \tValidation Loss: 1.396023 \t time: 0.3\n",
      "Validation loss decreased from 1.399754 to 1.396023. Model was saved\n",
      "Epoch: 291 \tTraining Loss: 1.250344 \tValidation Loss: 1.400359 \t time: 0.3\n",
      "Epoch: 292 \tTraining Loss: 1.249739 \tValidation Loss: 1.396705 \t time: 0.3\n",
      "Epoch: 293 \tTraining Loss: 1.249119 \tValidation Loss: 1.401590 \t time: 0.3\n",
      "Epoch: 294 \tTraining Loss: 1.248481 \tValidation Loss: 1.396940 \t time: 0.3\n",
      "Epoch: 295 \tTraining Loss: 1.247738 \tValidation Loss: 1.398983 \t time: 0.3\n",
      "Epoch: 296 \tTraining Loss: 1.246973 \tValidation Loss: 1.396493 \t time: 0.3\n",
      "Epoch: 297 \tTraining Loss: 1.246205 \tValidation Loss: 1.396367 \t time: 0.3\n",
      "Epoch: 298 \tTraining Loss: 1.245559 \tValidation Loss: 1.396901 \t time: 0.3\n",
      "Epoch: 299 \tTraining Loss: 1.244983 \tValidation Loss: 1.393636 \t time: 0.3\n",
      "Validation loss decreased from 1.396023 to 1.393636. Model was saved\n",
      "Epoch: 300 \tTraining Loss: 1.244529 \tValidation Loss: 1.397364 \t time: 0.3\n",
      "Epoch: 301 \tTraining Loss: 1.244184 \tValidation Loss: 1.391867 \t time: 0.3\n",
      "Validation loss decreased from 1.393636 to 1.391867. Model was saved\n",
      "Epoch: 302 \tTraining Loss: 1.243935 \tValidation Loss: 1.399145 \t time: 0.3\n",
      "Epoch: 303 \tTraining Loss: 1.243665 \tValidation Loss: 1.389599 \t time: 0.3\n",
      "Validation loss decreased from 1.391867 to 1.389599. Model was saved\n",
      "Epoch: 304 \tTraining Loss: 1.243597 \tValidation Loss: 1.400988 \t time: 0.3\n",
      "Epoch: 305 \tTraining Loss: 1.243371 \tValidation Loss: 1.388319 \t time: 0.3\n",
      "Validation loss decreased from 1.389599 to 1.388319. Model was saved\n",
      "Epoch: 306 \tTraining Loss: 1.243201 \tValidation Loss: 1.400780 \t time: 0.3\n",
      "Epoch: 307 \tTraining Loss: 1.242321 \tValidation Loss: 1.390174 \t time: 0.3\n",
      "Epoch: 308 \tTraining Loss: 1.241162 \tValidation Loss: 1.393771 \t time: 0.3\n",
      "Epoch: 309 \tTraining Loss: 1.240364 \tValidation Loss: 1.397327 \t time: 0.3\n",
      "Epoch: 310 \tTraining Loss: 1.240197 \tValidation Loss: 1.389965 \t time: 0.3\n",
      "Epoch: 311 \tTraining Loss: 1.240281 \tValidation Loss: 1.399120 \t time: 0.3\n",
      "Epoch: 312 \tTraining Loss: 1.239957 \tValidation Loss: 1.390217 \t time: 0.3\n",
      "Epoch: 313 \tTraining Loss: 1.239384 \tValidation Loss: 1.395759 \t time: 0.3\n",
      "Epoch: 314 \tTraining Loss: 1.238793 \tValidation Loss: 1.394413 \t time: 0.3\n",
      "Epoch: 315 \tTraining Loss: 1.238423 \tValidation Loss: 1.392014 \t time: 0.3\n",
      "Epoch: 316 \tTraining Loss: 1.238292 \tValidation Loss: 1.396397 \t time: 0.3\n",
      "Epoch: 317 \tTraining Loss: 1.238165 \tValidation Loss: 1.390495 \t time: 0.3\n",
      "Epoch: 318 \tTraining Loss: 1.237960 \tValidation Loss: 1.396370 \t time: 0.3\n",
      "Epoch: 319 \tTraining Loss: 1.237608 \tValidation Loss: 1.392406 \t time: 0.3\n",
      "Epoch: 320 \tTraining Loss: 1.237235 \tValidation Loss: 1.394063 \t time: 0.3\n",
      "Epoch: 321 \tTraining Loss: 1.236906 \tValidation Loss: 1.394684 \t time: 0.3\n",
      "Epoch: 322 \tTraining Loss: 1.236723 \tValidation Loss: 1.391123 \t time: 0.3\n",
      "Epoch: 323 \tTraining Loss: 1.236635 \tValidation Loss: 1.395833 \t time: 0.3\n",
      "Epoch: 324 \tTraining Loss: 1.236544 \tValidation Loss: 1.390577 \t time: 0.3\n",
      "Epoch: 325 \tTraining Loss: 1.236345 \tValidation Loss: 1.395241 \t time: 0.3\n",
      "Epoch: 326 \tTraining Loss: 1.236019 \tValidation Loss: 1.391953 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 327 \tTraining Loss: 1.235690 \tValidation Loss: 1.394287 \t time: 0.3\n",
      "Epoch: 328 \tTraining Loss: 1.235364 \tValidation Loss: 1.394164 \t time: 0.3\n",
      "Epoch: 329 \tTraining Loss: 1.235113 \tValidation Loss: 1.393061 \t time: 0.3\n",
      "Epoch: 330 \tTraining Loss: 1.235028 \tValidation Loss: 1.394698 \t time: 0.3\n",
      "Epoch: 331 \tTraining Loss: 1.234896 \tValidation Loss: 1.392594 \t time: 0.3\n",
      "Epoch: 332 \tTraining Loss: 1.234765 \tValidation Loss: 1.394848 \t time: 0.3\n",
      "Epoch: 333 \tTraining Loss: 1.234611 \tValidation Loss: 1.391963 \t time: 0.3\n",
      "Epoch: 334 \tTraining Loss: 1.234365 \tValidation Loss: 1.394664 \t time: 0.3\n",
      "Epoch: 335 \tTraining Loss: 1.234174 \tValidation Loss: 1.391620 \t time: 0.3\n",
      "Epoch: 336 \tTraining Loss: 1.234051 \tValidation Loss: 1.394887 \t time: 0.3\n",
      "Epoch: 337 \tTraining Loss: 1.233883 \tValidation Loss: 1.391691 \t time: 0.3\n",
      "Epoch: 338 \tTraining Loss: 1.233665 \tValidation Loss: 1.394086 \t time: 0.3\n",
      "Epoch: 339 \tTraining Loss: 1.233438 \tValidation Loss: 1.392309 \t time: 0.3\n",
      "Epoch: 340 \tTraining Loss: 1.233254 \tValidation Loss: 1.393696 \t time: 0.3\n",
      "Epoch: 341 \tTraining Loss: 1.233051 \tValidation Loss: 1.393316 \t time: 0.3\n",
      "Epoch: 342 \tTraining Loss: 1.232889 \tValidation Loss: 1.392874 \t time: 0.3\n",
      "Epoch: 343 \tTraining Loss: 1.232760 \tValidation Loss: 1.394122 \t time: 0.4\n",
      "Epoch: 344 \tTraining Loss: 1.232627 \tValidation Loss: 1.392317 \t time: 0.3\n",
      "Epoch: 345 \tTraining Loss: 1.232497 \tValidation Loss: 1.395007 \t time: 0.3\n",
      "Epoch: 346 \tTraining Loss: 1.232403 \tValidation Loss: 1.391305 \t time: 0.3\n",
      "Epoch: 347 \tTraining Loss: 1.232356 \tValidation Loss: 1.396165 \t time: 0.3\n",
      "Epoch: 348 \tTraining Loss: 1.232395 \tValidation Loss: 1.390566 \t time: 0.3\n",
      "Epoch: 349 \tTraining Loss: 1.232632 \tValidation Loss: 1.397436 \t time: 0.3\n",
      "Epoch: 350 \tTraining Loss: 1.232700 \tValidation Loss: 1.390332 \t time: 0.3\n",
      "Epoch: 351 \tTraining Loss: 1.232799 \tValidation Loss: 1.397495 \t time: 0.3\n",
      "Epoch: 352 \tTraining Loss: 1.232067 \tValidation Loss: 1.393379 \t time: 0.3\n",
      "Epoch: 353 \tTraining Loss: 1.231359 \tValidation Loss: 1.393950 \t time: 0.3\n",
      "Epoch: 354 \tTraining Loss: 1.230985 \tValidation Loss: 1.394541 \t time: 0.3\n",
      "Epoch: 355 \tTraining Loss: 1.231109 \tValidation Loss: 1.389713 \t time: 0.3\n",
      "Epoch: 356 \tTraining Loss: 1.231423 \tValidation Loss: 1.393469 \t time: 0.3\n",
      "Epoch: 357 \tTraining Loss: 1.231302 \tValidation Loss: 1.387199 \t time: 0.3\n",
      "Validation loss decreased from 1.388319 to 1.387199. Model was saved\n",
      "Epoch: 358 \tTraining Loss: 1.231040 \tValidation Loss: 1.390359 \t time: 0.3\n",
      "Epoch: 359 \tTraining Loss: 1.230508 \tValidation Loss: 1.387050 \t time: 0.3\n",
      "Validation loss decreased from 1.387199 to 1.387050. Model was saved\n",
      "Epoch: 360 \tTraining Loss: 1.230069 \tValidation Loss: 1.387180 \t time: 0.3\n",
      "Epoch: 361 \tTraining Loss: 1.229757 \tValidation Loss: 1.388560 \t time: 0.3\n",
      "Epoch: 362 \tTraining Loss: 1.229649 \tValidation Loss: 1.384373 \t time: 0.3\n",
      "Validation loss decreased from 1.387050 to 1.384373. Model was saved\n",
      "Epoch: 363 \tTraining Loss: 1.229619 \tValidation Loss: 1.390898 \t time: 0.3\n",
      "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
      "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
      "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
      "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
      "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
      "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
      "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n",
      "Epoch: 369 \tTraining Loss: 1.228766 \tValidation Loss: 1.387610 \t time: 0.3\n",
      "Epoch: 370 \tTraining Loss: 1.229227 \tValidation Loss: 1.396452 \t time: 0.3\n",
      "Epoch: 371 \tTraining Loss: 1.230099 \tValidation Loss: 1.386835 \t time: 0.3\n",
      "Epoch: 372 \tTraining Loss: 1.229857 \tValidation Loss: 1.394770 \t time: 0.3\n",
      "Epoch: 373 \tTraining Loss: 1.228157 \tValidation Loss: 1.397404 \t time: 0.3\n",
      "Epoch: 374 \tTraining Loss: 1.229059 \tValidation Loss: 1.381317 \t time: 0.3\n",
      "Epoch: 375 \tTraining Loss: 1.230676 \tValidation Loss: 1.397128 \t time: 0.4\n",
      "Epoch: 376 \tTraining Loss: 1.229115 \tValidation Loss: 1.395375 \t time: 0.3\n",
      "Epoch: 377 \tTraining Loss: 1.227698 \tValidation Loss: 1.388837 \t time: 0.4\n",
      "Epoch: 378 \tTraining Loss: 1.228381 \tValidation Loss: 1.394456 \t time: 0.3\n",
      "Epoch: 379 \tTraining Loss: 1.228449 \tValidation Loss: 1.392062 \t time: 0.3\n",
      "Epoch: 380 \tTraining Loss: 1.227351 \tValidation Loss: 1.394225 \t time: 0.3\n",
      "Epoch: 381 \tTraining Loss: 1.227210 \tValidation Loss: 1.396367 \t time: 0.4\n",
      "Epoch: 382 \tTraining Loss: 1.227510 \tValidation Loss: 1.389455 \t time: 0.4\n",
      "Epoch: 383 \tTraining Loss: 1.227245 \tValidation Loss: 1.394238 \t time: 0.4\n",
      "Epoch: 384 \tTraining Loss: 1.226601 \tValidation Loss: 1.396317 \t time: 0.3\n",
      "Epoch: 385 \tTraining Loss: 1.226631 \tValidation Loss: 1.390417 \t time: 0.4\n",
      "Epoch: 386 \tTraining Loss: 1.226864 \tValidation Loss: 1.395748 \t time: 0.4\n",
      "Epoch: 387 \tTraining Loss: 1.226647 \tValidation Loss: 1.392088 \t time: 0.3\n",
      "Epoch: 388 \tTraining Loss: 1.226288 \tValidation Loss: 1.394608 \t time: 0.3\n",
      "Epoch: 389 \tTraining Loss: 1.226067 \tValidation Loss: 1.397282 \t time: 0.4\n",
      "Epoch: 390 \tTraining Loss: 1.226194 \tValidation Loss: 1.391840 \t time: 0.4\n",
      "Epoch: 391 \tTraining Loss: 1.226155 \tValidation Loss: 1.396160 \t time: 0.3\n",
      "Epoch: 392 \tTraining Loss: 1.225981 \tValidation Loss: 1.393123 \t time: 0.4\n",
      "Epoch: 393 \tTraining Loss: 1.225752 \tValidation Loss: 1.394046 \t time: 0.4\n",
      "Epoch: 394 \tTraining Loss: 1.225655 \tValidation Loss: 1.396775 \t time: 0.4\n",
      "Epoch: 395 \tTraining Loss: 1.225652 \tValidation Loss: 1.391219 \t time: 0.4\n",
      "Epoch: 396 \tTraining Loss: 1.225670 \tValidation Loss: 1.397142 \t time: 0.4\n",
      "Epoch: 397 \tTraining Loss: 1.225614 \tValidation Loss: 1.393014 \t time: 0.4\n",
      "Epoch: 398 \tTraining Loss: 1.225538 \tValidation Loss: 1.398267 \t time: 0.3\n",
      "Epoch: 399 \tTraining Loss: 1.225367 \tValidation Loss: 1.394228 \t time: 0.3\n",
      "Epoch: 400 \tTraining Loss: 1.225179 \tValidation Loss: 1.396936 \t time: 0.3\n",
      "Epoch: 401 \tTraining Loss: 1.225006 \tValidation Loss: 1.397635 \t time: 0.3\n",
      "Epoch: 402 \tTraining Loss: 1.224875 \tValidation Loss: 1.396677 \t time: 0.3\n",
      "Epoch: 403 \tTraining Loss: 1.224728 \tValidation Loss: 1.399095 \t time: 0.3\n",
      "Epoch: 404 \tTraining Loss: 1.224672 \tValidation Loss: 1.395578 \t time: 0.3\n",
      "Epoch: 405 \tTraining Loss: 1.224664 \tValidation Loss: 1.401516 \t time: 0.3\n",
      "Epoch: 406 \tTraining Loss: 1.224714 \tValidation Loss: 1.395638 \t time: 0.3\n",
      "Epoch: 407 \tTraining Loss: 1.224811 \tValidation Loss: 1.402547 \t time: 0.3\n",
      "Epoch: 408 \tTraining Loss: 1.224697 \tValidation Loss: 1.396905 \t time: 0.3\n",
      "Epoch: 409 \tTraining Loss: 1.224637 \tValidation Loss: 1.403431 \t time: 0.3\n",
      "Epoch: 410 \tTraining Loss: 1.224384 \tValidation Loss: 1.399867 \t time: 0.3\n",
      "Epoch: 411 \tTraining Loss: 1.224133 \tValidation Loss: 1.401869 \t time: 0.3\n",
      "Epoch: 412 \tTraining Loss: 1.223927 \tValidation Loss: 1.402524 \t time: 0.3\n",
      "Epoch: 413 \tTraining Loss: 1.223931 \tValidation Loss: 1.399274 \t time: 0.4\n",
      "Epoch: 414 \tTraining Loss: 1.223998 \tValidation Loss: 1.403599 \t time: 0.3\n",
      "Epoch: 415 \tTraining Loss: 1.224064 \tValidation Loss: 1.398915 \t time: 0.4\n",
      "Epoch: 416 \tTraining Loss: 1.224021 \tValidation Loss: 1.403438 \t time: 0.3\n",
      "Epoch: 417 \tTraining Loss: 1.223863 \tValidation Loss: 1.400262 \t time: 0.3\n",
      "Epoch: 418 \tTraining Loss: 1.223680 \tValidation Loss: 1.402743 \t time: 0.3\n",
      "Epoch: 419 \tTraining Loss: 1.223518 \tValidation Loss: 1.402222 \t time: 0.3\n",
      "Epoch: 420 \tTraining Loss: 1.223436 \tValidation Loss: 1.400833 \t time: 0.3\n",
      "Epoch: 421 \tTraining Loss: 1.223435 \tValidation Loss: 1.403105 \t time: 0.3\n",
      "Epoch: 422 \tTraining Loss: 1.223457 \tValidation Loss: 1.400277 \t time: 0.3\n",
      "Epoch: 423 \tTraining Loss: 1.223515 \tValidation Loss: 1.403690 \t time: 0.3\n",
      "Epoch: 424 \tTraining Loss: 1.223508 \tValidation Loss: 1.399261 \t time: 0.3\n",
      "Epoch: 425 \tTraining Loss: 1.223555 \tValidation Loss: 1.404066 \t time: 0.3\n",
      "Epoch: 426 \tTraining Loss: 1.223518 \tValidation Loss: 1.400171 \t time: 0.3\n",
      "Epoch: 427 \tTraining Loss: 1.223445 \tValidation Loss: 1.404247 \t time: 0.3\n",
      "Epoch: 428 \tTraining Loss: 1.223232 \tValidation Loss: 1.402030 \t time: 0.3\n",
      "Epoch: 429 \tTraining Loss: 1.222995 \tValidation Loss: 1.403372 \t time: 0.3\n",
      "Epoch: 430 \tTraining Loss: 1.222847 \tValidation Loss: 1.403748 \t time: 0.3\n",
      "Epoch: 431 \tTraining Loss: 1.222815 \tValidation Loss: 1.401936 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 432 \tTraining Loss: 1.222863 \tValidation Loss: 1.404220 \t time: 0.3\n",
      "Epoch: 433 \tTraining Loss: 1.222951 \tValidation Loss: 1.400672 \t time: 0.3\n",
      "Epoch: 434 \tTraining Loss: 1.223092 \tValidation Loss: 1.405198 \t time: 0.3\n",
      "Epoch: 435 \tTraining Loss: 1.223189 \tValidation Loss: 1.400286 \t time: 0.3\n",
      "Epoch: 436 \tTraining Loss: 1.223274 \tValidation Loss: 1.405954 \t time: 0.3\n",
      "Epoch: 437 \tTraining Loss: 1.223033 \tValidation Loss: 1.402889 \t time: 0.3\n",
      "Epoch: 438 \tTraining Loss: 1.222612 \tValidation Loss: 1.405805 \t time: 0.3\n",
      "Epoch: 439 \tTraining Loss: 1.222242 \tValidation Loss: 1.405676 \t time: 0.3\n",
      "Epoch: 440 \tTraining Loss: 1.222175 \tValidation Loss: 1.403835 \t time: 0.3\n",
      "Epoch: 441 \tTraining Loss: 1.222296 \tValidation Loss: 1.406686 \t time: 0.3\n",
      "Epoch: 442 \tTraining Loss: 1.222430 \tValidation Loss: 1.403375 \t time: 0.4\n",
      "Epoch: 443 \tTraining Loss: 1.222551 \tValidation Loss: 1.406935 \t time: 0.3\n",
      "Epoch: 444 \tTraining Loss: 1.222397 \tValidation Loss: 1.404462 \t time: 0.3\n",
      "Epoch: 445 \tTraining Loss: 1.222106 \tValidation Loss: 1.407241 \t time: 0.3\n",
      "Epoch: 446 \tTraining Loss: 1.221832 \tValidation Loss: 1.406684 \t time: 0.3\n",
      "Epoch: 447 \tTraining Loss: 1.221668 \tValidation Loss: 1.406646 \t time: 0.3\n",
      "Epoch: 448 \tTraining Loss: 1.221661 \tValidation Loss: 1.408315 \t time: 0.3\n",
      "Epoch: 449 \tTraining Loss: 1.221751 \tValidation Loss: 1.407032 \t time: 0.4\n",
      "Epoch: 450 \tTraining Loss: 1.221828 \tValidation Loss: 1.408995 \t time: 0.4\n",
      "Epoch: 451 \tTraining Loss: 1.221850 \tValidation Loss: 1.407706 \t time: 0.4\n",
      "Epoch: 452 \tTraining Loss: 1.221818 \tValidation Loss: 1.409614 \t time: 0.3\n",
      "Epoch: 453 \tTraining Loss: 1.221701 \tValidation Loss: 1.408602 \t time: 0.4\n",
      "Epoch: 454 \tTraining Loss: 1.221578 \tValidation Loss: 1.410128 \t time: 0.3\n",
      "Epoch: 455 \tTraining Loss: 1.221446 \tValidation Loss: 1.409598 \t time: 0.3\n",
      "Epoch: 456 \tTraining Loss: 1.221329 \tValidation Loss: 1.410331 \t time: 0.4\n",
      "Epoch: 457 \tTraining Loss: 1.221225 \tValidation Loss: 1.410753 \t time: 0.3\n",
      "Epoch: 458 \tTraining Loss: 1.221128 \tValidation Loss: 1.411163 \t time: 0.5\n",
      "Epoch: 459 \tTraining Loss: 1.221051 \tValidation Loss: 1.411011 \t time: 0.4\n",
      "Epoch: 460 \tTraining Loss: 1.220992 \tValidation Loss: 1.411554 \t time: 0.3\n",
      "Epoch: 461 \tTraining Loss: 1.220963 \tValidation Loss: 1.412689 \t time: 0.4\n",
      "Epoch: 462 \tTraining Loss: 1.220966 \tValidation Loss: 1.412844 \t time: 0.4\n",
      "Epoch: 463 \tTraining Loss: 1.221024 \tValidation Loss: 1.413848 \t time: 0.4\n",
      "Epoch: 464 \tTraining Loss: 1.221315 \tValidation Loss: 1.413910 \t time: 0.3\n",
      "Epoch: 465 \tTraining Loss: 1.222037 \tValidation Loss: 1.414385 \t time: 0.4\n",
      "Epoch: 466 \tTraining Loss: 1.222756 \tValidation Loss: 1.415104 \t time: 0.4\n",
      "Epoch: 467 \tTraining Loss: 1.222901 \tValidation Loss: 1.414864 \t time: 0.4\n",
      "Epoch: 468 \tTraining Loss: 1.221605 \tValidation Loss: 1.416243 \t time: 0.4\n",
      "Epoch: 469 \tTraining Loss: 1.220597 \tValidation Loss: 1.417895 \t time: 0.4\n",
      "Epoch: 470 \tTraining Loss: 1.221225 \tValidation Loss: 1.415901 \t time: 0.4\n",
      "Epoch: 471 \tTraining Loss: 1.221855 \tValidation Loss: 1.419322 \t time: 0.4\n",
      "Epoch: 472 \tTraining Loss: 1.221285 \tValidation Loss: 1.419258 \t time: 0.4\n",
      "Epoch: 473 \tTraining Loss: 1.220394 \tValidation Loss: 1.417922 \t time: 0.4\n",
      "Epoch: 474 \tTraining Loss: 1.220732 \tValidation Loss: 1.422349 \t time: 0.4\n",
      "Epoch: 475 \tTraining Loss: 1.221321 \tValidation Loss: 1.418317 \t time: 0.4\n",
      "Epoch: 476 \tTraining Loss: 1.220859 \tValidation Loss: 1.419716 \t time: 0.4\n",
      "Epoch: 477 \tTraining Loss: 1.220219 \tValidation Loss: 1.418981 \t time: 0.4\n",
      "Epoch: 478 \tTraining Loss: 1.220256 \tValidation Loss: 1.417258 \t time: 0.4\n",
      "Epoch: 479 \tTraining Loss: 1.220663 \tValidation Loss: 1.419690 \t time: 0.4\n",
      "Epoch: 480 \tTraining Loss: 1.220605 \tValidation Loss: 1.417749 \t time: 0.4\n",
      "Epoch: 481 \tTraining Loss: 1.220138 \tValidation Loss: 1.416671 \t time: 0.4\n",
      "Epoch: 482 \tTraining Loss: 1.219850 \tValidation Loss: 1.416997 \t time: 0.4\n",
      "Epoch: 483 \tTraining Loss: 1.219962 \tValidation Loss: 1.417302 \t time: 0.4\n",
      "Epoch: 484 \tTraining Loss: 1.220138 \tValidation Loss: 1.417201 \t time: 0.4\n",
      "Epoch: 485 \tTraining Loss: 1.220241 \tValidation Loss: 1.417837 \t time: 0.4\n",
      "Epoch: 486 \tTraining Loss: 1.220117 \tValidation Loss: 1.419070 \t time: 0.4\n",
      "Epoch: 487 \tTraining Loss: 1.219906 \tValidation Loss: 1.418031 \t time: 0.4\n",
      "Epoch: 488 \tTraining Loss: 1.219652 \tValidation Loss: 1.419607 \t time: 0.3\n",
      "Epoch: 489 \tTraining Loss: 1.219361 \tValidation Loss: 1.419776 \t time: 0.4\n",
      "Epoch: 490 \tTraining Loss: 1.219342 \tValidation Loss: 1.418564 \t time: 0.4\n",
      "Epoch: 491 \tTraining Loss: 1.219338 \tValidation Loss: 1.420019 \t time: 0.3\n",
      "Epoch: 492 \tTraining Loss: 1.219382 \tValidation Loss: 1.420025 \t time: 0.4\n",
      "Epoch: 493 \tTraining Loss: 1.219401 \tValidation Loss: 1.420321 \t time: 0.4\n",
      "Epoch: 494 \tTraining Loss: 1.219351 \tValidation Loss: 1.419122 \t time: 0.4\n",
      "Epoch: 495 \tTraining Loss: 1.219332 \tValidation Loss: 1.420953 \t time: 0.4\n",
      "Epoch: 496 \tTraining Loss: 1.219372 \tValidation Loss: 1.417365 \t time: 0.3\n",
      "Epoch: 497 \tTraining Loss: 1.219628 \tValidation Loss: 1.419863 \t time: 0.4\n",
      "Epoch: 498 \tTraining Loss: 1.219512 \tValidation Loss: 1.419282 \t time: 0.3\n",
      "Epoch: 499 \tTraining Loss: 1.219308 \tValidation Loss: 1.417901 \t time: 0.3\n",
      "Epoch: 500 \tTraining Loss: 1.218821 \tValidation Loss: 1.416253 \t time: 0.4\n",
      "Epoch: 501 \tTraining Loss: 1.218395 \tValidation Loss: 1.418536 \t time: 0.4\n",
      "Epoch: 502 \tTraining Loss: 1.218290 \tValidation Loss: 1.416708 \t time: 0.3\n",
      "Epoch: 503 \tTraining Loss: 1.218093 \tValidation Loss: 1.415451 \t time: 0.4\n",
      "Epoch: 504 \tTraining Loss: 1.218135 \tValidation Loss: 1.421502 \t time: 0.3\n",
      "Epoch: 505 \tTraining Loss: 1.218490 \tValidation Loss: 1.411785 \t time: 0.3\n",
      "Epoch: 506 \tTraining Loss: 1.219618 \tValidation Loss: 1.417329 \t time: 0.3\n",
      "Epoch: 507 \tTraining Loss: 1.219520 \tValidation Loss: 1.418907 \t time: 0.3\n",
      "Epoch: 508 \tTraining Loss: 1.219847 \tValidation Loss: 1.417539 \t time: 0.3\n",
      "Epoch: 509 \tTraining Loss: 1.218389 \tValidation Loss: 1.415294 \t time: 0.3\n",
      "Epoch: 510 \tTraining Loss: 1.218039 \tValidation Loss: 1.419833 \t time: 0.3\n",
      "Epoch: 511 \tTraining Loss: 1.218550 \tValidation Loss: 1.422785 \t time: 0.3\n",
      "Epoch: 512 \tTraining Loss: 1.218215 \tValidation Loss: 1.410437 \t time: 0.4\n",
      "Epoch: 513 \tTraining Loss: 1.219016 \tValidation Loss: 1.416107 \t time: 0.3\n",
      "Epoch: 514 \tTraining Loss: 1.217440 \tValidation Loss: 1.418223 \t time: 0.4\n",
      "Epoch: 515 \tTraining Loss: 1.218825 \tValidation Loss: 1.409762 \t time: 0.3\n",
      "Epoch: 516 \tTraining Loss: 1.219620 \tValidation Loss: 1.412965 \t time: 0.3\n",
      "Epoch: 517 \tTraining Loss: 1.219152 \tValidation Loss: 1.424809 \t time: 0.3\n",
      "Epoch: 518 \tTraining Loss: 1.218970 \tValidation Loss: 1.419536 \t time: 0.4\n",
      "Epoch: 519 \tTraining Loss: 1.217676 \tValidation Loss: 1.417420 \t time: 0.3\n",
      "Epoch: 520 \tTraining Loss: 1.219424 \tValidation Loss: 1.418386 \t time: 0.3\n",
      "Epoch: 521 \tTraining Loss: 1.218107 \tValidation Loss: 1.424685 \t time: 0.4\n",
      "Epoch: 522 \tTraining Loss: 1.218149 \tValidation Loss: 1.417754 \t time: 0.3\n",
      "Epoch: 523 \tTraining Loss: 1.217617 \tValidation Loss: 1.418409 \t time: 0.4\n",
      "Epoch: 524 \tTraining Loss: 1.217193 \tValidation Loss: 1.420964 \t time: 0.3\n",
      "Epoch: 525 \tTraining Loss: 1.217567 \tValidation Loss: 1.420517 \t time: 0.3\n",
      "Epoch: 526 \tTraining Loss: 1.217013 \tValidation Loss: 1.417334 \t time: 0.4\n",
      "Epoch: 527 \tTraining Loss: 1.217193 \tValidation Loss: 1.421755 \t time: 0.4\n",
      "Epoch: 528 \tTraining Loss: 1.216278 \tValidation Loss: 1.424532 \t time: 0.4\n",
      "Epoch: 529 \tTraining Loss: 1.216653 \tValidation Loss: 1.421665 \t time: 0.3\n",
      "Epoch: 530 \tTraining Loss: 1.216591 \tValidation Loss: 1.421138 \t time: 0.3\n",
      "Epoch: 531 \tTraining Loss: 1.216146 \tValidation Loss: 1.422378 \t time: 0.3\n",
      "Epoch: 532 \tTraining Loss: 1.216507 \tValidation Loss: 1.417042 \t time: 0.3\n",
      "Epoch: 533 \tTraining Loss: 1.216161 \tValidation Loss: 1.417845 \t time: 0.3\n",
      "Epoch: 534 \tTraining Loss: 1.215984 \tValidation Loss: 1.420352 \t time: 0.4\n",
      "Epoch: 535 \tTraining Loss: 1.216204 \tValidation Loss: 1.417212 \t time: 0.4\n",
      "Epoch: 536 \tTraining Loss: 1.215602 \tValidation Loss: 1.416210 \t time: 0.3\n",
      "Epoch: 537 \tTraining Loss: 1.215700 \tValidation Loss: 1.417215 \t time: 0.3\n",
      "Epoch: 538 \tTraining Loss: 1.215647 \tValidation Loss: 1.416709 \t time: 0.3\n",
      "Epoch: 539 \tTraining Loss: 1.215416 \tValidation Loss: 1.415866 \t time: 0.3\n",
      "Epoch: 540 \tTraining Loss: 1.215598 \tValidation Loss: 1.418429 \t time: 0.3\n",
      "Epoch: 541 \tTraining Loss: 1.216038 \tValidation Loss: 1.415721 \t time: 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 542 \tTraining Loss: 1.218156 \tValidation Loss: 1.415368 \t time: 0.3\n",
      "Epoch: 543 \tTraining Loss: 1.218655 \tValidation Loss: 1.420722 \t time: 0.4\n",
      "Epoch: 544 \tTraining Loss: 1.217432 \tValidation Loss: 1.420098 \t time: 0.3\n",
      "Epoch: 545 \tTraining Loss: 1.215361 \tValidation Loss: 1.417719 \t time: 0.4\n",
      "Epoch: 546 \tTraining Loss: 1.216181 \tValidation Loss: 1.419693 \t time: 0.4\n",
      "Epoch: 547 \tTraining Loss: 1.215497 \tValidation Loss: 1.425152 \t time: 0.3\n",
      "Epoch: 548 \tTraining Loss: 1.216034 \tValidation Loss: 1.419042 \t time: 0.3\n",
      "Epoch: 549 \tTraining Loss: 1.217127 \tValidation Loss: 1.422086 \t time: 0.3\n",
      "Epoch: 550 \tTraining Loss: 1.215695 \tValidation Loss: 1.420694 \t time: 0.4\n",
      "Epoch: 551 \tTraining Loss: 1.217005 \tValidation Loss: 1.420157 \t time: 0.4\n",
      "Epoch: 552 \tTraining Loss: 1.216139 \tValidation Loss: 1.426527 \t time: 0.4\n",
      "Epoch: 553 \tTraining Loss: 1.217631 \tValidation Loss: 1.424297 \t time: 0.4\n",
      "Epoch: 554 \tTraining Loss: 1.215143 \tValidation Loss: 1.427089 \t time: 0.4\n",
      "Epoch: 555 \tTraining Loss: 1.216090 \tValidation Loss: 1.424706 \t time: 0.4\n",
      "Epoch: 556 \tTraining Loss: 1.215767 \tValidation Loss: 1.423162 \t time: 0.3\n",
      "Epoch: 557 \tTraining Loss: 1.215686 \tValidation Loss: 1.426765 \t time: 0.4\n",
      "Epoch: 558 \tTraining Loss: 1.215202 \tValidation Loss: 1.425399 \t time: 0.4\n",
      "Epoch: 559 \tTraining Loss: 1.215245 \tValidation Loss: 1.424266 \t time: 0.3\n",
      "Epoch: 560 \tTraining Loss: 1.216449 \tValidation Loss: 1.425256 \t time: 0.4\n",
      "Epoch: 561 \tTraining Loss: 1.214628 \tValidation Loss: 1.423557 \t time: 0.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e574b1207684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m model = train(600, loaders, model, optimizer, \n\u001b[0;32m---> 85\u001b[0;31m                       criterion, use_cuda, 'model.pt')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-e574b1207684>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-ff54b66ffe89>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ai/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(600, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.453425\n",
      "\n",
      "\n",
      "Test Accuracy: 50% ( 4/ 8)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 5, 2, 4, 2, 3, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,l = next(iter(loaders['test']))\n",
    "output = model(i)\n",
    "result = output.data.max(1, keepdim=True)[1].numpy()\n",
    "result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 2., 0., 1., 0., 2., 2.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = result[:,0]\n",
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 1., 0., 2., 0., 1., 0., 1., 1.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(l.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 4, ..., 5, 2, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = model(torch.tensor(features_test.values).type((torch.FloatTensor)))\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
