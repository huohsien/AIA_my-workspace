{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'class_0': 1611, 'class_2': 1478, 'class_5': 1411, 'class_1': 920, 'class_3': 889, 'class_4': 851})\n"
     ]
    }
   ],
   "source": [
    "# make number of data for each class equal\n",
    "#\n",
    "from collections import Counter\n",
    "\n",
    "class_counter = Counter()\n",
    "\n",
    "class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print(class_counter)\n",
    "\n",
    "max_count = -np.Inf\n",
    "for i in range(number_of_class):\n",
    "    if class_counter['class_' + str(i)] > max_count:\n",
    "        max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "    num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "    num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "    for j in range(num_resample_batch):\n",
    "        add_df = train_classified[i]\n",
    "        train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "        train =  train.append(df_to_be_added)\n",
    "        \n",
    "\n",
    "    df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "    train =  train.append(df_to_be_added)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class_0', 1611), (0, 1611), (1, 1611), (2, 1611), (3, 1611), (4, 1611)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names =[i for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter[i] += 1\n",
    "\n",
    "class_counter.most_common(number_of_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appearedTimeOfDay</th>\n",
       "      <th>appearedHour</th>\n",
       "      <th>appearedMinute</th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>city</th>\n",
       "      <th>continent</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>...</th>\n",
       "      <th>cooc_142</th>\n",
       "      <th>cooc_143</th>\n",
       "      <th>cooc_144</th>\n",
       "      <th>cooc_145</th>\n",
       "      <th>cooc_146</th>\n",
       "      <th>cooc_147</th>\n",
       "      <th>cooc_148</th>\n",
       "      <th>cooc_149</th>\n",
       "      <th>cooc_150</th>\n",
       "      <th>cooc_151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evening</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>Los_Angeles</td>\n",
       "      <td>America</td>\n",
       "      <td>PartlyCloudy</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  appearedTimeOfDay  appearedHour  appearedMinute  terrainType  closeToWater  \\\n",
       "0           evening            19              10           13         False   \n",
       "1             night             5              19           13          True   \n",
       "2           evening            19              46            0          True   \n",
       "3           morning            11              10            0          True   \n",
       "4           evening            18              32           13          True   \n",
       "\n",
       "          city  continent       weather  temperature  windSpeed    ...     \\\n",
       "0      Bangkok       Asia         Clear         27.8       9.00    ...      \n",
       "1     New_York    America         Clear         26.1       8.70    ...      \n",
       "2     New_York    America         Clear         24.7      16.82    ...      \n",
       "3       Hobart  Australia         Clear         12.7      13.25    ...      \n",
       "4  Los_Angeles    America  PartlyCloudy         19.1       5.78    ...      \n",
       "\n",
       "   cooc_142 cooc_143  cooc_144  cooc_145  cooc_146  cooc_147  cooc_148  \\\n",
       "0     False    False     False     False     False     False     False   \n",
       "1     False    False     False     False     False     False     False   \n",
       "2     False    False     False     False     False     False     False   \n",
       "3     False    False     False     False     False     False     False   \n",
       "4     False    False     False     False     False     False     False   \n",
       "\n",
       "   cooc_149  cooc_150  cooc_151  \n",
       "0     False     False     False  \n",
       "1     False     False     False  \n",
       "2     False     False     False  \n",
       "3     False     False     False  \n",
       "4     False     False     False  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1008.96</td>\n",
       "      <td>6019.04440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1018.96</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>128.89505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1011.36</td>\n",
       "      <td>4188.39100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.990268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0         13.0           0.0         27.8       9.00   1008.96   \n",
       "1         13.0           1.0         26.1       8.70   1018.96   \n",
       "2          0.0           1.0         24.7      16.82   1023.22   \n",
       "3          0.0           1.0         12.7      13.25   1014.19   \n",
       "4         13.0           1.0         19.1       5.78   1011.36   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0          6019.04440    1.0       1.0       1.0    0.0          ...            \n",
       "1             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "2             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "3           128.89505    0.0       0.0       0.0    1.0          ...            \n",
       "4          4188.39100    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                             0                      1   \n",
       "1                             0                      0   \n",
       "2                             0                      1   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                        0                   0                0   \n",
       "1                        1                   0                0   \n",
       "2                        0                   0                0   \n",
       "3                        1                   0                0   \n",
       "4                        0                   0                0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                              0                                0   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              1                                0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0                 0                 0             -0.953717  \n",
       "1                 0                 0              0.984041  \n",
       "2                 0                 0             -0.894934  \n",
       "3                 0                 0              0.216440  \n",
       "4                 0                 0             -0.990268  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631868</td>\n",
       "      <td>0.160342</td>\n",
       "      <td>0.333774</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.154997</td>\n",
       "      <td>0.598044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.710624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217033</td>\n",
       "      <td>0.236059</td>\n",
       "      <td>0.471987</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.102975</td>\n",
       "      <td>0.397199</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0       0.8125           0.0     0.631868   0.160342  0.333774   \n",
       "1       0.8125           1.0     0.585165   0.154997  0.598044   \n",
       "2       0.0000           1.0     0.546703   0.299662  0.710624   \n",
       "3       0.0000           1.0     0.217033   0.236059  0.471987   \n",
       "4       0.8125           1.0     0.392857   0.102975  0.397199   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0            0.601904    1.0       1.0       1.0    0.0          ...            \n",
       "1            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "2            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "3            0.012890    0.0       0.0       0.0    1.0          ...            \n",
       "4            0.418839    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                           0.0                    1.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    1.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                      0.0                 0.0              0.0   \n",
       "1                      1.0                 0.0              0.0   \n",
       "2                      0.0                 0.0              0.0   \n",
       "3                      1.0                 0.0              0.0   \n",
       "4                      0.0                 0.0              0.0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            1.0                              0.0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0               0.0               0.0              0.023142  \n",
       "1               0.0               0.0              0.992020  \n",
       "2               0.0               0.0              0.052533  \n",
       "3               0.0               0.0              0.608220  \n",
       "4               0.0               0.0              0.004866  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9666 entries, 0 to 1088\n",
      "Columns: 297 entries, terrainType to appearedTimeDayCycle\n",
      "dtypes: float64(272), int64(25)\n",
      "memory usage: 22.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9666, 297)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1611.,    0., 1611.,    0., 1611.,    0., 1611.,    0., 1611.,\n",
       "        1611.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8699, 297), (773, 297), (194, 297))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.9\n",
    "test_ratio = 0.2\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ratio = 0.98\n",
    "\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32.,  0., 32.,  0., 32.,  0., 32.,  0., 33., 33.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "# plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data per batch to load\n",
    "batch_size = 10000\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.793194 \tValidation Loss: 1.791268 \t time: 0.2\n",
      "Validation loss decreased from inf to 1.791268. Model was saved\n",
      "Epoch: 2 \tTraining Loss: 1.792939 \tValidation Loss: 1.790710 \t time: 0.2\n",
      "Validation loss decreased from 1.791268 to 1.790710. Model was saved\n",
      "Epoch: 3 \tTraining Loss: 1.791044 \tValidation Loss: 1.789438 \t time: 0.2\n",
      "Validation loss decreased from 1.790710 to 1.789438. Model was saved\n",
      "Epoch: 4 \tTraining Loss: 1.790036 \tValidation Loss: 1.787856 \t time: 0.2\n",
      "Validation loss decreased from 1.789438 to 1.787856. Model was saved\n",
      "Epoch: 5 \tTraining Loss: 1.788933 \tValidation Loss: 1.785870 \t time: 0.2\n",
      "Validation loss decreased from 1.787856 to 1.785870. Model was saved\n",
      "Epoch: 6 \tTraining Loss: 1.786380 \tValidation Loss: 1.783051 \t time: 0.2\n",
      "Validation loss decreased from 1.785870 to 1.783051. Model was saved\n",
      "Epoch: 7 \tTraining Loss: 1.783537 \tValidation Loss: 1.779059 \t time: 0.2\n",
      "Validation loss decreased from 1.783051 to 1.779059. Model was saved\n",
      "Epoch: 8 \tTraining Loss: 1.779881 \tValidation Loss: 1.773663 \t time: 0.2\n",
      "Validation loss decreased from 1.779059 to 1.773663. Model was saved\n",
      "Epoch: 9 \tTraining Loss: 1.774423 \tValidation Loss: 1.766767 \t time: 0.2\n",
      "Validation loss decreased from 1.773663 to 1.766767. Model was saved\n",
      "Epoch: 10 \tTraining Loss: 1.767583 \tValidation Loss: 1.758374 \t time: 0.2\n",
      "Validation loss decreased from 1.766767 to 1.758374. Model was saved\n",
      "Epoch: 11 \tTraining Loss: 1.760754 \tValidation Loss: 1.748634 \t time: 0.2\n",
      "Validation loss decreased from 1.758374 to 1.748634. Model was saved\n",
      "Epoch: 12 \tTraining Loss: 1.750849 \tValidation Loss: 1.737809 \t time: 0.2\n",
      "Validation loss decreased from 1.748634 to 1.737809. Model was saved\n",
      "Epoch: 13 \tTraining Loss: 1.742118 \tValidation Loss: 1.726374 \t time: 0.2\n",
      "Validation loss decreased from 1.737809 to 1.726374. Model was saved\n",
      "Epoch: 14 \tTraining Loss: 1.732501 \tValidation Loss: 1.714800 \t time: 0.2\n",
      "Validation loss decreased from 1.726374 to 1.714800. Model was saved\n",
      "Epoch: 15 \tTraining Loss: 1.721489 \tValidation Loss: 1.703587 \t time: 0.2\n",
      "Validation loss decreased from 1.714800 to 1.703587. Model was saved\n",
      "Epoch: 16 \tTraining Loss: 1.711315 \tValidation Loss: 1.693041 \t time: 0.2\n",
      "Validation loss decreased from 1.703587 to 1.693041. Model was saved\n",
      "Epoch: 17 \tTraining Loss: 1.700353 \tValidation Loss: 1.683198 \t time: 0.2\n",
      "Validation loss decreased from 1.693041 to 1.683198. Model was saved\n",
      "Epoch: 18 \tTraining Loss: 1.692784 \tValidation Loss: 1.674079 \t time: 0.2\n",
      "Validation loss decreased from 1.683198 to 1.674079. Model was saved\n",
      "Epoch: 19 \tTraining Loss: 1.683743 \tValidation Loss: 1.665444 \t time: 0.2\n",
      "Validation loss decreased from 1.674079 to 1.665444. Model was saved\n",
      "Epoch: 20 \tTraining Loss: 1.676945 \tValidation Loss: 1.657242 \t time: 0.2\n",
      "Validation loss decreased from 1.665444 to 1.657242. Model was saved\n",
      "Epoch: 21 \tTraining Loss: 1.669967 \tValidation Loss: 1.649558 \t time: 0.2\n",
      "Validation loss decreased from 1.657242 to 1.649558. Model was saved\n",
      "Epoch: 22 \tTraining Loss: 1.660490 \tValidation Loss: 1.642159 \t time: 0.2\n",
      "Validation loss decreased from 1.649558 to 1.642159. Model was saved\n",
      "Epoch: 23 \tTraining Loss: 1.653474 \tValidation Loss: 1.635195 \t time: 0.2\n",
      "Validation loss decreased from 1.642159 to 1.635195. Model was saved\n",
      "Epoch: 24 \tTraining Loss: 1.645644 \tValidation Loss: 1.628470 \t time: 0.2\n",
      "Validation loss decreased from 1.635195 to 1.628470. Model was saved\n",
      "Epoch: 25 \tTraining Loss: 1.638361 \tValidation Loss: 1.621672 \t time: 0.2\n",
      "Validation loss decreased from 1.628470 to 1.621672. Model was saved\n",
      "Epoch: 26 \tTraining Loss: 1.631445 \tValidation Loss: 1.615044 \t time: 0.2\n",
      "Validation loss decreased from 1.621672 to 1.615044. Model was saved\n",
      "Epoch: 27 \tTraining Loss: 1.623023 \tValidation Loss: 1.608617 \t time: 0.2\n",
      "Validation loss decreased from 1.615044 to 1.608617. Model was saved\n",
      "Epoch: 28 \tTraining Loss: 1.617042 \tValidation Loss: 1.602388 \t time: 0.2\n",
      "Validation loss decreased from 1.608617 to 1.602388. Model was saved\n",
      "Epoch: 29 \tTraining Loss: 1.607250 \tValidation Loss: 1.596335 \t time: 0.2\n",
      "Validation loss decreased from 1.602388 to 1.596335. Model was saved\n",
      "Epoch: 30 \tTraining Loss: 1.602211 \tValidation Loss: 1.590467 \t time: 0.2\n",
      "Validation loss decreased from 1.596335 to 1.590467. Model was saved\n",
      "Epoch: 31 \tTraining Loss: 1.595533 \tValidation Loss: 1.584775 \t time: 0.2\n",
      "Validation loss decreased from 1.590467 to 1.584775. Model was saved\n",
      "Epoch: 32 \tTraining Loss: 1.588345 \tValidation Loss: 1.578893 \t time: 0.2\n",
      "Validation loss decreased from 1.584775 to 1.578893. Model was saved\n",
      "Epoch: 33 \tTraining Loss: 1.584909 \tValidation Loss: 1.573112 \t time: 0.2\n",
      "Validation loss decreased from 1.578893 to 1.573112. Model was saved\n",
      "Epoch: 34 \tTraining Loss: 1.578810 \tValidation Loss: 1.567789 \t time: 0.2\n",
      "Validation loss decreased from 1.573112 to 1.567789. Model was saved\n",
      "Epoch: 35 \tTraining Loss: 1.573830 \tValidation Loss: 1.562543 \t time: 0.2\n",
      "Validation loss decreased from 1.567789 to 1.562543. Model was saved\n",
      "Epoch: 36 \tTraining Loss: 1.570917 \tValidation Loss: 1.556903 \t time: 0.2\n",
      "Validation loss decreased from 1.562543 to 1.556903. Model was saved\n",
      "Epoch: 37 \tTraining Loss: 1.563115 \tValidation Loss: 1.552041 \t time: 0.2\n",
      "Validation loss decreased from 1.556903 to 1.552041. Model was saved\n",
      "Epoch: 38 \tTraining Loss: 1.557151 \tValidation Loss: 1.547392 \t time: 0.2\n",
      "Validation loss decreased from 1.552041 to 1.547392. Model was saved\n",
      "Epoch: 39 \tTraining Loss: 1.555636 \tValidation Loss: 1.543300 \t time: 0.2\n",
      "Validation loss decreased from 1.547392 to 1.543300. Model was saved\n",
      "Epoch: 40 \tTraining Loss: 1.552217 \tValidation Loss: 1.539319 \t time: 0.2\n",
      "Validation loss decreased from 1.543300 to 1.539319. Model was saved\n",
      "Epoch: 41 \tTraining Loss: 1.548872 \tValidation Loss: 1.535401 \t time: 0.2\n",
      "Validation loss decreased from 1.539319 to 1.535401. Model was saved\n",
      "Epoch: 42 \tTraining Loss: 1.544210 \tValidation Loss: 1.531852 \t time: 0.2\n",
      "Validation loss decreased from 1.535401 to 1.531852. Model was saved\n",
      "Epoch: 43 \tTraining Loss: 1.539964 \tValidation Loss: 1.528334 \t time: 0.2\n",
      "Validation loss decreased from 1.531852 to 1.528334. Model was saved\n",
      "Epoch: 44 \tTraining Loss: 1.536233 \tValidation Loss: 1.525214 \t time: 0.2\n",
      "Validation loss decreased from 1.528334 to 1.525214. Model was saved\n",
      "Epoch: 45 \tTraining Loss: 1.532759 \tValidation Loss: 1.522267 \t time: 0.2\n",
      "Validation loss decreased from 1.525214 to 1.522267. Model was saved\n",
      "Epoch: 46 \tTraining Loss: 1.529379 \tValidation Loss: 1.519652 \t time: 0.2\n",
      "Validation loss decreased from 1.522267 to 1.519652. Model was saved\n",
      "Epoch: 47 \tTraining Loss: 1.528349 \tValidation Loss: 1.517071 \t time: 0.2\n",
      "Validation loss decreased from 1.519652 to 1.517071. Model was saved\n",
      "Epoch: 48 \tTraining Loss: 1.524933 \tValidation Loss: 1.514697 \t time: 0.2\n",
      "Validation loss decreased from 1.517071 to 1.514697. Model was saved\n",
      "Epoch: 49 \tTraining Loss: 1.523306 \tValidation Loss: 1.512586 \t time: 0.2\n",
      "Validation loss decreased from 1.514697 to 1.512586. Model was saved\n",
      "Epoch: 50 \tTraining Loss: 1.520119 \tValidation Loss: 1.510666 \t time: 0.2\n",
      "Validation loss decreased from 1.512586 to 1.510666. Model was saved\n",
      "Epoch: 51 \tTraining Loss: 1.519716 \tValidation Loss: 1.508885 \t time: 0.2\n",
      "Validation loss decreased from 1.510666 to 1.508885. Model was saved\n",
      "Epoch: 52 \tTraining Loss: 1.516041 \tValidation Loss: 1.507402 \t time: 0.2\n",
      "Validation loss decreased from 1.508885 to 1.507402. Model was saved\n",
      "Epoch: 53 \tTraining Loss: 1.512670 \tValidation Loss: 1.505729 \t time: 0.2\n",
      "Validation loss decreased from 1.507402 to 1.505729. Model was saved\n",
      "Epoch: 54 \tTraining Loss: 1.512359 \tValidation Loss: 1.503973 \t time: 0.2\n",
      "Validation loss decreased from 1.505729 to 1.503973. Model was saved\n",
      "Epoch: 55 \tTraining Loss: 1.505531 \tValidation Loss: 1.502615 \t time: 0.2\n",
      "Validation loss decreased from 1.503973 to 1.502615. Model was saved\n",
      "Epoch: 56 \tTraining Loss: 1.505952 \tValidation Loss: 1.501197 \t time: 0.2\n",
      "Validation loss decreased from 1.502615 to 1.501197. Model was saved\n",
      "Epoch: 57 \tTraining Loss: 1.504165 \tValidation Loss: 1.499856 \t time: 0.2\n",
      "Validation loss decreased from 1.501197 to 1.499856. Model was saved\n",
      "Epoch: 58 \tTraining Loss: 1.501403 \tValidation Loss: 1.498544 \t time: 0.2\n",
      "Validation loss decreased from 1.499856 to 1.498544. Model was saved\n",
      "Epoch: 59 \tTraining Loss: 1.501061 \tValidation Loss: 1.497232 \t time: 0.2\n",
      "Validation loss decreased from 1.498544 to 1.497232. Model was saved\n",
      "Epoch: 60 \tTraining Loss: 1.498979 \tValidation Loss: 1.496032 \t time: 0.2\n",
      "Validation loss decreased from 1.497232 to 1.496032. Model was saved\n",
      "Epoch: 61 \tTraining Loss: 1.496129 \tValidation Loss: 1.494942 \t time: 0.2\n",
      "Validation loss decreased from 1.496032 to 1.494942. Model was saved\n",
      "Epoch: 62 \tTraining Loss: 1.495188 \tValidation Loss: 1.493826 \t time: 0.2\n",
      "Validation loss decreased from 1.494942 to 1.493826. Model was saved\n",
      "Epoch: 63 \tTraining Loss: 1.496237 \tValidation Loss: 1.492942 \t time: 0.2\n",
      "Validation loss decreased from 1.493826 to 1.492942. Model was saved\n",
      "Epoch: 64 \tTraining Loss: 1.491283 \tValidation Loss: 1.491971 \t time: 0.2\n",
      "Validation loss decreased from 1.492942 to 1.491971. Model was saved\n",
      "Epoch: 65 \tTraining Loss: 1.489474 \tValidation Loss: 1.491103 \t time: 0.2\n",
      "Validation loss decreased from 1.491971 to 1.491103. Model was saved\n",
      "Epoch: 66 \tTraining Loss: 1.490690 \tValidation Loss: 1.490324 \t time: 0.2\n",
      "Validation loss decreased from 1.491103 to 1.490324. Model was saved\n",
      "Epoch: 67 \tTraining Loss: 1.487591 \tValidation Loss: 1.489436 \t time: 0.2\n",
      "Validation loss decreased from 1.490324 to 1.489436. Model was saved\n",
      "Epoch: 68 \tTraining Loss: 1.484507 \tValidation Loss: 1.488619 \t time: 0.2\n",
      "Validation loss decreased from 1.489436 to 1.488619. Model was saved\n",
      "Epoch: 69 \tTraining Loss: 1.484123 \tValidation Loss: 1.487475 \t time: 0.2\n",
      "Validation loss decreased from 1.488619 to 1.487475. Model was saved\n",
      "Epoch: 70 \tTraining Loss: 1.481058 \tValidation Loss: 1.486595 \t time: 0.2\n",
      "Validation loss decreased from 1.487475 to 1.486595. Model was saved\n",
      "Epoch: 71 \tTraining Loss: 1.478537 \tValidation Loss: 1.485727 \t time: 0.2\n",
      "Validation loss decreased from 1.486595 to 1.485727. Model was saved\n",
      "Epoch: 72 \tTraining Loss: 1.477823 \tValidation Loss: 1.484811 \t time: 0.2\n",
      "Validation loss decreased from 1.485727 to 1.484811. Model was saved\n",
      "Epoch: 73 \tTraining Loss: 1.478863 \tValidation Loss: 1.483761 \t time: 0.2\n",
      "Validation loss decreased from 1.484811 to 1.483761. Model was saved\n",
      "Epoch: 74 \tTraining Loss: 1.475893 \tValidation Loss: 1.482664 \t time: 0.2\n",
      "Validation loss decreased from 1.483761 to 1.482664. Model was saved\n",
      "Epoch: 75 \tTraining Loss: 1.473745 \tValidation Loss: 1.481645 \t time: 0.2\n",
      "Validation loss decreased from 1.482664 to 1.481645. Model was saved\n",
      "Epoch: 76 \tTraining Loss: 1.473046 \tValidation Loss: 1.480808 \t time: 0.2\n",
      "Validation loss decreased from 1.481645 to 1.480808. Model was saved\n",
      "Epoch: 77 \tTraining Loss: 1.473110 \tValidation Loss: 1.479837 \t time: 0.2\n",
      "Validation loss decreased from 1.480808 to 1.479837. Model was saved\n",
      "Epoch: 78 \tTraining Loss: 1.472423 \tValidation Loss: 1.479004 \t time: 0.2\n",
      "Validation loss decreased from 1.479837 to 1.479004. Model was saved\n",
      "Epoch: 79 \tTraining Loss: 1.470074 \tValidation Loss: 1.478128 \t time: 0.2\n",
      "Validation loss decreased from 1.479004 to 1.478128. Model was saved\n",
      "Epoch: 80 \tTraining Loss: 1.469081 \tValidation Loss: 1.477601 \t time: 0.2\n",
      "Validation loss decreased from 1.478128 to 1.477601. Model was saved\n",
      "Epoch: 81 \tTraining Loss: 1.467578 \tValidation Loss: 1.477068 \t time: 0.2\n",
      "Validation loss decreased from 1.477601 to 1.477068. Model was saved\n",
      "Epoch: 82 \tTraining Loss: 1.467863 \tValidation Loss: 1.476331 \t time: 0.2\n",
      "Validation loss decreased from 1.477068 to 1.476331. Model was saved\n",
      "Epoch: 83 \tTraining Loss: 1.467811 \tValidation Loss: 1.475873 \t time: 0.2\n",
      "Validation loss decreased from 1.476331 to 1.475873. Model was saved\n",
      "Epoch: 84 \tTraining Loss: 1.468006 \tValidation Loss: 1.474969 \t time: 0.2\n",
      "Validation loss decreased from 1.475873 to 1.474969. Model was saved\n",
      "Epoch: 85 \tTraining Loss: 1.464655 \tValidation Loss: 1.474508 \t time: 0.2\n",
      "Validation loss decreased from 1.474969 to 1.474508. Model was saved\n",
      "Epoch: 86 \tTraining Loss: 1.464132 \tValidation Loss: 1.473834 \t time: 0.2\n",
      "Validation loss decreased from 1.474508 to 1.473834. Model was saved\n",
      "Epoch: 87 \tTraining Loss: 1.464322 \tValidation Loss: 1.473166 \t time: 0.2\n",
      "Validation loss decreased from 1.473834 to 1.473166. Model was saved\n",
      "Epoch: 88 \tTraining Loss: 1.462659 \tValidation Loss: 1.473103 \t time: 0.2\n",
      "Validation loss decreased from 1.473166 to 1.473103. Model was saved\n",
      "Epoch: 89 \tTraining Loss: 1.459773 \tValidation Loss: 1.472314 \t time: 0.2\n",
      "Validation loss decreased from 1.473103 to 1.472314. Model was saved\n",
      "Epoch: 90 \tTraining Loss: 1.461112 \tValidation Loss: 1.471611 \t time: 0.2\n",
      "Validation loss decreased from 1.472314 to 1.471611. Model was saved\n",
      "Epoch: 91 \tTraining Loss: 1.460570 \tValidation Loss: 1.471159 \t time: 0.2\n",
      "Validation loss decreased from 1.471611 to 1.471159. Model was saved\n",
      "Epoch: 92 \tTraining Loss: 1.458124 \tValidation Loss: 1.470607 \t time: 0.2\n",
      "Validation loss decreased from 1.471159 to 1.470607. Model was saved\n",
      "Epoch: 93 \tTraining Loss: 1.457412 \tValidation Loss: 1.470569 \t time: 0.2\n",
      "Validation loss decreased from 1.470607 to 1.470569. Model was saved\n",
      "Epoch: 94 \tTraining Loss: 1.459050 \tValidation Loss: 1.470255 \t time: 0.2\n",
      "Validation loss decreased from 1.470569 to 1.470255. Model was saved\n",
      "Epoch: 95 \tTraining Loss: 1.455407 \tValidation Loss: 1.469693 \t time: 0.2\n",
      "Validation loss decreased from 1.470255 to 1.469693. Model was saved\n",
      "Epoch: 96 \tTraining Loss: 1.458507 \tValidation Loss: 1.469224 \t time: 0.2\n",
      "Validation loss decreased from 1.469693 to 1.469224. Model was saved\n",
      "Epoch: 97 \tTraining Loss: 1.456879 \tValidation Loss: 1.469058 \t time: 0.2\n",
      "Validation loss decreased from 1.469224 to 1.469058. Model was saved\n",
      "Epoch: 98 \tTraining Loss: 1.454559 \tValidation Loss: 1.468946 \t time: 0.2\n",
      "Validation loss decreased from 1.469058 to 1.468946. Model was saved\n",
      "Epoch: 99 \tTraining Loss: 1.456374 \tValidation Loss: 1.468952 \t time: 0.2\n",
      "Epoch: 100 \tTraining Loss: 1.455362 \tValidation Loss: 1.468605 \t time: 0.2\n",
      "Validation loss decreased from 1.468946 to 1.468605. Model was saved\n",
      "Epoch: 101 \tTraining Loss: 1.455502 \tValidation Loss: 1.468153 \t time: 0.2\n",
      "Validation loss decreased from 1.468605 to 1.468153. Model was saved\n",
      "Epoch: 102 \tTraining Loss: 1.453663 \tValidation Loss: 1.467963 \t time: 0.2\n",
      "Validation loss decreased from 1.468153 to 1.467963. Model was saved\n",
      "Epoch: 103 \tTraining Loss: 1.453878 \tValidation Loss: 1.467602 \t time: 0.2\n",
      "Validation loss decreased from 1.467963 to 1.467602. Model was saved\n",
      "Epoch: 104 \tTraining Loss: 1.450774 \tValidation Loss: 1.467198 \t time: 0.2\n",
      "Validation loss decreased from 1.467602 to 1.467198. Model was saved\n",
      "Epoch: 105 \tTraining Loss: 1.449227 \tValidation Loss: 1.467050 \t time: 0.2\n",
      "Validation loss decreased from 1.467198 to 1.467050. Model was saved\n",
      "Epoch: 106 \tTraining Loss: 1.449478 \tValidation Loss: 1.466639 \t time: 0.2\n",
      "Validation loss decreased from 1.467050 to 1.466639. Model was saved\n",
      "Epoch: 107 \tTraining Loss: 1.448763 \tValidation Loss: 1.466044 \t time: 0.2\n",
      "Validation loss decreased from 1.466639 to 1.466044. Model was saved\n",
      "Epoch: 108 \tTraining Loss: 1.450454 \tValidation Loss: 1.465416 \t time: 0.2\n",
      "Validation loss decreased from 1.466044 to 1.465416. Model was saved\n",
      "Epoch: 109 \tTraining Loss: 1.450967 \tValidation Loss: 1.464924 \t time: 0.2\n",
      "Validation loss decreased from 1.465416 to 1.464924. Model was saved\n",
      "Epoch: 110 \tTraining Loss: 1.449131 \tValidation Loss: 1.464656 \t time: 0.2\n",
      "Validation loss decreased from 1.464924 to 1.464656. Model was saved\n",
      "Epoch: 111 \tTraining Loss: 1.448986 \tValidation Loss: 1.464630 \t time: 0.2\n",
      "Validation loss decreased from 1.464656 to 1.464630. Model was saved\n",
      "Epoch: 112 \tTraining Loss: 1.449909 \tValidation Loss: 1.465104 \t time: 0.2\n",
      "Epoch: 113 \tTraining Loss: 1.446725 \tValidation Loss: 1.464835 \t time: 0.2\n",
      "Epoch: 114 \tTraining Loss: 1.445564 \tValidation Loss: 1.464614 \t time: 0.2\n",
      "Validation loss decreased from 1.464630 to 1.464614. Model was saved\n",
      "Epoch: 115 \tTraining Loss: 1.445002 \tValidation Loss: 1.464234 \t time: 0.2\n",
      "Validation loss decreased from 1.464614 to 1.464234. Model was saved\n",
      "Epoch: 116 \tTraining Loss: 1.446401 \tValidation Loss: 1.463861 \t time: 0.2\n",
      "Validation loss decreased from 1.464234 to 1.463861. Model was saved\n",
      "Epoch: 117 \tTraining Loss: 1.444915 \tValidation Loss: 1.463727 \t time: 0.2\n",
      "Validation loss decreased from 1.463861 to 1.463727. Model was saved\n",
      "Epoch: 118 \tTraining Loss: 1.445477 \tValidation Loss: 1.463670 \t time: 0.2\n",
      "Validation loss decreased from 1.463727 to 1.463670. Model was saved\n",
      "Epoch: 119 \tTraining Loss: 1.444364 \tValidation Loss: 1.463410 \t time: 0.2\n",
      "Validation loss decreased from 1.463670 to 1.463410. Model was saved\n",
      "Epoch: 120 \tTraining Loss: 1.443179 \tValidation Loss: 1.463064 \t time: 0.2\n",
      "Validation loss decreased from 1.463410 to 1.463064. Model was saved\n",
      "Epoch: 121 \tTraining Loss: 1.445159 \tValidation Loss: 1.462844 \t time: 0.2\n",
      "Validation loss decreased from 1.463064 to 1.462844. Model was saved\n",
      "Epoch: 122 \tTraining Loss: 1.442890 \tValidation Loss: 1.462728 \t time: 0.2\n",
      "Validation loss decreased from 1.462844 to 1.462728. Model was saved\n",
      "Epoch: 123 \tTraining Loss: 1.441487 \tValidation Loss: 1.462662 \t time: 0.2\n",
      "Validation loss decreased from 1.462728 to 1.462662. Model was saved\n",
      "Epoch: 124 \tTraining Loss: 1.442212 \tValidation Loss: 1.462401 \t time: 0.2\n",
      "Validation loss decreased from 1.462662 to 1.462401. Model was saved\n",
      "Epoch: 125 \tTraining Loss: 1.440912 \tValidation Loss: 1.462280 \t time: 0.2\n",
      "Validation loss decreased from 1.462401 to 1.462280. Model was saved\n",
      "Epoch: 126 \tTraining Loss: 1.440349 \tValidation Loss: 1.461982 \t time: 0.2\n",
      "Validation loss decreased from 1.462280 to 1.461982. Model was saved\n",
      "Epoch: 127 \tTraining Loss: 1.442701 \tValidation Loss: 1.461765 \t time: 0.2\n",
      "Validation loss decreased from 1.461982 to 1.461765. Model was saved\n",
      "Epoch: 128 \tTraining Loss: 1.439074 \tValidation Loss: 1.461790 \t time: 0.2\n",
      "Epoch: 129 \tTraining Loss: 1.439782 \tValidation Loss: 1.461806 \t time: 0.2\n",
      "Epoch: 130 \tTraining Loss: 1.441381 \tValidation Loss: 1.461506 \t time: 0.2\n",
      "Validation loss decreased from 1.461765 to 1.461506. Model was saved\n",
      "Epoch: 131 \tTraining Loss: 1.441266 \tValidation Loss: 1.461104 \t time: 0.2\n",
      "Validation loss decreased from 1.461506 to 1.461104. Model was saved\n",
      "Epoch: 132 \tTraining Loss: 1.439124 \tValidation Loss: 1.461194 \t time: 0.2\n",
      "Epoch: 133 \tTraining Loss: 1.439912 \tValidation Loss: 1.460875 \t time: 0.2\n",
      "Validation loss decreased from 1.461104 to 1.460875. Model was saved\n",
      "Epoch: 134 \tTraining Loss: 1.439800 \tValidation Loss: 1.461087 \t time: 0.2\n",
      "Epoch: 135 \tTraining Loss: 1.440476 \tValidation Loss: 1.460836 \t time: 0.2\n",
      "Validation loss decreased from 1.460875 to 1.460836. Model was saved\n",
      "Epoch: 136 \tTraining Loss: 1.437307 \tValidation Loss: 1.460599 \t time: 0.2\n",
      "Validation loss decreased from 1.460836 to 1.460599. Model was saved\n",
      "Epoch: 137 \tTraining Loss: 1.435937 \tValidation Loss: 1.460370 \t time: 0.2\n",
      "Validation loss decreased from 1.460599 to 1.460370. Model was saved\n",
      "Epoch: 138 \tTraining Loss: 1.436428 \tValidation Loss: 1.459702 \t time: 0.2\n",
      "Validation loss decreased from 1.460370 to 1.459702. Model was saved\n",
      "Epoch: 139 \tTraining Loss: 1.436224 \tValidation Loss: 1.459325 \t time: 0.2\n",
      "Validation loss decreased from 1.459702 to 1.459325. Model was saved\n",
      "Epoch: 140 \tTraining Loss: 1.435692 \tValidation Loss: 1.459373 \t time: 0.2\n",
      "Epoch: 141 \tTraining Loss: 1.436128 \tValidation Loss: 1.459686 \t time: 0.2\n",
      "Epoch: 142 \tTraining Loss: 1.435046 \tValidation Loss: 1.459849 \t time: 0.2\n",
      "Epoch: 143 \tTraining Loss: 1.435685 \tValidation Loss: 1.460085 \t time: 0.2\n",
      "Epoch: 144 \tTraining Loss: 1.432995 \tValidation Loss: 1.459593 \t time: 0.2\n",
      "Epoch: 145 \tTraining Loss: 1.434163 \tValidation Loss: 1.458812 \t time: 0.2\n",
      "Validation loss decreased from 1.459325 to 1.458812. Model was saved\n",
      "Epoch: 146 \tTraining Loss: 1.433601 \tValidation Loss: 1.458134 \t time: 0.2\n",
      "Validation loss decreased from 1.458812 to 1.458134. Model was saved\n",
      "Epoch: 147 \tTraining Loss: 1.433851 \tValidation Loss: 1.457860 \t time: 0.2\n",
      "Validation loss decreased from 1.458134 to 1.457860. Model was saved\n",
      "Epoch: 148 \tTraining Loss: 1.432803 \tValidation Loss: 1.458085 \t time: 0.2\n",
      "Epoch: 149 \tTraining Loss: 1.434099 \tValidation Loss: 1.458233 \t time: 0.2\n",
      "Epoch: 150 \tTraining Loss: 1.433138 \tValidation Loss: 1.458179 \t time: 0.2\n",
      "Epoch: 151 \tTraining Loss: 1.432626 \tValidation Loss: 1.457907 \t time: 0.2\n",
      "Epoch: 152 \tTraining Loss: 1.432366 \tValidation Loss: 1.457034 \t time: 0.2\n",
      "Validation loss decreased from 1.457860 to 1.457034. Model was saved\n",
      "Epoch: 153 \tTraining Loss: 1.430670 \tValidation Loss: 1.456397 \t time: 0.2\n",
      "Validation loss decreased from 1.457034 to 1.456397. Model was saved\n",
      "Epoch: 154 \tTraining Loss: 1.430819 \tValidation Loss: 1.456667 \t time: 0.2\n",
      "Epoch: 155 \tTraining Loss: 1.430020 \tValidation Loss: 1.456714 \t time: 0.2\n",
      "Epoch: 156 \tTraining Loss: 1.430271 \tValidation Loss: 1.456760 \t time: 0.2\n",
      "Epoch: 157 \tTraining Loss: 1.428854 \tValidation Loss: 1.457133 \t time: 0.2\n",
      "Epoch: 158 \tTraining Loss: 1.432314 \tValidation Loss: 1.456788 \t time: 0.2\n",
      "Epoch: 159 \tTraining Loss: 1.428436 \tValidation Loss: 1.456271 \t time: 0.2\n",
      "Validation loss decreased from 1.456397 to 1.456271. Model was saved\n",
      "Epoch: 160 \tTraining Loss: 1.428480 \tValidation Loss: 1.456311 \t time: 0.2\n",
      "Epoch: 161 \tTraining Loss: 1.425814 \tValidation Loss: 1.456097 \t time: 0.2\n",
      "Validation loss decreased from 1.456271 to 1.456097. Model was saved\n",
      "Epoch: 162 \tTraining Loss: 1.429036 \tValidation Loss: 1.456061 \t time: 0.2\n",
      "Validation loss decreased from 1.456097 to 1.456061. Model was saved\n",
      "Epoch: 163 \tTraining Loss: 1.427487 \tValidation Loss: 1.456110 \t time: 0.2\n",
      "Epoch: 164 \tTraining Loss: 1.428537 \tValidation Loss: 1.455893 \t time: 0.2\n",
      "Validation loss decreased from 1.456061 to 1.455893. Model was saved\n",
      "Epoch: 165 \tTraining Loss: 1.427728 \tValidation Loss: 1.455248 \t time: 0.2\n",
      "Validation loss decreased from 1.455893 to 1.455248. Model was saved\n",
      "Epoch: 166 \tTraining Loss: 1.426443 \tValidation Loss: 1.454571 \t time: 0.2\n",
      "Validation loss decreased from 1.455248 to 1.454571. Model was saved\n",
      "Epoch: 167 \tTraining Loss: 1.425768 \tValidation Loss: 1.454462 \t time: 0.2\n",
      "Validation loss decreased from 1.454571 to 1.454462. Model was saved\n",
      "Epoch: 168 \tTraining Loss: 1.426561 \tValidation Loss: 1.454580 \t time: 0.2\n",
      "Epoch: 169 \tTraining Loss: 1.426946 \tValidation Loss: 1.454531 \t time: 0.2\n",
      "Epoch: 170 \tTraining Loss: 1.426856 \tValidation Loss: 1.454679 \t time: 0.2\n",
      "Epoch: 171 \tTraining Loss: 1.424246 \tValidation Loss: 1.454305 \t time: 0.2\n",
      "Validation loss decreased from 1.454462 to 1.454305. Model was saved\n",
      "Epoch: 172 \tTraining Loss: 1.424718 \tValidation Loss: 1.452979 \t time: 0.2\n",
      "Validation loss decreased from 1.454305 to 1.452979. Model was saved\n",
      "Epoch: 173 \tTraining Loss: 1.423439 \tValidation Loss: 1.452487 \t time: 0.2\n",
      "Validation loss decreased from 1.452979 to 1.452487. Model was saved\n",
      "Epoch: 174 \tTraining Loss: 1.422045 \tValidation Loss: 1.452561 \t time: 0.2\n",
      "Epoch: 175 \tTraining Loss: 1.420274 \tValidation Loss: 1.453022 \t time: 0.2\n",
      "Epoch: 176 \tTraining Loss: 1.423662 \tValidation Loss: 1.453968 \t time: 0.2\n",
      "Epoch: 177 \tTraining Loss: 1.422810 \tValidation Loss: 1.454250 \t time: 0.2\n",
      "Epoch: 178 \tTraining Loss: 1.422288 \tValidation Loss: 1.453255 \t time: 0.2\n",
      "Epoch: 179 \tTraining Loss: 1.422836 \tValidation Loss: 1.452183 \t time: 0.2\n",
      "Validation loss decreased from 1.452487 to 1.452183. Model was saved\n",
      "Epoch: 180 \tTraining Loss: 1.423522 \tValidation Loss: 1.451523 \t time: 0.2\n",
      "Validation loss decreased from 1.452183 to 1.451523. Model was saved\n",
      "Epoch: 181 \tTraining Loss: 1.420647 \tValidation Loss: 1.451181 \t time: 0.2\n",
      "Validation loss decreased from 1.451523 to 1.451181. Model was saved\n",
      "Epoch: 182 \tTraining Loss: 1.421463 \tValidation Loss: 1.451202 \t time: 0.2\n",
      "Epoch: 183 \tTraining Loss: 1.420664 \tValidation Loss: 1.451342 \t time: 0.2\n",
      "Epoch: 184 \tTraining Loss: 1.420681 \tValidation Loss: 1.451907 \t time: 0.2\n",
      "Epoch: 185 \tTraining Loss: 1.419450 \tValidation Loss: 1.451497 \t time: 0.2\n",
      "Epoch: 186 \tTraining Loss: 1.418503 \tValidation Loss: 1.451298 \t time: 0.2\n",
      "Epoch: 187 \tTraining Loss: 1.418639 \tValidation Loss: 1.450933 \t time: 0.2\n",
      "Validation loss decreased from 1.451181 to 1.450933. Model was saved\n",
      "Epoch: 188 \tTraining Loss: 1.417726 \tValidation Loss: 1.450555 \t time: 0.2\n",
      "Validation loss decreased from 1.450933 to 1.450555. Model was saved\n",
      "Epoch: 189 \tTraining Loss: 1.420053 \tValidation Loss: 1.450458 \t time: 0.2\n",
      "Validation loss decreased from 1.450555 to 1.450458. Model was saved\n",
      "Epoch: 190 \tTraining Loss: 1.417588 \tValidation Loss: 1.450761 \t time: 0.2\n",
      "Epoch: 191 \tTraining Loss: 1.418691 \tValidation Loss: 1.451052 \t time: 0.2\n",
      "Epoch: 192 \tTraining Loss: 1.418318 \tValidation Loss: 1.451438 \t time: 0.2\n",
      "Epoch: 193 \tTraining Loss: 1.415788 \tValidation Loss: 1.451485 \t time: 0.2\n",
      "Epoch: 194 \tTraining Loss: 1.417063 \tValidation Loss: 1.450803 \t time: 0.2\n",
      "Epoch: 195 \tTraining Loss: 1.415132 \tValidation Loss: 1.450298 \t time: 0.2\n",
      "Validation loss decreased from 1.450458 to 1.450298. Model was saved\n",
      "Epoch: 196 \tTraining Loss: 1.417111 \tValidation Loss: 1.450078 \t time: 0.2\n",
      "Validation loss decreased from 1.450298 to 1.450078. Model was saved\n",
      "Epoch: 197 \tTraining Loss: 1.416893 \tValidation Loss: 1.450047 \t time: 0.2\n",
      "Validation loss decreased from 1.450078 to 1.450047. Model was saved\n",
      "Epoch: 198 \tTraining Loss: 1.417329 \tValidation Loss: 1.449460 \t time: 0.2\n",
      "Validation loss decreased from 1.450047 to 1.449460. Model was saved\n",
      "Epoch: 199 \tTraining Loss: 1.415762 \tValidation Loss: 1.448833 \t time: 0.2\n",
      "Validation loss decreased from 1.449460 to 1.448833. Model was saved\n",
      "Epoch: 200 \tTraining Loss: 1.414014 \tValidation Loss: 1.448316 \t time: 0.2\n",
      "Validation loss decreased from 1.448833 to 1.448316. Model was saved\n",
      "Epoch: 201 \tTraining Loss: 1.415199 \tValidation Loss: 1.448121 \t time: 0.2\n",
      "Validation loss decreased from 1.448316 to 1.448121. Model was saved\n",
      "Epoch: 202 \tTraining Loss: 1.415292 \tValidation Loss: 1.448245 \t time: 0.2\n",
      "Epoch: 203 \tTraining Loss: 1.412735 \tValidation Loss: 1.447864 \t time: 0.2\n",
      "Validation loss decreased from 1.448121 to 1.447864. Model was saved\n",
      "Epoch: 204 \tTraining Loss: 1.414341 \tValidation Loss: 1.447721 \t time: 0.2\n",
      "Validation loss decreased from 1.447864 to 1.447721. Model was saved\n",
      "Epoch: 205 \tTraining Loss: 1.414541 \tValidation Loss: 1.447410 \t time: 0.2\n",
      "Validation loss decreased from 1.447721 to 1.447410. Model was saved\n",
      "Epoch: 206 \tTraining Loss: 1.413554 \tValidation Loss: 1.447201 \t time: 0.2\n",
      "Validation loss decreased from 1.447410 to 1.447201. Model was saved\n",
      "Epoch: 207 \tTraining Loss: 1.414055 \tValidation Loss: 1.446762 \t time: 0.2\n",
      "Validation loss decreased from 1.447201 to 1.446762. Model was saved\n",
      "Epoch: 208 \tTraining Loss: 1.411798 \tValidation Loss: 1.446444 \t time: 0.2\n",
      "Validation loss decreased from 1.446762 to 1.446444. Model was saved\n",
      "Epoch: 209 \tTraining Loss: 1.412549 \tValidation Loss: 1.446667 \t time: 0.2\n",
      "Epoch: 210 \tTraining Loss: 1.412741 \tValidation Loss: 1.446598 \t time: 0.2\n",
      "Epoch: 211 \tTraining Loss: 1.411802 \tValidation Loss: 1.446868 \t time: 0.2\n",
      "Epoch: 212 \tTraining Loss: 1.410727 \tValidation Loss: 1.447215 \t time: 0.2\n",
      "Epoch: 213 \tTraining Loss: 1.410924 \tValidation Loss: 1.446860 \t time: 0.2\n",
      "Epoch: 214 \tTraining Loss: 1.411291 \tValidation Loss: 1.445742 \t time: 0.2\n",
      "Validation loss decreased from 1.446444 to 1.445742. Model was saved\n",
      "Epoch: 215 \tTraining Loss: 1.412408 \tValidation Loss: 1.444813 \t time: 0.2\n",
      "Validation loss decreased from 1.445742 to 1.444813. Model was saved\n",
      "Epoch: 216 \tTraining Loss: 1.409380 \tValidation Loss: 1.444292 \t time: 0.2\n",
      "Validation loss decreased from 1.444813 to 1.444292. Model was saved\n",
      "Epoch: 217 \tTraining Loss: 1.408647 \tValidation Loss: 1.444179 \t time: 0.2\n",
      "Validation loss decreased from 1.444292 to 1.444179. Model was saved\n",
      "Epoch: 218 \tTraining Loss: 1.408829 \tValidation Loss: 1.444307 \t time: 0.2\n",
      "Epoch: 219 \tTraining Loss: 1.408800 \tValidation Loss: 1.444344 \t time: 0.2\n",
      "Epoch: 220 \tTraining Loss: 1.408347 \tValidation Loss: 1.443666 \t time: 0.2\n",
      "Validation loss decreased from 1.444179 to 1.443666. Model was saved\n",
      "Epoch: 221 \tTraining Loss: 1.408335 \tValidation Loss: 1.442888 \t time: 0.2\n",
      "Validation loss decreased from 1.443666 to 1.442888. Model was saved\n",
      "Epoch: 222 \tTraining Loss: 1.408463 \tValidation Loss: 1.442289 \t time: 0.2\n",
      "Validation loss decreased from 1.442888 to 1.442289. Model was saved\n",
      "Epoch: 223 \tTraining Loss: 1.406669 \tValidation Loss: 1.442009 \t time: 0.2\n",
      "Validation loss decreased from 1.442289 to 1.442009. Model was saved\n",
      "Epoch: 224 \tTraining Loss: 1.409995 \tValidation Loss: 1.441983 \t time: 0.2\n",
      "Validation loss decreased from 1.442009 to 1.441983. Model was saved\n",
      "Epoch: 225 \tTraining Loss: 1.408783 \tValidation Loss: 1.442009 \t time: 0.2\n",
      "Epoch: 226 \tTraining Loss: 1.408732 \tValidation Loss: 1.441988 \t time: 0.2\n",
      "Epoch: 227 \tTraining Loss: 1.406521 \tValidation Loss: 1.441859 \t time: 0.2\n",
      "Validation loss decreased from 1.441983 to 1.441859. Model was saved\n",
      "Epoch: 228 \tTraining Loss: 1.406430 \tValidation Loss: 1.441818 \t time: 0.2\n",
      "Validation loss decreased from 1.441859 to 1.441818. Model was saved\n",
      "Epoch: 229 \tTraining Loss: 1.405697 \tValidation Loss: 1.441885 \t time: 0.2\n",
      "Epoch: 230 \tTraining Loss: 1.408756 \tValidation Loss: 1.441789 \t time: 0.2\n",
      "Validation loss decreased from 1.441818 to 1.441789. Model was saved\n",
      "Epoch: 231 \tTraining Loss: 1.405752 \tValidation Loss: 1.440992 \t time: 0.2\n",
      "Validation loss decreased from 1.441789 to 1.440992. Model was saved\n",
      "Epoch: 232 \tTraining Loss: 1.404978 \tValidation Loss: 1.440261 \t time: 0.2\n",
      "Validation loss decreased from 1.440992 to 1.440261. Model was saved\n",
      "Epoch: 233 \tTraining Loss: 1.404934 \tValidation Loss: 1.440286 \t time: 0.2\n",
      "Epoch: 234 \tTraining Loss: 1.405414 \tValidation Loss: 1.439947 \t time: 0.2\n",
      "Validation loss decreased from 1.440261 to 1.439947. Model was saved\n",
      "Epoch: 235 \tTraining Loss: 1.404520 \tValidation Loss: 1.439496 \t time: 0.2\n",
      "Validation loss decreased from 1.439947 to 1.439496. Model was saved\n",
      "Epoch: 236 \tTraining Loss: 1.405757 \tValidation Loss: 1.439230 \t time: 0.2\n",
      "Validation loss decreased from 1.439496 to 1.439230. Model was saved\n",
      "Epoch: 237 \tTraining Loss: 1.405489 \tValidation Loss: 1.438233 \t time: 0.2\n",
      "Validation loss decreased from 1.439230 to 1.438233. Model was saved\n",
      "Epoch: 238 \tTraining Loss: 1.403766 \tValidation Loss: 1.437498 \t time: 0.2\n",
      "Validation loss decreased from 1.438233 to 1.437498. Model was saved\n",
      "Epoch: 239 \tTraining Loss: 1.402010 \tValidation Loss: 1.437759 \t time: 0.2\n",
      "Epoch: 240 \tTraining Loss: 1.405556 \tValidation Loss: 1.437874 \t time: 0.2\n",
      "Epoch: 241 \tTraining Loss: 1.403200 \tValidation Loss: 1.437050 \t time: 0.2\n",
      "Validation loss decreased from 1.437498 to 1.437050. Model was saved\n",
      "Epoch: 242 \tTraining Loss: 1.401085 \tValidation Loss: 1.436771 \t time: 0.2\n",
      "Validation loss decreased from 1.437050 to 1.436771. Model was saved\n",
      "Epoch: 243 \tTraining Loss: 1.402854 \tValidation Loss: 1.437106 \t time: 0.2\n",
      "Epoch: 244 \tTraining Loss: 1.402210 \tValidation Loss: 1.437076 \t time: 0.2\n",
      "Epoch: 245 \tTraining Loss: 1.403894 \tValidation Loss: 1.437649 \t time: 0.2\n",
      "Epoch: 246 \tTraining Loss: 1.402104 \tValidation Loss: 1.438928 \t time: 0.2\n",
      "Epoch: 247 \tTraining Loss: 1.400162 \tValidation Loss: 1.438585 \t time: 0.2\n",
      "Epoch: 248 \tTraining Loss: 1.398978 \tValidation Loss: 1.436077 \t time: 0.2\n",
      "Validation loss decreased from 1.436771 to 1.436077. Model was saved\n",
      "Epoch: 249 \tTraining Loss: 1.401941 \tValidation Loss: 1.434677 \t time: 0.2\n",
      "Validation loss decreased from 1.436077 to 1.434677. Model was saved\n",
      "Epoch: 250 \tTraining Loss: 1.402089 \tValidation Loss: 1.434311 \t time: 0.2\n",
      "Validation loss decreased from 1.434677 to 1.434311. Model was saved\n",
      "Epoch: 251 \tTraining Loss: 1.399704 \tValidation Loss: 1.433936 \t time: 0.2\n",
      "Validation loss decreased from 1.434311 to 1.433936. Model was saved\n",
      "Epoch: 252 \tTraining Loss: 1.397501 \tValidation Loss: 1.434745 \t time: 0.2\n",
      "Epoch: 253 \tTraining Loss: 1.399188 \tValidation Loss: 1.436689 \t time: 0.2\n",
      "Epoch: 254 \tTraining Loss: 1.400887 \tValidation Loss: 1.436711 \t time: 0.2\n",
      "Epoch: 255 \tTraining Loss: 1.398943 \tValidation Loss: 1.435477 \t time: 0.2\n",
      "Epoch: 256 \tTraining Loss: 1.399550 \tValidation Loss: 1.434569 \t time: 0.2\n",
      "Epoch: 257 \tTraining Loss: 1.398280 \tValidation Loss: 1.433707 \t time: 0.2\n",
      "Validation loss decreased from 1.433936 to 1.433707. Model was saved\n",
      "Epoch: 258 \tTraining Loss: 1.399277 \tValidation Loss: 1.432753 \t time: 0.2\n",
      "Validation loss decreased from 1.433707 to 1.432753. Model was saved\n",
      "Epoch: 259 \tTraining Loss: 1.397382 \tValidation Loss: 1.433048 \t time: 0.2\n",
      "Epoch: 260 \tTraining Loss: 1.396760 \tValidation Loss: 1.433580 \t time: 0.2\n",
      "Epoch: 261 \tTraining Loss: 1.398145 \tValidation Loss: 1.433845 \t time: 0.2\n",
      "Epoch: 262 \tTraining Loss: 1.396702 \tValidation Loss: 1.433399 \t time: 0.2\n",
      "Epoch: 263 \tTraining Loss: 1.397688 \tValidation Loss: 1.432397 \t time: 0.2\n",
      "Validation loss decreased from 1.432753 to 1.432397. Model was saved\n",
      "Epoch: 264 \tTraining Loss: 1.395602 \tValidation Loss: 1.431390 \t time: 0.2\n",
      "Validation loss decreased from 1.432397 to 1.431390. Model was saved\n",
      "Epoch: 265 \tTraining Loss: 1.398598 \tValidation Loss: 1.430518 \t time: 0.2\n",
      "Validation loss decreased from 1.431390 to 1.430518. Model was saved\n",
      "Epoch: 266 \tTraining Loss: 1.396694 \tValidation Loss: 1.430375 \t time: 0.2\n",
      "Validation loss decreased from 1.430518 to 1.430375. Model was saved\n",
      "Epoch: 267 \tTraining Loss: 1.394409 \tValidation Loss: 1.430431 \t time: 0.2\n",
      "Epoch: 268 \tTraining Loss: 1.396132 \tValidation Loss: 1.430203 \t time: 0.2\n",
      "Validation loss decreased from 1.430375 to 1.430203. Model was saved\n",
      "Epoch: 269 \tTraining Loss: 1.394856 \tValidation Loss: 1.429342 \t time: 0.2\n",
      "Validation loss decreased from 1.430203 to 1.429342. Model was saved\n",
      "Epoch: 270 \tTraining Loss: 1.394210 \tValidation Loss: 1.429484 \t time: 0.2\n",
      "Epoch: 271 \tTraining Loss: 1.394827 \tValidation Loss: 1.429924 \t time: 0.2\n",
      "Epoch: 272 \tTraining Loss: 1.393112 \tValidation Loss: 1.430447 \t time: 0.2\n",
      "Epoch: 273 \tTraining Loss: 1.395168 \tValidation Loss: 1.430996 \t time: 0.2\n",
      "Epoch: 274 \tTraining Loss: 1.391808 \tValidation Loss: 1.430885 \t time: 0.2\n",
      "Epoch: 275 \tTraining Loss: 1.393610 \tValidation Loss: 1.429839 \t time: 0.2\n",
      "Epoch: 276 \tTraining Loss: 1.391368 \tValidation Loss: 1.428709 \t time: 0.2\n",
      "Validation loss decreased from 1.429342 to 1.428709. Model was saved\n",
      "Epoch: 277 \tTraining Loss: 1.393960 \tValidation Loss: 1.428113 \t time: 0.2\n",
      "Validation loss decreased from 1.428709 to 1.428113. Model was saved\n",
      "Epoch: 278 \tTraining Loss: 1.393152 \tValidation Loss: 1.427824 \t time: 0.2\n",
      "Validation loss decreased from 1.428113 to 1.427824. Model was saved\n",
      "Epoch: 279 \tTraining Loss: 1.392890 \tValidation Loss: 1.428094 \t time: 0.2\n",
      "Epoch: 280 \tTraining Loss: 1.391359 \tValidation Loss: 1.428756 \t time: 0.2\n",
      "Epoch: 281 \tTraining Loss: 1.390097 \tValidation Loss: 1.428977 \t time: 0.2\n",
      "Epoch: 282 \tTraining Loss: 1.389341 \tValidation Loss: 1.428245 \t time: 0.2\n",
      "Epoch: 283 \tTraining Loss: 1.392891 \tValidation Loss: 1.427150 \t time: 0.2\n",
      "Validation loss decreased from 1.427824 to 1.427150. Model was saved\n",
      "Epoch: 284 \tTraining Loss: 1.390314 \tValidation Loss: 1.426152 \t time: 0.2\n",
      "Validation loss decreased from 1.427150 to 1.426152. Model was saved\n",
      "Epoch: 285 \tTraining Loss: 1.389370 \tValidation Loss: 1.425750 \t time: 0.2\n",
      "Validation loss decreased from 1.426152 to 1.425750. Model was saved\n",
      "Epoch: 286 \tTraining Loss: 1.389443 \tValidation Loss: 1.425886 \t time: 0.2\n",
      "Epoch: 287 \tTraining Loss: 1.390582 \tValidation Loss: 1.426511 \t time: 0.2\n",
      "Epoch: 288 \tTraining Loss: 1.389409 \tValidation Loss: 1.426983 \t time: 0.2\n",
      "Epoch: 289 \tTraining Loss: 1.387377 \tValidation Loss: 1.427212 \t time: 0.2\n",
      "Epoch: 290 \tTraining Loss: 1.388888 \tValidation Loss: 1.427144 \t time: 0.2\n",
      "Epoch: 291 \tTraining Loss: 1.390525 \tValidation Loss: 1.426396 \t time: 0.2\n",
      "Epoch: 292 \tTraining Loss: 1.389923 \tValidation Loss: 1.425570 \t time: 0.2\n",
      "Validation loss decreased from 1.425750 to 1.425570. Model was saved\n",
      "Epoch: 293 \tTraining Loss: 1.386370 \tValidation Loss: 1.424807 \t time: 0.2\n",
      "Validation loss decreased from 1.425570 to 1.424807. Model was saved\n",
      "Epoch: 294 \tTraining Loss: 1.386816 \tValidation Loss: 1.423844 \t time: 0.2\n",
      "Validation loss decreased from 1.424807 to 1.423844. Model was saved\n",
      "Epoch: 295 \tTraining Loss: 1.386379 \tValidation Loss: 1.423103 \t time: 0.2\n",
      "Validation loss decreased from 1.423844 to 1.423103. Model was saved\n",
      "Epoch: 296 \tTraining Loss: 1.389361 \tValidation Loss: 1.423054 \t time: 0.2\n",
      "Validation loss decreased from 1.423103 to 1.423054. Model was saved\n",
      "Epoch: 297 \tTraining Loss: 1.386120 \tValidation Loss: 1.423636 \t time: 0.2\n",
      "Epoch: 298 \tTraining Loss: 1.389258 \tValidation Loss: 1.423949 \t time: 0.2\n",
      "Epoch: 299 \tTraining Loss: 1.385415 \tValidation Loss: 1.423939 \t time: 0.2\n",
      "Epoch: 300 \tTraining Loss: 1.385193 \tValidation Loss: 1.423046 \t time: 0.2\n",
      "Validation loss decreased from 1.423054 to 1.423046. Model was saved\n",
      "Epoch: 301 \tTraining Loss: 1.384415 \tValidation Loss: 1.422250 \t time: 0.2\n",
      "Validation loss decreased from 1.423046 to 1.422250. Model was saved\n",
      "Epoch: 302 \tTraining Loss: 1.385239 \tValidation Loss: 1.422344 \t time: 0.2\n",
      "Epoch: 303 \tTraining Loss: 1.382842 \tValidation Loss: 1.422603 \t time: 0.2\n",
      "Epoch: 304 \tTraining Loss: 1.386927 \tValidation Loss: 1.422703 \t time: 0.2\n",
      "Epoch: 305 \tTraining Loss: 1.385483 \tValidation Loss: 1.423087 \t time: 0.2\n",
      "Epoch: 306 \tTraining Loss: 1.385228 \tValidation Loss: 1.423563 \t time: 0.2\n",
      "Epoch: 307 \tTraining Loss: 1.383432 \tValidation Loss: 1.423809 \t time: 0.2\n",
      "Epoch: 308 \tTraining Loss: 1.383365 \tValidation Loss: 1.424250 \t time: 0.2\n",
      "Epoch: 309 \tTraining Loss: 1.385775 \tValidation Loss: 1.424401 \t time: 0.2\n",
      "Epoch: 310 \tTraining Loss: 1.384579 \tValidation Loss: 1.423259 \t time: 0.2\n",
      "Epoch: 311 \tTraining Loss: 1.381723 \tValidation Loss: 1.421756 \t time: 0.2\n",
      "Validation loss decreased from 1.422250 to 1.421756. Model was saved\n",
      "Epoch: 312 \tTraining Loss: 1.385939 \tValidation Loss: 1.421180 \t time: 0.2\n",
      "Validation loss decreased from 1.421756 to 1.421180. Model was saved\n",
      "Epoch: 313 \tTraining Loss: 1.383410 \tValidation Loss: 1.421326 \t time: 0.2\n",
      "Epoch: 314 \tTraining Loss: 1.381577 \tValidation Loss: 1.422541 \t time: 0.2\n",
      "Epoch: 315 \tTraining Loss: 1.381209 \tValidation Loss: 1.423864 \t time: 0.2\n",
      "Epoch: 316 \tTraining Loss: 1.381921 \tValidation Loss: 1.423131 \t time: 0.2\n",
      "Epoch: 317 \tTraining Loss: 1.385212 \tValidation Loss: 1.421813 \t time: 0.2\n",
      "Epoch: 318 \tTraining Loss: 1.381760 \tValidation Loss: 1.421316 \t time: 0.2\n",
      "Epoch: 319 \tTraining Loss: 1.381388 \tValidation Loss: 1.421133 \t time: 0.2\n",
      "Validation loss decreased from 1.421180 to 1.421133. Model was saved\n",
      "Epoch: 320 \tTraining Loss: 1.382196 \tValidation Loss: 1.421178 \t time: 0.2\n",
      "Epoch: 321 \tTraining Loss: 1.380747 \tValidation Loss: 1.421455 \t time: 0.2\n",
      "Epoch: 322 \tTraining Loss: 1.379546 \tValidation Loss: 1.421216 \t time: 0.2\n",
      "Epoch: 323 \tTraining Loss: 1.380107 \tValidation Loss: 1.420879 \t time: 0.2\n",
      "Validation loss decreased from 1.421133 to 1.420879. Model was saved\n",
      "Epoch: 324 \tTraining Loss: 1.380318 \tValidation Loss: 1.420626 \t time: 0.2\n",
      "Validation loss decreased from 1.420879 to 1.420626. Model was saved\n",
      "Epoch: 325 \tTraining Loss: 1.380568 \tValidation Loss: 1.420108 \t time: 0.2\n",
      "Validation loss decreased from 1.420626 to 1.420108. Model was saved\n",
      "Epoch: 326 \tTraining Loss: 1.379659 \tValidation Loss: 1.419893 \t time: 0.2\n",
      "Validation loss decreased from 1.420108 to 1.419893. Model was saved\n",
      "Epoch: 327 \tTraining Loss: 1.381615 \tValidation Loss: 1.419831 \t time: 0.2\n",
      "Validation loss decreased from 1.419893 to 1.419831. Model was saved\n",
      "Epoch: 328 \tTraining Loss: 1.378425 \tValidation Loss: 1.420116 \t time: 0.2\n",
      "Epoch: 329 \tTraining Loss: 1.377555 \tValidation Loss: 1.420373 \t time: 0.2\n",
      "Epoch: 330 \tTraining Loss: 1.379499 \tValidation Loss: 1.420529 \t time: 0.2\n",
      "Epoch: 331 \tTraining Loss: 1.379005 \tValidation Loss: 1.420561 \t time: 0.2\n",
      "Epoch: 332 \tTraining Loss: 1.379622 \tValidation Loss: 1.419878 \t time: 0.2\n",
      "Epoch: 333 \tTraining Loss: 1.378483 \tValidation Loss: 1.419046 \t time: 0.2\n",
      "Validation loss decreased from 1.419831 to 1.419046. Model was saved\n",
      "Epoch: 334 \tTraining Loss: 1.378703 \tValidation Loss: 1.418684 \t time: 0.2\n",
      "Validation loss decreased from 1.419046 to 1.418684. Model was saved\n",
      "Epoch: 335 \tTraining Loss: 1.379075 \tValidation Loss: 1.418699 \t time: 0.2\n",
      "Epoch: 336 \tTraining Loss: 1.376535 \tValidation Loss: 1.418782 \t time: 0.2\n",
      "Epoch: 337 \tTraining Loss: 1.376666 \tValidation Loss: 1.418735 \t time: 0.2\n",
      "Epoch: 338 \tTraining Loss: 1.376747 \tValidation Loss: 1.418812 \t time: 0.2\n",
      "Epoch: 339 \tTraining Loss: 1.375437 \tValidation Loss: 1.418731 \t time: 0.2\n",
      "Epoch: 340 \tTraining Loss: 1.378099 \tValidation Loss: 1.418462 \t time: 0.2\n",
      "Validation loss decreased from 1.418684 to 1.418462. Model was saved\n",
      "Epoch: 341 \tTraining Loss: 1.377580 \tValidation Loss: 1.418347 \t time: 0.2\n",
      "Validation loss decreased from 1.418462 to 1.418347. Model was saved\n",
      "Epoch: 342 \tTraining Loss: 1.376427 \tValidation Loss: 1.418181 \t time: 0.2\n",
      "Validation loss decreased from 1.418347 to 1.418181. Model was saved\n",
      "Epoch: 343 \tTraining Loss: 1.376184 \tValidation Loss: 1.418370 \t time: 0.2\n",
      "Epoch: 344 \tTraining Loss: 1.377339 \tValidation Loss: 1.418750 \t time: 0.2\n",
      "Epoch: 345 \tTraining Loss: 1.377458 \tValidation Loss: 1.418688 \t time: 0.2\n",
      "Epoch: 346 \tTraining Loss: 1.375612 \tValidation Loss: 1.418878 \t time: 0.2\n",
      "Epoch: 347 \tTraining Loss: 1.375566 \tValidation Loss: 1.418772 \t time: 0.2\n",
      "Epoch: 348 \tTraining Loss: 1.374713 \tValidation Loss: 1.418406 \t time: 0.2\n",
      "Epoch: 349 \tTraining Loss: 1.373400 \tValidation Loss: 1.418365 \t time: 0.2\n",
      "Epoch: 350 \tTraining Loss: 1.375573 \tValidation Loss: 1.418583 \t time: 0.2\n",
      "Epoch: 351 \tTraining Loss: 1.374688 \tValidation Loss: 1.418969 \t time: 0.2\n",
      "Epoch: 352 \tTraining Loss: 1.373645 \tValidation Loss: 1.418550 \t time: 0.2\n",
      "Epoch: 353 \tTraining Loss: 1.372512 \tValidation Loss: 1.417695 \t time: 0.2\n",
      "Validation loss decreased from 1.418181 to 1.417695. Model was saved\n",
      "Epoch: 354 \tTraining Loss: 1.373210 \tValidation Loss: 1.417132 \t time: 0.2\n",
      "Validation loss decreased from 1.417695 to 1.417132. Model was saved\n",
      "Epoch: 355 \tTraining Loss: 1.372614 \tValidation Loss: 1.417199 \t time: 0.2\n",
      "Epoch: 356 \tTraining Loss: 1.372080 \tValidation Loss: 1.417780 \t time: 0.2\n",
      "Epoch: 357 \tTraining Loss: 1.370488 \tValidation Loss: 1.418725 \t time: 0.2\n",
      "Epoch: 358 \tTraining Loss: 1.371864 \tValidation Loss: 1.419083 \t time: 0.2\n",
      "Epoch: 359 \tTraining Loss: 1.372867 \tValidation Loss: 1.418366 \t time: 0.2\n",
      "Epoch: 360 \tTraining Loss: 1.372605 \tValidation Loss: 1.417695 \t time: 0.2\n",
      "Epoch: 361 \tTraining Loss: 1.371366 \tValidation Loss: 1.416773 \t time: 0.2\n",
      "Validation loss decreased from 1.417132 to 1.416773. Model was saved\n",
      "Epoch: 362 \tTraining Loss: 1.369118 \tValidation Loss: 1.415893 \t time: 0.2\n",
      "Validation loss decreased from 1.416773 to 1.415893. Model was saved\n",
      "Epoch: 363 \tTraining Loss: 1.372408 \tValidation Loss: 1.415624 \t time: 0.2\n",
      "Validation loss decreased from 1.415893 to 1.415624. Model was saved\n",
      "Epoch: 364 \tTraining Loss: 1.372232 \tValidation Loss: 1.416052 \t time: 0.2\n",
      "Epoch: 365 \tTraining Loss: 1.370360 \tValidation Loss: 1.416680 \t time: 0.2\n",
      "Epoch: 366 \tTraining Loss: 1.369837 \tValidation Loss: 1.416413 \t time: 0.2\n",
      "Epoch: 367 \tTraining Loss: 1.370649 \tValidation Loss: 1.415547 \t time: 0.2\n",
      "Validation loss decreased from 1.415624 to 1.415547. Model was saved\n",
      "Epoch: 368 \tTraining Loss: 1.373183 \tValidation Loss: 1.415099 \t time: 0.2\n",
      "Validation loss decreased from 1.415547 to 1.415099. Model was saved\n",
      "Epoch: 369 \tTraining Loss: 1.370172 \tValidation Loss: 1.415143 \t time: 0.2\n",
      "Epoch: 370 \tTraining Loss: 1.370749 \tValidation Loss: 1.414932 \t time: 0.2\n",
      "Validation loss decreased from 1.415099 to 1.414932. Model was saved\n",
      "Epoch: 371 \tTraining Loss: 1.369056 \tValidation Loss: 1.414733 \t time: 0.2\n",
      "Validation loss decreased from 1.414932 to 1.414733. Model was saved\n",
      "Epoch: 372 \tTraining Loss: 1.370682 \tValidation Loss: 1.415151 \t time: 0.2\n",
      "Epoch: 373 \tTraining Loss: 1.366488 \tValidation Loss: 1.415719 \t time: 0.2\n",
      "Epoch: 374 \tTraining Loss: 1.368817 \tValidation Loss: 1.415802 \t time: 0.2\n",
      "Epoch: 375 \tTraining Loss: 1.367625 \tValidation Loss: 1.415334 \t time: 0.2\n",
      "Epoch: 376 \tTraining Loss: 1.369206 \tValidation Loss: 1.415431 \t time: 0.2\n",
      "Epoch: 377 \tTraining Loss: 1.367092 \tValidation Loss: 1.415902 \t time: 0.2\n",
      "Epoch: 378 \tTraining Loss: 1.369481 \tValidation Loss: 1.416071 \t time: 0.2\n",
      "Epoch: 379 \tTraining Loss: 1.368558 \tValidation Loss: 1.416264 \t time: 0.2\n",
      "Epoch: 380 \tTraining Loss: 1.365939 \tValidation Loss: 1.416407 \t time: 0.2\n",
      "Epoch: 381 \tTraining Loss: 1.367948 \tValidation Loss: 1.416107 \t time: 0.2\n",
      "Epoch: 382 \tTraining Loss: 1.366960 \tValidation Loss: 1.415112 \t time: 0.2\n",
      "Epoch: 383 \tTraining Loss: 1.367868 \tValidation Loss: 1.414695 \t time: 0.2\n",
      "Validation loss decreased from 1.414733 to 1.414695. Model was saved\n",
      "Epoch: 384 \tTraining Loss: 1.366133 \tValidation Loss: 1.414664 \t time: 0.2\n",
      "Validation loss decreased from 1.414695 to 1.414664. Model was saved\n",
      "Epoch: 385 \tTraining Loss: 1.366655 \tValidation Loss: 1.414627 \t time: 0.2\n",
      "Validation loss decreased from 1.414664 to 1.414627. Model was saved\n",
      "Epoch: 386 \tTraining Loss: 1.366021 \tValidation Loss: 1.414947 \t time: 0.2\n",
      "Epoch: 387 \tTraining Loss: 1.367120 \tValidation Loss: 1.415670 \t time: 0.2\n",
      "Epoch: 388 \tTraining Loss: 1.366181 \tValidation Loss: 1.415890 \t time: 0.2\n",
      "Epoch: 389 \tTraining Loss: 1.364342 \tValidation Loss: 1.415213 \t time: 0.2\n",
      "Epoch: 390 \tTraining Loss: 1.366965 \tValidation Loss: 1.414308 \t time: 0.2\n",
      "Validation loss decreased from 1.414627 to 1.414308. Model was saved\n",
      "Epoch: 391 \tTraining Loss: 1.364203 \tValidation Loss: 1.413920 \t time: 0.2\n",
      "Validation loss decreased from 1.414308 to 1.413920. Model was saved\n",
      "Epoch: 392 \tTraining Loss: 1.365319 \tValidation Loss: 1.414037 \t time: 0.2\n",
      "Epoch: 393 \tTraining Loss: 1.365089 \tValidation Loss: 1.414368 \t time: 0.2\n",
      "Epoch: 394 \tTraining Loss: 1.363588 \tValidation Loss: 1.415009 \t time: 0.2\n",
      "Epoch: 395 \tTraining Loss: 1.363404 \tValidation Loss: 1.415516 \t time: 0.2\n",
      "Epoch: 396 \tTraining Loss: 1.360847 \tValidation Loss: 1.414417 \t time: 0.2\n",
      "Epoch: 397 \tTraining Loss: 1.361907 \tValidation Loss: 1.413102 \t time: 0.2\n",
      "Validation loss decreased from 1.413920 to 1.413102. Model was saved\n",
      "Epoch: 398 \tTraining Loss: 1.362249 \tValidation Loss: 1.412179 \t time: 0.2\n",
      "Validation loss decreased from 1.413102 to 1.412179. Model was saved\n",
      "Epoch: 399 \tTraining Loss: 1.363077 \tValidation Loss: 1.412206 \t time: 0.2\n",
      "Epoch: 400 \tTraining Loss: 1.362300 \tValidation Loss: 1.413181 \t time: 0.2\n",
      "Epoch: 401 \tTraining Loss: 1.363690 \tValidation Loss: 1.414113 \t time: 0.2\n",
      "Epoch: 402 \tTraining Loss: 1.362525 \tValidation Loss: 1.414777 \t time: 0.2\n",
      "Epoch: 403 \tTraining Loss: 1.362252 \tValidation Loss: 1.415173 \t time: 0.2\n",
      "Epoch: 404 \tTraining Loss: 1.362338 \tValidation Loss: 1.414896 \t time: 0.2\n",
      "Epoch: 405 \tTraining Loss: 1.361183 \tValidation Loss: 1.414543 \t time: 0.2\n",
      "Epoch: 406 \tTraining Loss: 1.361598 \tValidation Loss: 1.413649 \t time: 0.2\n",
      "Epoch: 407 \tTraining Loss: 1.361225 \tValidation Loss: 1.413158 \t time: 0.2\n",
      "Epoch: 408 \tTraining Loss: 1.362461 \tValidation Loss: 1.413247 \t time: 0.2\n",
      "Epoch: 409 \tTraining Loss: 1.362978 \tValidation Loss: 1.413320 \t time: 0.2\n",
      "Epoch: 410 \tTraining Loss: 1.360268 \tValidation Loss: 1.413328 \t time: 0.2\n",
      "Epoch: 411 \tTraining Loss: 1.360379 \tValidation Loss: 1.413177 \t time: 0.2\n",
      "Epoch: 412 \tTraining Loss: 1.362041 \tValidation Loss: 1.412692 \t time: 0.2\n",
      "Epoch: 413 \tTraining Loss: 1.360432 \tValidation Loss: 1.412309 \t time: 0.2\n",
      "Epoch: 414 \tTraining Loss: 1.362426 \tValidation Loss: 1.412214 \t time: 0.2\n",
      "Epoch: 415 \tTraining Loss: 1.360007 \tValidation Loss: 1.412718 \t time: 0.2\n",
      "Epoch: 416 \tTraining Loss: 1.359442 \tValidation Loss: 1.413259 \t time: 0.2\n",
      "Epoch: 417 \tTraining Loss: 1.360670 \tValidation Loss: 1.413047 \t time: 0.2\n",
      "Epoch: 418 \tTraining Loss: 1.361378 \tValidation Loss: 1.413133 \t time: 0.2\n",
      "Epoch: 419 \tTraining Loss: 1.360297 \tValidation Loss: 1.413312 \t time: 0.2\n",
      "Epoch: 420 \tTraining Loss: 1.357398 \tValidation Loss: 1.413373 \t time: 0.2\n",
      "Epoch: 421 \tTraining Loss: 1.360334 \tValidation Loss: 1.413186 \t time: 0.2\n",
      "Epoch: 422 \tTraining Loss: 1.356763 \tValidation Loss: 1.413052 \t time: 0.2\n",
      "Epoch: 423 \tTraining Loss: 1.358232 \tValidation Loss: 1.412803 \t time: 0.2\n",
      "Epoch: 424 \tTraining Loss: 1.358785 \tValidation Loss: 1.412630 \t time: 0.2\n",
      "Epoch: 425 \tTraining Loss: 1.357947 \tValidation Loss: 1.412785 \t time: 0.2\n",
      "Epoch: 426 \tTraining Loss: 1.358295 \tValidation Loss: 1.412695 \t time: 0.2\n",
      "Epoch: 427 \tTraining Loss: 1.357842 \tValidation Loss: 1.412458 \t time: 0.2\n",
      "Epoch: 428 \tTraining Loss: 1.356309 \tValidation Loss: 1.411916 \t time: 0.2\n",
      "Validation loss decreased from 1.412179 to 1.411916. Model was saved\n",
      "Epoch: 429 \tTraining Loss: 1.357376 \tValidation Loss: 1.411484 \t time: 0.2\n",
      "Validation loss decreased from 1.411916 to 1.411484. Model was saved\n",
      "Epoch: 430 \tTraining Loss: 1.356922 \tValidation Loss: 1.411643 \t time: 0.2\n",
      "Epoch: 431 \tTraining Loss: 1.355422 \tValidation Loss: 1.411779 \t time: 0.2\n",
      "Epoch: 432 \tTraining Loss: 1.357262 \tValidation Loss: 1.411929 \t time: 0.2\n",
      "Epoch: 433 \tTraining Loss: 1.357860 \tValidation Loss: 1.411625 \t time: 0.2\n",
      "Epoch: 434 \tTraining Loss: 1.356917 \tValidation Loss: 1.411160 \t time: 0.2\n",
      "Validation loss decreased from 1.411484 to 1.411160. Model was saved\n",
      "Epoch: 435 \tTraining Loss: 1.356322 \tValidation Loss: 1.410936 \t time: 0.2\n",
      "Validation loss decreased from 1.411160 to 1.410936. Model was saved\n",
      "Epoch: 436 \tTraining Loss: 1.357522 \tValidation Loss: 1.410477 \t time: 0.2\n",
      "Validation loss decreased from 1.410936 to 1.410477. Model was saved\n",
      "Epoch: 437 \tTraining Loss: 1.360995 \tValidation Loss: 1.410276 \t time: 0.2\n",
      "Validation loss decreased from 1.410477 to 1.410276. Model was saved\n",
      "Epoch: 438 \tTraining Loss: 1.356872 \tValidation Loss: 1.410244 \t time: 0.2\n",
      "Validation loss decreased from 1.410276 to 1.410244. Model was saved\n",
      "Epoch: 439 \tTraining Loss: 1.356087 \tValidation Loss: 1.410586 \t time: 0.2\n",
      "Epoch: 440 \tTraining Loss: 1.355493 \tValidation Loss: 1.410814 \t time: 0.2\n",
      "Epoch: 441 \tTraining Loss: 1.355378 \tValidation Loss: 1.410969 \t time: 0.2\n",
      "Epoch: 442 \tTraining Loss: 1.354967 \tValidation Loss: 1.411174 \t time: 0.2\n",
      "Epoch: 443 \tTraining Loss: 1.354059 \tValidation Loss: 1.411330 \t time: 0.2\n",
      "Epoch: 444 \tTraining Loss: 1.355530 \tValidation Loss: 1.411144 \t time: 0.2\n",
      "Epoch: 445 \tTraining Loss: 1.354934 \tValidation Loss: 1.410932 \t time: 0.2\n",
      "Epoch: 446 \tTraining Loss: 1.355497 \tValidation Loss: 1.410615 \t time: 0.2\n",
      "Epoch: 447 \tTraining Loss: 1.356004 \tValidation Loss: 1.410280 \t time: 0.2\n",
      "Epoch: 448 \tTraining Loss: 1.355583 \tValidation Loss: 1.409569 \t time: 0.2\n",
      "Validation loss decreased from 1.410244 to 1.409569. Model was saved\n",
      "Epoch: 449 \tTraining Loss: 1.357314 \tValidation Loss: 1.409208 \t time: 0.2\n",
      "Validation loss decreased from 1.409569 to 1.409208. Model was saved\n",
      "Epoch: 450 \tTraining Loss: 1.351895 \tValidation Loss: 1.409510 \t time: 0.2\n",
      "Epoch: 451 \tTraining Loss: 1.349441 \tValidation Loss: 1.410173 \t time: 0.2\n",
      "Epoch: 452 \tTraining Loss: 1.354351 \tValidation Loss: 1.410961 \t time: 0.2\n",
      "Epoch: 453 \tTraining Loss: 1.352968 \tValidation Loss: 1.411805 \t time: 0.2\n",
      "Epoch: 454 \tTraining Loss: 1.354506 \tValidation Loss: 1.412080 \t time: 0.2\n",
      "Epoch: 455 \tTraining Loss: 1.354356 \tValidation Loss: 1.411575 \t time: 0.2\n",
      "Epoch: 456 \tTraining Loss: 1.352474 \tValidation Loss: 1.411110 \t time: 0.2\n",
      "Epoch: 457 \tTraining Loss: 1.351908 \tValidation Loss: 1.410273 \t time: 0.2\n",
      "Epoch: 458 \tTraining Loss: 1.351408 \tValidation Loss: 1.409602 \t time: 0.2\n",
      "Epoch: 459 \tTraining Loss: 1.352771 \tValidation Loss: 1.409399 \t time: 0.2\n",
      "Epoch: 460 \tTraining Loss: 1.351120 \tValidation Loss: 1.409245 \t time: 0.2\n",
      "Epoch: 461 \tTraining Loss: 1.352962 \tValidation Loss: 1.409364 \t time: 0.2\n",
      "Epoch: 462 \tTraining Loss: 1.353039 \tValidation Loss: 1.409264 \t time: 0.2\n",
      "Epoch: 463 \tTraining Loss: 1.351371 \tValidation Loss: 1.409426 \t time: 0.2\n",
      "Epoch: 464 \tTraining Loss: 1.352042 \tValidation Loss: 1.409495 \t time: 0.2\n",
      "Epoch: 465 \tTraining Loss: 1.352174 \tValidation Loss: 1.409408 \t time: 0.2\n",
      "Epoch: 466 \tTraining Loss: 1.351142 \tValidation Loss: 1.409041 \t time: 0.2\n",
      "Validation loss decreased from 1.409208 to 1.409041. Model was saved\n",
      "Epoch: 467 \tTraining Loss: 1.350065 \tValidation Loss: 1.408296 \t time: 0.2\n",
      "Validation loss decreased from 1.409041 to 1.408296. Model was saved\n",
      "Epoch: 468 \tTraining Loss: 1.348529 \tValidation Loss: 1.407366 \t time: 0.2\n",
      "Validation loss decreased from 1.408296 to 1.407366. Model was saved\n",
      "Epoch: 469 \tTraining Loss: 1.350061 \tValidation Loss: 1.406944 \t time: 0.2\n",
      "Validation loss decreased from 1.407366 to 1.406944. Model was saved\n",
      "Epoch: 470 \tTraining Loss: 1.352122 \tValidation Loss: 1.406923 \t time: 0.2\n",
      "Validation loss decreased from 1.406944 to 1.406923. Model was saved\n",
      "Epoch: 471 \tTraining Loss: 1.348698 \tValidation Loss: 1.407363 \t time: 0.2\n",
      "Epoch: 472 \tTraining Loss: 1.350255 \tValidation Loss: 1.408023 \t time: 0.2\n",
      "Epoch: 473 \tTraining Loss: 1.349376 \tValidation Loss: 1.408689 \t time: 0.2\n",
      "Epoch: 474 \tTraining Loss: 1.349799 \tValidation Loss: 1.408657 \t time: 0.2\n",
      "Epoch: 475 \tTraining Loss: 1.349862 \tValidation Loss: 1.408542 \t time: 0.2\n",
      "Epoch: 476 \tTraining Loss: 1.349888 \tValidation Loss: 1.407684 \t time: 0.2\n",
      "Epoch: 477 \tTraining Loss: 1.349487 \tValidation Loss: 1.406665 \t time: 0.2\n",
      "Validation loss decreased from 1.406923 to 1.406665. Model was saved\n",
      "Epoch: 478 \tTraining Loss: 1.347526 \tValidation Loss: 1.405749 \t time: 0.2\n",
      "Validation loss decreased from 1.406665 to 1.405749. Model was saved\n",
      "Epoch: 479 \tTraining Loss: 1.349242 \tValidation Loss: 1.405501 \t time: 0.2\n",
      "Validation loss decreased from 1.405749 to 1.405501. Model was saved\n",
      "Epoch: 480 \tTraining Loss: 1.350062 \tValidation Loss: 1.405959 \t time: 0.2\n",
      "Epoch: 481 \tTraining Loss: 1.347678 \tValidation Loss: 1.406800 \t time: 0.2\n",
      "Epoch: 482 \tTraining Loss: 1.350632 \tValidation Loss: 1.407356 \t time: 0.2\n",
      "Epoch: 483 \tTraining Loss: 1.347450 \tValidation Loss: 1.407590 \t time: 0.2\n",
      "Epoch: 484 \tTraining Loss: 1.349307 \tValidation Loss: 1.406794 \t time: 0.3\n",
      "Epoch: 485 \tTraining Loss: 1.347574 \tValidation Loss: 1.405448 \t time: 0.2\n",
      "Validation loss decreased from 1.405501 to 1.405448. Model was saved\n",
      "Epoch: 486 \tTraining Loss: 1.346973 \tValidation Loss: 1.404669 \t time: 0.2\n",
      "Validation loss decreased from 1.405448 to 1.404669. Model was saved\n",
      "Epoch: 487 \tTraining Loss: 1.348703 \tValidation Loss: 1.404509 \t time: 0.2\n",
      "Validation loss decreased from 1.404669 to 1.404509. Model was saved\n",
      "Epoch: 488 \tTraining Loss: 1.347011 \tValidation Loss: 1.404154 \t time: 0.2\n",
      "Validation loss decreased from 1.404509 to 1.404154. Model was saved\n",
      "Epoch: 489 \tTraining Loss: 1.347756 \tValidation Loss: 1.403258 \t time: 0.2\n",
      "Validation loss decreased from 1.404154 to 1.403258. Model was saved\n",
      "Epoch: 490 \tTraining Loss: 1.348775 \tValidation Loss: 1.403022 \t time: 0.2\n",
      "Validation loss decreased from 1.403258 to 1.403022. Model was saved\n",
      "Epoch: 491 \tTraining Loss: 1.348642 \tValidation Loss: 1.403575 \t time: 0.2\n",
      "Epoch: 492 \tTraining Loss: 1.346731 \tValidation Loss: 1.404280 \t time: 0.2\n",
      "Epoch: 493 \tTraining Loss: 1.346510 \tValidation Loss: 1.404529 \t time: 0.2\n",
      "Epoch: 494 \tTraining Loss: 1.346303 \tValidation Loss: 1.404685 \t time: 0.2\n",
      "Epoch: 495 \tTraining Loss: 1.344290 \tValidation Loss: 1.404763 \t time: 0.2\n",
      "Epoch: 496 \tTraining Loss: 1.344959 \tValidation Loss: 1.405032 \t time: 0.2\n",
      "Epoch: 497 \tTraining Loss: 1.348849 \tValidation Loss: 1.405156 \t time: 0.2\n",
      "Epoch: 498 \tTraining Loss: 1.343321 \tValidation Loss: 1.405566 \t time: 0.2\n",
      "Epoch: 499 \tTraining Loss: 1.346863 \tValidation Loss: 1.405584 \t time: 0.2\n",
      "Epoch: 500 \tTraining Loss: 1.346202 \tValidation Loss: 1.405644 \t time: 0.2\n",
      "Epoch: 501 \tTraining Loss: 1.345308 \tValidation Loss: 1.404875 \t time: 0.2\n",
      "Epoch: 502 \tTraining Loss: 1.342459 \tValidation Loss: 1.404195 \t time: 0.2\n",
      "Epoch: 503 \tTraining Loss: 1.347032 \tValidation Loss: 1.404472 \t time: 0.2\n",
      "Epoch: 504 \tTraining Loss: 1.345506 \tValidation Loss: 1.405074 \t time: 0.2\n",
      "Epoch: 505 \tTraining Loss: 1.344607 \tValidation Loss: 1.406071 \t time: 0.2\n",
      "Epoch: 506 \tTraining Loss: 1.346146 \tValidation Loss: 1.406802 \t time: 0.2\n",
      "Epoch: 507 \tTraining Loss: 1.342511 \tValidation Loss: 1.406452 \t time: 0.2\n",
      "Epoch: 508 \tTraining Loss: 1.343584 \tValidation Loss: 1.405259 \t time: 0.2\n",
      "Epoch: 509 \tTraining Loss: 1.342907 \tValidation Loss: 1.404100 \t time: 0.2\n",
      "Epoch: 510 \tTraining Loss: 1.344218 \tValidation Loss: 1.403838 \t time: 0.2\n",
      "Epoch: 511 \tTraining Loss: 1.342085 \tValidation Loss: 1.403927 \t time: 0.2\n",
      "Epoch: 512 \tTraining Loss: 1.343699 \tValidation Loss: 1.404111 \t time: 0.2\n",
      "Epoch: 513 \tTraining Loss: 1.344525 \tValidation Loss: 1.404280 \t time: 0.2\n",
      "Epoch: 514 \tTraining Loss: 1.343863 \tValidation Loss: 1.404095 \t time: 0.2\n",
      "Epoch: 515 \tTraining Loss: 1.343117 \tValidation Loss: 1.404114 \t time: 0.2\n",
      "Epoch: 516 \tTraining Loss: 1.340540 \tValidation Loss: 1.404171 \t time: 0.2\n",
      "Epoch: 517 \tTraining Loss: 1.341327 \tValidation Loss: 1.403609 \t time: 0.2\n",
      "Epoch: 518 \tTraining Loss: 1.343426 \tValidation Loss: 1.402909 \t time: 0.2\n",
      "Validation loss decreased from 1.403022 to 1.402909. Model was saved\n",
      "Epoch: 519 \tTraining Loss: 1.343185 \tValidation Loss: 1.402806 \t time: 0.2\n",
      "Validation loss decreased from 1.402909 to 1.402806. Model was saved\n",
      "Epoch: 520 \tTraining Loss: 1.339888 \tValidation Loss: 1.403320 \t time: 0.2\n",
      "Epoch: 521 \tTraining Loss: 1.343553 \tValidation Loss: 1.403944 \t time: 0.2\n",
      "Epoch: 522 \tTraining Loss: 1.341457 \tValidation Loss: 1.404424 \t time: 0.2\n",
      "Epoch: 523 \tTraining Loss: 1.340778 \tValidation Loss: 1.404041 \t time: 0.2\n",
      "Epoch: 524 \tTraining Loss: 1.343039 \tValidation Loss: 1.403300 \t time: 0.2\n",
      "Epoch: 525 \tTraining Loss: 1.340990 \tValidation Loss: 1.402726 \t time: 0.2\n",
      "Validation loss decreased from 1.402806 to 1.402726. Model was saved\n",
      "Epoch: 526 \tTraining Loss: 1.343570 \tValidation Loss: 1.402521 \t time: 0.2\n",
      "Validation loss decreased from 1.402726 to 1.402521. Model was saved\n",
      "Epoch: 527 \tTraining Loss: 1.340301 \tValidation Loss: 1.402738 \t time: 0.2\n",
      "Epoch: 528 \tTraining Loss: 1.340330 \tValidation Loss: 1.402861 \t time: 0.2\n",
      "Epoch: 529 \tTraining Loss: 1.341722 \tValidation Loss: 1.402812 \t time: 0.2\n",
      "Epoch: 530 \tTraining Loss: 1.338960 \tValidation Loss: 1.402397 \t time: 0.2\n",
      "Validation loss decreased from 1.402521 to 1.402397. Model was saved\n",
      "Epoch: 531 \tTraining Loss: 1.338846 \tValidation Loss: 1.401985 \t time: 0.2\n",
      "Validation loss decreased from 1.402397 to 1.401985. Model was saved\n",
      "Epoch: 532 \tTraining Loss: 1.341805 \tValidation Loss: 1.401729 \t time: 0.2\n",
      "Validation loss decreased from 1.401985 to 1.401729. Model was saved\n",
      "Epoch: 533 \tTraining Loss: 1.342967 \tValidation Loss: 1.401657 \t time: 0.2\n",
      "Validation loss decreased from 1.401729 to 1.401657. Model was saved\n",
      "Epoch: 534 \tTraining Loss: 1.341066 \tValidation Loss: 1.401946 \t time: 0.2\n",
      "Epoch: 535 \tTraining Loss: 1.340471 \tValidation Loss: 1.402697 \t time: 0.2\n",
      "Epoch: 536 \tTraining Loss: 1.340245 \tValidation Loss: 1.403270 \t time: 0.2\n",
      "Epoch: 537 \tTraining Loss: 1.339758 \tValidation Loss: 1.403263 \t time: 0.2\n",
      "Epoch: 538 \tTraining Loss: 1.338342 \tValidation Loss: 1.402932 \t time: 0.2\n",
      "Epoch: 539 \tTraining Loss: 1.340084 \tValidation Loss: 1.402329 \t time: 0.2\n",
      "Epoch: 540 \tTraining Loss: 1.339172 \tValidation Loss: 1.402309 \t time: 0.2\n",
      "Epoch: 541 \tTraining Loss: 1.337649 \tValidation Loss: 1.402573 \t time: 0.2\n",
      "Epoch: 542 \tTraining Loss: 1.339213 \tValidation Loss: 1.402994 \t time: 0.2\n",
      "Epoch: 543 \tTraining Loss: 1.338480 \tValidation Loss: 1.403317 \t time: 0.2\n",
      "Epoch: 544 \tTraining Loss: 1.339128 \tValidation Loss: 1.403085 \t time: 0.2\n",
      "Epoch: 545 \tTraining Loss: 1.337221 \tValidation Loss: 1.402865 \t time: 0.2\n",
      "Epoch: 546 \tTraining Loss: 1.337122 \tValidation Loss: 1.402311 \t time: 0.2\n",
      "Epoch: 547 \tTraining Loss: 1.339050 \tValidation Loss: 1.402005 \t time: 0.2\n",
      "Epoch: 548 \tTraining Loss: 1.336921 \tValidation Loss: 1.402338 \t time: 0.2\n",
      "Epoch: 549 \tTraining Loss: 1.338452 \tValidation Loss: 1.403479 \t time: 0.2\n",
      "Epoch: 550 \tTraining Loss: 1.336415 \tValidation Loss: 1.404325 \t time: 0.2\n",
      "Epoch: 551 \tTraining Loss: 1.337525 \tValidation Loss: 1.403850 \t time: 0.2\n",
      "Epoch: 552 \tTraining Loss: 1.334921 \tValidation Loss: 1.402560 \t time: 0.2\n",
      "Epoch: 553 \tTraining Loss: 1.336331 \tValidation Loss: 1.401661 \t time: 0.2\n",
      "Epoch: 554 \tTraining Loss: 1.335588 \tValidation Loss: 1.400907 \t time: 0.2\n",
      "Validation loss decreased from 1.401657 to 1.400907. Model was saved\n",
      "Epoch: 555 \tTraining Loss: 1.335813 \tValidation Loss: 1.400933 \t time: 0.2\n",
      "Epoch: 556 \tTraining Loss: 1.336302 \tValidation Loss: 1.400999 \t time: 0.2\n",
      "Epoch: 557 \tTraining Loss: 1.337946 \tValidation Loss: 1.400945 \t time: 0.2\n",
      "Epoch: 558 \tTraining Loss: 1.335410 \tValidation Loss: 1.400554 \t time: 0.2\n",
      "Validation loss decreased from 1.400907 to 1.400554. Model was saved\n",
      "Epoch: 559 \tTraining Loss: 1.337031 \tValidation Loss: 1.400020 \t time: 0.2\n",
      "Validation loss decreased from 1.400554 to 1.400020. Model was saved\n",
      "Epoch: 560 \tTraining Loss: 1.336908 \tValidation Loss: 1.399689 \t time: 0.2\n",
      "Validation loss decreased from 1.400020 to 1.399689. Model was saved\n",
      "Epoch: 561 \tTraining Loss: 1.335024 \tValidation Loss: 1.399610 \t time: 0.2\n",
      "Validation loss decreased from 1.399689 to 1.399610. Model was saved\n",
      "Epoch: 562 \tTraining Loss: 1.337130 \tValidation Loss: 1.399914 \t time: 0.2\n",
      "Epoch: 563 \tTraining Loss: 1.334060 \tValidation Loss: 1.400157 \t time: 0.2\n",
      "Epoch: 564 \tTraining Loss: 1.332833 \tValidation Loss: 1.399955 \t time: 0.2\n",
      "Epoch: 565 \tTraining Loss: 1.338893 \tValidation Loss: 1.398994 \t time: 0.2\n",
      "Validation loss decreased from 1.399610 to 1.398994. Model was saved\n",
      "Epoch: 566 \tTraining Loss: 1.335598 \tValidation Loss: 1.397997 \t time: 0.2\n",
      "Validation loss decreased from 1.398994 to 1.397997. Model was saved\n",
      "Epoch: 567 \tTraining Loss: 1.336905 \tValidation Loss: 1.397525 \t time: 0.2\n",
      "Validation loss decreased from 1.397997 to 1.397525. Model was saved\n",
      "Epoch: 568 \tTraining Loss: 1.334794 \tValidation Loss: 1.397439 \t time: 0.2\n",
      "Validation loss decreased from 1.397525 to 1.397439. Model was saved\n",
      "Epoch: 569 \tTraining Loss: 1.335420 \tValidation Loss: 1.397794 \t time: 0.2\n",
      "Epoch: 570 \tTraining Loss: 1.335653 \tValidation Loss: 1.398369 \t time: 0.2\n",
      "Epoch: 571 \tTraining Loss: 1.333454 \tValidation Loss: 1.399084 \t time: 0.2\n",
      "Epoch: 572 \tTraining Loss: 1.333314 \tValidation Loss: 1.399292 \t time: 0.2\n",
      "Epoch: 573 \tTraining Loss: 1.332916 \tValidation Loss: 1.399277 \t time: 0.2\n",
      "Epoch: 574 \tTraining Loss: 1.334753 \tValidation Loss: 1.399006 \t time: 0.2\n",
      "Epoch: 575 \tTraining Loss: 1.334064 \tValidation Loss: 1.398350 \t time: 0.2\n",
      "Epoch: 576 \tTraining Loss: 1.334559 \tValidation Loss: 1.397360 \t time: 0.2\n",
      "Validation loss decreased from 1.397439 to 1.397360. Model was saved\n",
      "Epoch: 577 \tTraining Loss: 1.335706 \tValidation Loss: 1.396967 \t time: 0.2\n",
      "Validation loss decreased from 1.397360 to 1.396967. Model was saved\n",
      "Epoch: 578 \tTraining Loss: 1.336289 \tValidation Loss: 1.397241 \t time: 0.2\n",
      "Epoch: 579 \tTraining Loss: 1.332197 \tValidation Loss: 1.397450 \t time: 0.2\n",
      "Epoch: 580 \tTraining Loss: 1.335553 \tValidation Loss: 1.397252 \t time: 0.2\n",
      "Epoch: 581 \tTraining Loss: 1.333855 \tValidation Loss: 1.396850 \t time: 0.2\n",
      "Validation loss decreased from 1.396967 to 1.396850. Model was saved\n",
      "Epoch: 582 \tTraining Loss: 1.333741 \tValidation Loss: 1.396406 \t time: 0.2\n",
      "Validation loss decreased from 1.396850 to 1.396406. Model was saved\n",
      "Epoch: 583 \tTraining Loss: 1.331396 \tValidation Loss: 1.396099 \t time: 0.2\n",
      "Validation loss decreased from 1.396406 to 1.396099. Model was saved\n",
      "Epoch: 584 \tTraining Loss: 1.331697 \tValidation Loss: 1.395495 \t time: 0.2\n",
      "Validation loss decreased from 1.396099 to 1.395495. Model was saved\n",
      "Epoch: 585 \tTraining Loss: 1.330400 \tValidation Loss: 1.395465 \t time: 0.2\n",
      "Validation loss decreased from 1.395495 to 1.395465. Model was saved\n",
      "Epoch: 586 \tTraining Loss: 1.332099 \tValidation Loss: 1.395146 \t time: 0.2\n",
      "Validation loss decreased from 1.395465 to 1.395146. Model was saved\n",
      "Epoch: 587 \tTraining Loss: 1.330392 \tValidation Loss: 1.394699 \t time: 0.2\n",
      "Validation loss decreased from 1.395146 to 1.394699. Model was saved\n",
      "Epoch: 588 \tTraining Loss: 1.329470 \tValidation Loss: 1.394391 \t time: 0.2\n",
      "Validation loss decreased from 1.394699 to 1.394391. Model was saved\n",
      "Epoch: 589 \tTraining Loss: 1.332455 \tValidation Loss: 1.394585 \t time: 0.2\n",
      "Epoch: 590 \tTraining Loss: 1.330893 \tValidation Loss: 1.394697 \t time: 0.2\n",
      "Epoch: 591 \tTraining Loss: 1.330625 \tValidation Loss: 1.394832 \t time: 0.2\n",
      "Epoch: 592 \tTraining Loss: 1.330457 \tValidation Loss: 1.394934 \t time: 0.2\n",
      "Epoch: 593 \tTraining Loss: 1.329824 \tValidation Loss: 1.395018 \t time: 0.2\n",
      "Epoch: 594 \tTraining Loss: 1.328519 \tValidation Loss: 1.395004 \t time: 0.2\n",
      "Epoch: 595 \tTraining Loss: 1.328421 \tValidation Loss: 1.395164 \t time: 0.2\n",
      "Epoch: 596 \tTraining Loss: 1.328848 \tValidation Loss: 1.394567 \t time: 0.2\n",
      "Epoch: 597 \tTraining Loss: 1.329930 \tValidation Loss: 1.393820 \t time: 0.2\n",
      "Validation loss decreased from 1.394391 to 1.393820. Model was saved\n",
      "Epoch: 598 \tTraining Loss: 1.330502 \tValidation Loss: 1.393258 \t time: 0.2\n",
      "Validation loss decreased from 1.393820 to 1.393258. Model was saved\n",
      "Epoch: 599 \tTraining Loss: 1.327927 \tValidation Loss: 1.393289 \t time: 0.2\n",
      "Epoch: 600 \tTraining Loss: 1.328703 \tValidation Loss: 1.393281 \t time: 0.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(600, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.399778\n",
      "\n",
      "\n",
      "Test Accuracy: 57% (112/194)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 5, 3, 1, 2, 5, 1, 1, 3, 1, 3, 5, 5, 3, 5, 5, 0, 3, 5, 5,\n",
       "       2, 5, 0, 3, 3, 2, 5, 5, 3, 2, 2, 5, 3, 2, 3, 5, 0, 0, 1, 3, 5, 3,\n",
       "       5, 5, 1, 5, 0, 3, 2, 5, 0, 0, 3, 3, 0, 3, 0, 1, 1, 1, 3, 3, 3, 3,\n",
       "       5, 5, 3, 3, 2, 0, 2, 1, 2, 3, 0, 2, 3, 5, 3, 5, 3, 5, 0, 0, 3, 2,\n",
       "       3, 5, 5, 3, 2, 3, 5, 3, 1, 3, 5, 3, 2, 5, 3, 3, 3, 1, 5, 5, 2, 3,\n",
       "       5, 5, 1, 5, 5, 3, 3, 3, 3, 5, 5, 3, 5, 3, 1, 3, 1, 2, 3, 0, 1, 1,\n",
       "       0, 3, 2, 2, 3, 0, 2, 0, 5, 0, 3, 3, 0, 1, 3, 2, 0, 2, 3, 5, 2, 5,\n",
       "       1, 0, 5, 1, 3, 5, 1, 0, 0, 1, 0, 2, 0, 2, 0, 5, 2, 2, 0, 5, 3, 3,\n",
       "       3, 3, 0, 3, 3, 1, 0, 3, 3, 5, 3, 3, 1, 5, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,l = next(iter(loaders['test']))\n",
    "if use_cuda:\n",
    "    i, l = i.cuda(), l.cuda()\n",
    "\n",
    "output = model(i)\n",
    "\n",
    "result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([31.,  0., 27.,  0., 27.,  0., 63.,  0.,  0., 46.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = result[:,0]\n",
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32.,  0., 32.,  0., 32.,  0., 32.,  0., 33., 33.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
