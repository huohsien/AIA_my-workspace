{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6\n",
    "# how many data per batch to load\n",
    "batch_size = 20000\n",
    "# data split ratio\n",
    "train_ratio = 0.97\n",
    "test_ratio = 0.1\n",
    "\n",
    "n_epochs = 4000\n",
    "\n",
    "lr=0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Counter({'class_0': 1611, 'class_2': 1478, 'class_5': 1411, 'class_1': 920, 'class_3': 889, 'class_4': 851})\n",
      "After:\n",
      "Counter({'class_0': 1611, 'class_1': 1611, 'class_2': 1611, 'class_3': 1611, 'class_4': 1611, 'class_5': 1611})\n"
     ]
    }
   ],
   "source": [
    "# make number of data for each class equal\n",
    "#\n",
    "from collections import Counter\n",
    "\n",
    "class_counter = Counter()\n",
    "\n",
    "class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('Before:')\n",
    "print(class_counter)\n",
    "\n",
    "max_count = -np.Inf\n",
    "for i in range(number_of_class):\n",
    "    if class_counter['class_' + str(i)] > max_count:\n",
    "        max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "    num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "    num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "    for j in range(num_resample_batch):\n",
    "        add_df = train_classified[i]\n",
    "        train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "        train =  train.append(df_to_be_added)\n",
    "        \n",
    "    df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "    train =  train.append(df_to_be_added)\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    class_counter['class_' + str(i)] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('After:')\n",
    "print(class_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9666, 297)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "# features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9376, 297), (261, 297), (29, 297))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "# a =plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 180)\n",
    "        self.fc2 = nn.Linear(180, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "#             print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "#         print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tValidation loss decreased from inf to 1.807453. Model was saved\n",
      "Epoch: 2 \tValidation loss decreased from 1.807453 to 1.799412. Model was saved\n",
      "Epoch: 3 \tValidation loss decreased from 1.799412 to 1.793509. Model was saved\n",
      "Epoch: 4 \tValidation loss decreased from 1.793509 to 1.790486. Model was saved\n",
      "Epoch: 5 \tValidation loss decreased from 1.790486 to 1.788663. Model was saved\n",
      "Epoch: 6 \tValidation loss decreased from 1.788663 to 1.786110. Model was saved\n",
      "Epoch: 7 \tValidation loss decreased from 1.786110 to 1.782421. Model was saved\n",
      "Epoch: 8 \tValidation loss decreased from 1.782421 to 1.777402. Model was saved\n",
      "Epoch: 9 \tValidation loss decreased from 1.777402 to 1.770323. Model was saved\n",
      "Epoch: 10 \tValidation loss decreased from 1.770323 to 1.761039. Model was saved\n",
      "Epoch: 11 \tValidation loss decreased from 1.761039 to 1.750442. Model was saved\n",
      "Epoch: 12 \tValidation loss decreased from 1.750442 to 1.739094. Model was saved\n",
      "Epoch: 13 \tValidation loss decreased from 1.739094 to 1.726147. Model was saved\n",
      "Epoch: 14 \tValidation loss decreased from 1.726147 to 1.712509. Model was saved\n",
      "Epoch: 15 \tValidation loss decreased from 1.712509 to 1.700833. Model was saved\n",
      "Epoch: 16 \tValidation loss decreased from 1.700833 to 1.689630. Model was saved\n",
      "Epoch: 17 \tValidation loss decreased from 1.689630 to 1.677098. Model was saved\n",
      "Epoch: 18 \tValidation loss decreased from 1.677098 to 1.664830. Model was saved\n",
      "Epoch: 19 \tValidation loss decreased from 1.664830 to 1.653159. Model was saved\n",
      "Epoch: 20 \tValidation loss decreased from 1.653159 to 1.643754. Model was saved\n",
      "Epoch: 21 \tValidation loss decreased from 1.643754 to 1.635466. Model was saved\n",
      "Epoch: 22 \tValidation loss decreased from 1.635466 to 1.624199. Model was saved\n",
      "Epoch: 23 \tValidation loss decreased from 1.624199 to 1.611796. Model was saved\n",
      "Epoch: 24 \tValidation loss decreased from 1.611796 to 1.601693. Model was saved\n",
      "Epoch: 25 \tValidation loss decreased from 1.601693 to 1.592652. Model was saved\n",
      "Epoch: 26 \tValidation loss decreased from 1.592652 to 1.584738. Model was saved\n",
      "Epoch: 27 \tValidation loss decreased from 1.584738 to 1.576932. Model was saved\n",
      "Epoch: 28 \tValidation loss decreased from 1.576932 to 1.570755. Model was saved\n",
      "Epoch: 29 \tValidation loss decreased from 1.570755 to 1.565545. Model was saved\n",
      "Epoch: 30 \tValidation loss decreased from 1.565545 to 1.558663. Model was saved\n",
      "Epoch: 31 \tValidation loss decreased from 1.558663 to 1.552163. Model was saved\n",
      "Epoch: 32 \tValidation loss decreased from 1.552163 to 1.547602. Model was saved\n",
      "Epoch: 33 \tValidation loss decreased from 1.547602 to 1.544942. Model was saved\n",
      "Epoch: 34 \tValidation loss decreased from 1.544942 to 1.542417. Model was saved\n",
      "Epoch: 35 \tValidation loss decreased from 1.542417 to 1.538779. Model was saved\n",
      "Epoch: 36 \tValidation loss decreased from 1.538779 to 1.535196. Model was saved\n",
      "Epoch: 37 \tValidation loss decreased from 1.535196 to 1.533448. Model was saved\n",
      "Epoch: 38 \tValidation loss decreased from 1.533448 to 1.532277. Model was saved\n",
      "Epoch: 39 \tValidation loss decreased from 1.532277 to 1.530317. Model was saved\n",
      "Epoch: 40 \tValidation loss decreased from 1.530317 to 1.528395. Model was saved\n",
      "Epoch: 41 \tValidation loss decreased from 1.528395 to 1.527364. Model was saved\n",
      "Epoch: 43 \tValidation loss decreased from 1.527364 to 1.527157. Model was saved\n",
      "Epoch: 44 \tValidation loss decreased from 1.527157 to 1.526784. Model was saved\n",
      "Epoch: 45 \tValidation loss decreased from 1.526784 to 1.526483. Model was saved\n",
      "Epoch: 46 \tValidation loss decreased from 1.526483 to 1.526027. Model was saved\n",
      "Epoch: 47 \tValidation loss decreased from 1.526027 to 1.525404. Model was saved\n",
      "Epoch: 48 \tValidation loss decreased from 1.525404 to 1.524338. Model was saved\n",
      "Epoch: 49 \tValidation loss decreased from 1.524338 to 1.523508. Model was saved\n",
      "Epoch: 50 \tValidation loss decreased from 1.523508 to 1.523286. Model was saved\n",
      "Epoch: 51 \tValidation loss decreased from 1.523286 to 1.523186. Model was saved\n",
      "Epoch: 52 \tValidation loss decreased from 1.523186 to 1.523042. Model was saved\n",
      "Epoch: 53 \tValidation loss decreased from 1.523042 to 1.522591. Model was saved\n",
      "Epoch: 54 \tValidation loss decreased from 1.522591 to 1.521631. Model was saved\n",
      "Epoch: 55 \tValidation loss decreased from 1.521631 to 1.520769. Model was saved\n",
      "Epoch: 56 \tValidation loss decreased from 1.520769 to 1.520148. Model was saved\n",
      "Epoch: 57 \tValidation loss decreased from 1.520148 to 1.519123. Model was saved\n",
      "Epoch: 58 \tValidation loss decreased from 1.519123 to 1.518490. Model was saved\n",
      "Epoch: 59 \tValidation loss decreased from 1.518490 to 1.518324. Model was saved\n",
      "Epoch: 60 \tValidation loss decreased from 1.518324 to 1.517427. Model was saved\n",
      "Epoch: 61 \tValidation loss decreased from 1.517427 to 1.516621. Model was saved\n",
      "Epoch: 62 \tValidation loss decreased from 1.516621 to 1.516223. Model was saved\n",
      "Epoch: 63 \tValidation loss decreased from 1.516223 to 1.515463. Model was saved\n",
      "Epoch: 79 \tValidation loss decreased from 1.515463 to 1.514800. Model was saved\n",
      "Epoch: 80 \tValidation loss decreased from 1.514800 to 1.513709. Model was saved\n",
      "Epoch: 81 \tValidation loss decreased from 1.513709 to 1.512756. Model was saved\n",
      "Epoch: 82 \tValidation loss decreased from 1.512756 to 1.511640. Model was saved\n",
      "Epoch: 83 \tValidation loss decreased from 1.511640 to 1.510351. Model was saved\n",
      "Epoch: 84 \tValidation loss decreased from 1.510351 to 1.509477. Model was saved\n",
      "Epoch: 85 \tValidation loss decreased from 1.509477 to 1.507949. Model was saved\n",
      "Epoch: 86 \tValidation loss decreased from 1.507949 to 1.506958. Model was saved\n",
      "Epoch: 87 \tValidation loss decreased from 1.506958 to 1.505163. Model was saved\n",
      "Epoch: 88 \tValidation loss decreased from 1.505163 to 1.504567. Model was saved\n",
      "Epoch: 89 \tValidation loss decreased from 1.504567 to 1.502292. Model was saved\n",
      "Epoch: 90 \tValidation loss decreased from 1.502292 to 1.501709. Model was saved\n",
      "Epoch: 91 \tValidation loss decreased from 1.501709 to 1.498959. Model was saved\n",
      "Epoch: 92 \tValidation loss decreased from 1.498959 to 1.498435. Model was saved\n",
      "Epoch: 93 \tValidation loss decreased from 1.498435 to 1.495556. Model was saved\n",
      "Epoch: 94 \tValidation loss decreased from 1.495556 to 1.495299. Model was saved\n",
      "Epoch: 95 \tValidation loss decreased from 1.495299 to 1.493061. Model was saved\n",
      "Epoch: 96 \tValidation loss decreased from 1.493061 to 1.492466. Model was saved\n",
      "Epoch: 97 \tValidation loss decreased from 1.492466 to 1.490441. Model was saved\n",
      "Epoch: 98 \tValidation loss decreased from 1.490441 to 1.489608. Model was saved\n",
      "Epoch: 99 \tValidation loss decreased from 1.489608 to 1.487669. Model was saved\n",
      "Epoch: 100 \tValidation loss decreased from 1.487669 to 1.486448. Model was saved\n",
      "Epoch: 101 \tValidation loss decreased from 1.486448 to 1.485140. Model was saved\n",
      "Epoch: 102 \tValidation loss decreased from 1.485140 to 1.484112. Model was saved\n",
      "Epoch: 103 \tValidation loss decreased from 1.484112 to 1.483116. Model was saved\n",
      "Epoch: 104 \tValidation loss decreased from 1.483116 to 1.482405. Model was saved\n",
      "Epoch: 105 \tValidation loss decreased from 1.482405 to 1.482029. Model was saved\n",
      "Epoch: 106 \tValidation loss decreased from 1.482029 to 1.481321. Model was saved\n",
      "Epoch: 107 \tValidation loss decreased from 1.481321 to 1.481261. Model was saved\n",
      "Epoch: 108 \tValidation loss decreased from 1.481261 to 1.480679. Model was saved\n",
      "Epoch: 110 \tValidation loss decreased from 1.480679 to 1.479667. Model was saved\n",
      "Epoch: 112 \tValidation loss decreased from 1.479667 to 1.478491. Model was saved\n",
      "Epoch: 114 \tValidation loss decreased from 1.478491 to 1.477026. Model was saved\n",
      "Epoch: 115 \tValidation loss decreased from 1.477026 to 1.476734. Model was saved\n",
      "Epoch: 116 \tValidation loss decreased from 1.476734 to 1.475843. Model was saved\n",
      "Epoch: 117 \tValidation loss decreased from 1.475843 to 1.474684. Model was saved\n",
      "Epoch: 119 \tValidation loss decreased from 1.474684 to 1.473389. Model was saved\n",
      "Epoch: 121 \tValidation loss decreased from 1.473389 to 1.472502. Model was saved\n",
      "Epoch: 122 \tValidation loss decreased from 1.472502 to 1.472039. Model was saved\n",
      "Epoch: 123 \tValidation loss decreased from 1.472039 to 1.471503. Model was saved\n",
      "Epoch: 124 \tValidation loss decreased from 1.471503 to 1.470826. Model was saved\n",
      "Epoch: 125 \tValidation loss decreased from 1.470826 to 1.470374. Model was saved\n",
      "Epoch: 126 \tValidation loss decreased from 1.470374 to 1.469713. Model was saved\n",
      "Epoch: 127 \tValidation loss decreased from 1.469713 to 1.469322. Model was saved\n",
      "Epoch: 128 \tValidation loss decreased from 1.469322 to 1.468702. Model was saved\n",
      "Epoch: 129 \tValidation loss decreased from 1.468702 to 1.468237. Model was saved\n",
      "Epoch: 130 \tValidation loss decreased from 1.468237 to 1.467677. Model was saved\n",
      "Epoch: 131 \tValidation loss decreased from 1.467677 to 1.467087. Model was saved\n",
      "Epoch: 132 \tValidation loss decreased from 1.467087 to 1.466613. Model was saved\n",
      "Epoch: 133 \tValidation loss decreased from 1.466613 to 1.466002. Model was saved\n",
      "Epoch: 134 \tValidation loss decreased from 1.466002 to 1.465582. Model was saved\n",
      "Epoch: 135 \tValidation loss decreased from 1.465582 to 1.465073. Model was saved\n",
      "Epoch: 136 \tValidation loss decreased from 1.465073 to 1.464690. Model was saved\n",
      "Epoch: 137 \tValidation loss decreased from 1.464690 to 1.464286. Model was saved\n",
      "Epoch: 138 \tValidation loss decreased from 1.464286 to 1.464136. Model was saved\n",
      "Epoch: 139 \tValidation loss decreased from 1.464136 to 1.463705. Model was saved\n",
      "Epoch: 141 \tValidation loss decreased from 1.463705 to 1.463557. Model was saved\n",
      "Epoch: 143 \tValidation loss decreased from 1.463557 to 1.463202. Model was saved\n",
      "Epoch: 144 \tValidation loss decreased from 1.463202 to 1.462997. Model was saved\n",
      "Epoch: 146 \tValidation loss decreased from 1.462997 to 1.462695. Model was saved\n",
      "Epoch: 149 \tValidation loss decreased from 1.462695 to 1.462368. Model was saved\n",
      "Epoch: 151 \tValidation loss decreased from 1.462368 to 1.462051. Model was saved\n",
      "Epoch: 152 \tValidation loss decreased from 1.462051 to 1.462041. Model was saved\n",
      "Epoch: 154 \tValidation loss decreased from 1.462041 to 1.461577. Model was saved\n",
      "Epoch: 156 \tValidation loss decreased from 1.461577 to 1.461271. Model was saved\n",
      "Epoch: 158 \tValidation loss decreased from 1.461271 to 1.461180. Model was saved\n",
      "Epoch: 159 \tValidation loss decreased from 1.461180 to 1.460706. Model was saved\n",
      "Epoch: 161 \tValidation loss decreased from 1.460706 to 1.460034. Model was saved\n",
      "Epoch: 163 \tValidation loss decreased from 1.460034 to 1.459567. Model was saved\n",
      "Epoch: 165 \tValidation loss decreased from 1.459567 to 1.459366. Model was saved\n",
      "Epoch: 167 \tValidation loss decreased from 1.459366 to 1.459055. Model was saved\n",
      "Epoch: 169 \tValidation loss decreased from 1.459055 to 1.458678. Model was saved\n",
      "Epoch: 171 \tValidation loss decreased from 1.458678 to 1.457997. Model was saved\n",
      "Epoch: 173 \tValidation loss decreased from 1.457997 to 1.456726. Model was saved\n",
      "Epoch: 175 \tValidation loss decreased from 1.456726 to 1.456004. Model was saved\n",
      "Epoch: 176 \tValidation loss decreased from 1.456004 to 1.455971. Model was saved\n",
      "Epoch: 177 \tValidation loss decreased from 1.455971 to 1.455971. Model was saved\n",
      "Epoch: 178 \tValidation loss decreased from 1.455971 to 1.454322. Model was saved\n",
      "Epoch: 180 \tValidation loss decreased from 1.454322 to 1.453337. Model was saved\n",
      "Epoch: 182 \tValidation loss decreased from 1.453337 to 1.452041. Model was saved\n",
      "Epoch: 184 \tValidation loss decreased from 1.452041 to 1.451716. Model was saved\n",
      "Epoch: 185 \tValidation loss decreased from 1.451716 to 1.451105. Model was saved\n",
      "Epoch: 187 \tValidation loss decreased from 1.451105 to 1.450414. Model was saved\n",
      "Epoch: 189 \tValidation loss decreased from 1.450414 to 1.449640. Model was saved\n",
      "Epoch: 191 \tValidation loss decreased from 1.449640 to 1.448248. Model was saved\n",
      "Epoch: 194 \tValidation loss decreased from 1.448248 to 1.447782. Model was saved\n",
      "Epoch: 199 \tValidation loss decreased from 1.447782 to 1.447470. Model was saved\n",
      "Epoch: 201 \tValidation loss decreased from 1.447470 to 1.446892. Model was saved\n",
      "Epoch: 203 \tValidation loss decreased from 1.446892 to 1.446043. Model was saved\n",
      "Epoch: 205 \tValidation loss decreased from 1.446043 to 1.445600. Model was saved\n",
      "Epoch: 207 \tValidation loss decreased from 1.445600 to 1.444992. Model was saved\n",
      "Epoch: 208 \tValidation loss decreased from 1.444992 to 1.444908. Model was saved\n",
      "Epoch: 209 \tValidation loss decreased from 1.444908 to 1.443806. Model was saved\n",
      "Epoch: 211 \tValidation loss decreased from 1.443806 to 1.443028. Model was saved\n",
      "Epoch: 213 \tValidation loss decreased from 1.443028 to 1.442012. Model was saved\n",
      "Epoch: 215 \tValidation loss decreased from 1.442012 to 1.440163. Model was saved\n",
      "Epoch: 218 \tValidation loss decreased from 1.440163 to 1.439173. Model was saved\n",
      "Epoch: 221 \tValidation loss decreased from 1.439173 to 1.438253. Model was saved\n",
      "Epoch: 224 \tValidation loss decreased from 1.438253 to 1.437320. Model was saved\n",
      "Epoch: 227 \tValidation loss decreased from 1.437320 to 1.436947. Model was saved\n",
      "Epoch: 230 \tValidation loss decreased from 1.436947 to 1.436555. Model was saved\n",
      "Epoch: 231 \tValidation loss decreased from 1.436555 to 1.436020. Model was saved\n",
      "Epoch: 232 \tValidation loss decreased from 1.436020 to 1.435631. Model was saved\n",
      "Epoch: 234 \tValidation loss decreased from 1.435631 to 1.433818. Model was saved\n",
      "Epoch: 237 \tValidation loss decreased from 1.433818 to 1.433070. Model was saved\n",
      "Epoch: 238 \tValidation loss decreased from 1.433070 to 1.432669. Model was saved\n",
      "Epoch: 241 \tValidation loss decreased from 1.432669 to 1.432109. Model was saved\n",
      "Epoch: 245 \tValidation loss decreased from 1.432109 to 1.432054. Model was saved\n",
      "Epoch: 247 \tValidation loss decreased from 1.432054 to 1.431476. Model was saved\n",
      "Epoch: 248 \tValidation loss decreased from 1.431476 to 1.430121. Model was saved\n",
      "Epoch: 250 \tValidation loss decreased from 1.430121 to 1.430052. Model was saved\n",
      "Epoch: 251 \tValidation loss decreased from 1.430052 to 1.428118. Model was saved\n",
      "Epoch: 254 \tValidation loss decreased from 1.428118 to 1.426630. Model was saved\n",
      "Epoch: 257 \tValidation loss decreased from 1.426630 to 1.425902. Model was saved\n",
      "Epoch: 258 \tValidation loss decreased from 1.425902 to 1.425733. Model was saved\n",
      "Epoch: 260 \tValidation loss decreased from 1.425733 to 1.425339. Model was saved\n",
      "Epoch: 261 \tValidation loss decreased from 1.425339 to 1.424760. Model was saved\n",
      "Epoch: 263 \tValidation loss decreased from 1.424760 to 1.424407. Model was saved\n",
      "Epoch: 264 \tValidation loss decreased from 1.424407 to 1.423644. Model was saved\n",
      "Epoch: 266 \tValidation loss decreased from 1.423644 to 1.423343. Model was saved\n",
      "Epoch: 267 \tValidation loss decreased from 1.423343 to 1.422693. Model was saved\n",
      "Epoch: 269 \tValidation loss decreased from 1.422693 to 1.422370. Model was saved\n",
      "Epoch: 270 \tValidation loss decreased from 1.422370 to 1.421957. Model was saved\n",
      "Epoch: 271 \tValidation loss decreased from 1.421957 to 1.421833. Model was saved\n",
      "Epoch: 272 \tValidation loss decreased from 1.421833 to 1.421577. Model was saved\n",
      "Epoch: 273 \tValidation loss decreased from 1.421577 to 1.421204. Model was saved\n",
      "Epoch: 274 \tValidation loss decreased from 1.421204 to 1.420813. Model was saved\n",
      "Epoch: 275 \tValidation loss decreased from 1.420813 to 1.420534. Model was saved\n",
      "Epoch: 276 \tValidation loss decreased from 1.420534 to 1.419695. Model was saved\n",
      "Epoch: 277 \tValidation loss decreased from 1.419695 to 1.419210. Model was saved\n",
      "Epoch: 278 \tValidation loss decreased from 1.419210 to 1.418504. Model was saved\n",
      "Epoch: 279 \tValidation loss decreased from 1.418504 to 1.417551. Model was saved\n",
      "Epoch: 280 \tValidation loss decreased from 1.417551 to 1.416969. Model was saved\n",
      "Epoch: 281 \tValidation loss decreased from 1.416969 to 1.416064. Model was saved\n",
      "Epoch: 282 \tValidation loss decreased from 1.416064 to 1.415416. Model was saved\n",
      "Epoch: 283 \tValidation loss decreased from 1.415416 to 1.414728. Model was saved\n",
      "Epoch: 284 \tValidation loss decreased from 1.414728 to 1.414136. Model was saved\n",
      "Epoch: 285 \tValidation loss decreased from 1.414136 to 1.413523. Model was saved\n",
      "Epoch: 286 \tValidation loss decreased from 1.413523 to 1.413005. Model was saved\n",
      "Epoch: 287 \tValidation loss decreased from 1.413005 to 1.412527. Model was saved\n",
      "Epoch: 288 \tValidation loss decreased from 1.412527 to 1.412001. Model was saved\n",
      "Epoch: 289 \tValidation loss decreased from 1.412001 to 1.411884. Model was saved\n",
      "Epoch: 290 \tValidation loss decreased from 1.411884 to 1.411378. Model was saved\n",
      "Epoch: 292 \tValidation loss decreased from 1.411378 to 1.411050. Model was saved\n",
      "Epoch: 293 \tValidation loss decreased from 1.411050 to 1.410960. Model was saved\n",
      "Epoch: 294 \tValidation loss decreased from 1.410960 to 1.410517. Model was saved\n",
      "Epoch: 295 \tValidation loss decreased from 1.410517 to 1.410394. Model was saved\n",
      "Epoch: 296 \tValidation loss decreased from 1.410394 to 1.409593. Model was saved\n",
      "Epoch: 297 \tValidation loss decreased from 1.409593 to 1.409522. Model was saved\n",
      "Epoch: 298 \tValidation loss decreased from 1.409522 to 1.408548. Model was saved\n",
      "Epoch: 299 \tValidation loss decreased from 1.408548 to 1.408474. Model was saved\n",
      "Epoch: 300 \tValidation loss decreased from 1.408474 to 1.407577. Model was saved\n",
      "Epoch: 302 \tValidation loss decreased from 1.407577 to 1.406799. Model was saved\n",
      "Epoch: 304 \tValidation loss decreased from 1.406799 to 1.406158. Model was saved\n",
      "Epoch: 306 \tValidation loss decreased from 1.406158 to 1.405897. Model was saved\n",
      "Epoch: 309 \tValidation loss decreased from 1.405897 to 1.405761. Model was saved\n",
      "Epoch: 311 \tValidation loss decreased from 1.405761 to 1.405104. Model was saved\n",
      "Epoch: 313 \tValidation loss decreased from 1.405104 to 1.404751. Model was saved\n",
      "Epoch: 315 \tValidation loss decreased from 1.404751 to 1.404406. Model was saved\n",
      "Epoch: 317 \tValidation loss decreased from 1.404406 to 1.404167. Model was saved\n",
      "Epoch: 319 \tValidation loss decreased from 1.404167 to 1.403916. Model was saved\n",
      "Epoch: 320 \tValidation loss decreased from 1.403916 to 1.403281. Model was saved\n",
      "Epoch: 322 \tValidation loss decreased from 1.403281 to 1.402204. Model was saved\n",
      "Epoch: 324 \tValidation loss decreased from 1.402204 to 1.401702. Model was saved\n",
      "Epoch: 326 \tValidation loss decreased from 1.401702 to 1.400882. Model was saved\n",
      "Epoch: 329 \tValidation loss decreased from 1.400882 to 1.400523. Model was saved\n",
      "Epoch: 332 \tValidation loss decreased from 1.400523 to 1.399831. Model was saved\n",
      "Epoch: 335 \tValidation loss decreased from 1.399831 to 1.399608. Model was saved\n",
      "Epoch: 339 \tValidation loss decreased from 1.399608 to 1.399417. Model was saved\n",
      "Epoch: 341 \tValidation loss decreased from 1.399417 to 1.399332. Model was saved\n",
      "Epoch: 342 \tValidation loss decreased from 1.399332 to 1.398385. Model was saved\n",
      "Epoch: 345 \tValidation loss decreased from 1.398385 to 1.397973. Model was saved\n",
      "Epoch: 347 \tValidation loss decreased from 1.397973 to 1.397774. Model was saved\n",
      "Epoch: 348 \tValidation loss decreased from 1.397774 to 1.397748. Model was saved\n",
      "Epoch: 350 \tValidation loss decreased from 1.397748 to 1.397404. Model was saved\n",
      "Epoch: 354 \tValidation loss decreased from 1.397404 to 1.397036. Model was saved\n",
      "Epoch: 355 \tValidation loss decreased from 1.397036 to 1.396842. Model was saved\n",
      "Epoch: 356 \tValidation loss decreased from 1.396842 to 1.396660. Model was saved\n",
      "Epoch: 357 \tValidation loss decreased from 1.396660 to 1.395629. Model was saved\n",
      "Epoch: 359 \tValidation loss decreased from 1.395629 to 1.395272. Model was saved\n",
      "Epoch: 360 \tValidation loss decreased from 1.395272 to 1.394830. Model was saved\n",
      "Epoch: 362 \tValidation loss decreased from 1.394830 to 1.394177. Model was saved\n",
      "Epoch: 364 \tValidation loss decreased from 1.394177 to 1.394104. Model was saved\n",
      "Epoch: 365 \tValidation loss decreased from 1.394104 to 1.394094. Model was saved\n",
      "Epoch: 366 \tValidation loss decreased from 1.394094 to 1.393549. Model was saved\n",
      "Epoch: 368 \tValidation loss decreased from 1.393549 to 1.393034. Model was saved\n",
      "Epoch: 370 \tValidation loss decreased from 1.393034 to 1.392686. Model was saved\n",
      "Epoch: 371 \tValidation loss decreased from 1.392686 to 1.392455. Model was saved\n",
      "Epoch: 372 \tValidation loss decreased from 1.392455 to 1.391881. Model was saved\n",
      "Epoch: 374 \tValidation loss decreased from 1.391881 to 1.391010. Model was saved\n",
      "Epoch: 376 \tValidation loss decreased from 1.391010 to 1.390637. Model was saved\n",
      "Epoch: 378 \tValidation loss decreased from 1.390637 to 1.390262. Model was saved\n",
      "Epoch: 380 \tValidation loss decreased from 1.390262 to 1.389616. Model was saved\n",
      "Epoch: 382 \tValidation loss decreased from 1.389616 to 1.389421. Model was saved\n",
      "Epoch: 389 \tValidation loss decreased from 1.389421 to 1.389030. Model was saved\n",
      "Epoch: 391 \tValidation loss decreased from 1.389030 to 1.388564. Model was saved\n",
      "Epoch: 393 \tValidation loss decreased from 1.388564 to 1.387353. Model was saved\n",
      "Epoch: 394 \tValidation loss decreased from 1.387353 to 1.386751. Model was saved\n",
      "Epoch: 395 \tValidation loss decreased from 1.386751 to 1.386311. Model was saved\n",
      "Epoch: 396 \tValidation loss decreased from 1.386311 to 1.384924. Model was saved\n",
      "Epoch: 398 \tValidation loss decreased from 1.384924 to 1.384513. Model was saved\n",
      "Epoch: 403 \tValidation loss decreased from 1.384513 to 1.383113. Model was saved\n",
      "Epoch: 405 \tValidation loss decreased from 1.383113 to 1.382315. Model was saved\n",
      "Epoch: 408 \tValidation loss decreased from 1.382315 to 1.381225. Model was saved\n",
      "Epoch: 410 \tValidation loss decreased from 1.381225 to 1.380335. Model was saved\n",
      "Epoch: 416 \tValidation loss decreased from 1.380335 to 1.380176. Model was saved\n",
      "Epoch: 417 \tValidation loss decreased from 1.380176 to 1.379313. Model was saved\n",
      "Epoch: 419 \tValidation loss decreased from 1.379313 to 1.377954. Model was saved\n",
      "Epoch: 421 \tValidation loss decreased from 1.377954 to 1.377144. Model was saved\n",
      "Epoch: 424 \tValidation loss decreased from 1.377144 to 1.375246. Model was saved\n",
      "Epoch: 426 \tValidation loss decreased from 1.375246 to 1.374986. Model was saved\n",
      "Epoch: 429 \tValidation loss decreased from 1.374986 to 1.374214. Model was saved\n",
      "Epoch: 431 \tValidation loss decreased from 1.374214 to 1.373389. Model was saved\n",
      "Epoch: 436 \tValidation loss decreased from 1.373389 to 1.372952. Model was saved\n",
      "Epoch: 445 \tValidation loss decreased from 1.372952 to 1.372646. Model was saved\n",
      "Epoch: 447 \tValidation loss decreased from 1.372646 to 1.371838. Model was saved\n",
      "Epoch: 448 \tValidation loss decreased from 1.371838 to 1.371437. Model was saved\n",
      "Epoch: 449 \tValidation loss decreased from 1.371437 to 1.370750. Model was saved\n",
      "Epoch: 450 \tValidation loss decreased from 1.370750 to 1.369871. Model was saved\n",
      "Epoch: 452 \tValidation loss decreased from 1.369871 to 1.369135. Model was saved\n",
      "Epoch: 454 \tValidation loss decreased from 1.369135 to 1.369084. Model was saved\n",
      "Epoch: 456 \tValidation loss decreased from 1.369084 to 1.368722. Model was saved\n",
      "Epoch: 458 \tValidation loss decreased from 1.368722 to 1.368031. Model was saved\n",
      "Epoch: 460 \tValidation loss decreased from 1.368031 to 1.367903. Model was saved\n",
      "Epoch: 461 \tValidation loss decreased from 1.367903 to 1.367332. Model was saved\n",
      "Epoch: 463 \tValidation loss decreased from 1.367332 to 1.366976. Model was saved\n",
      "Epoch: 465 \tValidation loss decreased from 1.366976 to 1.366817. Model was saved\n",
      "Epoch: 467 \tValidation loss decreased from 1.366817 to 1.366629. Model was saved\n",
      "Epoch: 469 \tValidation loss decreased from 1.366629 to 1.366582. Model was saved\n",
      "Epoch: 470 \tValidation loss decreased from 1.366582 to 1.366416. Model was saved\n",
      "Epoch: 472 \tValidation loss decreased from 1.366416 to 1.365325. Model was saved\n",
      "Epoch: 474 \tValidation loss decreased from 1.365325 to 1.364860. Model was saved\n",
      "Epoch: 476 \tValidation loss decreased from 1.364860 to 1.364782. Model was saved\n",
      "Epoch: 478 \tValidation loss decreased from 1.364782 to 1.364586. Model was saved\n",
      "Epoch: 480 \tValidation loss decreased from 1.364586 to 1.364119. Model was saved\n",
      "Epoch: 482 \tValidation loss decreased from 1.364119 to 1.363779. Model was saved\n",
      "Epoch: 483 \tValidation loss decreased from 1.363779 to 1.363615. Model was saved\n",
      "Epoch: 484 \tValidation loss decreased from 1.363615 to 1.363569. Model was saved\n",
      "Epoch: 485 \tValidation loss decreased from 1.363569 to 1.363254. Model was saved\n",
      "Epoch: 487 \tValidation loss decreased from 1.363254 to 1.363201. Model was saved\n",
      "Epoch: 489 \tValidation loss decreased from 1.363201 to 1.363178. Model was saved\n",
      "Epoch: 491 \tValidation loss decreased from 1.363178 to 1.363075. Model was saved\n",
      "Epoch: 493 \tValidation loss decreased from 1.363075 to 1.362595. Model was saved\n",
      "Epoch: 496 \tValidation loss decreased from 1.362595 to 1.362315. Model was saved\n",
      "Epoch: 498 \tValidation loss decreased from 1.362315 to 1.362144. Model was saved\n",
      "Epoch: 501 \tValidation loss decreased from 1.362144 to 1.362027. Model was saved\n",
      "Epoch: 507 \tValidation loss decreased from 1.362027 to 1.361937. Model was saved\n",
      "Epoch: 508 \tValidation loss decreased from 1.361937 to 1.361797. Model was saved\n",
      "Epoch: 510 \tValidation loss decreased from 1.361797 to 1.359668. Model was saved\n",
      "Epoch: 513 \tValidation loss decreased from 1.359668 to 1.359222. Model was saved\n",
      "Epoch: 515 \tValidation loss decreased from 1.359222 to 1.358961. Model was saved\n",
      "Epoch: 517 \tValidation loss decreased from 1.358961 to 1.358738. Model was saved\n",
      "Epoch: 518 \tValidation loss decreased from 1.358738 to 1.358653. Model was saved\n",
      "Epoch: 519 \tValidation loss decreased from 1.358653 to 1.357890. Model was saved\n",
      "Epoch: 520 \tValidation loss decreased from 1.357890 to 1.357791. Model was saved\n",
      "Epoch: 522 \tValidation loss decreased from 1.357791 to 1.356812. Model was saved\n",
      "Epoch: 524 \tValidation loss decreased from 1.356812 to 1.356316. Model was saved\n",
      "Epoch: 525 \tValidation loss decreased from 1.356316 to 1.355717. Model was saved\n",
      "Epoch: 526 \tValidation loss decreased from 1.355717 to 1.355598. Model was saved\n",
      "Epoch: 527 \tValidation loss decreased from 1.355598 to 1.354101. Model was saved\n",
      "Epoch: 529 \tValidation loss decreased from 1.354101 to 1.353742. Model was saved\n",
      "Epoch: 530 \tValidation loss decreased from 1.353742 to 1.353091. Model was saved\n",
      "Epoch: 532 \tValidation loss decreased from 1.353091 to 1.352809. Model was saved\n",
      "Epoch: 539 \tValidation loss decreased from 1.352809 to 1.352529. Model was saved\n",
      "Epoch: 541 \tValidation loss decreased from 1.352529 to 1.352479. Model was saved\n",
      "Epoch: 542 \tValidation loss decreased from 1.352479 to 1.352414. Model was saved\n",
      "Epoch: 544 \tValidation loss decreased from 1.352414 to 1.352312. Model was saved\n",
      "Epoch: 546 \tValidation loss decreased from 1.352312 to 1.352267. Model was saved\n",
      "Epoch: 547 \tValidation loss decreased from 1.352267 to 1.352156. Model was saved\n",
      "Epoch: 548 \tValidation loss decreased from 1.352156 to 1.352001. Model was saved\n",
      "Epoch: 550 \tValidation loss decreased from 1.352001 to 1.351963. Model was saved\n",
      "Epoch: 553 \tValidation loss decreased from 1.351963 to 1.351862. Model was saved\n",
      "Epoch: 563 \tValidation loss decreased from 1.351862 to 1.351779. Model was saved\n",
      "Epoch: 565 \tValidation loss decreased from 1.351779 to 1.351511. Model was saved\n",
      "Epoch: 567 \tValidation loss decreased from 1.351511 to 1.351341. Model was saved\n",
      "Epoch: 571 \tValidation loss decreased from 1.351341 to 1.351205. Model was saved\n",
      "Epoch: 573 \tValidation loss decreased from 1.351205 to 1.350932. Model was saved\n",
      "Epoch: 575 \tValidation loss decreased from 1.350932 to 1.350607. Model was saved\n",
      "Epoch: 576 \tValidation loss decreased from 1.350607 to 1.350451. Model was saved\n",
      "Epoch: 578 \tValidation loss decreased from 1.350451 to 1.349976. Model was saved\n",
      "Epoch: 580 \tValidation loss decreased from 1.349976 to 1.349647. Model was saved\n",
      "Epoch: 582 \tValidation loss decreased from 1.349647 to 1.349305. Model was saved\n",
      "Epoch: 584 \tValidation loss decreased from 1.349305 to 1.348991. Model was saved\n",
      "Epoch: 586 \tValidation loss decreased from 1.348991 to 1.348726. Model was saved\n",
      "Epoch: 588 \tValidation loss decreased from 1.348726 to 1.348714. Model was saved\n",
      "Epoch: 613 \tValidation loss decreased from 1.348714 to 1.348325. Model was saved\n",
      "Epoch: 615 \tValidation loss decreased from 1.348325 to 1.347422. Model was saved\n",
      "Epoch: 617 \tValidation loss decreased from 1.347422 to 1.347389. Model was saved\n",
      "Epoch: 703 \tValidation loss decreased from 1.347389 to 1.347201. Model was saved\n",
      "Epoch: 704 \tValidation loss decreased from 1.347201 to 1.346320. Model was saved\n",
      "Epoch: 709 \tValidation loss decreased from 1.346320 to 1.346051. Model was saved\n",
      "Epoch: 714 \tValidation loss decreased from 1.346051 to 1.345768. Model was saved\n",
      "Epoch: 719 \tValidation loss decreased from 1.345768 to 1.345718. Model was saved\n",
      "Epoch: 724 \tValidation loss decreased from 1.345718 to 1.345470. Model was saved\n",
      "Epoch: 745 \tValidation loss decreased from 1.345470 to 1.345420. Model was saved\n",
      "Epoch: 749 \tValidation loss decreased from 1.345420 to 1.345263. Model was saved\n",
      "Epoch: 750 \tValidation loss decreased from 1.345263 to 1.345029. Model was saved\n",
      "Epoch: 751 \tValidation loss decreased from 1.345029 to 1.344880. Model was saved\n",
      "Epoch: 752 \tValidation loss decreased from 1.344880 to 1.344827. Model was saved\n",
      "Epoch: 753 \tValidation loss decreased from 1.344827 to 1.344772. Model was saved\n",
      "Epoch: 754 \tValidation loss decreased from 1.344772 to 1.344645. Model was saved\n",
      "Epoch: 755 \tValidation loss decreased from 1.344645 to 1.344467. Model was saved\n",
      "Epoch: 756 \tValidation loss decreased from 1.344467 to 1.344350. Model was saved\n",
      "Epoch: 757 \tValidation loss decreased from 1.344350 to 1.344308. Model was saved\n",
      "Epoch: 758 \tValidation loss decreased from 1.344308 to 1.344273. Model was saved\n",
      "Epoch: 759 \tValidation loss decreased from 1.344273 to 1.344155. Model was saved\n",
      "Epoch: 760 \tValidation loss decreased from 1.344155 to 1.344055. Model was saved\n",
      "Epoch: 785 \tValidation loss decreased from 1.344055 to 1.343994. Model was saved\n",
      "Epoch: 786 \tValidation loss decreased from 1.343994 to 1.343835. Model was saved\n",
      "Epoch: 787 \tValidation loss decreased from 1.343835 to 1.343670. Model was saved\n",
      "Epoch: 788 \tValidation loss decreased from 1.343670 to 1.343497. Model was saved\n",
      "Epoch: 789 \tValidation loss decreased from 1.343497 to 1.343342. Model was saved\n",
      "Epoch: 790 \tValidation loss decreased from 1.343342 to 1.343240. Model was saved\n",
      "Epoch: 791 \tValidation loss decreased from 1.343240 to 1.343176. Model was saved\n",
      "Epoch: 792 \tValidation loss decreased from 1.343176 to 1.343107. Model was saved\n",
      "Epoch: 793 \tValidation loss decreased from 1.343107 to 1.343008. Model was saved\n",
      "Epoch: 794 \tValidation loss decreased from 1.343008 to 1.342903. Model was saved\n",
      "Epoch: 795 \tValidation loss decreased from 1.342903 to 1.342818. Model was saved\n",
      "Epoch: 796 \tValidation loss decreased from 1.342818 to 1.342723. Model was saved\n",
      "Epoch: 797 \tValidation loss decreased from 1.342723 to 1.342581. Model was saved\n",
      "Epoch: 798 \tValidation loss decreased from 1.342581 to 1.342428. Model was saved\n",
      "Epoch: 799 \tValidation loss decreased from 1.342428 to 1.342319. Model was saved\n",
      "Epoch: 800 \tValidation loss decreased from 1.342319 to 1.342262. Model was saved\n",
      "Epoch: 801 \tValidation loss decreased from 1.342262 to 1.342227. Model was saved\n",
      "Epoch: 802 \tValidation loss decreased from 1.342227 to 1.342214. Model was saved\n",
      "Epoch: 804 \tValidation loss decreased from 1.342214 to 1.342210. Model was saved\n",
      "Epoch: 805 \tValidation loss decreased from 1.342210 to 1.342206. Model was saved\n",
      "Epoch: 889 \tValidation loss decreased from 1.342206 to 1.342149. Model was saved\n",
      "Epoch: 890 \tValidation loss decreased from 1.342149 to 1.341966. Model was saved\n",
      "Epoch: 891 \tValidation loss decreased from 1.341966 to 1.341714. Model was saved\n",
      "Epoch: 892 \tValidation loss decreased from 1.341714 to 1.341413. Model was saved\n",
      "Epoch: 893 \tValidation loss decreased from 1.341413 to 1.341135. Model was saved\n",
      "Epoch: 894 \tValidation loss decreased from 1.341135 to 1.340913. Model was saved\n",
      "Epoch: 895 \tValidation loss decreased from 1.340913 to 1.340723. Model was saved\n",
      "Epoch: 896 \tValidation loss decreased from 1.340723 to 1.340562. Model was saved\n",
      "Epoch: 897 \tValidation loss decreased from 1.340562 to 1.340452. Model was saved\n",
      "Epoch: 898 \tValidation loss decreased from 1.340452 to 1.340370. Model was saved\n",
      "Epoch: 899 \tValidation loss decreased from 1.340370 to 1.340317. Model was saved\n",
      "Epoch: 955 \tValidation loss decreased from 1.340317 to 1.340203. Model was saved\n",
      "Epoch: 956 \tValidation loss decreased from 1.340203 to 1.340081. Model was saved\n",
      "Epoch: 957 \tValidation loss decreased from 1.340081 to 1.339969. Model was saved\n",
      "Epoch: 958 \tValidation loss decreased from 1.339969 to 1.339864. Model was saved\n",
      "Epoch: 959 \tValidation loss decreased from 1.339864 to 1.339768. Model was saved\n",
      "Epoch: 960 \tValidation loss decreased from 1.339768 to 1.339695. Model was saved\n",
      "Epoch: 961 \tValidation loss decreased from 1.339695 to 1.339642. Model was saved\n",
      "Epoch: 962 \tValidation loss decreased from 1.339642 to 1.339586. Model was saved\n",
      "Epoch: 963 \tValidation loss decreased from 1.339586 to 1.339520. Model was saved\n",
      "Epoch: 964 \tValidation loss decreased from 1.339520 to 1.339435. Model was saved\n",
      "Epoch: 965 \tValidation loss decreased from 1.339435 to 1.339324. Model was saved\n",
      "Epoch: 966 \tValidation loss decreased from 1.339324 to 1.339195. Model was saved\n",
      "Epoch: 967 \tValidation loss decreased from 1.339195 to 1.339056. Model was saved\n",
      "Epoch: 968 \tValidation loss decreased from 1.339056 to 1.338907. Model was saved\n",
      "Epoch: 969 \tValidation loss decreased from 1.338907 to 1.338756. Model was saved\n",
      "Epoch: 970 \tValidation loss decreased from 1.338756 to 1.338616. Model was saved\n",
      "Epoch: 971 \tValidation loss decreased from 1.338616 to 1.338492. Model was saved\n",
      "Epoch: 972 \tValidation loss decreased from 1.338492 to 1.338392. Model was saved\n",
      "Epoch: 973 \tValidation loss decreased from 1.338392 to 1.338321. Model was saved\n",
      "Epoch: 974 \tValidation loss decreased from 1.338321 to 1.338268. Model was saved\n",
      "Epoch: 975 \tValidation loss decreased from 1.338268 to 1.338218. Model was saved\n",
      "Epoch: 976 \tValidation loss decreased from 1.338218 to 1.338171. Model was saved\n",
      "Epoch: 977 \tValidation loss decreased from 1.338171 to 1.338130. Model was saved\n",
      "Epoch: 978 \tValidation loss decreased from 1.338130 to 1.338103. Model was saved\n",
      "Epoch: 979 \tValidation loss decreased from 1.338103 to 1.338094. Model was saved\n",
      "Epoch: 1001 \tValidation loss decreased from 1.338094 to 1.338055. Model was saved\n",
      "Epoch: 1002 \tValidation loss decreased from 1.338055 to 1.337980. Model was saved\n",
      "Epoch: 1003 \tValidation loss decreased from 1.337980 to 1.337904. Model was saved\n",
      "Epoch: 1004 \tValidation loss decreased from 1.337904 to 1.337833. Model was saved\n",
      "Epoch: 1005 \tValidation loss decreased from 1.337833 to 1.337763. Model was saved\n",
      "Epoch: 1006 \tValidation loss decreased from 1.337763 to 1.337708. Model was saved\n",
      "Epoch: 1007 \tValidation loss decreased from 1.337708 to 1.337694. Model was saved\n",
      "Epoch: 1015 \tValidation loss decreased from 1.337694 to 1.337670. Model was saved\n",
      "Epoch: 1016 \tValidation loss decreased from 1.337670 to 1.337593. Model was saved\n",
      "Epoch: 1017 \tValidation loss decreased from 1.337593 to 1.337552. Model was saved\n",
      "Epoch: 1018 \tValidation loss decreased from 1.337552 to 1.337546. Model was saved\n",
      "Epoch: 1024 \tValidation loss decreased from 1.337546 to 1.337505. Model was saved\n",
      "Epoch: 1025 \tValidation loss decreased from 1.337505 to 1.337373. Model was saved\n",
      "Epoch: 1026 \tValidation loss decreased from 1.337373 to 1.337228. Model was saved\n",
      "Epoch: 1027 \tValidation loss decreased from 1.337228 to 1.337115. Model was saved\n",
      "Epoch: 1028 \tValidation loss decreased from 1.337115 to 1.337088. Model was saved\n",
      "Epoch: 1069 \tValidation loss decreased from 1.337088 to 1.336992. Model was saved\n",
      "Epoch: 1070 \tValidation loss decreased from 1.336992 to 1.336921. Model was saved\n",
      "Epoch: 1071 \tValidation loss decreased from 1.336921 to 1.336918. Model was saved\n",
      "Epoch: 1078 \tValidation loss decreased from 1.336918 to 1.336803. Model was saved\n",
      "Epoch: 1079 \tValidation loss decreased from 1.336803 to 1.336546. Model was saved\n",
      "Epoch: 1080 \tValidation loss decreased from 1.336546 to 1.336261. Model was saved\n",
      "Epoch: 1081 \tValidation loss decreased from 1.336261 to 1.335986. Model was saved\n",
      "Epoch: 1082 \tValidation loss decreased from 1.335986 to 1.335752. Model was saved\n",
      "Epoch: 1083 \tValidation loss decreased from 1.335752 to 1.335580. Model was saved\n",
      "Epoch: 1084 \tValidation loss decreased from 1.335580 to 1.335465. Model was saved\n",
      "Epoch: 1085 \tValidation loss decreased from 1.335465 to 1.335426. Model was saved\n",
      "Epoch: 1090 \tValidation loss decreased from 1.335426 to 1.335410. Model was saved\n",
      "Epoch: 1091 \tValidation loss decreased from 1.335410 to 1.335330. Model was saved\n",
      "Epoch: 1092 \tValidation loss decreased from 1.335330 to 1.335268. Model was saved\n",
      "Epoch: 1093 \tValidation loss decreased from 1.335268 to 1.335255. Model was saved\n",
      "Epoch: 1122 \tValidation loss decreased from 1.335255 to 1.335231. Model was saved\n",
      "Epoch: 1273 \tValidation loss decreased from 1.335231 to 1.335166. Model was saved\n",
      "Epoch: 1274 \tValidation loss decreased from 1.335166 to 1.335068. Model was saved\n",
      "Epoch: 1275 \tValidation loss decreased from 1.335068 to 1.335016. Model was saved\n",
      "Epoch: 1279 \tValidation loss decreased from 1.335016 to 1.334792. Model was saved\n",
      "Epoch: 1283 \tValidation loss decreased from 1.334792 to 1.334632. Model was saved\n",
      "Epoch: 1289 \tValidation loss decreased from 1.334632 to 1.334454. Model was saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-741272d6cb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m model = train(n_epochs, loaders, model, optimizer, \n\u001b[0;32m---> 97\u001b[0;31m                       criterion, use_cuda, 'model.pt')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-741272d6cb1e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#             data = data.type((torch.FloatTensor))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    # open a new log file\n",
    "    history_file = open(\"training_history.txt\", \"w\")\n",
    "    history_file.close()\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        # reopen log file for appending new line of info\n",
    "        history_file = open(\"training_history.txt\", \"a\")\n",
    "\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ), file=history_file)\n",
    "\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ), file=history_file)\n",
    "            print('Epoch: {} \\tValidation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                epoch,\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        history_file.close()\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(n_epochs, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.304674\n",
      "\n",
      "\n",
      "Test Accuracy: 62% (18/29)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i,l = next(iter(loaders['test']))\n",
    "# if use_cuda:\n",
    "#     i, l = i.cuda(), l.cuda()\n",
    "\n",
    "# output = model(i)\n",
    "\n",
    "# result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "# result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = result[:,0]\n",
    "# plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
