{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'class_0': 1611, 'class_2': 1478, 'class_5': 1411, 'class_1': 920, 'class_3': 889, 'class_4': 851})\n",
      "df to be added: (0, 184)\n",
      "(7160, 184)\n",
      "df to be added: (691, 184)\n",
      "(7851, 184)\n",
      "df to be added: (133, 184)\n",
      "(7984, 184)\n",
      "df to be added: (722, 184)\n",
      "(8706, 184)\n",
      "df to be added: (760, 184)\n",
      "(9466, 184)\n",
      "df to be added: (200, 184)\n",
      "(9666, 184)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counter = Counter()\n",
    "# print(len(train['class']))\n",
    "class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print(class_counter)\n",
    "\n",
    "max_count = -np.Inf\n",
    "for i in range(number_of_class):\n",
    "    if class_counter['class_' + str(i)] > max_count:\n",
    "        max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "    num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "    num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "    for j in range(num_resample_batch):\n",
    "        add_df = train_classified[i]\n",
    "        train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "        train =  train.append(df_to_be_added)\n",
    "        \n",
    "\n",
    "    df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "    print('df to be added:', df_to_be_added.shape)\n",
    "    train =  train.append(df_to_be_added)\n",
    "    print(train.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('class_0', 1611), (0, 1611), (1, 1611), (2, 1611), (3, 1611), (4, 1611)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names =[i for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter[i] += 1\n",
    "\n",
    "class_counter.most_common(number_of_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appearedTimeOfDay</th>\n",
       "      <th>appearedHour</th>\n",
       "      <th>appearedMinute</th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>city</th>\n",
       "      <th>continent</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>...</th>\n",
       "      <th>cooc_142</th>\n",
       "      <th>cooc_143</th>\n",
       "      <th>cooc_144</th>\n",
       "      <th>cooc_145</th>\n",
       "      <th>cooc_146</th>\n",
       "      <th>cooc_147</th>\n",
       "      <th>cooc_148</th>\n",
       "      <th>cooc_149</th>\n",
       "      <th>cooc_150</th>\n",
       "      <th>cooc_151</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>night</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>evening</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>New_York</td>\n",
       "      <td>America</td>\n",
       "      <td>Clear</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Hobart</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Clear</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>evening</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>Los_Angeles</td>\n",
       "      <td>America</td>\n",
       "      <td>PartlyCloudy</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  appearedTimeOfDay  appearedHour  appearedMinute  terrainType  closeToWater  \\\n",
       "0           evening            19              10           13         False   \n",
       "1             night             5              19           13          True   \n",
       "2           evening            19              46            0          True   \n",
       "3           morning            11              10            0          True   \n",
       "4           evening            18              32           13          True   \n",
       "\n",
       "          city  continent       weather  temperature  windSpeed    ...     \\\n",
       "0      Bangkok       Asia         Clear         27.8       9.00    ...      \n",
       "1     New_York    America         Clear         26.1       8.70    ...      \n",
       "2     New_York    America         Clear         24.7      16.82    ...      \n",
       "3       Hobart  Australia         Clear         12.7      13.25    ...      \n",
       "4  Los_Angeles    America  PartlyCloudy         19.1       5.78    ...      \n",
       "\n",
       "   cooc_142 cooc_143  cooc_144  cooc_145  cooc_146  cooc_147  cooc_148  \\\n",
       "0     False    False     False     False     False     False     False   \n",
       "1     False    False     False     False     False     False     False   \n",
       "2     False    False     False     False     False     False     False   \n",
       "3     False    False     False     False     False     False     False   \n",
       "4     False    False     False     False     False     False     False   \n",
       "\n",
       "   cooc_149  cooc_150  cooc_151  \n",
       "0     False     False     False  \n",
       "1     False     False     False  \n",
       "2     False     False     False  \n",
       "3     False     False     False  \n",
       "4     False     False     False  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1008.96</td>\n",
       "      <td>6019.04440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.953717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.70</td>\n",
       "      <td>1018.96</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>16.82</td>\n",
       "      <td>1023.22</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.894934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1014.19</td>\n",
       "      <td>128.89505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.216440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.78</td>\n",
       "      <td>1011.36</td>\n",
       "      <td>4188.39100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.990268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0         13.0           0.0         27.8       9.00   1008.96   \n",
       "1         13.0           1.0         26.1       8.70   1018.96   \n",
       "2          0.0           1.0         24.7      16.82   1023.22   \n",
       "3          0.0           1.0         12.7      13.25   1014.19   \n",
       "4         13.0           1.0         19.1       5.78   1011.36   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0          6019.04440    1.0       1.0       1.0    0.0          ...            \n",
       "1             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "2             0.00000    0.0       0.0       0.0    1.0          ...            \n",
       "3           128.89505    0.0       0.0       0.0    1.0          ...            \n",
       "4          4188.39100    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                             0                      1   \n",
       "1                             0                      0   \n",
       "2                             0                      1   \n",
       "3                             0                      0   \n",
       "4                             0                      0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                        0                   0                0   \n",
       "1                        1                   0                0   \n",
       "2                        0                   0                0   \n",
       "3                        1                   0                0   \n",
       "4                        0                   0                0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                              0                                0   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              1                                0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0                 0                 0             -0.953717  \n",
       "1                 0                 0              0.984041  \n",
       "2                 0                 0             -0.894934  \n",
       "3                 0                 0              0.216440  \n",
       "4                 0                 0             -0.990268  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terrainType</th>\n",
       "      <th>closeToWater</th>\n",
       "      <th>temperature</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>population_density</th>\n",
       "      <th>urban</th>\n",
       "      <th>suburban</th>\n",
       "      <th>midurban</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>weather_WindyandPartlyCloudy</th>\n",
       "      <th>weatherIcon_clear-day</th>\n",
       "      <th>weatherIcon_clear-night</th>\n",
       "      <th>weatherIcon_cloudy</th>\n",
       "      <th>weatherIcon_fog</th>\n",
       "      <th>weatherIcon_partly-cloudy-day</th>\n",
       "      <th>weatherIcon_partly-cloudy-night</th>\n",
       "      <th>weatherIcon_rain</th>\n",
       "      <th>weatherIcon_wind</th>\n",
       "      <th>appearedTimeDayCycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631868</td>\n",
       "      <td>0.160342</td>\n",
       "      <td>0.333774</td>\n",
       "      <td>0.601904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.154997</td>\n",
       "      <td>0.598044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.546703</td>\n",
       "      <td>0.299662</td>\n",
       "      <td>0.710624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217033</td>\n",
       "      <td>0.236059</td>\n",
       "      <td>0.471987</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.102975</td>\n",
       "      <td>0.397199</td>\n",
       "      <td>0.418839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   terrainType  closeToWater  temperature  windSpeed  pressure  \\\n",
       "0       0.8125           0.0     0.631868   0.160342  0.333774   \n",
       "1       0.8125           1.0     0.585165   0.154997  0.598044   \n",
       "2       0.0000           1.0     0.546703   0.299662  0.710624   \n",
       "3       0.0000           1.0     0.217033   0.236059  0.471987   \n",
       "4       0.8125           1.0     0.392857   0.102975  0.397199   \n",
       "\n",
       "   population_density  urban  suburban  midurban  rural          ...           \\\n",
       "0            0.601904    1.0       1.0       1.0    0.0          ...            \n",
       "1            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "2            0.000000    0.0       0.0       0.0    1.0          ...            \n",
       "3            0.012890    0.0       0.0       0.0    1.0          ...            \n",
       "4            0.418839    1.0       1.0       1.0    0.0          ...            \n",
       "\n",
       "   weather_WindyandPartlyCloudy  weatherIcon_clear-day  \\\n",
       "0                           0.0                    1.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    1.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   weatherIcon_clear-night  weatherIcon_cloudy  weatherIcon_fog  \\\n",
       "0                      0.0                 0.0              0.0   \n",
       "1                      1.0                 0.0              0.0   \n",
       "2                      0.0                 0.0              0.0   \n",
       "3                      1.0                 0.0              0.0   \n",
       "4                      0.0                 0.0              0.0   \n",
       "\n",
       "   weatherIcon_partly-cloudy-day  weatherIcon_partly-cloudy-night  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            1.0                              0.0   \n",
       "\n",
       "   weatherIcon_rain  weatherIcon_wind  appearedTimeDayCycle  \n",
       "0               0.0               0.0              0.023142  \n",
       "1               0.0               0.0              0.992020  \n",
       "2               0.0               0.0              0.052533  \n",
       "3               0.0               0.0              0.608220  \n",
       "4               0.0               0.0              0.004866  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9666 entries, 0 to 1088\n",
      "Columns: 297 entries, terrainType to appearedTimeDayCycle\n",
      "dtypes: float64(272), int64(25)\n",
      "memory usage: 22.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9666, 297)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1611.,    0., 1611.,    0., 1611.,    0., 1611.,    0., 1611.,\n",
       "        1611.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8699, 297), (773, 297), (194, 297))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.9\n",
    "test_ratio = 0.2\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_ratio = 0.98\n",
    "\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32.,  0., 32.,  0., 32.,  0., 32.,  0., 33., 33.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "# plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data per batch to load\n",
    "batch_size = 10000\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "            print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "        print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.794868 \tValidation Loss: 1.791257 \t time: 0.3\n",
      "Validation loss decreased from inf to 1.791257. Model was saved\n",
      "Epoch: 2 \tTraining Loss: 1.793078 \tValidation Loss: 1.791187 \t time: 0.2\n",
      "Validation loss decreased from 1.791257 to 1.791187. Model was saved\n",
      "Epoch: 3 \tTraining Loss: 1.791942 \tValidation Loss: 1.790441 \t time: 0.2\n",
      "Validation loss decreased from 1.791187 to 1.790441. Model was saved\n",
      "Epoch: 4 \tTraining Loss: 1.791087 \tValidation Loss: 1.789143 \t time: 0.3\n",
      "Validation loss decreased from 1.790441 to 1.789143. Model was saved\n",
      "Epoch: 5 \tTraining Loss: 1.789765 \tValidation Loss: 1.787500 \t time: 0.2\n",
      "Validation loss decreased from 1.789143 to 1.787500. Model was saved\n",
      "Epoch: 6 \tTraining Loss: 1.787651 \tValidation Loss: 1.785343 \t time: 0.3\n",
      "Validation loss decreased from 1.787500 to 1.785343. Model was saved\n",
      "Epoch: 7 \tTraining Loss: 1.785821 \tValidation Loss: 1.782363 \t time: 0.3\n",
      "Validation loss decreased from 1.785343 to 1.782363. Model was saved\n",
      "Epoch: 8 \tTraining Loss: 1.782480 \tValidation Loss: 1.778184 \t time: 0.3\n",
      "Validation loss decreased from 1.782363 to 1.778184. Model was saved\n",
      "Epoch: 9 \tTraining Loss: 1.778777 \tValidation Loss: 1.772529 \t time: 0.3\n",
      "Validation loss decreased from 1.778184 to 1.772529. Model was saved\n",
      "Epoch: 10 \tTraining Loss: 1.772866 \tValidation Loss: 1.765283 \t time: 0.2\n",
      "Validation loss decreased from 1.772529 to 1.765283. Model was saved\n",
      "Epoch: 11 \tTraining Loss: 1.766755 \tValidation Loss: 1.756510 \t time: 0.3\n",
      "Validation loss decreased from 1.765283 to 1.756510. Model was saved\n",
      "Epoch: 12 \tTraining Loss: 1.757842 \tValidation Loss: 1.746472 \t time: 0.3\n",
      "Validation loss decreased from 1.756510 to 1.746472. Model was saved\n",
      "Epoch: 13 \tTraining Loss: 1.748165 \tValidation Loss: 1.735584 \t time: 0.2\n",
      "Validation loss decreased from 1.746472 to 1.735584. Model was saved\n",
      "Epoch: 14 \tTraining Loss: 1.738715 \tValidation Loss: 1.724314 \t time: 0.2\n",
      "Validation loss decreased from 1.735584 to 1.724314. Model was saved\n",
      "Epoch: 15 \tTraining Loss: 1.728704 \tValidation Loss: 1.713146 \t time: 0.2\n",
      "Validation loss decreased from 1.724314 to 1.713146. Model was saved\n",
      "Epoch: 16 \tTraining Loss: 1.717882 \tValidation Loss: 1.702423 \t time: 0.2\n",
      "Validation loss decreased from 1.713146 to 1.702423. Model was saved\n",
      "Epoch: 17 \tTraining Loss: 1.708724 \tValidation Loss: 1.692342 \t time: 0.2\n",
      "Validation loss decreased from 1.702423 to 1.692342. Model was saved\n",
      "Epoch: 18 \tTraining Loss: 1.699243 \tValidation Loss: 1.683088 \t time: 0.2\n",
      "Validation loss decreased from 1.692342 to 1.683088. Model was saved\n",
      "Epoch: 19 \tTraining Loss: 1.690965 \tValidation Loss: 1.674650 \t time: 0.2\n",
      "Validation loss decreased from 1.683088 to 1.674650. Model was saved\n",
      "Epoch: 20 \tTraining Loss: 1.682522 \tValidation Loss: 1.667086 \t time: 0.2\n",
      "Validation loss decreased from 1.674650 to 1.667086. Model was saved\n",
      "Epoch: 21 \tTraining Loss: 1.674393 \tValidation Loss: 1.659985 \t time: 0.2\n",
      "Validation loss decreased from 1.667086 to 1.659985. Model was saved\n",
      "Epoch: 22 \tTraining Loss: 1.667200 \tValidation Loss: 1.653290 \t time: 0.2\n",
      "Validation loss decreased from 1.659985 to 1.653290. Model was saved\n",
      "Epoch: 23 \tTraining Loss: 1.660329 \tValidation Loss: 1.647100 \t time: 0.2\n",
      "Validation loss decreased from 1.653290 to 1.647100. Model was saved\n",
      "Epoch: 24 \tTraining Loss: 1.653876 \tValidation Loss: 1.641441 \t time: 0.2\n",
      "Validation loss decreased from 1.647100 to 1.641441. Model was saved\n",
      "Epoch: 25 \tTraining Loss: 1.647382 \tValidation Loss: 1.635893 \t time: 0.2\n",
      "Validation loss decreased from 1.641441 to 1.635893. Model was saved\n",
      "Epoch: 26 \tTraining Loss: 1.639889 \tValidation Loss: 1.630321 \t time: 0.3\n",
      "Validation loss decreased from 1.635893 to 1.630321. Model was saved\n",
      "Epoch: 27 \tTraining Loss: 1.632307 \tValidation Loss: 1.624789 \t time: 0.3\n",
      "Validation loss decreased from 1.630321 to 1.624789. Model was saved\n",
      "Epoch: 28 \tTraining Loss: 1.627649 \tValidation Loss: 1.619599 \t time: 0.3\n",
      "Validation loss decreased from 1.624789 to 1.619599. Model was saved\n",
      "Epoch: 29 \tTraining Loss: 1.622434 \tValidation Loss: 1.614297 \t time: 0.3\n",
      "Validation loss decreased from 1.619599 to 1.614297. Model was saved\n",
      "Epoch: 30 \tTraining Loss: 1.614572 \tValidation Loss: 1.609123 \t time: 0.2\n",
      "Validation loss decreased from 1.614297 to 1.609123. Model was saved\n",
      "Epoch: 31 \tTraining Loss: 1.608871 \tValidation Loss: 1.603528 \t time: 0.2\n",
      "Validation loss decreased from 1.609123 to 1.603528. Model was saved\n",
      "Epoch: 32 \tTraining Loss: 1.604298 \tValidation Loss: 1.598168 \t time: 0.3\n",
      "Validation loss decreased from 1.603528 to 1.598168. Model was saved\n",
      "Epoch: 33 \tTraining Loss: 1.599356 \tValidation Loss: 1.592799 \t time: 0.2\n",
      "Validation loss decreased from 1.598168 to 1.592799. Model was saved\n",
      "Epoch: 34 \tTraining Loss: 1.594266 \tValidation Loss: 1.587556 \t time: 0.3\n",
      "Validation loss decreased from 1.592799 to 1.587556. Model was saved\n",
      "Epoch: 35 \tTraining Loss: 1.586842 \tValidation Loss: 1.582390 \t time: 0.3\n",
      "Validation loss decreased from 1.587556 to 1.582390. Model was saved\n",
      "Epoch: 36 \tTraining Loss: 1.584599 \tValidation Loss: 1.577306 \t time: 0.3\n",
      "Validation loss decreased from 1.582390 to 1.577306. Model was saved\n",
      "Epoch: 37 \tTraining Loss: 1.580470 \tValidation Loss: 1.572337 \t time: 0.3\n",
      "Validation loss decreased from 1.577306 to 1.572337. Model was saved\n",
      "Epoch: 38 \tTraining Loss: 1.576824 \tValidation Loss: 1.567495 \t time: 0.3\n",
      "Validation loss decreased from 1.572337 to 1.567495. Model was saved\n",
      "Epoch: 39 \tTraining Loss: 1.571568 \tValidation Loss: 1.562718 \t time: 0.2\n",
      "Validation loss decreased from 1.567495 to 1.562718. Model was saved\n",
      "Epoch: 40 \tTraining Loss: 1.569526 \tValidation Loss: 1.558280 \t time: 0.3\n",
      "Validation loss decreased from 1.562718 to 1.558280. Model was saved\n",
      "Epoch: 41 \tTraining Loss: 1.565892 \tValidation Loss: 1.553436 \t time: 0.2\n",
      "Validation loss decreased from 1.558280 to 1.553436. Model was saved\n",
      "Epoch: 42 \tTraining Loss: 1.561585 \tValidation Loss: 1.548923 \t time: 0.3\n",
      "Validation loss decreased from 1.553436 to 1.548923. Model was saved\n",
      "Epoch: 43 \tTraining Loss: 1.555245 \tValidation Loss: 1.544756 \t time: 0.2\n",
      "Validation loss decreased from 1.548923 to 1.544756. Model was saved\n",
      "Epoch: 44 \tTraining Loss: 1.553919 \tValidation Loss: 1.541061 \t time: 0.2\n",
      "Validation loss decreased from 1.544756 to 1.541061. Model was saved\n",
      "Epoch: 45 \tTraining Loss: 1.547814 \tValidation Loss: 1.537252 \t time: 0.3\n",
      "Validation loss decreased from 1.541061 to 1.537252. Model was saved\n",
      "Epoch: 46 \tTraining Loss: 1.543874 \tValidation Loss: 1.533260 \t time: 0.3\n",
      "Validation loss decreased from 1.537252 to 1.533260. Model was saved\n",
      "Epoch: 47 \tTraining Loss: 1.540843 \tValidation Loss: 1.529904 \t time: 0.3\n",
      "Validation loss decreased from 1.533260 to 1.529904. Model was saved\n",
      "Epoch: 48 \tTraining Loss: 1.538751 \tValidation Loss: 1.527238 \t time: 0.2\n",
      "Validation loss decreased from 1.529904 to 1.527238. Model was saved\n",
      "Epoch: 49 \tTraining Loss: 1.536536 \tValidation Loss: 1.524853 \t time: 0.2\n",
      "Validation loss decreased from 1.527238 to 1.524853. Model was saved\n",
      "Epoch: 50 \tTraining Loss: 1.531107 \tValidation Loss: 1.521702 \t time: 0.3\n",
      "Validation loss decreased from 1.524853 to 1.521702. Model was saved\n",
      "Epoch: 51 \tTraining Loss: 1.530094 \tValidation Loss: 1.519299 \t time: 0.2\n",
      "Validation loss decreased from 1.521702 to 1.519299. Model was saved\n",
      "Epoch: 52 \tTraining Loss: 1.527110 \tValidation Loss: 1.517154 \t time: 0.2\n",
      "Validation loss decreased from 1.519299 to 1.517154. Model was saved\n",
      "Epoch: 53 \tTraining Loss: 1.523454 \tValidation Loss: 1.514990 \t time: 0.3\n",
      "Validation loss decreased from 1.517154 to 1.514990. Model was saved\n",
      "Epoch: 54 \tTraining Loss: 1.521157 \tValidation Loss: 1.512448 \t time: 0.3\n",
      "Validation loss decreased from 1.514990 to 1.512448. Model was saved\n",
      "Epoch: 55 \tTraining Loss: 1.520208 \tValidation Loss: 1.510250 \t time: 0.3\n",
      "Validation loss decreased from 1.512448 to 1.510250. Model was saved\n",
      "Epoch: 56 \tTraining Loss: 1.514306 \tValidation Loss: 1.508197 \t time: 0.3\n",
      "Validation loss decreased from 1.510250 to 1.508197. Model was saved\n",
      "Epoch: 57 \tTraining Loss: 1.514490 \tValidation Loss: 1.506325 \t time: 0.3\n",
      "Validation loss decreased from 1.508197 to 1.506325. Model was saved\n",
      "Epoch: 58 \tTraining Loss: 1.513285 \tValidation Loss: 1.504481 \t time: 0.2\n",
      "Validation loss decreased from 1.506325 to 1.504481. Model was saved\n",
      "Epoch: 59 \tTraining Loss: 1.507917 \tValidation Loss: 1.502534 \t time: 0.3\n",
      "Validation loss decreased from 1.504481 to 1.502534. Model was saved\n",
      "Epoch: 60 \tTraining Loss: 1.508005 \tValidation Loss: 1.500805 \t time: 0.2\n",
      "Validation loss decreased from 1.502534 to 1.500805. Model was saved\n",
      "Epoch: 61 \tTraining Loss: 1.503974 \tValidation Loss: 1.499166 \t time: 0.3\n",
      "Validation loss decreased from 1.500805 to 1.499166. Model was saved\n",
      "Epoch: 62 \tTraining Loss: 1.502945 \tValidation Loss: 1.497502 \t time: 0.3\n",
      "Validation loss decreased from 1.499166 to 1.497502. Model was saved\n",
      "Epoch: 63 \tTraining Loss: 1.500363 \tValidation Loss: 1.496284 \t time: 0.3\n",
      "Validation loss decreased from 1.497502 to 1.496284. Model was saved\n",
      "Epoch: 64 \tTraining Loss: 1.498401 \tValidation Loss: 1.494455 \t time: 0.3\n",
      "Validation loss decreased from 1.496284 to 1.494455. Model was saved\n",
      "Epoch: 65 \tTraining Loss: 1.496516 \tValidation Loss: 1.492726 \t time: 0.2\n",
      "Validation loss decreased from 1.494455 to 1.492726. Model was saved\n",
      "Epoch: 66 \tTraining Loss: 1.492208 \tValidation Loss: 1.491554 \t time: 0.3\n",
      "Validation loss decreased from 1.492726 to 1.491554. Model was saved\n",
      "Epoch: 67 \tTraining Loss: 1.491402 \tValidation Loss: 1.490625 \t time: 0.3\n",
      "Validation loss decreased from 1.491554 to 1.490625. Model was saved\n",
      "Epoch: 68 \tTraining Loss: 1.491933 \tValidation Loss: 1.489014 \t time: 0.2\n",
      "Validation loss decreased from 1.490625 to 1.489014. Model was saved\n",
      "Epoch: 69 \tTraining Loss: 1.489321 \tValidation Loss: 1.487604 \t time: 0.2\n",
      "Validation loss decreased from 1.489014 to 1.487604. Model was saved\n",
      "Epoch: 70 \tTraining Loss: 1.486553 \tValidation Loss: 1.486416 \t time: 0.3\n",
      "Validation loss decreased from 1.487604 to 1.486416. Model was saved\n",
      "Epoch: 71 \tTraining Loss: 1.486167 \tValidation Loss: 1.485000 \t time: 0.3\n",
      "Validation loss decreased from 1.486416 to 1.485000. Model was saved\n",
      "Epoch: 72 \tTraining Loss: 1.484596 \tValidation Loss: 1.484094 \t time: 0.2\n",
      "Validation loss decreased from 1.485000 to 1.484094. Model was saved\n",
      "Epoch: 73 \tTraining Loss: 1.482266 \tValidation Loss: 1.483055 \t time: 0.3\n",
      "Validation loss decreased from 1.484094 to 1.483055. Model was saved\n",
      "Epoch: 74 \tTraining Loss: 1.482854 \tValidation Loss: 1.481957 \t time: 0.3\n",
      "Validation loss decreased from 1.483055 to 1.481957. Model was saved\n",
      "Epoch: 75 \tTraining Loss: 1.478459 \tValidation Loss: 1.481227 \t time: 0.2\n",
      "Validation loss decreased from 1.481957 to 1.481227. Model was saved\n",
      "Epoch: 76 \tTraining Loss: 1.476318 \tValidation Loss: 1.480444 \t time: 0.3\n",
      "Validation loss decreased from 1.481227 to 1.480444. Model was saved\n",
      "Epoch: 77 \tTraining Loss: 1.478601 \tValidation Loss: 1.479571 \t time: 0.3\n",
      "Validation loss decreased from 1.480444 to 1.479571. Model was saved\n",
      "Epoch: 78 \tTraining Loss: 1.474398 \tValidation Loss: 1.478911 \t time: 0.3\n",
      "Validation loss decreased from 1.479571 to 1.478911. Model was saved\n",
      "Epoch: 79 \tTraining Loss: 1.476439 \tValidation Loss: 1.478292 \t time: 0.3\n",
      "Validation loss decreased from 1.478911 to 1.478292. Model was saved\n",
      "Epoch: 80 \tTraining Loss: 1.472062 \tValidation Loss: 1.478032 \t time: 0.3\n",
      "Validation loss decreased from 1.478292 to 1.478032. Model was saved\n",
      "Epoch: 81 \tTraining Loss: 1.473507 \tValidation Loss: 1.477098 \t time: 0.3\n",
      "Validation loss decreased from 1.478032 to 1.477098. Model was saved\n",
      "Epoch: 82 \tTraining Loss: 1.470390 \tValidation Loss: 1.476092 \t time: 0.2\n",
      "Validation loss decreased from 1.477098 to 1.476092. Model was saved\n",
      "Epoch: 83 \tTraining Loss: 1.469499 \tValidation Loss: 1.475435 \t time: 0.2\n",
      "Validation loss decreased from 1.476092 to 1.475435. Model was saved\n",
      "Epoch: 84 \tTraining Loss: 1.469056 \tValidation Loss: 1.474798 \t time: 0.3\n",
      "Validation loss decreased from 1.475435 to 1.474798. Model was saved\n",
      "Epoch: 85 \tTraining Loss: 1.467463 \tValidation Loss: 1.474256 \t time: 0.3\n",
      "Validation loss decreased from 1.474798 to 1.474256. Model was saved\n",
      "Epoch: 86 \tTraining Loss: 1.465459 \tValidation Loss: 1.473970 \t time: 0.2\n",
      "Validation loss decreased from 1.474256 to 1.473970. Model was saved\n",
      "Epoch: 87 \tTraining Loss: 1.467573 \tValidation Loss: 1.473150 \t time: 0.2\n",
      "Validation loss decreased from 1.473970 to 1.473150. Model was saved\n",
      "Epoch: 88 \tTraining Loss: 1.465768 \tValidation Loss: 1.472636 \t time: 0.3\n",
      "Validation loss decreased from 1.473150 to 1.472636. Model was saved\n",
      "Epoch: 89 \tTraining Loss: 1.465792 \tValidation Loss: 1.471940 \t time: 0.2\n",
      "Validation loss decreased from 1.472636 to 1.471940. Model was saved\n",
      "Epoch: 90 \tTraining Loss: 1.466703 \tValidation Loss: 1.471715 \t time: 0.3\n",
      "Validation loss decreased from 1.471940 to 1.471715. Model was saved\n",
      "Epoch: 91 \tTraining Loss: 1.462696 \tValidation Loss: 1.471870 \t time: 0.3\n",
      "Epoch: 92 \tTraining Loss: 1.462193 \tValidation Loss: 1.471153 \t time: 0.3\n",
      "Validation loss decreased from 1.471715 to 1.471153. Model was saved\n",
      "Epoch: 93 \tTraining Loss: 1.460063 \tValidation Loss: 1.470577 \t time: 0.2\n",
      "Validation loss decreased from 1.471153 to 1.470577. Model was saved\n",
      "Epoch: 94 \tTraining Loss: 1.459861 \tValidation Loss: 1.470216 \t time: 0.2\n",
      "Validation loss decreased from 1.470577 to 1.470216. Model was saved\n",
      "Epoch: 95 \tTraining Loss: 1.460600 \tValidation Loss: 1.469880 \t time: 0.2\n",
      "Validation loss decreased from 1.470216 to 1.469880. Model was saved\n",
      "Epoch: 96 \tTraining Loss: 1.457983 \tValidation Loss: 1.469592 \t time: 0.3\n",
      "Validation loss decreased from 1.469880 to 1.469592. Model was saved\n",
      "Epoch: 97 \tTraining Loss: 1.456129 \tValidation Loss: 1.469413 \t time: 0.2\n",
      "Validation loss decreased from 1.469592 to 1.469413. Model was saved\n",
      "Epoch: 98 \tTraining Loss: 1.458365 \tValidation Loss: 1.468924 \t time: 0.2\n",
      "Validation loss decreased from 1.469413 to 1.468924. Model was saved\n",
      "Epoch: 99 \tTraining Loss: 1.455677 \tValidation Loss: 1.468676 \t time: 0.2\n",
      "Validation loss decreased from 1.468924 to 1.468676. Model was saved\n",
      "Epoch: 100 \tTraining Loss: 1.454620 \tValidation Loss: 1.468317 \t time: 0.2\n",
      "Validation loss decreased from 1.468676 to 1.468317. Model was saved\n",
      "Epoch: 101 \tTraining Loss: 1.454892 \tValidation Loss: 1.467797 \t time: 0.2\n",
      "Validation loss decreased from 1.468317 to 1.467797. Model was saved\n",
      "Epoch: 102 \tTraining Loss: 1.452250 \tValidation Loss: 1.467376 \t time: 0.3\n",
      "Validation loss decreased from 1.467797 to 1.467376. Model was saved\n",
      "Epoch: 103 \tTraining Loss: 1.449618 \tValidation Loss: 1.467249 \t time: 0.3\n",
      "Validation loss decreased from 1.467376 to 1.467249. Model was saved\n",
      "Epoch: 104 \tTraining Loss: 1.453023 \tValidation Loss: 1.467293 \t time: 0.3\n",
      "Epoch: 105 \tTraining Loss: 1.451227 \tValidation Loss: 1.467384 \t time: 0.3\n",
      "Epoch: 106 \tTraining Loss: 1.451718 \tValidation Loss: 1.467529 \t time: 0.3\n",
      "Epoch: 107 \tTraining Loss: 1.449044 \tValidation Loss: 1.467219 \t time: 0.3\n",
      "Validation loss decreased from 1.467249 to 1.467219. Model was saved\n",
      "Epoch: 108 \tTraining Loss: 1.451697 \tValidation Loss: 1.466871 \t time: 0.2\n",
      "Validation loss decreased from 1.467219 to 1.466871. Model was saved\n",
      "Epoch: 109 \tTraining Loss: 1.449452 \tValidation Loss: 1.466473 \t time: 0.3\n",
      "Validation loss decreased from 1.466871 to 1.466473. Model was saved\n",
      "Epoch: 110 \tTraining Loss: 1.448778 \tValidation Loss: 1.466108 \t time: 0.3\n",
      "Validation loss decreased from 1.466473 to 1.466108. Model was saved\n",
      "Epoch: 111 \tTraining Loss: 1.446302 \tValidation Loss: 1.465940 \t time: 0.3\n",
      "Validation loss decreased from 1.466108 to 1.465940. Model was saved\n",
      "Epoch: 112 \tTraining Loss: 1.447946 \tValidation Loss: 1.465817 \t time: 0.2\n",
      "Validation loss decreased from 1.465940 to 1.465817. Model was saved\n",
      "Epoch: 113 \tTraining Loss: 1.446641 \tValidation Loss: 1.465841 \t time: 0.3\n",
      "Epoch: 114 \tTraining Loss: 1.446187 \tValidation Loss: 1.465607 \t time: 0.3\n",
      "Validation loss decreased from 1.465817 to 1.465607. Model was saved\n",
      "Epoch: 115 \tTraining Loss: 1.448819 \tValidation Loss: 1.464938 \t time: 0.3\n",
      "Validation loss decreased from 1.465607 to 1.464938. Model was saved\n",
      "Epoch: 116 \tTraining Loss: 1.445502 \tValidation Loss: 1.464234 \t time: 0.2\n",
      "Validation loss decreased from 1.464938 to 1.464234. Model was saved\n",
      "Epoch: 117 \tTraining Loss: 1.446366 \tValidation Loss: 1.463704 \t time: 0.2\n",
      "Validation loss decreased from 1.464234 to 1.463704. Model was saved\n",
      "Epoch: 118 \tTraining Loss: 1.443600 \tValidation Loss: 1.463366 \t time: 0.2\n",
      "Validation loss decreased from 1.463704 to 1.463366. Model was saved\n",
      "Epoch: 119 \tTraining Loss: 1.445390 \tValidation Loss: 1.462856 \t time: 0.2\n",
      "Validation loss decreased from 1.463366 to 1.462856. Model was saved\n",
      "Epoch: 120 \tTraining Loss: 1.443867 \tValidation Loss: 1.462285 \t time: 0.2\n",
      "Validation loss decreased from 1.462856 to 1.462285. Model was saved\n",
      "Epoch: 121 \tTraining Loss: 1.443586 \tValidation Loss: 1.462127 \t time: 0.2\n",
      "Validation loss decreased from 1.462285 to 1.462127. Model was saved\n",
      "Epoch: 122 \tTraining Loss: 1.444093 \tValidation Loss: 1.462100 \t time: 0.3\n",
      "Validation loss decreased from 1.462127 to 1.462100. Model was saved\n",
      "Epoch: 123 \tTraining Loss: 1.443175 \tValidation Loss: 1.461954 \t time: 0.3\n",
      "Validation loss decreased from 1.462100 to 1.461954. Model was saved\n",
      "Epoch: 124 \tTraining Loss: 1.442012 \tValidation Loss: 1.462070 \t time: 0.3\n",
      "Epoch: 125 \tTraining Loss: 1.444127 \tValidation Loss: 1.461774 \t time: 0.2\n",
      "Validation loss decreased from 1.461954 to 1.461774. Model was saved\n",
      "Epoch: 126 \tTraining Loss: 1.443073 \tValidation Loss: 1.461782 \t time: 0.2\n",
      "Epoch: 127 \tTraining Loss: 1.440581 \tValidation Loss: 1.461470 \t time: 0.2\n",
      "Validation loss decreased from 1.461774 to 1.461470. Model was saved\n",
      "Epoch: 128 \tTraining Loss: 1.441317 \tValidation Loss: 1.460934 \t time: 0.2\n",
      "Validation loss decreased from 1.461470 to 1.460934. Model was saved\n",
      "Epoch: 129 \tTraining Loss: 1.437646 \tValidation Loss: 1.460710 \t time: 0.3\n",
      "Validation loss decreased from 1.460934 to 1.460710. Model was saved\n",
      "Epoch: 130 \tTraining Loss: 1.440713 \tValidation Loss: 1.460488 \t time: 0.3\n",
      "Validation loss decreased from 1.460710 to 1.460488. Model was saved\n",
      "Epoch: 131 \tTraining Loss: 1.439041 \tValidation Loss: 1.460132 \t time: 0.3\n",
      "Validation loss decreased from 1.460488 to 1.460132. Model was saved\n",
      "Epoch: 132 \tTraining Loss: 1.437653 \tValidation Loss: 1.459922 \t time: 0.3\n",
      "Validation loss decreased from 1.460132 to 1.459922. Model was saved\n",
      "Epoch: 133 \tTraining Loss: 1.438055 \tValidation Loss: 1.459310 \t time: 0.2\n",
      "Validation loss decreased from 1.459922 to 1.459310. Model was saved\n",
      "Epoch: 134 \tTraining Loss: 1.438840 \tValidation Loss: 1.459047 \t time: 0.2\n",
      "Validation loss decreased from 1.459310 to 1.459047. Model was saved\n",
      "Epoch: 135 \tTraining Loss: 1.435232 \tValidation Loss: 1.458917 \t time: 0.2\n",
      "Validation loss decreased from 1.459047 to 1.458917. Model was saved\n",
      "Epoch: 136 \tTraining Loss: 1.436913 \tValidation Loss: 1.458547 \t time: 0.3\n",
      "Validation loss decreased from 1.458917 to 1.458547. Model was saved\n",
      "Epoch: 137 \tTraining Loss: 1.437819 \tValidation Loss: 1.458382 \t time: 0.3\n",
      "Validation loss decreased from 1.458547 to 1.458382. Model was saved\n",
      "Epoch: 138 \tTraining Loss: 1.435732 \tValidation Loss: 1.458232 \t time: 0.3\n",
      "Validation loss decreased from 1.458382 to 1.458232. Model was saved\n",
      "Epoch: 139 \tTraining Loss: 1.435747 \tValidation Loss: 1.458030 \t time: 0.3\n",
      "Validation loss decreased from 1.458232 to 1.458030. Model was saved\n",
      "Epoch: 140 \tTraining Loss: 1.435268 \tValidation Loss: 1.457369 \t time: 0.3\n",
      "Validation loss decreased from 1.458030 to 1.457369. Model was saved\n",
      "Epoch: 141 \tTraining Loss: 1.435102 \tValidation Loss: 1.457037 \t time: 0.3\n",
      "Validation loss decreased from 1.457369 to 1.457037. Model was saved\n",
      "Epoch: 142 \tTraining Loss: 1.436503 \tValidation Loss: 1.456960 \t time: 0.3\n",
      "Validation loss decreased from 1.457037 to 1.456960. Model was saved\n",
      "Epoch: 143 \tTraining Loss: 1.434916 \tValidation Loss: 1.457014 \t time: 0.3\n",
      "Epoch: 144 \tTraining Loss: 1.434430 \tValidation Loss: 1.457384 \t time: 0.3\n",
      "Epoch: 145 \tTraining Loss: 1.434201 \tValidation Loss: 1.457646 \t time: 0.2\n",
      "Epoch: 146 \tTraining Loss: 1.433753 \tValidation Loss: 1.457465 \t time: 0.3\n",
      "Epoch: 147 \tTraining Loss: 1.434051 \tValidation Loss: 1.456996 \t time: 0.2\n",
      "Epoch: 148 \tTraining Loss: 1.432615 \tValidation Loss: 1.456384 \t time: 0.3\n",
      "Validation loss decreased from 1.456960 to 1.456384. Model was saved\n",
      "Epoch: 149 \tTraining Loss: 1.429960 \tValidation Loss: 1.456137 \t time: 0.2\n",
      "Validation loss decreased from 1.456384 to 1.456137. Model was saved\n",
      "Epoch: 150 \tTraining Loss: 1.432214 \tValidation Loss: 1.455986 \t time: 0.3\n",
      "Validation loss decreased from 1.456137 to 1.455986. Model was saved\n",
      "Epoch: 151 \tTraining Loss: 1.433375 \tValidation Loss: 1.456134 \t time: 0.3\n",
      "Epoch: 152 \tTraining Loss: 1.432250 \tValidation Loss: 1.456406 \t time: 0.3\n",
      "Epoch: 153 \tTraining Loss: 1.430970 \tValidation Loss: 1.456212 \t time: 0.2\n",
      "Epoch: 154 \tTraining Loss: 1.431784 \tValidation Loss: 1.455674 \t time: 0.3\n",
      "Validation loss decreased from 1.455986 to 1.455674. Model was saved\n",
      "Epoch: 155 \tTraining Loss: 1.429271 \tValidation Loss: 1.455169 \t time: 0.3\n",
      "Validation loss decreased from 1.455674 to 1.455169. Model was saved\n",
      "Epoch: 156 \tTraining Loss: 1.428435 \tValidation Loss: 1.455001 \t time: 0.3\n",
      "Validation loss decreased from 1.455169 to 1.455001. Model was saved\n",
      "Epoch: 157 \tTraining Loss: 1.428983 \tValidation Loss: 1.454874 \t time: 0.2\n",
      "Validation loss decreased from 1.455001 to 1.454874. Model was saved\n",
      "Epoch: 158 \tTraining Loss: 1.429236 \tValidation Loss: 1.454200 \t time: 0.2\n",
      "Validation loss decreased from 1.454874 to 1.454200. Model was saved\n",
      "Epoch: 159 \tTraining Loss: 1.428930 \tValidation Loss: 1.453808 \t time: 0.2\n",
      "Validation loss decreased from 1.454200 to 1.453808. Model was saved\n",
      "Epoch: 160 \tTraining Loss: 1.426661 \tValidation Loss: 1.453604 \t time: 0.2\n",
      "Validation loss decreased from 1.453808 to 1.453604. Model was saved\n",
      "Epoch: 161 \tTraining Loss: 1.427471 \tValidation Loss: 1.453549 \t time: 0.2\n",
      "Validation loss decreased from 1.453604 to 1.453549. Model was saved\n",
      "Epoch: 162 \tTraining Loss: 1.425726 \tValidation Loss: 1.453415 \t time: 0.3\n",
      "Validation loss decreased from 1.453549 to 1.453415. Model was saved\n",
      "Epoch: 163 \tTraining Loss: 1.427208 \tValidation Loss: 1.453004 \t time: 0.3\n",
      "Validation loss decreased from 1.453415 to 1.453004. Model was saved\n",
      "Epoch: 164 \tTraining Loss: 1.428161 \tValidation Loss: 1.452669 \t time: 0.3\n",
      "Validation loss decreased from 1.453004 to 1.452669. Model was saved\n",
      "Epoch: 165 \tTraining Loss: 1.426696 \tValidation Loss: 1.452334 \t time: 0.3\n",
      "Validation loss decreased from 1.452669 to 1.452334. Model was saved\n",
      "Epoch: 166 \tTraining Loss: 1.425879 \tValidation Loss: 1.452022 \t time: 0.3\n",
      "Validation loss decreased from 1.452334 to 1.452022. Model was saved\n",
      "Epoch: 167 \tTraining Loss: 1.424653 \tValidation Loss: 1.451479 \t time: 0.2\n",
      "Validation loss decreased from 1.452022 to 1.451479. Model was saved\n",
      "Epoch: 168 \tTraining Loss: 1.427034 \tValidation Loss: 1.450812 \t time: 0.2\n",
      "Validation loss decreased from 1.451479 to 1.450812. Model was saved\n",
      "Epoch: 169 \tTraining Loss: 1.424293 \tValidation Loss: 1.450470 \t time: 0.3\n",
      "Validation loss decreased from 1.450812 to 1.450470. Model was saved\n",
      "Epoch: 170 \tTraining Loss: 1.424157 \tValidation Loss: 1.450763 \t time: 0.3\n",
      "Epoch: 171 \tTraining Loss: 1.423082 \tValidation Loss: 1.451224 \t time: 0.2\n",
      "Epoch: 172 \tTraining Loss: 1.422257 \tValidation Loss: 1.451079 \t time: 0.3\n",
      "Epoch: 173 \tTraining Loss: 1.424092 \tValidation Loss: 1.450423 \t time: 0.3\n",
      "Validation loss decreased from 1.450470 to 1.450423. Model was saved\n",
      "Epoch: 174 \tTraining Loss: 1.424060 \tValidation Loss: 1.449807 \t time: 0.3\n",
      "Validation loss decreased from 1.450423 to 1.449807. Model was saved\n",
      "Epoch: 175 \tTraining Loss: 1.423311 \tValidation Loss: 1.449347 \t time: 0.2\n",
      "Validation loss decreased from 1.449807 to 1.449347. Model was saved\n",
      "Epoch: 176 \tTraining Loss: 1.424595 \tValidation Loss: 1.449349 \t time: 0.2\n",
      "Epoch: 177 \tTraining Loss: 1.422033 \tValidation Loss: 1.449523 \t time: 0.2\n",
      "Epoch: 178 \tTraining Loss: 1.421847 \tValidation Loss: 1.449552 \t time: 0.3\n",
      "Epoch: 179 \tTraining Loss: 1.421149 \tValidation Loss: 1.448839 \t time: 0.3\n",
      "Validation loss decreased from 1.449347 to 1.448839. Model was saved\n",
      "Epoch: 180 \tTraining Loss: 1.421929 \tValidation Loss: 1.448003 \t time: 0.3\n",
      "Validation loss decreased from 1.448839 to 1.448003. Model was saved\n",
      "Epoch: 181 \tTraining Loss: 1.420017 \tValidation Loss: 1.447391 \t time: 0.3\n",
      "Validation loss decreased from 1.448003 to 1.447391. Model was saved\n",
      "Epoch: 182 \tTraining Loss: 1.419532 \tValidation Loss: 1.446982 \t time: 0.3\n",
      "Validation loss decreased from 1.447391 to 1.446982. Model was saved\n",
      "Epoch: 183 \tTraining Loss: 1.420649 \tValidation Loss: 1.446895 \t time: 0.3\n",
      "Validation loss decreased from 1.446982 to 1.446895. Model was saved\n",
      "Epoch: 184 \tTraining Loss: 1.419271 \tValidation Loss: 1.447061 \t time: 0.3\n",
      "Epoch: 185 \tTraining Loss: 1.420641 \tValidation Loss: 1.447248 \t time: 0.3\n",
      "Epoch: 186 \tTraining Loss: 1.418735 \tValidation Loss: 1.447328 \t time: 0.3\n",
      "Epoch: 187 \tTraining Loss: 1.419185 \tValidation Loss: 1.446939 \t time: 0.3\n",
      "Epoch: 188 \tTraining Loss: 1.417991 \tValidation Loss: 1.446496 \t time: 0.3\n",
      "Validation loss decreased from 1.446895 to 1.446496. Model was saved\n",
      "Epoch: 189 \tTraining Loss: 1.419605 \tValidation Loss: 1.446402 \t time: 0.3\n",
      "Validation loss decreased from 1.446496 to 1.446402. Model was saved\n",
      "Epoch: 190 \tTraining Loss: 1.420120 \tValidation Loss: 1.446342 \t time: 0.3\n",
      "Validation loss decreased from 1.446402 to 1.446342. Model was saved\n",
      "Epoch: 191 \tTraining Loss: 1.418925 \tValidation Loss: 1.446421 \t time: 0.3\n",
      "Epoch: 192 \tTraining Loss: 1.416934 \tValidation Loss: 1.446296 \t time: 0.2\n",
      "Validation loss decreased from 1.446342 to 1.446296. Model was saved\n",
      "Epoch: 193 \tTraining Loss: 1.418187 \tValidation Loss: 1.446071 \t time: 0.3\n",
      "Validation loss decreased from 1.446296 to 1.446071. Model was saved\n",
      "Epoch: 194 \tTraining Loss: 1.415935 \tValidation Loss: 1.445575 \t time: 0.3\n",
      "Validation loss decreased from 1.446071 to 1.445575. Model was saved\n",
      "Epoch: 195 \tTraining Loss: 1.415172 \tValidation Loss: 1.444837 \t time: 0.3\n",
      "Validation loss decreased from 1.445575 to 1.444837. Model was saved\n",
      "Epoch: 196 \tTraining Loss: 1.416056 \tValidation Loss: 1.444152 \t time: 0.3\n",
      "Validation loss decreased from 1.444837 to 1.444152. Model was saved\n",
      "Epoch: 197 \tTraining Loss: 1.416091 \tValidation Loss: 1.443810 \t time: 0.3\n",
      "Validation loss decreased from 1.444152 to 1.443810. Model was saved\n",
      "Epoch: 198 \tTraining Loss: 1.414853 \tValidation Loss: 1.443429 \t time: 0.3\n",
      "Validation loss decreased from 1.443810 to 1.443429. Model was saved\n",
      "Epoch: 199 \tTraining Loss: 1.415465 \tValidation Loss: 1.443161 \t time: 0.3\n",
      "Validation loss decreased from 1.443429 to 1.443161. Model was saved\n",
      "Epoch: 200 \tTraining Loss: 1.411939 \tValidation Loss: 1.443116 \t time: 0.3\n",
      "Validation loss decreased from 1.443161 to 1.443116. Model was saved\n",
      "Epoch: 201 \tTraining Loss: 1.415282 \tValidation Loss: 1.442594 \t time: 0.2\n",
      "Validation loss decreased from 1.443116 to 1.442594. Model was saved\n",
      "Epoch: 202 \tTraining Loss: 1.413175 \tValidation Loss: 1.441918 \t time: 0.3\n",
      "Validation loss decreased from 1.442594 to 1.441918. Model was saved\n",
      "Epoch: 203 \tTraining Loss: 1.416274 \tValidation Loss: 1.441442 \t time: 0.3\n",
      "Validation loss decreased from 1.441918 to 1.441442. Model was saved\n",
      "Epoch: 204 \tTraining Loss: 1.412664 \tValidation Loss: 1.440944 \t time: 0.3\n",
      "Validation loss decreased from 1.441442 to 1.440944. Model was saved\n",
      "Epoch: 205 \tTraining Loss: 1.412646 \tValidation Loss: 1.440800 \t time: 0.2\n",
      "Validation loss decreased from 1.440944 to 1.440800. Model was saved\n",
      "Epoch: 206 \tTraining Loss: 1.411711 \tValidation Loss: 1.440701 \t time: 0.3\n",
      "Validation loss decreased from 1.440800 to 1.440701. Model was saved\n",
      "Epoch: 207 \tTraining Loss: 1.411453 \tValidation Loss: 1.440590 \t time: 0.2\n",
      "Validation loss decreased from 1.440701 to 1.440590. Model was saved\n",
      "Epoch: 208 \tTraining Loss: 1.412769 \tValidation Loss: 1.440595 \t time: 0.3\n",
      "Epoch: 209 \tTraining Loss: 1.411599 \tValidation Loss: 1.440571 \t time: 0.3\n",
      "Validation loss decreased from 1.440590 to 1.440571. Model was saved\n",
      "Epoch: 210 \tTraining Loss: 1.409843 \tValidation Loss: 1.440378 \t time: 0.3\n",
      "Validation loss decreased from 1.440571 to 1.440378. Model was saved\n",
      "Epoch: 211 \tTraining Loss: 1.411656 \tValidation Loss: 1.440027 \t time: 0.2\n",
      "Validation loss decreased from 1.440378 to 1.440027. Model was saved\n",
      "Epoch: 212 \tTraining Loss: 1.407824 \tValidation Loss: 1.439619 \t time: 0.3\n",
      "Validation loss decreased from 1.440027 to 1.439619. Model was saved\n",
      "Epoch: 213 \tTraining Loss: 1.409712 \tValidation Loss: 1.439261 \t time: 0.2\n",
      "Validation loss decreased from 1.439619 to 1.439261. Model was saved\n",
      "Epoch: 214 \tTraining Loss: 1.410378 \tValidation Loss: 1.438797 \t time: 0.2\n",
      "Validation loss decreased from 1.439261 to 1.438797. Model was saved\n",
      "Epoch: 215 \tTraining Loss: 1.407833 \tValidation Loss: 1.438430 \t time: 0.3\n",
      "Validation loss decreased from 1.438797 to 1.438430. Model was saved\n",
      "Epoch: 216 \tTraining Loss: 1.408496 \tValidation Loss: 1.438188 \t time: 0.3\n",
      "Validation loss decreased from 1.438430 to 1.438188. Model was saved\n",
      "Epoch: 217 \tTraining Loss: 1.409193 \tValidation Loss: 1.437842 \t time: 0.3\n",
      "Validation loss decreased from 1.438188 to 1.437842. Model was saved\n",
      "Epoch: 218 \tTraining Loss: 1.408430 \tValidation Loss: 1.437486 \t time: 0.3\n",
      "Validation loss decreased from 1.437842 to 1.437486. Model was saved\n",
      "Epoch: 219 \tTraining Loss: 1.407209 \tValidation Loss: 1.437361 \t time: 0.3\n",
      "Validation loss decreased from 1.437486 to 1.437361. Model was saved\n",
      "Epoch: 220 \tTraining Loss: 1.406486 \tValidation Loss: 1.437276 \t time: 0.3\n",
      "Validation loss decreased from 1.437361 to 1.437276. Model was saved\n",
      "Epoch: 221 \tTraining Loss: 1.406716 \tValidation Loss: 1.437484 \t time: 0.3\n",
      "Epoch: 222 \tTraining Loss: 1.404693 \tValidation Loss: 1.437090 \t time: 0.3\n",
      "Validation loss decreased from 1.437276 to 1.437090. Model was saved\n",
      "Epoch: 223 \tTraining Loss: 1.407363 \tValidation Loss: 1.436642 \t time: 0.3\n",
      "Validation loss decreased from 1.437090 to 1.436642. Model was saved\n",
      "Epoch: 224 \tTraining Loss: 1.405607 \tValidation Loss: 1.436205 \t time: 0.3\n",
      "Validation loss decreased from 1.436642 to 1.436205. Model was saved\n",
      "Epoch: 225 \tTraining Loss: 1.405026 \tValidation Loss: 1.436068 \t time: 0.3\n",
      "Validation loss decreased from 1.436205 to 1.436068. Model was saved\n",
      "Epoch: 226 \tTraining Loss: 1.406963 \tValidation Loss: 1.436063 \t time: 0.2\n",
      "Validation loss decreased from 1.436068 to 1.436063. Model was saved\n",
      "Epoch: 227 \tTraining Loss: 1.405483 \tValidation Loss: 1.436172 \t time: 0.3\n",
      "Epoch: 228 \tTraining Loss: 1.403525 \tValidation Loss: 1.436344 \t time: 0.3\n",
      "Epoch: 229 \tTraining Loss: 1.405577 \tValidation Loss: 1.435854 \t time: 0.3\n",
      "Validation loss decreased from 1.436063 to 1.435854. Model was saved\n",
      "Epoch: 230 \tTraining Loss: 1.406854 \tValidation Loss: 1.435377 \t time: 0.2\n",
      "Validation loss decreased from 1.435854 to 1.435377. Model was saved\n",
      "Epoch: 231 \tTraining Loss: 1.403960 \tValidation Loss: 1.434671 \t time: 0.3\n",
      "Validation loss decreased from 1.435377 to 1.434671. Model was saved\n",
      "Epoch: 232 \tTraining Loss: 1.403704 \tValidation Loss: 1.433804 \t time: 0.3\n",
      "Validation loss decreased from 1.434671 to 1.433804. Model was saved\n",
      "Epoch: 233 \tTraining Loss: 1.403287 \tValidation Loss: 1.433532 \t time: 0.3\n",
      "Validation loss decreased from 1.433804 to 1.433532. Model was saved\n",
      "Epoch: 234 \tTraining Loss: 1.403247 \tValidation Loss: 1.433672 \t time: 0.3\n",
      "Epoch: 235 \tTraining Loss: 1.404785 \tValidation Loss: 1.433914 \t time: 0.3\n",
      "Epoch: 236 \tTraining Loss: 1.402661 \tValidation Loss: 1.433891 \t time: 0.3\n",
      "Epoch: 237 \tTraining Loss: 1.402684 \tValidation Loss: 1.433093 \t time: 0.3\n",
      "Validation loss decreased from 1.433532 to 1.433093. Model was saved\n",
      "Epoch: 238 \tTraining Loss: 1.400052 \tValidation Loss: 1.432824 \t time: 0.3\n",
      "Validation loss decreased from 1.433093 to 1.432824. Model was saved\n",
      "Epoch: 239 \tTraining Loss: 1.401687 \tValidation Loss: 1.432362 \t time: 0.3\n",
      "Validation loss decreased from 1.432824 to 1.432362. Model was saved\n",
      "Epoch: 240 \tTraining Loss: 1.400304 \tValidation Loss: 1.432315 \t time: 0.3\n",
      "Validation loss decreased from 1.432362 to 1.432315. Model was saved\n",
      "Epoch: 241 \tTraining Loss: 1.401362 \tValidation Loss: 1.432411 \t time: 0.3\n",
      "Epoch: 242 \tTraining Loss: 1.399520 \tValidation Loss: 1.431870 \t time: 0.3\n",
      "Validation loss decreased from 1.432315 to 1.431870. Model was saved\n",
      "Epoch: 243 \tTraining Loss: 1.399525 \tValidation Loss: 1.431468 \t time: 0.3\n",
      "Validation loss decreased from 1.431870 to 1.431468. Model was saved\n",
      "Epoch: 244 \tTraining Loss: 1.401680 \tValidation Loss: 1.431349 \t time: 0.3\n",
      "Validation loss decreased from 1.431468 to 1.431349. Model was saved\n",
      "Epoch: 245 \tTraining Loss: 1.397616 \tValidation Loss: 1.431166 \t time: 0.2\n",
      "Validation loss decreased from 1.431349 to 1.431166. Model was saved\n",
      "Epoch: 246 \tTraining Loss: 1.400686 \tValidation Loss: 1.431110 \t time: 0.3\n",
      "Validation loss decreased from 1.431166 to 1.431110. Model was saved\n",
      "Epoch: 247 \tTraining Loss: 1.396951 \tValidation Loss: 1.430624 \t time: 0.2\n",
      "Validation loss decreased from 1.431110 to 1.430624. Model was saved\n",
      "Epoch: 248 \tTraining Loss: 1.397896 \tValidation Loss: 1.429848 \t time: 0.3\n",
      "Validation loss decreased from 1.430624 to 1.429848. Model was saved\n",
      "Epoch: 249 \tTraining Loss: 1.399919 \tValidation Loss: 1.429160 \t time: 0.2\n",
      "Validation loss decreased from 1.429848 to 1.429160. Model was saved\n",
      "Epoch: 250 \tTraining Loss: 1.398477 \tValidation Loss: 1.428906 \t time: 0.3\n",
      "Validation loss decreased from 1.429160 to 1.428906. Model was saved\n",
      "Epoch: 251 \tTraining Loss: 1.396703 \tValidation Loss: 1.428806 \t time: 0.3\n",
      "Validation loss decreased from 1.428906 to 1.428806. Model was saved\n",
      "Epoch: 252 \tTraining Loss: 1.397697 \tValidation Loss: 1.428784 \t time: 0.3\n",
      "Validation loss decreased from 1.428806 to 1.428784. Model was saved\n",
      "Epoch: 253 \tTraining Loss: 1.400482 \tValidation Loss: 1.429165 \t time: 0.3\n",
      "Epoch: 254 \tTraining Loss: 1.396057 \tValidation Loss: 1.429263 \t time: 0.2\n",
      "Epoch: 255 \tTraining Loss: 1.395544 \tValidation Loss: 1.429241 \t time: 0.3\n",
      "Epoch: 256 \tTraining Loss: 1.396032 \tValidation Loss: 1.429489 \t time: 0.3\n",
      "Epoch: 257 \tTraining Loss: 1.394382 \tValidation Loss: 1.428473 \t time: 0.2\n",
      "Validation loss decreased from 1.428784 to 1.428473. Model was saved\n",
      "Epoch: 258 \tTraining Loss: 1.396545 \tValidation Loss: 1.427660 \t time: 0.2\n",
      "Validation loss decreased from 1.428473 to 1.427660. Model was saved\n",
      "Epoch: 259 \tTraining Loss: 1.393317 \tValidation Loss: 1.427192 \t time: 0.2\n",
      "Validation loss decreased from 1.427660 to 1.427192. Model was saved\n",
      "Epoch: 260 \tTraining Loss: 1.397683 \tValidation Loss: 1.426816 \t time: 0.2\n",
      "Validation loss decreased from 1.427192 to 1.426816. Model was saved\n",
      "Epoch: 261 \tTraining Loss: 1.395789 \tValidation Loss: 1.426913 \t time: 0.3\n",
      "Epoch: 262 \tTraining Loss: 1.395680 \tValidation Loss: 1.427347 \t time: 0.3\n",
      "Epoch: 263 \tTraining Loss: 1.392043 \tValidation Loss: 1.427935 \t time: 0.2\n",
      "Epoch: 264 \tTraining Loss: 1.394345 \tValidation Loss: 1.428216 \t time: 0.3\n",
      "Epoch: 265 \tTraining Loss: 1.392610 \tValidation Loss: 1.427864 \t time: 0.3\n",
      "Epoch: 266 \tTraining Loss: 1.396384 \tValidation Loss: 1.427212 \t time: 0.3\n",
      "Epoch: 267 \tTraining Loss: 1.391356 \tValidation Loss: 1.426707 \t time: 0.3\n",
      "Validation loss decreased from 1.426816 to 1.426707. Model was saved\n",
      "Epoch: 268 \tTraining Loss: 1.391716 \tValidation Loss: 1.426391 \t time: 0.2\n",
      "Validation loss decreased from 1.426707 to 1.426391. Model was saved\n",
      "Epoch: 269 \tTraining Loss: 1.393108 \tValidation Loss: 1.426268 \t time: 0.2\n",
      "Validation loss decreased from 1.426391 to 1.426268. Model was saved\n",
      "Epoch: 270 \tTraining Loss: 1.393129 \tValidation Loss: 1.426188 \t time: 0.2\n",
      "Validation loss decreased from 1.426268 to 1.426188. Model was saved\n",
      "Epoch: 271 \tTraining Loss: 1.390704 \tValidation Loss: 1.426113 \t time: 0.3\n",
      "Validation loss decreased from 1.426188 to 1.426113. Model was saved\n",
      "Epoch: 272 \tTraining Loss: 1.391110 \tValidation Loss: 1.425946 \t time: 0.2\n",
      "Validation loss decreased from 1.426113 to 1.425946. Model was saved\n",
      "Epoch: 273 \tTraining Loss: 1.388379 \tValidation Loss: 1.425963 \t time: 0.3\n",
      "Epoch: 274 \tTraining Loss: 1.391192 \tValidation Loss: 1.425967 \t time: 0.3\n",
      "Epoch: 275 \tTraining Loss: 1.390420 \tValidation Loss: 1.425881 \t time: 0.3\n",
      "Validation loss decreased from 1.425946 to 1.425881. Model was saved\n",
      "Epoch: 276 \tTraining Loss: 1.390408 \tValidation Loss: 1.425425 \t time: 0.3\n",
      "Validation loss decreased from 1.425881 to 1.425425. Model was saved\n",
      "Epoch: 277 \tTraining Loss: 1.389577 \tValidation Loss: 1.425006 \t time: 0.3\n",
      "Validation loss decreased from 1.425425 to 1.425006. Model was saved\n",
      "Epoch: 278 \tTraining Loss: 1.390564 \tValidation Loss: 1.424275 \t time: 0.3\n",
      "Validation loss decreased from 1.425006 to 1.424275. Model was saved\n",
      "Epoch: 279 \tTraining Loss: 1.386218 \tValidation Loss: 1.423933 \t time: 0.3\n",
      "Validation loss decreased from 1.424275 to 1.423933. Model was saved\n",
      "Epoch: 280 \tTraining Loss: 1.390254 \tValidation Loss: 1.423833 \t time: 0.3\n",
      "Validation loss decreased from 1.423933 to 1.423833. Model was saved\n",
      "Epoch: 281 \tTraining Loss: 1.389974 \tValidation Loss: 1.423507 \t time: 0.3\n",
      "Validation loss decreased from 1.423833 to 1.423507. Model was saved\n",
      "Epoch: 282 \tTraining Loss: 1.388089 \tValidation Loss: 1.423768 \t time: 0.3\n",
      "Epoch: 283 \tTraining Loss: 1.388417 \tValidation Loss: 1.424165 \t time: 0.2\n",
      "Epoch: 284 \tTraining Loss: 1.387793 \tValidation Loss: 1.424270 \t time: 0.3\n",
      "Epoch: 285 \tTraining Loss: 1.386774 \tValidation Loss: 1.423780 \t time: 0.3\n",
      "Epoch: 286 \tTraining Loss: 1.386310 \tValidation Loss: 1.423368 \t time: 0.2\n",
      "Validation loss decreased from 1.423507 to 1.423368. Model was saved\n",
      "Epoch: 287 \tTraining Loss: 1.388211 \tValidation Loss: 1.422794 \t time: 0.3\n",
      "Validation loss decreased from 1.423368 to 1.422794. Model was saved\n",
      "Epoch: 288 \tTraining Loss: 1.388377 \tValidation Loss: 1.422552 \t time: 0.3\n",
      "Validation loss decreased from 1.422794 to 1.422552. Model was saved\n",
      "Epoch: 289 \tTraining Loss: 1.386867 \tValidation Loss: 1.422315 \t time: 0.3\n",
      "Validation loss decreased from 1.422552 to 1.422315. Model was saved\n",
      "Epoch: 290 \tTraining Loss: 1.384897 \tValidation Loss: 1.421701 \t time: 0.3\n",
      "Validation loss decreased from 1.422315 to 1.421701. Model was saved\n",
      "Epoch: 291 \tTraining Loss: 1.384549 \tValidation Loss: 1.421770 \t time: 0.2\n",
      "Epoch: 292 \tTraining Loss: 1.384116 \tValidation Loss: 1.422001 \t time: 0.3\n",
      "Epoch: 293 \tTraining Loss: 1.386791 \tValidation Loss: 1.421856 \t time: 0.3\n",
      "Epoch: 294 \tTraining Loss: 1.384175 \tValidation Loss: 1.421756 \t time: 0.3\n",
      "Epoch: 295 \tTraining Loss: 1.384316 \tValidation Loss: 1.421059 \t time: 0.3\n",
      "Validation loss decreased from 1.421701 to 1.421059. Model was saved\n",
      "Epoch: 296 \tTraining Loss: 1.383947 \tValidation Loss: 1.420160 \t time: 0.2\n",
      "Validation loss decreased from 1.421059 to 1.420160. Model was saved\n",
      "Epoch: 297 \tTraining Loss: 1.383407 \tValidation Loss: 1.419586 \t time: 0.3\n",
      "Validation loss decreased from 1.420160 to 1.419586. Model was saved\n",
      "Epoch: 298 \tTraining Loss: 1.384280 \tValidation Loss: 1.419900 \t time: 0.3\n",
      "Epoch: 299 \tTraining Loss: 1.384298 \tValidation Loss: 1.420166 \t time: 0.3\n",
      "Epoch: 300 \tTraining Loss: 1.382119 \tValidation Loss: 1.420967 \t time: 0.3\n",
      "Epoch: 301 \tTraining Loss: 1.381836 \tValidation Loss: 1.422364 \t time: 0.3\n",
      "Epoch: 302 \tTraining Loss: 1.385207 \tValidation Loss: 1.422798 \t time: 0.3\n",
      "Epoch: 303 \tTraining Loss: 1.383709 \tValidation Loss: 1.422018 \t time: 0.3\n",
      "Epoch: 304 \tTraining Loss: 1.384075 \tValidation Loss: 1.421258 \t time: 0.3\n",
      "Epoch: 305 \tTraining Loss: 1.383300 \tValidation Loss: 1.420084 \t time: 0.3\n",
      "Epoch: 306 \tTraining Loss: 1.381133 \tValidation Loss: 1.419160 \t time: 0.3\n",
      "Validation loss decreased from 1.419586 to 1.419160. Model was saved\n",
      "Epoch: 307 \tTraining Loss: 1.380096 \tValidation Loss: 1.419146 \t time: 0.3\n",
      "Validation loss decreased from 1.419160 to 1.419146. Model was saved\n",
      "Epoch: 308 \tTraining Loss: 1.383425 \tValidation Loss: 1.419520 \t time: 0.3\n",
      "Epoch: 309 \tTraining Loss: 1.381058 \tValidation Loss: 1.420273 \t time: 0.3\n",
      "Epoch: 310 \tTraining Loss: 1.382408 \tValidation Loss: 1.421130 \t time: 0.3\n",
      "Epoch: 311 \tTraining Loss: 1.379589 \tValidation Loss: 1.421206 \t time: 0.3\n",
      "Epoch: 312 \tTraining Loss: 1.379711 \tValidation Loss: 1.420194 \t time: 0.3\n",
      "Epoch: 313 \tTraining Loss: 1.381259 \tValidation Loss: 1.419353 \t time: 0.3\n",
      "Epoch: 314 \tTraining Loss: 1.381032 \tValidation Loss: 1.418475 \t time: 0.3\n",
      "Validation loss decreased from 1.419146 to 1.418475. Model was saved\n",
      "Epoch: 315 \tTraining Loss: 1.376969 \tValidation Loss: 1.417983 \t time: 0.3\n",
      "Validation loss decreased from 1.418475 to 1.417983. Model was saved\n",
      "Epoch: 316 \tTraining Loss: 1.380293 \tValidation Loss: 1.417954 \t time: 0.3\n",
      "Validation loss decreased from 1.417983 to 1.417954. Model was saved\n",
      "Epoch: 317 \tTraining Loss: 1.377858 \tValidation Loss: 1.418026 \t time: 0.3\n",
      "Epoch: 318 \tTraining Loss: 1.379862 \tValidation Loss: 1.418367 \t time: 0.3\n",
      "Epoch: 319 \tTraining Loss: 1.380810 \tValidation Loss: 1.418782 \t time: 0.3\n",
      "Epoch: 320 \tTraining Loss: 1.378453 \tValidation Loss: 1.418992 \t time: 0.2\n",
      "Epoch: 321 \tTraining Loss: 1.378743 \tValidation Loss: 1.418713 \t time: 0.3\n",
      "Epoch: 322 \tTraining Loss: 1.379822 \tValidation Loss: 1.418086 \t time: 0.2\n",
      "Epoch: 323 \tTraining Loss: 1.377113 \tValidation Loss: 1.417634 \t time: 0.3\n",
      "Validation loss decreased from 1.417954 to 1.417634. Model was saved\n",
      "Epoch: 324 \tTraining Loss: 1.376283 \tValidation Loss: 1.417178 \t time: 0.3\n",
      "Validation loss decreased from 1.417634 to 1.417178. Model was saved\n",
      "Epoch: 325 \tTraining Loss: 1.378029 \tValidation Loss: 1.417068 \t time: 0.3\n",
      "Validation loss decreased from 1.417178 to 1.417068. Model was saved\n",
      "Epoch: 326 \tTraining Loss: 1.377282 \tValidation Loss: 1.417183 \t time: 0.2\n",
      "Epoch: 327 \tTraining Loss: 1.376826 \tValidation Loss: 1.417034 \t time: 0.2\n",
      "Validation loss decreased from 1.417068 to 1.417034. Model was saved\n",
      "Epoch: 328 \tTraining Loss: 1.378569 \tValidation Loss: 1.416834 \t time: 0.2\n",
      "Validation loss decreased from 1.417034 to 1.416834. Model was saved\n",
      "Epoch: 329 \tTraining Loss: 1.375285 \tValidation Loss: 1.416808 \t time: 0.2\n",
      "Validation loss decreased from 1.416834 to 1.416808. Model was saved\n",
      "Epoch: 330 \tTraining Loss: 1.375680 \tValidation Loss: 1.416542 \t time: 0.2\n",
      "Validation loss decreased from 1.416808 to 1.416542. Model was saved\n",
      "Epoch: 331 \tTraining Loss: 1.374784 \tValidation Loss: 1.416525 \t time: 0.2\n",
      "Validation loss decreased from 1.416542 to 1.416525. Model was saved\n",
      "Epoch: 332 \tTraining Loss: 1.375369 \tValidation Loss: 1.416341 \t time: 0.3\n",
      "Validation loss decreased from 1.416525 to 1.416341. Model was saved\n",
      "Epoch: 333 \tTraining Loss: 1.375682 \tValidation Loss: 1.415597 \t time: 0.2\n",
      "Validation loss decreased from 1.416341 to 1.415597. Model was saved\n",
      "Epoch: 334 \tTraining Loss: 1.374517 \tValidation Loss: 1.415021 \t time: 0.2\n",
      "Validation loss decreased from 1.415597 to 1.415021. Model was saved\n",
      "Epoch: 335 \tTraining Loss: 1.373801 \tValidation Loss: 1.414620 \t time: 0.3\n",
      "Validation loss decreased from 1.415021 to 1.414620. Model was saved\n",
      "Epoch: 336 \tTraining Loss: 1.374370 \tValidation Loss: 1.414359 \t time: 0.3\n",
      "Validation loss decreased from 1.414620 to 1.414359. Model was saved\n",
      "Epoch: 337 \tTraining Loss: 1.373826 \tValidation Loss: 1.414823 \t time: 0.2\n",
      "Epoch: 338 \tTraining Loss: 1.374084 \tValidation Loss: 1.415298 \t time: 0.2\n",
      "Epoch: 339 \tTraining Loss: 1.376307 \tValidation Loss: 1.415140 \t time: 0.3\n",
      "Epoch: 340 \tTraining Loss: 1.376961 \tValidation Loss: 1.414553 \t time: 0.3\n",
      "Epoch: 341 \tTraining Loss: 1.372620 \tValidation Loss: 1.413898 \t time: 0.3\n",
      "Validation loss decreased from 1.414359 to 1.413898. Model was saved\n",
      "Epoch: 342 \tTraining Loss: 1.373217 \tValidation Loss: 1.413451 \t time: 0.3\n",
      "Validation loss decreased from 1.413898 to 1.413451. Model was saved\n",
      "Epoch: 343 \tTraining Loss: 1.371488 \tValidation Loss: 1.413027 \t time: 0.3\n",
      "Validation loss decreased from 1.413451 to 1.413027. Model was saved\n",
      "Epoch: 344 \tTraining Loss: 1.370708 \tValidation Loss: 1.412976 \t time: 0.3\n",
      "Validation loss decreased from 1.413027 to 1.412976. Model was saved\n",
      "Epoch: 345 \tTraining Loss: 1.371935 \tValidation Loss: 1.412647 \t time: 0.3\n",
      "Validation loss decreased from 1.412976 to 1.412647. Model was saved\n",
      "Epoch: 346 \tTraining Loss: 1.372283 \tValidation Loss: 1.412655 \t time: 0.3\n",
      "Epoch: 347 \tTraining Loss: 1.370473 \tValidation Loss: 1.412723 \t time: 0.3\n",
      "Epoch: 348 \tTraining Loss: 1.370819 \tValidation Loss: 1.412759 \t time: 0.3\n",
      "Epoch: 349 \tTraining Loss: 1.370096 \tValidation Loss: 1.412323 \t time: 0.2\n",
      "Validation loss decreased from 1.412647 to 1.412323. Model was saved\n",
      "Epoch: 350 \tTraining Loss: 1.371154 \tValidation Loss: 1.411759 \t time: 0.3\n",
      "Validation loss decreased from 1.412323 to 1.411759. Model was saved\n",
      "Epoch: 351 \tTraining Loss: 1.370301 \tValidation Loss: 1.411698 \t time: 0.3\n",
      "Validation loss decreased from 1.411759 to 1.411698. Model was saved\n",
      "Epoch: 352 \tTraining Loss: 1.370387 \tValidation Loss: 1.411717 \t time: 0.3\n",
      "Epoch: 353 \tTraining Loss: 1.369183 \tValidation Loss: 1.411518 \t time: 0.3\n",
      "Validation loss decreased from 1.411698 to 1.411518. Model was saved\n",
      "Epoch: 354 \tTraining Loss: 1.369909 \tValidation Loss: 1.411438 \t time: 0.3\n",
      "Validation loss decreased from 1.411518 to 1.411438. Model was saved\n",
      "Epoch: 355 \tTraining Loss: 1.370736 \tValidation Loss: 1.411142 \t time: 0.2\n",
      "Validation loss decreased from 1.411438 to 1.411142. Model was saved\n",
      "Epoch: 356 \tTraining Loss: 1.370015 \tValidation Loss: 1.411040 \t time: 0.2\n",
      "Validation loss decreased from 1.411142 to 1.411040. Model was saved\n",
      "Epoch: 357 \tTraining Loss: 1.368159 \tValidation Loss: 1.410696 \t time: 0.2\n",
      "Validation loss decreased from 1.411040 to 1.410696. Model was saved\n",
      "Epoch: 358 \tTraining Loss: 1.368005 \tValidation Loss: 1.410006 \t time: 0.2\n",
      "Validation loss decreased from 1.410696 to 1.410006. Model was saved\n",
      "Epoch: 359 \tTraining Loss: 1.369613 \tValidation Loss: 1.409412 \t time: 0.3\n",
      "Validation loss decreased from 1.410006 to 1.409412. Model was saved\n",
      "Epoch: 360 \tTraining Loss: 1.367960 \tValidation Loss: 1.408923 \t time: 0.3\n",
      "Validation loss decreased from 1.409412 to 1.408923. Model was saved\n",
      "Epoch: 361 \tTraining Loss: 1.366678 \tValidation Loss: 1.408505 \t time: 0.2\n",
      "Validation loss decreased from 1.408923 to 1.408505. Model was saved\n",
      "Epoch: 362 \tTraining Loss: 1.370559 \tValidation Loss: 1.408241 \t time: 0.3\n",
      "Validation loss decreased from 1.408505 to 1.408241. Model was saved\n",
      "Epoch: 363 \tTraining Loss: 1.368721 \tValidation Loss: 1.408104 \t time: 0.3\n",
      "Validation loss decreased from 1.408241 to 1.408104. Model was saved\n",
      "Epoch: 364 \tTraining Loss: 1.368707 \tValidation Loss: 1.408232 \t time: 0.3\n",
      "Epoch: 365 \tTraining Loss: 1.367383 \tValidation Loss: 1.408147 \t time: 0.2\n",
      "Epoch: 366 \tTraining Loss: 1.367878 \tValidation Loss: 1.407704 \t time: 0.3\n",
      "Validation loss decreased from 1.408104 to 1.407704. Model was saved\n",
      "Epoch: 367 \tTraining Loss: 1.366950 \tValidation Loss: 1.407225 \t time: 0.2\n",
      "Validation loss decreased from 1.407704 to 1.407225. Model was saved\n",
      "Epoch: 368 \tTraining Loss: 1.367346 \tValidation Loss: 1.406934 \t time: 0.3\n",
      "Validation loss decreased from 1.407225 to 1.406934. Model was saved\n",
      "Epoch: 369 \tTraining Loss: 1.366764 \tValidation Loss: 1.407100 \t time: 0.3\n",
      "Epoch: 370 \tTraining Loss: 1.365635 \tValidation Loss: 1.407262 \t time: 0.3\n",
      "Epoch: 371 \tTraining Loss: 1.366457 \tValidation Loss: 1.407188 \t time: 0.3\n",
      "Epoch: 372 \tTraining Loss: 1.366578 \tValidation Loss: 1.407055 \t time: 0.3\n",
      "Epoch: 373 \tTraining Loss: 1.365135 \tValidation Loss: 1.407072 \t time: 0.3\n",
      "Epoch: 374 \tTraining Loss: 1.365134 \tValidation Loss: 1.406810 \t time: 0.3\n",
      "Validation loss decreased from 1.406934 to 1.406810. Model was saved\n",
      "Epoch: 375 \tTraining Loss: 1.363920 \tValidation Loss: 1.406612 \t time: 0.3\n",
      "Validation loss decreased from 1.406810 to 1.406612. Model was saved\n",
      "Epoch: 376 \tTraining Loss: 1.363346 \tValidation Loss: 1.406531 \t time: 0.3\n",
      "Validation loss decreased from 1.406612 to 1.406531. Model was saved\n",
      "Epoch: 377 \tTraining Loss: 1.363307 \tValidation Loss: 1.406479 \t time: 0.3\n",
      "Validation loss decreased from 1.406531 to 1.406479. Model was saved\n",
      "Epoch: 378 \tTraining Loss: 1.362760 \tValidation Loss: 1.405967 \t time: 0.3\n",
      "Validation loss decreased from 1.406479 to 1.405967. Model was saved\n",
      "Epoch: 379 \tTraining Loss: 1.363739 \tValidation Loss: 1.405260 \t time: 0.3\n",
      "Validation loss decreased from 1.405967 to 1.405260. Model was saved\n",
      "Epoch: 380 \tTraining Loss: 1.363315 \tValidation Loss: 1.404786 \t time: 0.2\n",
      "Validation loss decreased from 1.405260 to 1.404786. Model was saved\n",
      "Epoch: 381 \tTraining Loss: 1.363441 \tValidation Loss: 1.404648 \t time: 0.2\n",
      "Validation loss decreased from 1.404786 to 1.404648. Model was saved\n",
      "Epoch: 382 \tTraining Loss: 1.361520 \tValidation Loss: 1.404441 \t time: 0.3\n",
      "Validation loss decreased from 1.404648 to 1.404441. Model was saved\n",
      "Epoch: 383 \tTraining Loss: 1.363217 \tValidation Loss: 1.404445 \t time: 0.3\n",
      "Epoch: 384 \tTraining Loss: 1.363256 \tValidation Loss: 1.404255 \t time: 0.3\n",
      "Validation loss decreased from 1.404441 to 1.404255. Model was saved\n",
      "Epoch: 385 \tTraining Loss: 1.361743 \tValidation Loss: 1.403890 \t time: 0.2\n",
      "Validation loss decreased from 1.404255 to 1.403890. Model was saved\n",
      "Epoch: 386 \tTraining Loss: 1.363279 \tValidation Loss: 1.403780 \t time: 0.3\n",
      "Validation loss decreased from 1.403890 to 1.403780. Model was saved\n",
      "Epoch: 387 \tTraining Loss: 1.360713 \tValidation Loss: 1.403702 \t time: 0.3\n",
      "Validation loss decreased from 1.403780 to 1.403702. Model was saved\n",
      "Epoch: 388 \tTraining Loss: 1.359555 \tValidation Loss: 1.403184 \t time: 0.2\n",
      "Validation loss decreased from 1.403702 to 1.403184. Model was saved\n",
      "Epoch: 389 \tTraining Loss: 1.362282 \tValidation Loss: 1.402896 \t time: 0.2\n",
      "Validation loss decreased from 1.403184 to 1.402896. Model was saved\n",
      "Epoch: 390 \tTraining Loss: 1.365874 \tValidation Loss: 1.403004 \t time: 0.3\n",
      "Epoch: 391 \tTraining Loss: 1.361252 \tValidation Loss: 1.403339 \t time: 0.3\n",
      "Epoch: 392 \tTraining Loss: 1.361979 \tValidation Loss: 1.403764 \t time: 0.3\n",
      "Epoch: 393 \tTraining Loss: 1.361958 \tValidation Loss: 1.404062 \t time: 0.3\n",
      "Epoch: 394 \tTraining Loss: 1.359781 \tValidation Loss: 1.404345 \t time: 0.3\n",
      "Epoch: 395 \tTraining Loss: 1.358738 \tValidation Loss: 1.403717 \t time: 0.3\n",
      "Epoch: 396 \tTraining Loss: 1.360811 \tValidation Loss: 1.402637 \t time: 0.3\n",
      "Validation loss decreased from 1.402896 to 1.402637. Model was saved\n",
      "Epoch: 397 \tTraining Loss: 1.361124 \tValidation Loss: 1.402016 \t time: 0.3\n",
      "Validation loss decreased from 1.402637 to 1.402016. Model was saved\n",
      "Epoch: 398 \tTraining Loss: 1.360193 \tValidation Loss: 1.401955 \t time: 0.3\n",
      "Validation loss decreased from 1.402016 to 1.401955. Model was saved\n",
      "Epoch: 399 \tTraining Loss: 1.359763 \tValidation Loss: 1.402616 \t time: 0.3\n",
      "Epoch: 400 \tTraining Loss: 1.358464 \tValidation Loss: 1.403906 \t time: 0.3\n",
      "Epoch: 401 \tTraining Loss: 1.360384 \tValidation Loss: 1.404814 \t time: 0.3\n",
      "Epoch: 402 \tTraining Loss: 1.357495 \tValidation Loss: 1.405008 \t time: 0.3\n",
      "Epoch: 403 \tTraining Loss: 1.357993 \tValidation Loss: 1.404500 \t time: 0.3\n",
      "Epoch: 404 \tTraining Loss: 1.360283 \tValidation Loss: 1.403727 \t time: 0.2\n",
      "Epoch: 405 \tTraining Loss: 1.357801 \tValidation Loss: 1.403368 \t time: 0.2\n",
      "Epoch: 406 \tTraining Loss: 1.359462 \tValidation Loss: 1.403021 \t time: 0.3\n",
      "Epoch: 407 \tTraining Loss: 1.358072 \tValidation Loss: 1.402786 \t time: 0.3\n",
      "Epoch: 408 \tTraining Loss: 1.356326 \tValidation Loss: 1.402857 \t time: 0.3\n",
      "Epoch: 409 \tTraining Loss: 1.357519 \tValidation Loss: 1.403031 \t time: 0.3\n",
      "Epoch: 410 \tTraining Loss: 1.359395 \tValidation Loss: 1.403315 \t time: 0.3\n",
      "Epoch: 411 \tTraining Loss: 1.359027 \tValidation Loss: 1.403559 \t time: 0.2\n",
      "Epoch: 412 \tTraining Loss: 1.355971 \tValidation Loss: 1.403726 \t time: 0.3\n",
      "Epoch: 413 \tTraining Loss: 1.357620 \tValidation Loss: 1.403673 \t time: 0.3\n",
      "Epoch: 414 \tTraining Loss: 1.356969 \tValidation Loss: 1.403358 \t time: 0.3\n",
      "Epoch: 415 \tTraining Loss: 1.358596 \tValidation Loss: 1.402495 \t time: 0.3\n",
      "Epoch: 416 \tTraining Loss: 1.356023 \tValidation Loss: 1.402075 \t time: 0.3\n",
      "Epoch: 417 \tTraining Loss: 1.356429 \tValidation Loss: 1.401522 \t time: 0.3\n",
      "Validation loss decreased from 1.401955 to 1.401522. Model was saved\n",
      "Epoch: 418 \tTraining Loss: 1.354797 \tValidation Loss: 1.401238 \t time: 0.3\n",
      "Validation loss decreased from 1.401522 to 1.401238. Model was saved\n",
      "Epoch: 419 \tTraining Loss: 1.356287 \tValidation Loss: 1.401064 \t time: 0.2\n",
      "Validation loss decreased from 1.401238 to 1.401064. Model was saved\n",
      "Epoch: 420 \tTraining Loss: 1.357771 \tValidation Loss: 1.400839 \t time: 0.3\n",
      "Validation loss decreased from 1.401064 to 1.400839. Model was saved\n",
      "Epoch: 421 \tTraining Loss: 1.355082 \tValidation Loss: 1.400928 \t time: 0.2\n",
      "Epoch: 422 \tTraining Loss: 1.354888 \tValidation Loss: 1.401215 \t time: 0.3\n",
      "Epoch: 423 \tTraining Loss: 1.356158 \tValidation Loss: 1.401042 \t time: 0.3\n",
      "Epoch: 424 \tTraining Loss: 1.355143 \tValidation Loss: 1.400830 \t time: 0.3\n",
      "Validation loss decreased from 1.400839 to 1.400830. Model was saved\n",
      "Epoch: 425 \tTraining Loss: 1.356625 \tValidation Loss: 1.400468 \t time: 0.2\n",
      "Validation loss decreased from 1.400830 to 1.400468. Model was saved\n",
      "Epoch: 426 \tTraining Loss: 1.354971 \tValidation Loss: 1.399949 \t time: 0.3\n",
      "Validation loss decreased from 1.400468 to 1.399949. Model was saved\n",
      "Epoch: 427 \tTraining Loss: 1.355330 \tValidation Loss: 1.399646 \t time: 0.2\n",
      "Validation loss decreased from 1.399949 to 1.399646. Model was saved\n",
      "Epoch: 428 \tTraining Loss: 1.354585 \tValidation Loss: 1.399584 \t time: 0.3\n",
      "Validation loss decreased from 1.399646 to 1.399584. Model was saved\n",
      "Epoch: 429 \tTraining Loss: 1.353582 \tValidation Loss: 1.399774 \t time: 0.2\n",
      "Epoch: 430 \tTraining Loss: 1.355322 \tValidation Loss: 1.400191 \t time: 0.3\n",
      "Epoch: 431 \tTraining Loss: 1.353280 \tValidation Loss: 1.400589 \t time: 0.3\n",
      "Epoch: 432 \tTraining Loss: 1.352997 \tValidation Loss: 1.400810 \t time: 0.3\n",
      "Epoch: 433 \tTraining Loss: 1.351319 \tValidation Loss: 1.400637 \t time: 0.3\n",
      "Epoch: 434 \tTraining Loss: 1.349653 \tValidation Loss: 1.400507 \t time: 0.3\n",
      "Epoch: 435 \tTraining Loss: 1.352539 \tValidation Loss: 1.400455 \t time: 0.3\n",
      "Epoch: 436 \tTraining Loss: 1.353952 \tValidation Loss: 1.400450 \t time: 0.3\n",
      "Epoch: 437 \tTraining Loss: 1.352534 \tValidation Loss: 1.400560 \t time: 0.3\n",
      "Epoch: 438 \tTraining Loss: 1.353190 \tValidation Loss: 1.400655 \t time: 0.3\n",
      "Epoch: 439 \tTraining Loss: 1.349872 \tValidation Loss: 1.400936 \t time: 0.3\n",
      "Epoch: 440 \tTraining Loss: 1.350737 \tValidation Loss: 1.401084 \t time: 0.3\n",
      "Epoch: 441 \tTraining Loss: 1.351250 \tValidation Loss: 1.400958 \t time: 0.3\n",
      "Epoch: 442 \tTraining Loss: 1.352486 \tValidation Loss: 1.400547 \t time: 0.3\n",
      "Epoch: 443 \tTraining Loss: 1.352668 \tValidation Loss: 1.400017 \t time: 0.3\n",
      "Epoch: 444 \tTraining Loss: 1.349706 \tValidation Loss: 1.399593 \t time: 0.3\n",
      "Epoch: 445 \tTraining Loss: 1.351796 \tValidation Loss: 1.399489 \t time: 0.3\n",
      "Validation loss decreased from 1.399584 to 1.399489. Model was saved\n",
      "Epoch: 446 \tTraining Loss: 1.349975 \tValidation Loss: 1.399391 \t time: 0.3\n",
      "Validation loss decreased from 1.399489 to 1.399391. Model was saved\n",
      "Epoch: 447 \tTraining Loss: 1.350943 \tValidation Loss: 1.398999 \t time: 0.3\n",
      "Validation loss decreased from 1.399391 to 1.398999. Model was saved\n",
      "Epoch: 448 \tTraining Loss: 1.350399 \tValidation Loss: 1.398368 \t time: 0.3\n",
      "Validation loss decreased from 1.398999 to 1.398368. Model was saved\n",
      "Epoch: 449 \tTraining Loss: 1.351011 \tValidation Loss: 1.398384 \t time: 0.3\n",
      "Epoch: 450 \tTraining Loss: 1.351205 \tValidation Loss: 1.398307 \t time: 0.3\n",
      "Validation loss decreased from 1.398368 to 1.398307. Model was saved\n",
      "Epoch: 451 \tTraining Loss: 1.349115 \tValidation Loss: 1.397903 \t time: 0.3\n",
      "Validation loss decreased from 1.398307 to 1.397903. Model was saved\n",
      "Epoch: 452 \tTraining Loss: 1.348291 \tValidation Loss: 1.397351 \t time: 0.3\n",
      "Validation loss decreased from 1.397903 to 1.397351. Model was saved\n",
      "Epoch: 453 \tTraining Loss: 1.350686 \tValidation Loss: 1.396850 \t time: 0.3\n",
      "Validation loss decreased from 1.397351 to 1.396850. Model was saved\n",
      "Epoch: 454 \tTraining Loss: 1.349383 \tValidation Loss: 1.396753 \t time: 0.2\n",
      "Validation loss decreased from 1.396850 to 1.396753. Model was saved\n",
      "Epoch: 455 \tTraining Loss: 1.346583 \tValidation Loss: 1.396733 \t time: 0.3\n",
      "Validation loss decreased from 1.396753 to 1.396733. Model was saved\n",
      "Epoch: 456 \tTraining Loss: 1.348511 \tValidation Loss: 1.396692 \t time: 0.3\n",
      "Validation loss decreased from 1.396733 to 1.396692. Model was saved\n",
      "Epoch: 457 \tTraining Loss: 1.347797 \tValidation Loss: 1.397018 \t time: 0.3\n",
      "Epoch: 458 \tTraining Loss: 1.347529 \tValidation Loss: 1.397492 \t time: 0.3\n",
      "Epoch: 459 \tTraining Loss: 1.350162 \tValidation Loss: 1.397549 \t time: 0.3\n",
      "Epoch: 460 \tTraining Loss: 1.348619 \tValidation Loss: 1.397437 \t time: 0.3\n",
      "Epoch: 461 \tTraining Loss: 1.347194 \tValidation Loss: 1.397283 \t time: 0.3\n",
      "Epoch: 462 \tTraining Loss: 1.348073 \tValidation Loss: 1.396807 \t time: 0.3\n",
      "Epoch: 463 \tTraining Loss: 1.347768 \tValidation Loss: 1.396044 \t time: 0.3\n",
      "Validation loss decreased from 1.396692 to 1.396044. Model was saved\n",
      "Epoch: 464 \tTraining Loss: 1.347442 \tValidation Loss: 1.395203 \t time: 0.3\n",
      "Validation loss decreased from 1.396044 to 1.395203. Model was saved\n",
      "Epoch: 465 \tTraining Loss: 1.347779 \tValidation Loss: 1.394814 \t time: 0.3\n",
      "Validation loss decreased from 1.395203 to 1.394814. Model was saved\n",
      "Epoch: 466 \tTraining Loss: 1.348107 \tValidation Loss: 1.394649 \t time: 0.3\n",
      "Validation loss decreased from 1.394814 to 1.394649. Model was saved\n",
      "Epoch: 467 \tTraining Loss: 1.348403 \tValidation Loss: 1.394770 \t time: 0.3\n",
      "Epoch: 468 \tTraining Loss: 1.345321 \tValidation Loss: 1.394933 \t time: 0.3\n",
      "Epoch: 469 \tTraining Loss: 1.344495 \tValidation Loss: 1.394989 \t time: 0.3\n",
      "Epoch: 470 \tTraining Loss: 1.347318 \tValidation Loss: 1.395113 \t time: 0.3\n",
      "Epoch: 471 \tTraining Loss: 1.344986 \tValidation Loss: 1.395443 \t time: 0.3\n",
      "Epoch: 472 \tTraining Loss: 1.345335 \tValidation Loss: 1.395759 \t time: 0.3\n",
      "Epoch: 473 \tTraining Loss: 1.347048 \tValidation Loss: 1.395826 \t time: 0.3\n",
      "Epoch: 474 \tTraining Loss: 1.347067 \tValidation Loss: 1.396133 \t time: 0.3\n",
      "Epoch: 475 \tTraining Loss: 1.344524 \tValidation Loss: 1.396385 \t time: 0.3\n",
      "Epoch: 476 \tTraining Loss: 1.344923 \tValidation Loss: 1.396438 \t time: 0.3\n",
      "Epoch: 477 \tTraining Loss: 1.346279 \tValidation Loss: 1.396527 \t time: 0.3\n",
      "Epoch: 478 \tTraining Loss: 1.345195 \tValidation Loss: 1.396326 \t time: 0.3\n",
      "Epoch: 479 \tTraining Loss: 1.346156 \tValidation Loss: 1.396518 \t time: 0.3\n",
      "Epoch: 480 \tTraining Loss: 1.345478 \tValidation Loss: 1.396564 \t time: 0.3\n",
      "Epoch: 481 \tTraining Loss: 1.343801 \tValidation Loss: 1.396437 \t time: 0.3\n",
      "Epoch: 482 \tTraining Loss: 1.344635 \tValidation Loss: 1.395772 \t time: 0.3\n",
      "Epoch: 483 \tTraining Loss: 1.343614 \tValidation Loss: 1.394906 \t time: 0.3\n",
      "Epoch: 484 \tTraining Loss: 1.345100 \tValidation Loss: 1.394736 \t time: 0.3\n",
      "Epoch: 485 \tTraining Loss: 1.344357 \tValidation Loss: 1.394592 \t time: 0.3\n",
      "Validation loss decreased from 1.394649 to 1.394592. Model was saved\n",
      "Epoch: 486 \tTraining Loss: 1.342138 \tValidation Loss: 1.394555 \t time: 0.3\n",
      "Validation loss decreased from 1.394592 to 1.394555. Model was saved\n",
      "Epoch: 487 \tTraining Loss: 1.343682 \tValidation Loss: 1.394744 \t time: 0.2\n",
      "Epoch: 488 \tTraining Loss: 1.345436 \tValidation Loss: 1.394888 \t time: 0.2\n",
      "Epoch: 489 \tTraining Loss: 1.341859 \tValidation Loss: 1.395381 \t time: 0.3\n",
      "Epoch: 490 \tTraining Loss: 1.342425 \tValidation Loss: 1.395441 \t time: 0.3\n",
      "Epoch: 491 \tTraining Loss: 1.341538 \tValidation Loss: 1.395379 \t time: 0.3\n",
      "Epoch: 492 \tTraining Loss: 1.341728 \tValidation Loss: 1.395109 \t time: 0.3\n",
      "Epoch: 493 \tTraining Loss: 1.342680 \tValidation Loss: 1.394683 \t time: 0.3\n",
      "Epoch: 494 \tTraining Loss: 1.341910 \tValidation Loss: 1.394304 \t time: 0.3\n",
      "Validation loss decreased from 1.394555 to 1.394304. Model was saved\n",
      "Epoch: 495 \tTraining Loss: 1.342683 \tValidation Loss: 1.394271 \t time: 0.3\n",
      "Validation loss decreased from 1.394304 to 1.394271. Model was saved\n",
      "Epoch: 496 \tTraining Loss: 1.343001 \tValidation Loss: 1.394529 \t time: 0.3\n",
      "Epoch: 497 \tTraining Loss: 1.342855 \tValidation Loss: 1.394918 \t time: 0.2\n",
      "Epoch: 498 \tTraining Loss: 1.339890 \tValidation Loss: 1.395169 \t time: 0.2\n",
      "Epoch: 499 \tTraining Loss: 1.342007 \tValidation Loss: 1.395770 \t time: 0.3\n",
      "Epoch: 500 \tTraining Loss: 1.340911 \tValidation Loss: 1.395904 \t time: 0.3\n",
      "Epoch: 501 \tTraining Loss: 1.340537 \tValidation Loss: 1.395825 \t time: 0.3\n",
      "Epoch: 502 \tTraining Loss: 1.341992 \tValidation Loss: 1.395774 \t time: 0.2\n",
      "Epoch: 503 \tTraining Loss: 1.340651 \tValidation Loss: 1.395532 \t time: 0.3\n",
      "Epoch: 504 \tTraining Loss: 1.340452 \tValidation Loss: 1.395572 \t time: 0.2\n",
      "Epoch: 505 \tTraining Loss: 1.339625 \tValidation Loss: 1.395501 \t time: 0.3\n",
      "Epoch: 506 \tTraining Loss: 1.340271 \tValidation Loss: 1.395177 \t time: 0.3\n",
      "Epoch: 507 \tTraining Loss: 1.340771 \tValidation Loss: 1.394771 \t time: 0.3\n",
      "Epoch: 508 \tTraining Loss: 1.342795 \tValidation Loss: 1.394341 \t time: 0.3\n",
      "Epoch: 509 \tTraining Loss: 1.341617 \tValidation Loss: 1.393701 \t time: 0.3\n",
      "Validation loss decreased from 1.394271 to 1.393701. Model was saved\n",
      "Epoch: 510 \tTraining Loss: 1.340681 \tValidation Loss: 1.393359 \t time: 0.2\n",
      "Validation loss decreased from 1.393701 to 1.393359. Model was saved\n",
      "Epoch: 511 \tTraining Loss: 1.341890 \tValidation Loss: 1.393209 \t time: 0.2\n",
      "Validation loss decreased from 1.393359 to 1.393209. Model was saved\n",
      "Epoch: 512 \tTraining Loss: 1.338993 \tValidation Loss: 1.393077 \t time: 0.3\n",
      "Validation loss decreased from 1.393209 to 1.393077. Model was saved\n",
      "Epoch: 513 \tTraining Loss: 1.339962 \tValidation Loss: 1.393369 \t time: 0.3\n",
      "Epoch: 514 \tTraining Loss: 1.339280 \tValidation Loss: 1.394053 \t time: 0.3\n",
      "Epoch: 515 \tTraining Loss: 1.339623 \tValidation Loss: 1.394376 \t time: 0.3\n",
      "Epoch: 516 \tTraining Loss: 1.338719 \tValidation Loss: 1.394423 \t time: 0.3\n",
      "Epoch: 517 \tTraining Loss: 1.341071 \tValidation Loss: 1.394023 \t time: 0.2\n",
      "Epoch: 518 \tTraining Loss: 1.338368 \tValidation Loss: 1.393426 \t time: 0.3\n",
      "Epoch: 519 \tTraining Loss: 1.340383 \tValidation Loss: 1.392971 \t time: 0.3\n",
      "Validation loss decreased from 1.393077 to 1.392971. Model was saved\n",
      "Epoch: 520 \tTraining Loss: 1.337992 \tValidation Loss: 1.392715 \t time: 0.2\n",
      "Validation loss decreased from 1.392971 to 1.392715. Model was saved\n",
      "Epoch: 521 \tTraining Loss: 1.339229 \tValidation Loss: 1.392313 \t time: 0.3\n",
      "Validation loss decreased from 1.392715 to 1.392313. Model was saved\n",
      "Epoch: 522 \tTraining Loss: 1.338415 \tValidation Loss: 1.392087 \t time: 0.3\n",
      "Validation loss decreased from 1.392313 to 1.392087. Model was saved\n",
      "Epoch: 523 \tTraining Loss: 1.334932 \tValidation Loss: 1.392243 \t time: 0.3\n",
      "Epoch: 524 \tTraining Loss: 1.337155 \tValidation Loss: 1.392632 \t time: 0.3\n",
      "Epoch: 525 \tTraining Loss: 1.338256 \tValidation Loss: 1.393023 \t time: 0.3\n",
      "Epoch: 526 \tTraining Loss: 1.336590 \tValidation Loss: 1.393140 \t time: 0.2\n",
      "Epoch: 527 \tTraining Loss: 1.339248 \tValidation Loss: 1.392710 \t time: 0.3\n",
      "Epoch: 528 \tTraining Loss: 1.335438 \tValidation Loss: 1.392143 \t time: 0.3\n",
      "Epoch: 529 \tTraining Loss: 1.336505 \tValidation Loss: 1.391675 \t time: 0.3\n",
      "Validation loss decreased from 1.392087 to 1.391675. Model was saved\n",
      "Epoch: 530 \tTraining Loss: 1.336051 \tValidation Loss: 1.391525 \t time: 0.3\n",
      "Validation loss decreased from 1.391675 to 1.391525. Model was saved\n",
      "Epoch: 531 \tTraining Loss: 1.336886 \tValidation Loss: 1.391941 \t time: 0.3\n",
      "Epoch: 532 \tTraining Loss: 1.335960 \tValidation Loss: 1.392452 \t time: 0.3\n",
      "Epoch: 533 \tTraining Loss: 1.336309 \tValidation Loss: 1.392919 \t time: 0.3\n",
      "Epoch: 534 \tTraining Loss: 1.337470 \tValidation Loss: 1.392755 \t time: 0.3\n",
      "Epoch: 535 \tTraining Loss: 1.335905 \tValidation Loss: 1.392395 \t time: 0.3\n",
      "Epoch: 536 \tTraining Loss: 1.335225 \tValidation Loss: 1.391849 \t time: 0.3\n",
      "Epoch: 537 \tTraining Loss: 1.336376 \tValidation Loss: 1.391605 \t time: 0.3\n",
      "Epoch: 538 \tTraining Loss: 1.335970 \tValidation Loss: 1.391608 \t time: 0.3\n",
      "Epoch: 539 \tTraining Loss: 1.334124 \tValidation Loss: 1.391871 \t time: 0.3\n",
      "Epoch: 540 \tTraining Loss: 1.336580 \tValidation Loss: 1.391883 \t time: 0.3\n",
      "Epoch: 541 \tTraining Loss: 1.334892 \tValidation Loss: 1.392091 \t time: 0.3\n",
      "Epoch: 542 \tTraining Loss: 1.334232 \tValidation Loss: 1.392456 \t time: 0.3\n",
      "Epoch: 543 \tTraining Loss: 1.335729 \tValidation Loss: 1.392616 \t time: 0.3\n",
      "Epoch: 544 \tTraining Loss: 1.336347 \tValidation Loss: 1.392311 \t time: 0.3\n",
      "Epoch: 545 \tTraining Loss: 1.334236 \tValidation Loss: 1.391739 \t time: 0.3\n",
      "Epoch: 546 \tTraining Loss: 1.334946 \tValidation Loss: 1.391644 \t time: 0.3\n",
      "Epoch: 547 \tTraining Loss: 1.334477 \tValidation Loss: 1.391659 \t time: 0.3\n",
      "Epoch: 548 \tTraining Loss: 1.334880 \tValidation Loss: 1.391659 \t time: 0.3\n",
      "Epoch: 549 \tTraining Loss: 1.335715 \tValidation Loss: 1.391351 \t time: 0.3\n",
      "Validation loss decreased from 1.391525 to 1.391351. Model was saved\n",
      "Epoch: 550 \tTraining Loss: 1.335209 \tValidation Loss: 1.390928 \t time: 0.3\n",
      "Validation loss decreased from 1.391351 to 1.390928. Model was saved\n",
      "Epoch: 551 \tTraining Loss: 1.334280 \tValidation Loss: 1.390411 \t time: 0.3\n",
      "Validation loss decreased from 1.390928 to 1.390411. Model was saved\n",
      "Epoch: 552 \tTraining Loss: 1.333445 \tValidation Loss: 1.389612 \t time: 0.3\n",
      "Validation loss decreased from 1.390411 to 1.389612. Model was saved\n",
      "Epoch: 553 \tTraining Loss: 1.336794 \tValidation Loss: 1.389009 \t time: 0.3\n",
      "Validation loss decreased from 1.389612 to 1.389009. Model was saved\n",
      "Epoch: 554 \tTraining Loss: 1.332813 \tValidation Loss: 1.388951 \t time: 0.2\n",
      "Validation loss decreased from 1.389009 to 1.388951. Model was saved\n",
      "Epoch: 555 \tTraining Loss: 1.332466 \tValidation Loss: 1.388793 \t time: 0.2\n",
      "Validation loss decreased from 1.388951 to 1.388793. Model was saved\n",
      "Epoch: 556 \tTraining Loss: 1.331346 \tValidation Loss: 1.389061 \t time: 0.3\n",
      "Epoch: 557 \tTraining Loss: 1.335725 \tValidation Loss: 1.389370 \t time: 0.3\n",
      "Epoch: 558 \tTraining Loss: 1.333026 \tValidation Loss: 1.389031 \t time: 0.3\n",
      "Epoch: 559 \tTraining Loss: 1.332905 \tValidation Loss: 1.388389 \t time: 0.3\n",
      "Validation loss decreased from 1.388793 to 1.388389. Model was saved\n",
      "Epoch: 560 \tTraining Loss: 1.330968 \tValidation Loss: 1.387779 \t time: 0.3\n",
      "Validation loss decreased from 1.388389 to 1.387779. Model was saved\n",
      "Epoch: 561 \tTraining Loss: 1.333603 \tValidation Loss: 1.387517 \t time: 0.3\n",
      "Validation loss decreased from 1.387779 to 1.387517. Model was saved\n",
      "Epoch: 562 \tTraining Loss: 1.332489 \tValidation Loss: 1.387490 \t time: 0.3\n",
      "Validation loss decreased from 1.387517 to 1.387490. Model was saved\n",
      "Epoch: 563 \tTraining Loss: 1.330851 \tValidation Loss: 1.387750 \t time: 0.3\n",
      "Epoch: 564 \tTraining Loss: 1.333280 \tValidation Loss: 1.388216 \t time: 0.3\n",
      "Epoch: 565 \tTraining Loss: 1.332982 \tValidation Loss: 1.388764 \t time: 0.3\n",
      "Epoch: 566 \tTraining Loss: 1.331840 \tValidation Loss: 1.389273 \t time: 0.2\n",
      "Epoch: 567 \tTraining Loss: 1.329786 \tValidation Loss: 1.389337 \t time: 0.3\n",
      "Epoch: 568 \tTraining Loss: 1.331237 \tValidation Loss: 1.388725 \t time: 0.3\n",
      "Epoch: 569 \tTraining Loss: 1.332697 \tValidation Loss: 1.387675 \t time: 0.2\n",
      "Epoch: 570 \tTraining Loss: 1.330495 \tValidation Loss: 1.386719 \t time: 0.3\n",
      "Validation loss decreased from 1.387490 to 1.386719. Model was saved\n",
      "Epoch: 571 \tTraining Loss: 1.330827 \tValidation Loss: 1.386529 \t time: 0.3\n",
      "Validation loss decreased from 1.386719 to 1.386529. Model was saved\n",
      "Epoch: 572 \tTraining Loss: 1.332962 \tValidation Loss: 1.386721 \t time: 0.3\n",
      "Epoch: 573 \tTraining Loss: 1.330675 \tValidation Loss: 1.387080 \t time: 0.3\n",
      "Epoch: 574 \tTraining Loss: 1.329315 \tValidation Loss: 1.387651 \t time: 0.3\n",
      "Epoch: 575 \tTraining Loss: 1.329206 \tValidation Loss: 1.388093 \t time: 0.3\n",
      "Epoch: 576 \tTraining Loss: 1.329709 \tValidation Loss: 1.388445 \t time: 0.2\n",
      "Epoch: 577 \tTraining Loss: 1.329672 \tValidation Loss: 1.388508 \t time: 0.3\n",
      "Epoch: 578 \tTraining Loss: 1.328701 \tValidation Loss: 1.388090 \t time: 0.3\n",
      "Epoch: 579 \tTraining Loss: 1.330139 \tValidation Loss: 1.387828 \t time: 0.2\n",
      "Epoch: 580 \tTraining Loss: 1.331503 \tValidation Loss: 1.387436 \t time: 0.3\n",
      "Epoch: 581 \tTraining Loss: 1.328220 \tValidation Loss: 1.387248 \t time: 0.2\n",
      "Epoch: 582 \tTraining Loss: 1.329803 \tValidation Loss: 1.387216 \t time: 0.3\n",
      "Epoch: 583 \tTraining Loss: 1.331176 \tValidation Loss: 1.386653 \t time: 0.3\n",
      "Epoch: 584 \tTraining Loss: 1.327739 \tValidation Loss: 1.386059 \t time: 0.3\n",
      "Validation loss decreased from 1.386529 to 1.386059. Model was saved\n",
      "Epoch: 585 \tTraining Loss: 1.330128 \tValidation Loss: 1.385669 \t time: 0.3\n",
      "Validation loss decreased from 1.386059 to 1.385669. Model was saved\n",
      "Epoch: 586 \tTraining Loss: 1.330056 \tValidation Loss: 1.385345 \t time: 0.3\n",
      "Validation loss decreased from 1.385669 to 1.385345. Model was saved\n",
      "Epoch: 587 \tTraining Loss: 1.330770 \tValidation Loss: 1.385394 \t time: 0.3\n",
      "Epoch: 588 \tTraining Loss: 1.330432 \tValidation Loss: 1.385319 \t time: 0.2\n",
      "Validation loss decreased from 1.385345 to 1.385319. Model was saved\n",
      "Epoch: 589 \tTraining Loss: 1.327687 \tValidation Loss: 1.385589 \t time: 0.3\n",
      "Epoch: 590 \tTraining Loss: 1.331278 \tValidation Loss: 1.385797 \t time: 0.2\n",
      "Epoch: 591 \tTraining Loss: 1.326193 \tValidation Loss: 1.385544 \t time: 0.3\n",
      "Epoch: 592 \tTraining Loss: 1.327422 \tValidation Loss: 1.385219 \t time: 0.3\n",
      "Validation loss decreased from 1.385319 to 1.385219. Model was saved\n",
      "Epoch: 593 \tTraining Loss: 1.326547 \tValidation Loss: 1.384932 \t time: 0.3\n",
      "Validation loss decreased from 1.385219 to 1.384932. Model was saved\n",
      "Epoch: 594 \tTraining Loss: 1.329472 \tValidation Loss: 1.384925 \t time: 0.3\n",
      "Validation loss decreased from 1.384932 to 1.384925. Model was saved\n",
      "Epoch: 595 \tTraining Loss: 1.328756 \tValidation Loss: 1.384674 \t time: 0.3\n",
      "Validation loss decreased from 1.384925 to 1.384674. Model was saved\n",
      "Epoch: 596 \tTraining Loss: 1.326022 \tValidation Loss: 1.384374 \t time: 0.3\n",
      "Validation loss decreased from 1.384674 to 1.384374. Model was saved\n",
      "Epoch: 597 \tTraining Loss: 1.327100 \tValidation Loss: 1.384260 \t time: 0.3\n",
      "Validation loss decreased from 1.384374 to 1.384260. Model was saved\n",
      "Epoch: 598 \tTraining Loss: 1.328178 \tValidation Loss: 1.384287 \t time: 0.3\n",
      "Epoch: 599 \tTraining Loss: 1.325521 \tValidation Loss: 1.384171 \t time: 0.2\n",
      "Validation loss decreased from 1.384260 to 1.384171. Model was saved\n",
      "Epoch: 600 \tTraining Loss: 1.326023 \tValidation Loss: 1.383987 \t time: 0.3\n",
      "Validation loss decreased from 1.384171 to 1.383987. Model was saved\n",
      "Epoch: 601 \tTraining Loss: 1.326456 \tValidation Loss: 1.384148 \t time: 0.3\n",
      "Epoch: 602 \tTraining Loss: 1.325841 \tValidation Loss: 1.384244 \t time: 0.3\n",
      "Epoch: 603 \tTraining Loss: 1.324330 \tValidation Loss: 1.384323 \t time: 0.2\n",
      "Epoch: 604 \tTraining Loss: 1.327436 \tValidation Loss: 1.384713 \t time: 0.3\n",
      "Epoch: 605 \tTraining Loss: 1.328083 \tValidation Loss: 1.384819 \t time: 0.3\n",
      "Epoch: 606 \tTraining Loss: 1.327711 \tValidation Loss: 1.384414 \t time: 0.3\n",
      "Epoch: 607 \tTraining Loss: 1.326156 \tValidation Loss: 1.384393 \t time: 0.2\n",
      "Epoch: 608 \tTraining Loss: 1.325739 \tValidation Loss: 1.384424 \t time: 0.3\n",
      "Epoch: 609 \tTraining Loss: 1.326902 \tValidation Loss: 1.384295 \t time: 0.2\n",
      "Epoch: 610 \tTraining Loss: 1.328482 \tValidation Loss: 1.384102 \t time: 0.2\n",
      "Epoch: 611 \tTraining Loss: 1.326669 \tValidation Loss: 1.384224 \t time: 0.2\n",
      "Epoch: 612 \tTraining Loss: 1.326243 \tValidation Loss: 1.384482 \t time: 0.3\n",
      "Epoch: 613 \tTraining Loss: 1.326442 \tValidation Loss: 1.384539 \t time: 0.3\n",
      "Epoch: 614 \tTraining Loss: 1.326394 \tValidation Loss: 1.384403 \t time: 0.3\n",
      "Epoch: 615 \tTraining Loss: 1.324759 \tValidation Loss: 1.384323 \t time: 0.3\n",
      "Epoch: 616 \tTraining Loss: 1.325337 \tValidation Loss: 1.384274 \t time: 0.3\n",
      "Epoch: 617 \tTraining Loss: 1.326505 \tValidation Loss: 1.384264 \t time: 0.3\n",
      "Epoch: 618 \tTraining Loss: 1.325690 \tValidation Loss: 1.384211 \t time: 0.3\n",
      "Epoch: 619 \tTraining Loss: 1.324316 \tValidation Loss: 1.384351 \t time: 0.3\n",
      "Epoch: 620 \tTraining Loss: 1.323125 \tValidation Loss: 1.384545 \t time: 0.2\n",
      "Epoch: 621 \tTraining Loss: 1.324707 \tValidation Loss: 1.384754 \t time: 0.3\n",
      "Epoch: 622 \tTraining Loss: 1.326051 \tValidation Loss: 1.384828 \t time: 0.3\n",
      "Epoch: 623 \tTraining Loss: 1.324005 \tValidation Loss: 1.384692 \t time: 0.3\n",
      "Epoch: 624 \tTraining Loss: 1.324106 \tValidation Loss: 1.384454 \t time: 0.2\n",
      "Epoch: 625 \tTraining Loss: 1.324490 \tValidation Loss: 1.384297 \t time: 0.3\n",
      "Epoch: 626 \tTraining Loss: 1.321896 \tValidation Loss: 1.384246 \t time: 0.3\n",
      "Epoch: 627 \tTraining Loss: 1.323506 \tValidation Loss: 1.384346 \t time: 0.3\n",
      "Epoch: 628 \tTraining Loss: 1.322909 \tValidation Loss: 1.384564 \t time: 0.3\n",
      "Epoch: 629 \tTraining Loss: 1.322503 \tValidation Loss: 1.384776 \t time: 0.2\n",
      "Epoch: 630 \tTraining Loss: 1.323230 \tValidation Loss: 1.384789 \t time: 0.3\n",
      "Epoch: 631 \tTraining Loss: 1.323182 \tValidation Loss: 1.384199 \t time: 0.3\n",
      "Epoch: 632 \tTraining Loss: 1.323568 \tValidation Loss: 1.383524 \t time: 0.2\n",
      "Validation loss decreased from 1.383987 to 1.383524. Model was saved\n",
      "Epoch: 633 \tTraining Loss: 1.324042 \tValidation Loss: 1.383065 \t time: 0.3\n",
      "Validation loss decreased from 1.383524 to 1.383065. Model was saved\n",
      "Epoch: 634 \tTraining Loss: 1.324684 \tValidation Loss: 1.382699 \t time: 0.2\n",
      "Validation loss decreased from 1.383065 to 1.382699. Model was saved\n",
      "Epoch: 635 \tTraining Loss: 1.323898 \tValidation Loss: 1.382265 \t time: 0.2\n",
      "Validation loss decreased from 1.382699 to 1.382265. Model was saved\n",
      "Epoch: 636 \tTraining Loss: 1.323179 \tValidation Loss: 1.382003 \t time: 0.3\n",
      "Validation loss decreased from 1.382265 to 1.382003. Model was saved\n",
      "Epoch: 637 \tTraining Loss: 1.323473 \tValidation Loss: 1.382019 \t time: 0.3\n",
      "Epoch: 638 \tTraining Loss: 1.323077 \tValidation Loss: 1.382223 \t time: 0.3\n",
      "Epoch: 639 \tTraining Loss: 1.321755 \tValidation Loss: 1.382764 \t time: 0.3\n",
      "Epoch: 640 \tTraining Loss: 1.322475 \tValidation Loss: 1.382836 \t time: 0.3\n",
      "Epoch: 641 \tTraining Loss: 1.322054 \tValidation Loss: 1.382440 \t time: 0.3\n",
      "Epoch: 642 \tTraining Loss: 1.323485 \tValidation Loss: 1.381818 \t time: 0.3\n",
      "Validation loss decreased from 1.382003 to 1.381818. Model was saved\n",
      "Epoch: 643 \tTraining Loss: 1.321113 \tValidation Loss: 1.381375 \t time: 0.3\n",
      "Validation loss decreased from 1.381818 to 1.381375. Model was saved\n",
      "Epoch: 644 \tTraining Loss: 1.320991 \tValidation Loss: 1.381302 \t time: 0.3\n",
      "Validation loss decreased from 1.381375 to 1.381302. Model was saved\n",
      "Epoch: 645 \tTraining Loss: 1.323523 \tValidation Loss: 1.381594 \t time: 0.2\n",
      "Epoch: 646 \tTraining Loss: 1.323953 \tValidation Loss: 1.382198 \t time: 0.3\n",
      "Epoch: 647 \tTraining Loss: 1.322207 \tValidation Loss: 1.382656 \t time: 0.2\n",
      "Epoch: 648 \tTraining Loss: 1.318012 \tValidation Loss: 1.382656 \t time: 0.3\n",
      "Epoch: 649 \tTraining Loss: 1.321998 \tValidation Loss: 1.382501 \t time: 0.3\n",
      "Epoch: 650 \tTraining Loss: 1.320653 \tValidation Loss: 1.382641 \t time: 0.2\n",
      "Epoch: 651 \tTraining Loss: 1.319142 \tValidation Loss: 1.382565 \t time: 0.2\n",
      "Epoch: 652 \tTraining Loss: 1.321095 \tValidation Loss: 1.382773 \t time: 0.2\n",
      "Epoch: 653 \tTraining Loss: 1.321097 \tValidation Loss: 1.383194 \t time: 0.3\n",
      "Epoch: 654 \tTraining Loss: 1.320991 \tValidation Loss: 1.383435 \t time: 0.2\n",
      "Epoch: 655 \tTraining Loss: 1.321119 \tValidation Loss: 1.383377 \t time: 0.2\n",
      "Epoch: 656 \tTraining Loss: 1.321608 \tValidation Loss: 1.382864 \t time: 0.3\n",
      "Epoch: 657 \tTraining Loss: 1.320122 \tValidation Loss: 1.381798 \t time: 0.2\n",
      "Epoch: 658 \tTraining Loss: 1.321252 \tValidation Loss: 1.380940 \t time: 0.2\n",
      "Validation loss decreased from 1.381302 to 1.380940. Model was saved\n",
      "Epoch: 659 \tTraining Loss: 1.319329 \tValidation Loss: 1.380541 \t time: 0.3\n",
      "Validation loss decreased from 1.380940 to 1.380541. Model was saved\n",
      "Epoch: 660 \tTraining Loss: 1.320462 \tValidation Loss: 1.380894 \t time: 0.2\n",
      "Epoch: 661 \tTraining Loss: 1.320973 \tValidation Loss: 1.381695 \t time: 0.3\n",
      "Epoch: 662 \tTraining Loss: 1.320980 \tValidation Loss: 1.382289 \t time: 0.3\n",
      "Epoch: 663 \tTraining Loss: 1.321707 \tValidation Loss: 1.381867 \t time: 0.3\n",
      "Epoch: 664 \tTraining Loss: 1.321666 \tValidation Loss: 1.380689 \t time: 0.3\n",
      "Epoch: 665 \tTraining Loss: 1.319834 \tValidation Loss: 1.379828 \t time: 0.2\n",
      "Validation loss decreased from 1.380541 to 1.379828. Model was saved\n",
      "Epoch: 666 \tTraining Loss: 1.320587 \tValidation Loss: 1.379887 \t time: 0.3\n",
      "Epoch: 667 \tTraining Loss: 1.319437 \tValidation Loss: 1.380539 \t time: 0.2\n",
      "Epoch: 668 \tTraining Loss: 1.319180 \tValidation Loss: 1.381379 \t time: 0.2\n",
      "Epoch: 669 \tTraining Loss: 1.318722 \tValidation Loss: 1.382337 \t time: 0.3\n",
      "Epoch: 670 \tTraining Loss: 1.320489 \tValidation Loss: 1.382551 \t time: 0.3\n",
      "Epoch: 671 \tTraining Loss: 1.319149 \tValidation Loss: 1.382048 \t time: 0.2\n",
      "Epoch: 672 \tTraining Loss: 1.318396 \tValidation Loss: 1.381328 \t time: 0.2\n",
      "Epoch: 673 \tTraining Loss: 1.316734 \tValidation Loss: 1.381111 \t time: 0.3\n",
      "Epoch: 674 \tTraining Loss: 1.319402 \tValidation Loss: 1.381435 \t time: 0.2\n",
      "Epoch: 675 \tTraining Loss: 1.320119 \tValidation Loss: 1.382254 \t time: 0.2\n",
      "Epoch: 676 \tTraining Loss: 1.319161 \tValidation Loss: 1.383003 \t time: 0.3\n",
      "Epoch: 677 \tTraining Loss: 1.318837 \tValidation Loss: 1.383125 \t time: 0.3\n",
      "Epoch: 678 \tTraining Loss: 1.322276 \tValidation Loss: 1.382704 \t time: 0.3\n",
      "Epoch: 679 \tTraining Loss: 1.320023 \tValidation Loss: 1.381980 \t time: 0.2\n",
      "Epoch: 680 \tTraining Loss: 1.318399 \tValidation Loss: 1.381103 \t time: 0.2\n",
      "Epoch: 681 \tTraining Loss: 1.318035 \tValidation Loss: 1.380857 \t time: 0.3\n",
      "Epoch: 682 \tTraining Loss: 1.316889 \tValidation Loss: 1.381150 \t time: 0.3\n",
      "Epoch: 683 \tTraining Loss: 1.316486 \tValidation Loss: 1.381619 \t time: 0.3\n",
      "Epoch: 684 \tTraining Loss: 1.317016 \tValidation Loss: 1.382068 \t time: 0.3\n",
      "Epoch: 685 \tTraining Loss: 1.318858 \tValidation Loss: 1.381953 \t time: 0.3\n",
      "Epoch: 686 \tTraining Loss: 1.316271 \tValidation Loss: 1.381314 \t time: 0.3\n",
      "Epoch: 687 \tTraining Loss: 1.317414 \tValidation Loss: 1.380931 \t time: 0.2\n",
      "Epoch: 688 \tTraining Loss: 1.316316 \tValidation Loss: 1.380714 \t time: 0.3\n",
      "Epoch: 689 \tTraining Loss: 1.317331 \tValidation Loss: 1.380670 \t time: 0.3\n",
      "Epoch: 690 \tTraining Loss: 1.316930 \tValidation Loss: 1.380892 \t time: 0.3\n",
      "Epoch: 691 \tTraining Loss: 1.318572 \tValidation Loss: 1.381249 \t time: 0.2\n",
      "Epoch: 692 \tTraining Loss: 1.317276 \tValidation Loss: 1.381455 \t time: 0.3\n",
      "Epoch: 693 \tTraining Loss: 1.319767 \tValidation Loss: 1.381862 \t time: 0.2\n",
      "Epoch: 694 \tTraining Loss: 1.315067 \tValidation Loss: 1.382236 \t time: 0.2\n",
      "Epoch: 695 \tTraining Loss: 1.316835 \tValidation Loss: 1.382259 \t time: 0.3\n",
      "Epoch: 696 \tTraining Loss: 1.317325 \tValidation Loss: 1.381917 \t time: 0.3\n",
      "Epoch: 697 \tTraining Loss: 1.316640 \tValidation Loss: 1.381516 \t time: 0.2\n",
      "Epoch: 698 \tTraining Loss: 1.314242 \tValidation Loss: 1.380982 \t time: 0.3\n",
      "Epoch: 699 \tTraining Loss: 1.319270 \tValidation Loss: 1.380841 \t time: 0.3\n",
      "Epoch: 700 \tTraining Loss: 1.317288 \tValidation Loss: 1.380687 \t time: 0.3\n",
      "Epoch: 701 \tTraining Loss: 1.315230 \tValidation Loss: 1.380476 \t time: 0.3\n",
      "Epoch: 702 \tTraining Loss: 1.315822 \tValidation Loss: 1.380539 \t time: 0.3\n",
      "Epoch: 703 \tTraining Loss: 1.315764 \tValidation Loss: 1.380607 \t time: 0.3\n",
      "Epoch: 704 \tTraining Loss: 1.316558 \tValidation Loss: 1.380565 \t time: 0.3\n",
      "Epoch: 705 \tTraining Loss: 1.314884 \tValidation Loss: 1.380193 \t time: 0.3\n",
      "Epoch: 706 \tTraining Loss: 1.316918 \tValidation Loss: 1.379853 \t time: 0.3\n",
      "Epoch: 707 \tTraining Loss: 1.317555 \tValidation Loss: 1.379688 \t time: 0.3\n",
      "Validation loss decreased from 1.379828 to 1.379688. Model was saved\n",
      "Epoch: 708 \tTraining Loss: 1.313947 \tValidation Loss: 1.379979 \t time: 0.2\n",
      "Epoch: 709 \tTraining Loss: 1.314498 \tValidation Loss: 1.381128 \t time: 0.2\n",
      "Epoch: 710 \tTraining Loss: 1.315839 \tValidation Loss: 1.382136 \t time: 0.3\n",
      "Epoch: 711 \tTraining Loss: 1.315390 \tValidation Loss: 1.382694 \t time: 0.3\n",
      "Epoch: 712 \tTraining Loss: 1.315870 \tValidation Loss: 1.382242 \t time: 0.3\n",
      "Epoch: 713 \tTraining Loss: 1.316462 \tValidation Loss: 1.381371 \t time: 0.2\n",
      "Epoch: 714 \tTraining Loss: 1.315690 \tValidation Loss: 1.380491 \t time: 0.3\n",
      "Epoch: 715 \tTraining Loss: 1.314360 \tValidation Loss: 1.379866 \t time: 0.2\n",
      "Epoch: 716 \tTraining Loss: 1.316860 \tValidation Loss: 1.379508 \t time: 0.3\n",
      "Validation loss decreased from 1.379688 to 1.379508. Model was saved\n",
      "Epoch: 717 \tTraining Loss: 1.316252 \tValidation Loss: 1.379460 \t time: 0.2\n",
      "Validation loss decreased from 1.379508 to 1.379460. Model was saved\n",
      "Epoch: 718 \tTraining Loss: 1.312562 \tValidation Loss: 1.379903 \t time: 0.3\n",
      "Epoch: 719 \tTraining Loss: 1.314266 \tValidation Loss: 1.380418 \t time: 0.3\n",
      "Epoch: 720 \tTraining Loss: 1.315074 \tValidation Loss: 1.380687 \t time: 0.3\n",
      "Epoch: 721 \tTraining Loss: 1.316617 \tValidation Loss: 1.381087 \t time: 0.3\n",
      "Epoch: 722 \tTraining Loss: 1.313503 \tValidation Loss: 1.381439 \t time: 0.3\n",
      "Epoch: 723 \tTraining Loss: 1.313770 \tValidation Loss: 1.381578 \t time: 0.3\n",
      "Epoch: 724 \tTraining Loss: 1.316828 \tValidation Loss: 1.381382 \t time: 0.3\n",
      "Epoch: 725 \tTraining Loss: 1.315398 \tValidation Loss: 1.381071 \t time: 0.3\n",
      "Epoch: 726 \tTraining Loss: 1.315559 \tValidation Loss: 1.380421 \t time: 0.3\n",
      "Epoch: 727 \tTraining Loss: 1.314318 \tValidation Loss: 1.380258 \t time: 0.3\n",
      "Epoch: 728 \tTraining Loss: 1.313255 \tValidation Loss: 1.380601 \t time: 0.3\n",
      "Epoch: 729 \tTraining Loss: 1.314595 \tValidation Loss: 1.380754 \t time: 0.3\n",
      "Epoch: 730 \tTraining Loss: 1.316992 \tValidation Loss: 1.380209 \t time: 0.3\n",
      "Epoch: 731 \tTraining Loss: 1.314590 \tValidation Loss: 1.379417 \t time: 0.3\n",
      "Validation loss decreased from 1.379460 to 1.379417. Model was saved\n",
      "Epoch: 732 \tTraining Loss: 1.313006 \tValidation Loss: 1.378150 \t time: 0.3\n",
      "Validation loss decreased from 1.379417 to 1.378150. Model was saved\n",
      "Epoch: 733 \tTraining Loss: 1.314636 \tValidation Loss: 1.377337 \t time: 0.3\n",
      "Validation loss decreased from 1.378150 to 1.377337. Model was saved\n",
      "Epoch: 734 \tTraining Loss: 1.314206 \tValidation Loss: 1.377054 \t time: 0.3\n",
      "Validation loss decreased from 1.377337 to 1.377054. Model was saved\n",
      "Epoch: 735 \tTraining Loss: 1.312353 \tValidation Loss: 1.377035 \t time: 0.3\n",
      "Validation loss decreased from 1.377054 to 1.377035. Model was saved\n",
      "Epoch: 736 \tTraining Loss: 1.313594 \tValidation Loss: 1.376891 \t time: 0.3\n",
      "Validation loss decreased from 1.377035 to 1.376891. Model was saved\n",
      "Epoch: 737 \tTraining Loss: 1.314973 \tValidation Loss: 1.377302 \t time: 0.3\n",
      "Epoch: 738 \tTraining Loss: 1.312969 \tValidation Loss: 1.377773 \t time: 0.3\n",
      "Epoch: 739 \tTraining Loss: 1.310943 \tValidation Loss: 1.378749 \t time: 0.3\n",
      "Epoch: 740 \tTraining Loss: 1.312706 \tValidation Loss: 1.379319 \t time: 0.3\n",
      "Epoch: 741 \tTraining Loss: 1.313743 \tValidation Loss: 1.379367 \t time: 0.3\n",
      "Epoch: 742 \tTraining Loss: 1.310892 \tValidation Loss: 1.379099 \t time: 0.3\n",
      "Epoch: 743 \tTraining Loss: 1.310380 \tValidation Loss: 1.378546 \t time: 0.3\n",
      "Epoch: 744 \tTraining Loss: 1.313581 \tValidation Loss: 1.378046 \t time: 0.2\n",
      "Epoch: 745 \tTraining Loss: 1.310429 \tValidation Loss: 1.378012 \t time: 0.3\n",
      "Epoch: 746 \tTraining Loss: 1.310044 \tValidation Loss: 1.378119 \t time: 0.3\n",
      "Epoch: 747 \tTraining Loss: 1.312579 \tValidation Loss: 1.378256 \t time: 0.3\n",
      "Epoch: 748 \tTraining Loss: 1.312241 \tValidation Loss: 1.378622 \t time: 0.3\n",
      "Epoch: 749 \tTraining Loss: 1.310629 \tValidation Loss: 1.379545 \t time: 0.3\n",
      "Epoch: 750 \tTraining Loss: 1.312242 \tValidation Loss: 1.380325 \t time: 0.3\n",
      "Epoch: 751 \tTraining Loss: 1.311675 \tValidation Loss: 1.380279 \t time: 0.3\n",
      "Epoch: 752 \tTraining Loss: 1.313738 \tValidation Loss: 1.379410 \t time: 0.3\n",
      "Epoch: 753 \tTraining Loss: 1.313944 \tValidation Loss: 1.377875 \t time: 0.3\n",
      "Epoch: 754 \tTraining Loss: 1.311323 \tValidation Loss: 1.376704 \t time: 0.3\n",
      "Validation loss decreased from 1.376891 to 1.376704. Model was saved\n",
      "Epoch: 755 \tTraining Loss: 1.314708 \tValidation Loss: 1.376198 \t time: 0.2\n",
      "Validation loss decreased from 1.376704 to 1.376198. Model was saved\n",
      "Epoch: 756 \tTraining Loss: 1.313346 \tValidation Loss: 1.375998 \t time: 0.3\n",
      "Validation loss decreased from 1.376198 to 1.375998. Model was saved\n",
      "Epoch: 757 \tTraining Loss: 1.312716 \tValidation Loss: 1.376394 \t time: 0.3\n",
      "Epoch: 758 \tTraining Loss: 1.310552 \tValidation Loss: 1.377411 \t time: 0.3\n",
      "Epoch: 759 \tTraining Loss: 1.311191 \tValidation Loss: 1.378674 \t time: 0.3\n",
      "Epoch: 760 \tTraining Loss: 1.312209 \tValidation Loss: 1.379389 \t time: 0.2\n",
      "Epoch: 761 \tTraining Loss: 1.311772 \tValidation Loss: 1.378852 \t time: 0.3\n",
      "Epoch: 762 \tTraining Loss: 1.312942 \tValidation Loss: 1.378062 \t time: 0.3\n",
      "Epoch: 763 \tTraining Loss: 1.312558 \tValidation Loss: 1.377254 \t time: 0.3\n",
      "Epoch: 764 \tTraining Loss: 1.312584 \tValidation Loss: 1.376664 \t time: 0.3\n",
      "Epoch: 765 \tTraining Loss: 1.309235 \tValidation Loss: 1.376465 \t time: 0.3\n",
      "Epoch: 766 \tTraining Loss: 1.311955 \tValidation Loss: 1.376632 \t time: 0.3\n",
      "Epoch: 767 \tTraining Loss: 1.314031 \tValidation Loss: 1.377718 \t time: 0.2\n",
      "Epoch: 768 \tTraining Loss: 1.313046 \tValidation Loss: 1.379027 \t time: 0.3\n",
      "Epoch: 769 \tTraining Loss: 1.313393 \tValidation Loss: 1.380260 \t time: 0.3\n",
      "Epoch: 770 \tTraining Loss: 1.310132 \tValidation Loss: 1.380652 \t time: 0.2\n",
      "Epoch: 771 \tTraining Loss: 1.311957 \tValidation Loss: 1.380386 \t time: 0.3\n",
      "Epoch: 772 \tTraining Loss: 1.311978 \tValidation Loss: 1.379995 \t time: 0.3\n",
      "Epoch: 773 \tTraining Loss: 1.310940 \tValidation Loss: 1.379448 \t time: 0.3\n",
      "Epoch: 774 \tTraining Loss: 1.313542 \tValidation Loss: 1.379282 \t time: 0.3\n",
      "Epoch: 775 \tTraining Loss: 1.310795 \tValidation Loss: 1.379324 \t time: 0.3\n",
      "Epoch: 776 \tTraining Loss: 1.311139 \tValidation Loss: 1.379284 \t time: 0.3\n",
      "Epoch: 777 \tTraining Loss: 1.306689 \tValidation Loss: 1.378946 \t time: 0.3\n",
      "Epoch: 778 \tTraining Loss: 1.312544 \tValidation Loss: 1.378110 \t time: 0.3\n",
      "Epoch: 779 \tTraining Loss: 1.309268 \tValidation Loss: 1.377145 \t time: 0.3\n",
      "Epoch: 780 \tTraining Loss: 1.311374 \tValidation Loss: 1.376080 \t time: 0.2\n",
      "Epoch: 781 \tTraining Loss: 1.309644 \tValidation Loss: 1.375955 \t time: 0.3\n",
      "Validation loss decreased from 1.375998 to 1.375955. Model was saved\n",
      "Epoch: 782 \tTraining Loss: 1.309493 \tValidation Loss: 1.377128 \t time: 0.3\n",
      "Epoch: 783 \tTraining Loss: 1.309121 \tValidation Loss: 1.378340 \t time: 0.3\n",
      "Epoch: 784 \tTraining Loss: 1.306742 \tValidation Loss: 1.378857 \t time: 0.3\n",
      "Epoch: 785 \tTraining Loss: 1.310642 \tValidation Loss: 1.378502 \t time: 0.2\n",
      "Epoch: 786 \tTraining Loss: 1.311372 \tValidation Loss: 1.377514 \t time: 0.2\n",
      "Epoch: 787 \tTraining Loss: 1.307630 \tValidation Loss: 1.376527 \t time: 0.3\n",
      "Epoch: 788 \tTraining Loss: 1.308955 \tValidation Loss: 1.376457 \t time: 0.3\n",
      "Epoch: 789 \tTraining Loss: 1.309465 \tValidation Loss: 1.376936 \t time: 0.3\n",
      "Epoch: 790 \tTraining Loss: 1.308715 \tValidation Loss: 1.377604 \t time: 0.2\n",
      "Epoch: 791 \tTraining Loss: 1.307220 \tValidation Loss: 1.378213 \t time: 0.3\n",
      "Epoch: 792 \tTraining Loss: 1.305918 \tValidation Loss: 1.378704 \t time: 0.3\n",
      "Epoch: 793 \tTraining Loss: 1.306304 \tValidation Loss: 1.378590 \t time: 0.3\n",
      "Epoch: 794 \tTraining Loss: 1.310038 \tValidation Loss: 1.378181 \t time: 0.3\n",
      "Epoch: 795 \tTraining Loss: 1.310493 \tValidation Loss: 1.377307 \t time: 0.2\n",
      "Epoch: 796 \tTraining Loss: 1.306805 \tValidation Loss: 1.376788 \t time: 0.2\n",
      "Epoch: 797 \tTraining Loss: 1.310504 \tValidation Loss: 1.376768 \t time: 0.3\n",
      "Epoch: 798 \tTraining Loss: 1.307652 \tValidation Loss: 1.376982 \t time: 0.3\n",
      "Epoch: 799 \tTraining Loss: 1.308885 \tValidation Loss: 1.377110 \t time: 0.2\n",
      "Epoch: 800 \tTraining Loss: 1.309170 \tValidation Loss: 1.377063 \t time: 0.3\n",
      "Epoch: 801 \tTraining Loss: 1.309011 \tValidation Loss: 1.377035 \t time: 0.2\n",
      "Epoch: 802 \tTraining Loss: 1.307936 \tValidation Loss: 1.376433 \t time: 0.3\n",
      "Epoch: 803 \tTraining Loss: 1.308494 \tValidation Loss: 1.376102 \t time: 0.2\n",
      "Epoch: 804 \tTraining Loss: 1.310045 \tValidation Loss: 1.375700 \t time: 0.3\n",
      "Validation loss decreased from 1.375955 to 1.375700. Model was saved\n",
      "Epoch: 805 \tTraining Loss: 1.308515 \tValidation Loss: 1.375734 \t time: 0.3\n",
      "Epoch: 806 \tTraining Loss: 1.306735 \tValidation Loss: 1.375900 \t time: 0.2\n",
      "Epoch: 807 \tTraining Loss: 1.308155 \tValidation Loss: 1.376353 \t time: 0.3\n",
      "Epoch: 808 \tTraining Loss: 1.305537 \tValidation Loss: 1.377144 \t time: 0.3\n",
      "Epoch: 809 \tTraining Loss: 1.306877 \tValidation Loss: 1.377392 \t time: 0.3\n",
      "Epoch: 810 \tTraining Loss: 1.308035 \tValidation Loss: 1.377167 \t time: 0.3\n",
      "Epoch: 811 \tTraining Loss: 1.308040 \tValidation Loss: 1.376595 \t time: 0.3\n",
      "Epoch: 812 \tTraining Loss: 1.308733 \tValidation Loss: 1.375753 \t time: 0.3\n",
      "Epoch: 813 \tTraining Loss: 1.305232 \tValidation Loss: 1.375160 \t time: 0.3\n",
      "Validation loss decreased from 1.375700 to 1.375160. Model was saved\n",
      "Epoch: 814 \tTraining Loss: 1.307150 \tValidation Loss: 1.375113 \t time: 0.2\n",
      "Validation loss decreased from 1.375160 to 1.375113. Model was saved\n",
      "Epoch: 815 \tTraining Loss: 1.306977 \tValidation Loss: 1.374799 \t time: 0.3\n",
      "Validation loss decreased from 1.375113 to 1.374799. Model was saved\n",
      "Epoch: 816 \tTraining Loss: 1.306188 \tValidation Loss: 1.374871 \t time: 0.2\n",
      "Epoch: 817 \tTraining Loss: 1.306008 \tValidation Loss: 1.375560 \t time: 0.2\n",
      "Epoch: 818 \tTraining Loss: 1.306910 \tValidation Loss: 1.376561 \t time: 0.3\n",
      "Epoch: 819 \tTraining Loss: 1.306263 \tValidation Loss: 1.377752 \t time: 0.3\n",
      "Epoch: 820 \tTraining Loss: 1.308324 \tValidation Loss: 1.377490 \t time: 0.3\n",
      "Epoch: 821 \tTraining Loss: 1.303956 \tValidation Loss: 1.375998 \t time: 0.3\n",
      "Epoch: 822 \tTraining Loss: 1.306102 \tValidation Loss: 1.374906 \t time: 0.3\n",
      "Epoch: 823 \tTraining Loss: 1.306460 \tValidation Loss: 1.374433 \t time: 0.3\n",
      "Validation loss decreased from 1.374799 to 1.374433. Model was saved\n",
      "Epoch: 824 \tTraining Loss: 1.304997 \tValidation Loss: 1.374734 \t time: 0.2\n",
      "Epoch: 825 \tTraining Loss: 1.306557 \tValidation Loss: 1.375466 \t time: 0.3\n",
      "Epoch: 826 \tTraining Loss: 1.304479 \tValidation Loss: 1.376413 \t time: 0.3\n",
      "Epoch: 827 \tTraining Loss: 1.303759 \tValidation Loss: 1.376778 \t time: 0.3\n",
      "Epoch: 828 \tTraining Loss: 1.306115 \tValidation Loss: 1.376517 \t time: 0.3\n",
      "Epoch: 829 \tTraining Loss: 1.308209 \tValidation Loss: 1.376320 \t time: 0.2\n",
      "Epoch: 830 \tTraining Loss: 1.304745 \tValidation Loss: 1.375543 \t time: 0.3\n",
      "Epoch: 831 \tTraining Loss: 1.305486 \tValidation Loss: 1.374536 \t time: 0.3\n",
      "Epoch: 832 \tTraining Loss: 1.304050 \tValidation Loss: 1.374134 \t time: 0.2\n",
      "Validation loss decreased from 1.374433 to 1.374134. Model was saved\n",
      "Epoch: 833 \tTraining Loss: 1.304565 \tValidation Loss: 1.374592 \t time: 0.2\n",
      "Epoch: 834 \tTraining Loss: 1.305324 \tValidation Loss: 1.375995 \t time: 0.2\n",
      "Epoch: 835 \tTraining Loss: 1.306296 \tValidation Loss: 1.377670 \t time: 0.2\n",
      "Epoch: 836 \tTraining Loss: 1.308158 \tValidation Loss: 1.378142 \t time: 0.3\n",
      "Epoch: 837 \tTraining Loss: 1.306482 \tValidation Loss: 1.378328 \t time: 0.3\n",
      "Epoch: 838 \tTraining Loss: 1.305759 \tValidation Loss: 1.377918 \t time: 0.3\n",
      "Epoch: 839 \tTraining Loss: 1.303487 \tValidation Loss: 1.376786 \t time: 0.3\n",
      "Epoch: 840 \tTraining Loss: 1.302244 \tValidation Loss: 1.375800 \t time: 0.3\n",
      "Epoch: 841 \tTraining Loss: 1.305225 \tValidation Loss: 1.375264 \t time: 0.3\n",
      "Epoch: 842 \tTraining Loss: 1.304661 \tValidation Loss: 1.375140 \t time: 0.2\n",
      "Epoch: 843 \tTraining Loss: 1.304534 \tValidation Loss: 1.375555 \t time: 0.2\n",
      "Epoch: 844 \tTraining Loss: 1.306388 \tValidation Loss: 1.376418 \t time: 0.2\n",
      "Epoch: 845 \tTraining Loss: 1.305043 \tValidation Loss: 1.376734 \t time: 0.3\n",
      "Epoch: 846 \tTraining Loss: 1.302890 \tValidation Loss: 1.376149 \t time: 0.3\n",
      "Epoch: 847 \tTraining Loss: 1.303534 \tValidation Loss: 1.375043 \t time: 0.2\n",
      "Epoch: 848 \tTraining Loss: 1.301408 \tValidation Loss: 1.374067 \t time: 0.2\n",
      "Validation loss decreased from 1.374134 to 1.374067. Model was saved\n",
      "Epoch: 849 \tTraining Loss: 1.303926 \tValidation Loss: 1.373528 \t time: 0.2\n",
      "Validation loss decreased from 1.374067 to 1.373528. Model was saved\n",
      "Epoch: 850 \tTraining Loss: 1.303665 \tValidation Loss: 1.373548 \t time: 0.2\n",
      "Epoch: 851 \tTraining Loss: 1.302531 \tValidation Loss: 1.373785 \t time: 0.2\n",
      "Epoch: 852 \tTraining Loss: 1.303484 \tValidation Loss: 1.373782 \t time: 0.2\n",
      "Epoch: 853 \tTraining Loss: 1.302607 \tValidation Loss: 1.373294 \t time: 0.3\n",
      "Validation loss decreased from 1.373528 to 1.373294. Model was saved\n",
      "Epoch: 854 \tTraining Loss: 1.302187 \tValidation Loss: 1.372492 \t time: 0.3\n",
      "Validation loss decreased from 1.373294 to 1.372492. Model was saved\n",
      "Epoch: 855 \tTraining Loss: 1.301723 \tValidation Loss: 1.372224 \t time: 0.3\n",
      "Validation loss decreased from 1.372492 to 1.372224. Model was saved\n",
      "Epoch: 856 \tTraining Loss: 1.305200 \tValidation Loss: 1.372535 \t time: 0.3\n",
      "Epoch: 857 \tTraining Loss: 1.305177 \tValidation Loss: 1.373413 \t time: 0.3\n",
      "Epoch: 858 \tTraining Loss: 1.302913 \tValidation Loss: 1.374597 \t time: 0.2\n",
      "Epoch: 859 \tTraining Loss: 1.302748 \tValidation Loss: 1.375516 \t time: 0.2\n",
      "Epoch: 860 \tTraining Loss: 1.303434 \tValidation Loss: 1.375658 \t time: 0.2\n",
      "Epoch: 861 \tTraining Loss: 1.304873 \tValidation Loss: 1.374687 \t time: 0.2\n",
      "Epoch: 862 \tTraining Loss: 1.304730 \tValidation Loss: 1.373765 \t time: 0.2\n",
      "Epoch: 863 \tTraining Loss: 1.304668 \tValidation Loss: 1.373046 \t time: 0.3\n",
      "Epoch: 864 \tTraining Loss: 1.304149 \tValidation Loss: 1.372308 \t time: 0.2\n",
      "Epoch: 865 \tTraining Loss: 1.304067 \tValidation Loss: 1.372705 \t time: 0.3\n",
      "Epoch: 866 \tTraining Loss: 1.305858 \tValidation Loss: 1.373499 \t time: 0.2\n",
      "Epoch: 867 \tTraining Loss: 1.299351 \tValidation Loss: 1.374672 \t time: 0.2\n",
      "Epoch: 868 \tTraining Loss: 1.303521 \tValidation Loss: 1.376074 \t time: 0.3\n",
      "Epoch: 869 \tTraining Loss: 1.302631 \tValidation Loss: 1.376478 \t time: 0.2\n",
      "Epoch: 870 \tTraining Loss: 1.304111 \tValidation Loss: 1.374832 \t time: 0.3\n",
      "Epoch: 871 \tTraining Loss: 1.302837 \tValidation Loss: 1.372612 \t time: 0.2\n",
      "Epoch: 872 \tTraining Loss: 1.302361 \tValidation Loss: 1.371057 \t time: 0.3\n",
      "Validation loss decreased from 1.372224 to 1.371057. Model was saved\n",
      "Epoch: 873 \tTraining Loss: 1.304973 \tValidation Loss: 1.370324 \t time: 0.2\n",
      "Validation loss decreased from 1.371057 to 1.370324. Model was saved\n",
      "Epoch: 874 \tTraining Loss: 1.303330 \tValidation Loss: 1.370933 \t time: 0.2\n",
      "Epoch: 875 \tTraining Loss: 1.302701 \tValidation Loss: 1.371555 \t time: 0.2\n",
      "Epoch: 876 \tTraining Loss: 1.301130 \tValidation Loss: 1.372413 \t time: 0.3\n",
      "Epoch: 877 \tTraining Loss: 1.301857 \tValidation Loss: 1.373137 \t time: 0.3\n",
      "Epoch: 878 \tTraining Loss: 1.303263 \tValidation Loss: 1.373279 \t time: 0.3\n",
      "Epoch: 879 \tTraining Loss: 1.301735 \tValidation Loss: 1.372787 \t time: 0.3\n",
      "Epoch: 880 \tTraining Loss: 1.302168 \tValidation Loss: 1.371730 \t time: 0.3\n",
      "Epoch: 881 \tTraining Loss: 1.299890 \tValidation Loss: 1.370438 \t time: 0.3\n",
      "Epoch: 882 \tTraining Loss: 1.302139 \tValidation Loss: 1.369863 \t time: 0.3\n",
      "Validation loss decreased from 1.370324 to 1.369863. Model was saved\n",
      "Epoch: 883 \tTraining Loss: 1.300992 \tValidation Loss: 1.370394 \t time: 0.3\n",
      "Epoch: 884 \tTraining Loss: 1.300148 \tValidation Loss: 1.370677 \t time: 0.3\n",
      "Epoch: 885 \tTraining Loss: 1.301955 \tValidation Loss: 1.371056 \t time: 0.3\n",
      "Epoch: 886 \tTraining Loss: 1.302325 \tValidation Loss: 1.371566 \t time: 0.3\n",
      "Epoch: 887 \tTraining Loss: 1.301670 \tValidation Loss: 1.372115 \t time: 0.2\n",
      "Epoch: 888 \tTraining Loss: 1.301610 \tValidation Loss: 1.372287 \t time: 0.2\n",
      "Epoch: 889 \tTraining Loss: 1.301157 \tValidation Loss: 1.371989 \t time: 0.3\n",
      "Epoch: 890 \tTraining Loss: 1.300916 \tValidation Loss: 1.371621 \t time: 0.3\n",
      "Epoch: 891 \tTraining Loss: 1.300888 \tValidation Loss: 1.371029 \t time: 0.3\n",
      "Epoch: 892 \tTraining Loss: 1.300566 \tValidation Loss: 1.370777 \t time: 0.3\n",
      "Epoch: 893 \tTraining Loss: 1.301843 \tValidation Loss: 1.371303 \t time: 0.3\n",
      "Epoch: 894 \tTraining Loss: 1.301166 \tValidation Loss: 1.372118 \t time: 0.3\n",
      "Epoch: 895 \tTraining Loss: 1.301925 \tValidation Loss: 1.373211 \t time: 0.2\n",
      "Epoch: 896 \tTraining Loss: 1.301340 \tValidation Loss: 1.374187 \t time: 0.3\n",
      "Epoch: 897 \tTraining Loss: 1.301483 \tValidation Loss: 1.374579 \t time: 0.3\n",
      "Epoch: 898 \tTraining Loss: 1.300662 \tValidation Loss: 1.374087 \t time: 0.3\n",
      "Epoch: 899 \tTraining Loss: 1.299241 \tValidation Loss: 1.373234 \t time: 0.3\n",
      "Epoch: 900 \tTraining Loss: 1.299441 \tValidation Loss: 1.372102 \t time: 0.3\n",
      "Epoch: 901 \tTraining Loss: 1.302131 \tValidation Loss: 1.371509 \t time: 0.3\n",
      "Epoch: 902 \tTraining Loss: 1.300236 \tValidation Loss: 1.372326 \t time: 0.3\n",
      "Epoch: 903 \tTraining Loss: 1.299847 \tValidation Loss: 1.372920 \t time: 0.3\n",
      "Epoch: 904 \tTraining Loss: 1.301375 \tValidation Loss: 1.373297 \t time: 0.2\n",
      "Epoch: 905 \tTraining Loss: 1.299583 \tValidation Loss: 1.373292 \t time: 0.3\n",
      "Epoch: 906 \tTraining Loss: 1.300138 \tValidation Loss: 1.372283 \t time: 0.2\n",
      "Epoch: 907 \tTraining Loss: 1.300302 \tValidation Loss: 1.371151 \t time: 0.3\n",
      "Epoch: 908 \tTraining Loss: 1.299998 \tValidation Loss: 1.370521 \t time: 0.3\n",
      "Epoch: 909 \tTraining Loss: 1.299855 \tValidation Loss: 1.370248 \t time: 0.3\n",
      "Epoch: 910 \tTraining Loss: 1.300383 \tValidation Loss: 1.370490 \t time: 0.2\n",
      "Epoch: 911 \tTraining Loss: 1.300015 \tValidation Loss: 1.371655 \t time: 0.3\n",
      "Epoch: 912 \tTraining Loss: 1.300385 \tValidation Loss: 1.372927 \t time: 0.2\n",
      "Epoch: 913 \tTraining Loss: 1.300499 \tValidation Loss: 1.373787 \t time: 0.3\n",
      "Epoch: 914 \tTraining Loss: 1.299548 \tValidation Loss: 1.374469 \t time: 0.3\n",
      "Epoch: 915 \tTraining Loss: 1.299043 \tValidation Loss: 1.374239 \t time: 0.3\n",
      "Epoch: 916 \tTraining Loss: 1.298126 \tValidation Loss: 1.373324 \t time: 0.2\n",
      "Epoch: 917 \tTraining Loss: 1.300482 \tValidation Loss: 1.372423 \t time: 0.3\n",
      "Epoch: 918 \tTraining Loss: 1.299093 \tValidation Loss: 1.372069 \t time: 0.3\n",
      "Epoch: 919 \tTraining Loss: 1.302000 \tValidation Loss: 1.372245 \t time: 0.3\n",
      "Epoch: 920 \tTraining Loss: 1.301214 \tValidation Loss: 1.372358 \t time: 0.3\n",
      "Epoch: 921 \tTraining Loss: 1.300328 \tValidation Loss: 1.372265 \t time: 0.3\n",
      "Epoch: 922 \tTraining Loss: 1.298006 \tValidation Loss: 1.371820 \t time: 0.2\n",
      "Epoch: 923 \tTraining Loss: 1.298269 \tValidation Loss: 1.371770 \t time: 0.3\n",
      "Epoch: 924 \tTraining Loss: 1.298838 \tValidation Loss: 1.371958 \t time: 0.3\n",
      "Epoch: 925 \tTraining Loss: 1.297711 \tValidation Loss: 1.372355 \t time: 0.2\n",
      "Epoch: 926 \tTraining Loss: 1.299764 \tValidation Loss: 1.373312 \t time: 0.3\n",
      "Epoch: 927 \tTraining Loss: 1.296521 \tValidation Loss: 1.374370 \t time: 0.3\n",
      "Epoch: 928 \tTraining Loss: 1.298790 \tValidation Loss: 1.374441 \t time: 0.2\n",
      "Epoch: 929 \tTraining Loss: 1.298891 \tValidation Loss: 1.373782 \t time: 0.3\n",
      "Epoch: 930 \tTraining Loss: 1.299097 \tValidation Loss: 1.373155 \t time: 0.2\n",
      "Epoch: 931 \tTraining Loss: 1.298619 \tValidation Loss: 1.372544 \t time: 0.2\n",
      "Epoch: 932 \tTraining Loss: 1.296110 \tValidation Loss: 1.372210 \t time: 0.3\n",
      "Epoch: 933 \tTraining Loss: 1.299238 \tValidation Loss: 1.372539 \t time: 0.3\n",
      "Epoch: 934 \tTraining Loss: 1.297976 \tValidation Loss: 1.373477 \t time: 0.3\n",
      "Epoch: 935 \tTraining Loss: 1.300301 \tValidation Loss: 1.374362 \t time: 0.3\n",
      "Epoch: 936 \tTraining Loss: 1.298911 \tValidation Loss: 1.375201 \t time: 0.2\n",
      "Epoch: 937 \tTraining Loss: 1.298071 \tValidation Loss: 1.375301 \t time: 0.2\n",
      "Epoch: 938 \tTraining Loss: 1.300538 \tValidation Loss: 1.375338 \t time: 0.2\n",
      "Epoch: 939 \tTraining Loss: 1.296588 \tValidation Loss: 1.374959 \t time: 0.2\n",
      "Epoch: 940 \tTraining Loss: 1.296989 \tValidation Loss: 1.374484 \t time: 0.3\n",
      "Epoch: 941 \tTraining Loss: 1.297561 \tValidation Loss: 1.374275 \t time: 0.3\n",
      "Epoch: 942 \tTraining Loss: 1.297400 \tValidation Loss: 1.374533 \t time: 0.2\n",
      "Epoch: 943 \tTraining Loss: 1.298505 \tValidation Loss: 1.374818 \t time: 0.2\n",
      "Epoch: 944 \tTraining Loss: 1.297864 \tValidation Loss: 1.375041 \t time: 0.2\n",
      "Epoch: 945 \tTraining Loss: 1.299467 \tValidation Loss: 1.375275 \t time: 0.2\n",
      "Epoch: 946 \tTraining Loss: 1.297240 \tValidation Loss: 1.375244 \t time: 0.2\n",
      "Epoch: 947 \tTraining Loss: 1.295332 \tValidation Loss: 1.374281 \t time: 0.3\n",
      "Epoch: 948 \tTraining Loss: 1.299219 \tValidation Loss: 1.373114 \t time: 0.3\n",
      "Epoch: 949 \tTraining Loss: 1.297062 \tValidation Loss: 1.372603 \t time: 0.3\n",
      "Epoch: 950 \tTraining Loss: 1.296696 \tValidation Loss: 1.371848 \t time: 0.3\n",
      "Epoch: 951 \tTraining Loss: 1.298179 \tValidation Loss: 1.371502 \t time: 0.3\n",
      "Epoch: 952 \tTraining Loss: 1.295430 \tValidation Loss: 1.370918 \t time: 0.3\n",
      "Epoch: 953 \tTraining Loss: 1.297067 \tValidation Loss: 1.370907 \t time: 0.3\n",
      "Epoch: 954 \tTraining Loss: 1.294979 \tValidation Loss: 1.371165 \t time: 0.3\n",
      "Epoch: 955 \tTraining Loss: 1.297471 \tValidation Loss: 1.371450 \t time: 0.3\n",
      "Epoch: 956 \tTraining Loss: 1.296965 \tValidation Loss: 1.372210 \t time: 0.3\n",
      "Epoch: 957 \tTraining Loss: 1.296881 \tValidation Loss: 1.372918 \t time: 0.3\n",
      "Epoch: 958 \tTraining Loss: 1.295580 \tValidation Loss: 1.373064 \t time: 0.3\n",
      "Epoch: 959 \tTraining Loss: 1.296236 \tValidation Loss: 1.372260 \t time: 0.2\n",
      "Epoch: 960 \tTraining Loss: 1.295368 \tValidation Loss: 1.371808 \t time: 0.3\n",
      "Epoch: 961 \tTraining Loss: 1.296739 \tValidation Loss: 1.371664 \t time: 0.3\n",
      "Epoch: 962 \tTraining Loss: 1.295606 \tValidation Loss: 1.371419 \t time: 0.3\n",
      "Epoch: 963 \tTraining Loss: 1.296561 \tValidation Loss: 1.371762 \t time: 0.3\n",
      "Epoch: 964 \tTraining Loss: 1.295586 \tValidation Loss: 1.371969 \t time: 0.3\n",
      "Epoch: 965 \tTraining Loss: 1.297714 \tValidation Loss: 1.372476 \t time: 0.3\n",
      "Epoch: 966 \tTraining Loss: 1.296380 \tValidation Loss: 1.373140 \t time: 0.3\n",
      "Epoch: 967 \tTraining Loss: 1.296537 \tValidation Loss: 1.373521 \t time: 0.3\n",
      "Epoch: 968 \tTraining Loss: 1.294313 \tValidation Loss: 1.373675 \t time: 0.3\n",
      "Epoch: 969 \tTraining Loss: 1.296587 \tValidation Loss: 1.373542 \t time: 0.3\n",
      "Epoch: 970 \tTraining Loss: 1.296944 \tValidation Loss: 1.373250 \t time: 0.3\n",
      "Epoch: 971 \tTraining Loss: 1.294528 \tValidation Loss: 1.372971 \t time: 0.3\n",
      "Epoch: 972 \tTraining Loss: 1.293691 \tValidation Loss: 1.372617 \t time: 0.3\n",
      "Epoch: 973 \tTraining Loss: 1.296784 \tValidation Loss: 1.372078 \t time: 0.3\n",
      "Epoch: 974 \tTraining Loss: 1.296896 \tValidation Loss: 1.371658 \t time: 0.3\n",
      "Epoch: 975 \tTraining Loss: 1.293011 \tValidation Loss: 1.371312 \t time: 0.3\n",
      "Epoch: 976 \tTraining Loss: 1.295028 \tValidation Loss: 1.371749 \t time: 0.3\n",
      "Epoch: 977 \tTraining Loss: 1.294866 \tValidation Loss: 1.371658 \t time: 0.3\n",
      "Epoch: 978 \tTraining Loss: 1.294272 \tValidation Loss: 1.371553 \t time: 0.3\n",
      "Epoch: 979 \tTraining Loss: 1.293734 \tValidation Loss: 1.370878 \t time: 0.3\n",
      "Epoch: 980 \tTraining Loss: 1.294380 \tValidation Loss: 1.369720 \t time: 0.3\n",
      "Validation loss decreased from 1.369863 to 1.369720. Model was saved\n",
      "Epoch: 981 \tTraining Loss: 1.296229 \tValidation Loss: 1.369263 \t time: 0.3\n",
      "Validation loss decreased from 1.369720 to 1.369263. Model was saved\n",
      "Epoch: 982 \tTraining Loss: 1.294330 \tValidation Loss: 1.369209 \t time: 0.3\n",
      "Validation loss decreased from 1.369263 to 1.369209. Model was saved\n",
      "Epoch: 983 \tTraining Loss: 1.292956 \tValidation Loss: 1.369604 \t time: 0.3\n",
      "Epoch: 984 \tTraining Loss: 1.297363 \tValidation Loss: 1.370522 \t time: 0.3\n",
      "Epoch: 985 \tTraining Loss: 1.292715 \tValidation Loss: 1.371333 \t time: 0.3\n",
      "Epoch: 986 \tTraining Loss: 1.295094 \tValidation Loss: 1.371715 \t time: 0.2\n",
      "Epoch: 987 \tTraining Loss: 1.295063 \tValidation Loss: 1.371627 \t time: 0.3\n",
      "Epoch: 988 \tTraining Loss: 1.293613 \tValidation Loss: 1.371776 \t time: 0.3\n",
      "Epoch: 989 \tTraining Loss: 1.296419 \tValidation Loss: 1.371519 \t time: 0.3\n",
      "Epoch: 990 \tTraining Loss: 1.291858 \tValidation Loss: 1.371642 \t time: 0.2\n",
      "Epoch: 991 \tTraining Loss: 1.295084 \tValidation Loss: 1.371785 \t time: 0.3\n",
      "Epoch: 992 \tTraining Loss: 1.294666 \tValidation Loss: 1.371752 \t time: 0.3\n",
      "Epoch: 993 \tTraining Loss: 1.292171 \tValidation Loss: 1.371821 \t time: 0.3\n",
      "Epoch: 994 \tTraining Loss: 1.294044 \tValidation Loss: 1.372383 \t time: 0.3\n",
      "Epoch: 995 \tTraining Loss: 1.292742 \tValidation Loss: 1.372831 \t time: 0.3\n",
      "Epoch: 996 \tTraining Loss: 1.294744 \tValidation Loss: 1.373434 \t time: 0.3\n",
      "Epoch: 997 \tTraining Loss: 1.293637 \tValidation Loss: 1.373489 \t time: 0.3\n",
      "Epoch: 998 \tTraining Loss: 1.293775 \tValidation Loss: 1.372959 \t time: 0.3\n",
      "Epoch: 999 \tTraining Loss: 1.291144 \tValidation Loss: 1.372485 \t time: 0.3\n",
      "Epoch: 1000 \tTraining Loss: 1.290640 \tValidation Loss: 1.371912 \t time: 0.3\n",
      "Epoch: 1001 \tTraining Loss: 1.292359 \tValidation Loss: 1.372069 \t time: 0.3\n",
      "Epoch: 1002 \tTraining Loss: 1.291755 \tValidation Loss: 1.372261 \t time: 0.3\n",
      "Epoch: 1003 \tTraining Loss: 1.293223 \tValidation Loss: 1.372596 \t time: 0.3\n",
      "Epoch: 1004 \tTraining Loss: 1.293016 \tValidation Loss: 1.372431 \t time: 0.3\n",
      "Epoch: 1005 \tTraining Loss: 1.294465 \tValidation Loss: 1.371633 \t time: 0.3\n",
      "Epoch: 1006 \tTraining Loss: 1.294259 \tValidation Loss: 1.370970 \t time: 0.3\n",
      "Epoch: 1007 \tTraining Loss: 1.294129 \tValidation Loss: 1.370147 \t time: 0.3\n",
      "Epoch: 1008 \tTraining Loss: 1.293449 \tValidation Loss: 1.369483 \t time: 0.3\n",
      "Epoch: 1009 \tTraining Loss: 1.292264 \tValidation Loss: 1.368986 \t time: 0.3\n",
      "Validation loss decreased from 1.369209 to 1.368986. Model was saved\n",
      "Epoch: 1010 \tTraining Loss: 1.292562 \tValidation Loss: 1.369109 \t time: 0.3\n",
      "Epoch: 1011 \tTraining Loss: 1.291949 \tValidation Loss: 1.369524 \t time: 0.2\n",
      "Epoch: 1012 \tTraining Loss: 1.292225 \tValidation Loss: 1.370316 \t time: 0.3\n",
      "Epoch: 1013 \tTraining Loss: 1.293956 \tValidation Loss: 1.371342 \t time: 0.3\n",
      "Epoch: 1014 \tTraining Loss: 1.291368 \tValidation Loss: 1.371981 \t time: 0.3\n",
      "Epoch: 1015 \tTraining Loss: 1.293468 \tValidation Loss: 1.371656 \t time: 0.3\n",
      "Epoch: 1016 \tTraining Loss: 1.293876 \tValidation Loss: 1.371122 \t time: 0.3\n",
      "Epoch: 1017 \tTraining Loss: 1.290918 \tValidation Loss: 1.370587 \t time: 0.3\n",
      "Epoch: 1018 \tTraining Loss: 1.292159 \tValidation Loss: 1.370419 \t time: 0.3\n",
      "Epoch: 1019 \tTraining Loss: 1.289210 \tValidation Loss: 1.370216 \t time: 0.2\n",
      "Epoch: 1020 \tTraining Loss: 1.290159 \tValidation Loss: 1.370166 \t time: 0.3\n",
      "Epoch: 1021 \tTraining Loss: 1.290601 \tValidation Loss: 1.370008 \t time: 0.2\n",
      "Epoch: 1022 \tTraining Loss: 1.289277 \tValidation Loss: 1.370278 \t time: 0.3\n",
      "Epoch: 1023 \tTraining Loss: 1.293437 \tValidation Loss: 1.371036 \t time: 0.3\n",
      "Epoch: 1024 \tTraining Loss: 1.294036 \tValidation Loss: 1.371118 \t time: 0.3\n",
      "Epoch: 1025 \tTraining Loss: 1.289557 \tValidation Loss: 1.370730 \t time: 0.3\n",
      "Epoch: 1026 \tTraining Loss: 1.292258 \tValidation Loss: 1.369702 \t time: 0.3\n",
      "Epoch: 1027 \tTraining Loss: 1.291073 \tValidation Loss: 1.368758 \t time: 0.3\n",
      "Validation loss decreased from 1.368986 to 1.368758. Model was saved\n",
      "Epoch: 1028 \tTraining Loss: 1.291403 \tValidation Loss: 1.368110 \t time: 0.2\n",
      "Validation loss decreased from 1.368758 to 1.368110. Model was saved\n",
      "Epoch: 1029 \tTraining Loss: 1.292626 \tValidation Loss: 1.367994 \t time: 0.2\n",
      "Validation loss decreased from 1.368110 to 1.367994. Model was saved\n",
      "Epoch: 1030 \tTraining Loss: 1.291112 \tValidation Loss: 1.368663 \t time: 0.3\n",
      "Epoch: 1031 \tTraining Loss: 1.290973 \tValidation Loss: 1.369816 \t time: 0.3\n",
      "Epoch: 1032 \tTraining Loss: 1.290919 \tValidation Loss: 1.371255 \t time: 0.3\n",
      "Epoch: 1033 \tTraining Loss: 1.291870 \tValidation Loss: 1.371697 \t time: 0.3\n",
      "Epoch: 1034 \tTraining Loss: 1.291148 \tValidation Loss: 1.370830 \t time: 0.3\n",
      "Epoch: 1035 \tTraining Loss: 1.289716 \tValidation Loss: 1.369308 \t time: 0.3\n",
      "Epoch: 1036 \tTraining Loss: 1.292421 \tValidation Loss: 1.367774 \t time: 0.3\n",
      "Validation loss decreased from 1.367994 to 1.367774. Model was saved\n",
      "Epoch: 1037 \tTraining Loss: 1.289975 \tValidation Loss: 1.366942 \t time: 0.3\n",
      "Validation loss decreased from 1.367774 to 1.366942. Model was saved\n",
      "Epoch: 1038 \tTraining Loss: 1.291532 \tValidation Loss: 1.366592 \t time: 0.3\n",
      "Validation loss decreased from 1.366942 to 1.366592. Model was saved\n",
      "Epoch: 1039 \tTraining Loss: 1.291344 \tValidation Loss: 1.366468 \t time: 0.3\n",
      "Validation loss decreased from 1.366592 to 1.366468. Model was saved\n",
      "Epoch: 1040 \tTraining Loss: 1.289549 \tValidation Loss: 1.366527 \t time: 0.3\n",
      "Epoch: 1041 \tTraining Loss: 1.288503 \tValidation Loss: 1.366678 \t time: 0.3\n",
      "Epoch: 1042 \tTraining Loss: 1.291169 \tValidation Loss: 1.366900 \t time: 0.3\n",
      "Epoch: 1043 \tTraining Loss: 1.287853 \tValidation Loss: 1.366907 \t time: 0.3\n",
      "Epoch: 1044 \tTraining Loss: 1.290218 \tValidation Loss: 1.366705 \t time: 0.2\n",
      "Epoch: 1045 \tTraining Loss: 1.289944 \tValidation Loss: 1.366890 \t time: 0.3\n",
      "Epoch: 1046 \tTraining Loss: 1.288074 \tValidation Loss: 1.367058 \t time: 0.3\n",
      "Epoch: 1047 \tTraining Loss: 1.290269 \tValidation Loss: 1.367275 \t time: 0.3\n",
      "Epoch: 1048 \tTraining Loss: 1.287144 \tValidation Loss: 1.368018 \t time: 0.3\n",
      "Epoch: 1049 \tTraining Loss: 1.288163 \tValidation Loss: 1.368665 \t time: 0.3\n",
      "Epoch: 1050 \tTraining Loss: 1.289131 \tValidation Loss: 1.368979 \t time: 0.3\n",
      "Epoch: 1051 \tTraining Loss: 1.290567 \tValidation Loss: 1.369093 \t time: 0.3\n",
      "Epoch: 1052 \tTraining Loss: 1.289968 \tValidation Loss: 1.368385 \t time: 0.3\n",
      "Epoch: 1053 \tTraining Loss: 1.289133 \tValidation Loss: 1.367131 \t time: 0.3\n",
      "Epoch: 1054 \tTraining Loss: 1.288510 \tValidation Loss: 1.365621 \t time: 0.3\n",
      "Validation loss decreased from 1.366468 to 1.365621. Model was saved\n",
      "Epoch: 1055 \tTraining Loss: 1.287524 \tValidation Loss: 1.364751 \t time: 0.3\n",
      "Validation loss decreased from 1.365621 to 1.364751. Model was saved\n",
      "Epoch: 1056 \tTraining Loss: 1.289970 \tValidation Loss: 1.364358 \t time: 0.3\n",
      "Validation loss decreased from 1.364751 to 1.364358. Model was saved\n",
      "Epoch: 1057 \tTraining Loss: 1.288686 \tValidation Loss: 1.364769 \t time: 0.3\n",
      "Epoch: 1058 \tTraining Loss: 1.285972 \tValidation Loss: 1.365938 \t time: 0.3\n",
      "Epoch: 1059 \tTraining Loss: 1.289035 \tValidation Loss: 1.367017 \t time: 0.3\n",
      "Epoch: 1060 \tTraining Loss: 1.286445 \tValidation Loss: 1.367754 \t time: 0.3\n",
      "Epoch: 1061 \tTraining Loss: 1.286995 \tValidation Loss: 1.368325 \t time: 0.3\n",
      "Epoch: 1062 \tTraining Loss: 1.288446 \tValidation Loss: 1.368425 \t time: 0.3\n",
      "Epoch: 1063 \tTraining Loss: 1.287453 \tValidation Loss: 1.367846 \t time: 0.3\n",
      "Epoch: 1064 \tTraining Loss: 1.289847 \tValidation Loss: 1.367291 \t time: 0.3\n",
      "Epoch: 1065 \tTraining Loss: 1.288996 \tValidation Loss: 1.366952 \t time: 0.3\n",
      "Epoch: 1066 \tTraining Loss: 1.285258 \tValidation Loss: 1.366672 \t time: 0.3\n",
      "Epoch: 1067 \tTraining Loss: 1.288537 \tValidation Loss: 1.366878 \t time: 0.3\n",
      "Epoch: 1068 \tTraining Loss: 1.287538 \tValidation Loss: 1.366977 \t time: 0.3\n",
      "Epoch: 1069 \tTraining Loss: 1.286729 \tValidation Loss: 1.367723 \t time: 0.3\n",
      "Epoch: 1070 \tTraining Loss: 1.286945 \tValidation Loss: 1.368315 \t time: 0.3\n",
      "Epoch: 1071 \tTraining Loss: 1.286533 \tValidation Loss: 1.368232 \t time: 0.3\n",
      "Epoch: 1072 \tTraining Loss: 1.287046 \tValidation Loss: 1.367106 \t time: 0.3\n",
      "Epoch: 1073 \tTraining Loss: 1.286678 \tValidation Loss: 1.365640 \t time: 0.3\n",
      "Epoch: 1074 \tTraining Loss: 1.286667 \tValidation Loss: 1.364500 \t time: 0.3\n",
      "Epoch: 1075 \tTraining Loss: 1.287324 \tValidation Loss: 1.363758 \t time: 0.3\n",
      "Validation loss decreased from 1.364358 to 1.363758. Model was saved\n",
      "Epoch: 1076 \tTraining Loss: 1.285797 \tValidation Loss: 1.363770 \t time: 0.3\n",
      "Epoch: 1077 \tTraining Loss: 1.283880 \tValidation Loss: 1.364041 \t time: 0.2\n",
      "Epoch: 1078 \tTraining Loss: 1.285752 \tValidation Loss: 1.364718 \t time: 0.3\n",
      "Epoch: 1079 \tTraining Loss: 1.288548 \tValidation Loss: 1.364822 \t time: 0.3\n",
      "Epoch: 1080 \tTraining Loss: 1.285368 \tValidation Loss: 1.364710 \t time: 0.3\n",
      "Epoch: 1081 \tTraining Loss: 1.285489 \tValidation Loss: 1.364570 \t time: 0.3\n",
      "Epoch: 1082 \tTraining Loss: 1.287679 \tValidation Loss: 1.364492 \t time: 0.3\n",
      "Epoch: 1083 \tTraining Loss: 1.287007 \tValidation Loss: 1.364735 \t time: 0.3\n",
      "Epoch: 1084 \tTraining Loss: 1.283597 \tValidation Loss: 1.365333 \t time: 0.3\n",
      "Epoch: 1085 \tTraining Loss: 1.286725 \tValidation Loss: 1.365922 \t time: 0.3\n",
      "Epoch: 1086 \tTraining Loss: 1.286053 \tValidation Loss: 1.366898 \t time: 0.3\n",
      "Epoch: 1087 \tTraining Loss: 1.287453 \tValidation Loss: 1.367405 \t time: 0.3\n",
      "Epoch: 1088 \tTraining Loss: 1.287001 \tValidation Loss: 1.367746 \t time: 0.3\n",
      "Epoch: 1089 \tTraining Loss: 1.284877 \tValidation Loss: 1.367211 \t time: 0.3\n",
      "Epoch: 1090 \tTraining Loss: 1.286274 \tValidation Loss: 1.366382 \t time: 0.3\n",
      "Epoch: 1091 \tTraining Loss: 1.286387 \tValidation Loss: 1.365095 \t time: 0.3\n",
      "Epoch: 1092 \tTraining Loss: 1.285278 \tValidation Loss: 1.364391 \t time: 0.2\n",
      "Epoch: 1093 \tTraining Loss: 1.284739 \tValidation Loss: 1.363702 \t time: 0.3\n",
      "Validation loss decreased from 1.363758 to 1.363702. Model was saved\n",
      "Epoch: 1094 \tTraining Loss: 1.284178 \tValidation Loss: 1.363394 \t time: 0.2\n",
      "Validation loss decreased from 1.363702 to 1.363394. Model was saved\n",
      "Epoch: 1095 \tTraining Loss: 1.284558 \tValidation Loss: 1.363492 \t time: 0.3\n",
      "Epoch: 1096 \tTraining Loss: 1.283947 \tValidation Loss: 1.363962 \t time: 0.3\n",
      "Epoch: 1097 \tTraining Loss: 1.283168 \tValidation Loss: 1.364694 \t time: 0.3\n",
      "Epoch: 1098 \tTraining Loss: 1.286180 \tValidation Loss: 1.365340 \t time: 0.3\n",
      "Epoch: 1099 \tTraining Loss: 1.283607 \tValidation Loss: 1.366185 \t time: 0.3\n",
      "Epoch: 1100 \tTraining Loss: 1.284541 \tValidation Loss: 1.367219 \t time: 0.3\n",
      "Epoch: 1101 \tTraining Loss: 1.284190 \tValidation Loss: 1.367597 \t time: 0.3\n",
      "Epoch: 1102 \tTraining Loss: 1.285559 \tValidation Loss: 1.368194 \t time: 0.2\n",
      "Epoch: 1103 \tTraining Loss: 1.282990 \tValidation Loss: 1.368034 \t time: 0.3\n",
      "Epoch: 1104 \tTraining Loss: 1.281869 \tValidation Loss: 1.367209 \t time: 0.3\n",
      "Epoch: 1105 \tTraining Loss: 1.287238 \tValidation Loss: 1.365992 \t time: 0.3\n",
      "Epoch: 1106 \tTraining Loss: 1.284783 \tValidation Loss: 1.365036 \t time: 0.3\n",
      "Epoch: 1107 \tTraining Loss: 1.283062 \tValidation Loss: 1.364791 \t time: 0.3\n",
      "Epoch: 1108 \tTraining Loss: 1.282184 \tValidation Loss: 1.365286 \t time: 0.3\n",
      "Epoch: 1109 \tTraining Loss: 1.283840 \tValidation Loss: 1.365684 \t time: 0.2\n",
      "Epoch: 1110 \tTraining Loss: 1.281860 \tValidation Loss: 1.365994 \t time: 0.3\n",
      "Epoch: 1111 \tTraining Loss: 1.283474 \tValidation Loss: 1.366594 \t time: 0.2\n",
      "Epoch: 1112 \tTraining Loss: 1.282043 \tValidation Loss: 1.366656 \t time: 0.3\n",
      "Epoch: 1113 \tTraining Loss: 1.283888 \tValidation Loss: 1.366057 \t time: 0.3\n",
      "Epoch: 1114 \tTraining Loss: 1.282977 \tValidation Loss: 1.365353 \t time: 0.3\n",
      "Epoch: 1115 \tTraining Loss: 1.284323 \tValidation Loss: 1.364702 \t time: 0.2\n",
      "Epoch: 1116 \tTraining Loss: 1.282701 \tValidation Loss: 1.364370 \t time: 0.2\n",
      "Epoch: 1117 \tTraining Loss: 1.282382 \tValidation Loss: 1.364543 \t time: 0.3\n",
      "Epoch: 1118 \tTraining Loss: 1.283508 \tValidation Loss: 1.365205 \t time: 0.3\n",
      "Epoch: 1119 \tTraining Loss: 1.283605 \tValidation Loss: 1.366035 \t time: 0.3\n",
      "Epoch: 1120 \tTraining Loss: 1.282669 \tValidation Loss: 1.366891 \t time: 0.3\n",
      "Epoch: 1121 \tTraining Loss: 1.283851 \tValidation Loss: 1.366717 \t time: 0.3\n",
      "Epoch: 1122 \tTraining Loss: 1.283272 \tValidation Loss: 1.365680 \t time: 0.3\n",
      "Epoch: 1123 \tTraining Loss: 1.281061 \tValidation Loss: 1.364887 \t time: 0.3\n",
      "Epoch: 1124 \tTraining Loss: 1.282783 \tValidation Loss: 1.364216 \t time: 0.3\n",
      "Epoch: 1125 \tTraining Loss: 1.280753 \tValidation Loss: 1.363916 \t time: 0.2\n",
      "Epoch: 1126 \tTraining Loss: 1.284323 \tValidation Loss: 1.363747 \t time: 0.3\n",
      "Epoch: 1127 \tTraining Loss: 1.281748 \tValidation Loss: 1.363810 \t time: 0.3\n",
      "Epoch: 1128 \tTraining Loss: 1.282852 \tValidation Loss: 1.364139 \t time: 0.3\n",
      "Epoch: 1129 \tTraining Loss: 1.282518 \tValidation Loss: 1.364948 \t time: 0.3\n",
      "Epoch: 1130 \tTraining Loss: 1.284782 \tValidation Loss: 1.365608 \t time: 0.2\n",
      "Epoch: 1131 \tTraining Loss: 1.280043 \tValidation Loss: 1.366108 \t time: 0.2\n",
      "Epoch: 1132 \tTraining Loss: 1.283466 \tValidation Loss: 1.366166 \t time: 0.2\n",
      "Epoch: 1133 \tTraining Loss: 1.283598 \tValidation Loss: 1.365602 \t time: 0.3\n",
      "Epoch: 1134 \tTraining Loss: 1.284107 \tValidation Loss: 1.365285 \t time: 0.2\n",
      "Epoch: 1135 \tTraining Loss: 1.281374 \tValidation Loss: 1.364997 \t time: 0.3\n",
      "Epoch: 1136 \tTraining Loss: 1.282480 \tValidation Loss: 1.364969 \t time: 0.3\n",
      "Epoch: 1137 \tTraining Loss: 1.281788 \tValidation Loss: 1.364921 \t time: 0.2\n",
      "Epoch: 1138 \tTraining Loss: 1.282185 \tValidation Loss: 1.365004 \t time: 0.2\n",
      "Epoch: 1139 \tTraining Loss: 1.281933 \tValidation Loss: 1.365143 \t time: 0.3\n",
      "Epoch: 1140 \tTraining Loss: 1.280923 \tValidation Loss: 1.365081 \t time: 0.3\n",
      "Epoch: 1141 \tTraining Loss: 1.279819 \tValidation Loss: 1.364943 \t time: 0.3\n",
      "Epoch: 1142 \tTraining Loss: 1.282113 \tValidation Loss: 1.364438 \t time: 0.3\n",
      "Epoch: 1143 \tTraining Loss: 1.282567 \tValidation Loss: 1.363750 \t time: 0.3\n",
      "Epoch: 1144 \tTraining Loss: 1.279655 \tValidation Loss: 1.363451 \t time: 0.3\n",
      "Epoch: 1145 \tTraining Loss: 1.280931 \tValidation Loss: 1.363270 \t time: 0.3\n",
      "Validation loss decreased from 1.363394 to 1.363270. Model was saved\n",
      "Epoch: 1146 \tTraining Loss: 1.282000 \tValidation Loss: 1.363727 \t time: 0.3\n",
      "Epoch: 1147 \tTraining Loss: 1.278954 \tValidation Loss: 1.364286 \t time: 0.3\n",
      "Epoch: 1148 \tTraining Loss: 1.282107 \tValidation Loss: 1.364372 \t time: 0.3\n",
      "Epoch: 1149 \tTraining Loss: 1.281549 \tValidation Loss: 1.364399 \t time: 0.3\n",
      "Epoch: 1150 \tTraining Loss: 1.280221 \tValidation Loss: 1.363755 \t time: 0.3\n",
      "Epoch: 1151 \tTraining Loss: 1.282344 \tValidation Loss: 1.362737 \t time: 0.3\n",
      "Validation loss decreased from 1.363270 to 1.362737. Model was saved\n",
      "Epoch: 1152 \tTraining Loss: 1.279178 \tValidation Loss: 1.361649 \t time: 0.3\n",
      "Validation loss decreased from 1.362737 to 1.361649. Model was saved\n",
      "Epoch: 1153 \tTraining Loss: 1.281709 \tValidation Loss: 1.361186 \t time: 0.3\n",
      "Validation loss decreased from 1.361649 to 1.361186. Model was saved\n",
      "Epoch: 1154 \tTraining Loss: 1.281666 \tValidation Loss: 1.361056 \t time: 0.3\n",
      "Validation loss decreased from 1.361186 to 1.361056. Model was saved\n",
      "Epoch: 1155 \tTraining Loss: 1.281776 \tValidation Loss: 1.361594 \t time: 0.3\n",
      "Epoch: 1156 \tTraining Loss: 1.281570 \tValidation Loss: 1.362579 \t time: 0.3\n",
      "Epoch: 1157 \tTraining Loss: 1.279400 \tValidation Loss: 1.363652 \t time: 0.3\n",
      "Epoch: 1158 \tTraining Loss: 1.281617 \tValidation Loss: 1.364302 \t time: 0.3\n",
      "Epoch: 1159 \tTraining Loss: 1.284066 \tValidation Loss: 1.364624 \t time: 0.3\n",
      "Epoch: 1160 \tTraining Loss: 1.280363 \tValidation Loss: 1.364283 \t time: 0.3\n",
      "Epoch: 1161 \tTraining Loss: 1.282681 \tValidation Loss: 1.363598 \t time: 0.3\n",
      "Epoch: 1162 \tTraining Loss: 1.281211 \tValidation Loss: 1.363169 \t time: 0.3\n",
      "Epoch: 1163 \tTraining Loss: 1.279256 \tValidation Loss: 1.363380 \t time: 0.3\n",
      "Epoch: 1164 \tTraining Loss: 1.278657 \tValidation Loss: 1.363839 \t time: 0.3\n",
      "Epoch: 1165 \tTraining Loss: 1.281877 \tValidation Loss: 1.364190 \t time: 0.2\n",
      "Epoch: 1166 \tTraining Loss: 1.280859 \tValidation Loss: 1.364726 \t time: 0.3\n",
      "Epoch: 1167 \tTraining Loss: 1.280483 \tValidation Loss: 1.365305 \t time: 0.3\n",
      "Epoch: 1168 \tTraining Loss: 1.277713 \tValidation Loss: 1.365677 \t time: 0.3\n",
      "Epoch: 1169 \tTraining Loss: 1.279541 \tValidation Loss: 1.365629 \t time: 0.2\n",
      "Epoch: 1170 \tTraining Loss: 1.279248 \tValidation Loss: 1.364984 \t time: 0.3\n",
      "Epoch: 1171 \tTraining Loss: 1.280424 \tValidation Loss: 1.363515 \t time: 0.3\n",
      "Epoch: 1172 \tTraining Loss: 1.282414 \tValidation Loss: 1.362033 \t time: 0.3\n",
      "Epoch: 1173 \tTraining Loss: 1.280756 \tValidation Loss: 1.361092 \t time: 0.3\n",
      "Epoch: 1174 \tTraining Loss: 1.279309 \tValidation Loss: 1.360536 \t time: 0.2\n",
      "Validation loss decreased from 1.361056 to 1.360536. Model was saved\n",
      "Epoch: 1175 \tTraining Loss: 1.277577 \tValidation Loss: 1.360385 \t time: 0.3\n",
      "Validation loss decreased from 1.360536 to 1.360385. Model was saved\n",
      "Epoch: 1176 \tTraining Loss: 1.278768 \tValidation Loss: 1.360702 \t time: 0.3\n",
      "Epoch: 1177 \tTraining Loss: 1.279085 \tValidation Loss: 1.360665 \t time: 0.3\n",
      "Epoch: 1178 \tTraining Loss: 1.277509 \tValidation Loss: 1.360126 \t time: 0.3\n",
      "Validation loss decreased from 1.360385 to 1.360126. Model was saved\n",
      "Epoch: 1179 \tTraining Loss: 1.280514 \tValidation Loss: 1.359625 \t time: 0.3\n",
      "Validation loss decreased from 1.360126 to 1.359625. Model was saved\n",
      "Epoch: 1180 \tTraining Loss: 1.277998 \tValidation Loss: 1.359373 \t time: 0.3\n",
      "Validation loss decreased from 1.359625 to 1.359373. Model was saved\n",
      "Epoch: 1181 \tTraining Loss: 1.281818 \tValidation Loss: 1.359440 \t time: 0.3\n",
      "Epoch: 1182 \tTraining Loss: 1.281313 \tValidation Loss: 1.360085 \t time: 0.3\n",
      "Epoch: 1183 \tTraining Loss: 1.279150 \tValidation Loss: 1.360669 \t time: 0.3\n",
      "Epoch: 1184 \tTraining Loss: 1.278262 \tValidation Loss: 1.360910 \t time: 0.3\n",
      "Epoch: 1185 \tTraining Loss: 1.280568 \tValidation Loss: 1.360929 \t time: 0.3\n",
      "Epoch: 1186 \tTraining Loss: 1.279960 \tValidation Loss: 1.361094 \t time: 0.3\n",
      "Epoch: 1187 \tTraining Loss: 1.280845 \tValidation Loss: 1.361732 \t time: 0.3\n",
      "Epoch: 1188 \tTraining Loss: 1.280093 \tValidation Loss: 1.362220 \t time: 0.3\n",
      "Epoch: 1189 \tTraining Loss: 1.278663 \tValidation Loss: 1.362087 \t time: 0.3\n",
      "Epoch: 1190 \tTraining Loss: 1.280375 \tValidation Loss: 1.362001 \t time: 0.3\n",
      "Epoch: 1191 \tTraining Loss: 1.278489 \tValidation Loss: 1.361386 \t time: 0.3\n",
      "Epoch: 1192 \tTraining Loss: 1.278161 \tValidation Loss: 1.360913 \t time: 0.3\n",
      "Epoch: 1193 \tTraining Loss: 1.280038 \tValidation Loss: 1.360954 \t time: 0.3\n",
      "Epoch: 1194 \tTraining Loss: 1.281846 \tValidation Loss: 1.361423 \t time: 0.3\n",
      "Epoch: 1195 \tTraining Loss: 1.280176 \tValidation Loss: 1.362200 \t time: 0.3\n",
      "Epoch: 1196 \tTraining Loss: 1.277395 \tValidation Loss: 1.362447 \t time: 0.3\n",
      "Epoch: 1197 \tTraining Loss: 1.278171 \tValidation Loss: 1.362682 \t time: 0.3\n",
      "Epoch: 1198 \tTraining Loss: 1.279228 \tValidation Loss: 1.362751 \t time: 0.3\n",
      "Epoch: 1199 \tTraining Loss: 1.278555 \tValidation Loss: 1.362650 \t time: 0.3\n",
      "Epoch: 1200 \tTraining Loss: 1.278828 \tValidation Loss: 1.362718 \t time: 0.3\n",
      "Epoch: 1201 \tTraining Loss: 1.278742 \tValidation Loss: 1.362372 \t time: 0.3\n",
      "Epoch: 1202 \tTraining Loss: 1.275859 \tValidation Loss: 1.362072 \t time: 0.3\n",
      "Epoch: 1203 \tTraining Loss: 1.276600 \tValidation Loss: 1.361306 \t time: 0.3\n",
      "Epoch: 1204 \tTraining Loss: 1.276652 \tValidation Loss: 1.360200 \t time: 0.3\n",
      "Epoch: 1205 \tTraining Loss: 1.275643 \tValidation Loss: 1.359359 \t time: 0.3\n",
      "Validation loss decreased from 1.359373 to 1.359359. Model was saved\n",
      "Epoch: 1206 \tTraining Loss: 1.278030 \tValidation Loss: 1.359127 \t time: 0.2\n",
      "Validation loss decreased from 1.359359 to 1.359127. Model was saved\n",
      "Epoch: 1207 \tTraining Loss: 1.277407 \tValidation Loss: 1.358763 \t time: 0.3\n",
      "Validation loss decreased from 1.359127 to 1.358763. Model was saved\n",
      "Epoch: 1208 \tTraining Loss: 1.278809 \tValidation Loss: 1.358986 \t time: 0.2\n",
      "Epoch: 1209 \tTraining Loss: 1.274641 \tValidation Loss: 1.359340 \t time: 0.3\n",
      "Epoch: 1210 \tTraining Loss: 1.277727 \tValidation Loss: 1.359156 \t time: 0.3\n",
      "Epoch: 1211 \tTraining Loss: 1.280478 \tValidation Loss: 1.359424 \t time: 0.3\n",
      "Epoch: 1212 \tTraining Loss: 1.277998 \tValidation Loss: 1.360497 \t time: 0.2\n",
      "Epoch: 1213 \tTraining Loss: 1.276114 \tValidation Loss: 1.361243 \t time: 0.2\n",
      "Epoch: 1214 \tTraining Loss: 1.278923 \tValidation Loss: 1.361540 \t time: 0.3\n",
      "Epoch: 1215 \tTraining Loss: 1.278974 \tValidation Loss: 1.361060 \t time: 0.3\n",
      "Epoch: 1216 \tTraining Loss: 1.275770 \tValidation Loss: 1.360501 \t time: 0.3\n",
      "Epoch: 1217 \tTraining Loss: 1.277665 \tValidation Loss: 1.359673 \t time: 0.3\n",
      "Epoch: 1218 \tTraining Loss: 1.279482 \tValidation Loss: 1.359673 \t time: 0.3\n",
      "Epoch: 1219 \tTraining Loss: 1.276865 \tValidation Loss: 1.360219 \t time: 0.3\n",
      "Epoch: 1220 \tTraining Loss: 1.278685 \tValidation Loss: 1.361001 \t time: 0.3\n",
      "Epoch: 1221 \tTraining Loss: 1.275666 \tValidation Loss: 1.361982 \t time: 0.3\n",
      "Epoch: 1222 \tTraining Loss: 1.277906 \tValidation Loss: 1.362829 \t time: 0.2\n",
      "Epoch: 1223 \tTraining Loss: 1.277858 \tValidation Loss: 1.362995 \t time: 0.3\n",
      "Epoch: 1224 \tTraining Loss: 1.279285 \tValidation Loss: 1.362503 \t time: 0.3\n",
      "Epoch: 1225 \tTraining Loss: 1.278818 \tValidation Loss: 1.362052 \t time: 0.3\n",
      "Epoch: 1226 \tTraining Loss: 1.276845 \tValidation Loss: 1.361157 \t time: 0.3\n",
      "Epoch: 1227 \tTraining Loss: 1.278193 \tValidation Loss: 1.360480 \t time: 0.3\n",
      "Epoch: 1228 \tTraining Loss: 1.276110 \tValidation Loss: 1.360258 \t time: 0.3\n",
      "Epoch: 1229 \tTraining Loss: 1.276090 \tValidation Loss: 1.360247 \t time: 0.3\n",
      "Epoch: 1230 \tTraining Loss: 1.275524 \tValidation Loss: 1.360414 \t time: 0.3\n",
      "Epoch: 1231 \tTraining Loss: 1.278056 \tValidation Loss: 1.360159 \t time: 0.3\n",
      "Epoch: 1232 \tTraining Loss: 1.277906 \tValidation Loss: 1.360184 \t time: 0.2\n",
      "Epoch: 1233 \tTraining Loss: 1.278292 \tValidation Loss: 1.360194 \t time: 0.3\n",
      "Epoch: 1234 \tTraining Loss: 1.277112 \tValidation Loss: 1.360417 \t time: 0.3\n",
      "Epoch: 1235 \tTraining Loss: 1.275151 \tValidation Loss: 1.360616 \t time: 0.3\n",
      "Epoch: 1236 \tTraining Loss: 1.276747 \tValidation Loss: 1.360633 \t time: 0.3\n",
      "Epoch: 1237 \tTraining Loss: 1.276391 \tValidation Loss: 1.360574 \t time: 0.3\n",
      "Epoch: 1238 \tTraining Loss: 1.275854 \tValidation Loss: 1.360784 \t time: 0.3\n",
      "Epoch: 1239 \tTraining Loss: 1.275148 \tValidation Loss: 1.361009 \t time: 0.3\n",
      "Epoch: 1240 \tTraining Loss: 1.276289 \tValidation Loss: 1.361156 \t time: 0.3\n",
      "Epoch: 1241 \tTraining Loss: 1.278539 \tValidation Loss: 1.361285 \t time: 0.3\n",
      "Epoch: 1242 \tTraining Loss: 1.275355 \tValidation Loss: 1.361590 \t time: 0.3\n",
      "Epoch: 1243 \tTraining Loss: 1.276821 \tValidation Loss: 1.361668 \t time: 0.3\n",
      "Epoch: 1244 \tTraining Loss: 1.273844 \tValidation Loss: 1.361505 \t time: 0.3\n",
      "Epoch: 1245 \tTraining Loss: 1.277331 \tValidation Loss: 1.361311 \t time: 0.3\n",
      "Epoch: 1246 \tTraining Loss: 1.275345 \tValidation Loss: 1.361235 \t time: 0.3\n",
      "Epoch: 1247 \tTraining Loss: 1.274175 \tValidation Loss: 1.360839 \t time: 0.3\n",
      "Epoch: 1248 \tTraining Loss: 1.276150 \tValidation Loss: 1.360321 \t time: 0.3\n",
      "Epoch: 1249 \tTraining Loss: 1.275161 \tValidation Loss: 1.359760 \t time: 0.3\n",
      "Epoch: 1250 \tTraining Loss: 1.274498 \tValidation Loss: 1.359419 \t time: 0.3\n",
      "Epoch: 1251 \tTraining Loss: 1.274931 \tValidation Loss: 1.359307 \t time: 0.3\n",
      "Epoch: 1252 \tTraining Loss: 1.277115 \tValidation Loss: 1.359371 \t time: 0.3\n",
      "Epoch: 1253 \tTraining Loss: 1.276450 \tValidation Loss: 1.359883 \t time: 0.2\n",
      "Epoch: 1254 \tTraining Loss: 1.274585 \tValidation Loss: 1.360651 \t time: 0.3\n",
      "Epoch: 1255 \tTraining Loss: 1.278300 \tValidation Loss: 1.361260 \t time: 0.3\n",
      "Epoch: 1256 \tTraining Loss: 1.276195 \tValidation Loss: 1.361228 \t time: 0.3\n",
      "Epoch: 1257 \tTraining Loss: 1.276255 \tValidation Loss: 1.360696 \t time: 0.2\n",
      "Epoch: 1258 \tTraining Loss: 1.275716 \tValidation Loss: 1.359985 \t time: 0.3\n",
      "Epoch: 1259 \tTraining Loss: 1.276278 \tValidation Loss: 1.359295 \t time: 0.2\n",
      "Epoch: 1260 \tTraining Loss: 1.273767 \tValidation Loss: 1.359170 \t time: 0.3\n",
      "Epoch: 1261 \tTraining Loss: 1.276163 \tValidation Loss: 1.359289 \t time: 0.2\n",
      "Epoch: 1262 \tTraining Loss: 1.274954 \tValidation Loss: 1.359500 \t time: 0.2\n",
      "Epoch: 1263 \tTraining Loss: 1.275114 \tValidation Loss: 1.359647 \t time: 0.2\n",
      "Epoch: 1264 \tTraining Loss: 1.272993 \tValidation Loss: 1.359777 \t time: 0.2\n",
      "Epoch: 1265 \tTraining Loss: 1.274861 \tValidation Loss: 1.359896 \t time: 0.2\n",
      "Epoch: 1266 \tTraining Loss: 1.275316 \tValidation Loss: 1.360076 \t time: 0.2\n",
      "Epoch: 1267 \tTraining Loss: 1.276342 \tValidation Loss: 1.360224 \t time: 0.3\n",
      "Epoch: 1268 \tTraining Loss: 1.274376 \tValidation Loss: 1.360259 \t time: 0.2\n",
      "Epoch: 1269 \tTraining Loss: 1.274301 \tValidation Loss: 1.360109 \t time: 0.3\n",
      "Epoch: 1270 \tTraining Loss: 1.274103 \tValidation Loss: 1.359514 \t time: 0.3\n",
      "Epoch: 1271 \tTraining Loss: 1.274733 \tValidation Loss: 1.358830 \t time: 0.3\n",
      "Epoch: 1272 \tTraining Loss: 1.276108 \tValidation Loss: 1.358361 \t time: 0.2\n",
      "Validation loss decreased from 1.358763 to 1.358361. Model was saved\n",
      "Epoch: 1273 \tTraining Loss: 1.275493 \tValidation Loss: 1.358221 \t time: 0.2\n",
      "Validation loss decreased from 1.358361 to 1.358221. Model was saved\n",
      "Epoch: 1274 \tTraining Loss: 1.277949 \tValidation Loss: 1.358233 \t time: 0.2\n",
      "Epoch: 1275 \tTraining Loss: 1.276124 \tValidation Loss: 1.358533 \t time: 0.3\n",
      "Epoch: 1276 \tTraining Loss: 1.272982 \tValidation Loss: 1.359183 \t time: 0.2\n",
      "Epoch: 1277 \tTraining Loss: 1.272460 \tValidation Loss: 1.359853 \t time: 0.2\n",
      "Epoch: 1278 \tTraining Loss: 1.273271 \tValidation Loss: 1.360597 \t time: 0.3\n",
      "Epoch: 1279 \tTraining Loss: 1.277919 \tValidation Loss: 1.361376 \t time: 0.2\n",
      "Epoch: 1280 \tTraining Loss: 1.274116 \tValidation Loss: 1.361906 \t time: 0.3\n",
      "Epoch: 1281 \tTraining Loss: 1.274818 \tValidation Loss: 1.362334 \t time: 0.3\n",
      "Epoch: 1282 \tTraining Loss: 1.276034 \tValidation Loss: 1.362134 \t time: 0.3\n",
      "Epoch: 1283 \tTraining Loss: 1.275229 \tValidation Loss: 1.361230 \t time: 0.2\n",
      "Epoch: 1284 \tTraining Loss: 1.275386 \tValidation Loss: 1.360295 \t time: 0.2\n",
      "Epoch: 1285 \tTraining Loss: 1.273860 \tValidation Loss: 1.359286 \t time: 0.3\n",
      "Epoch: 1286 \tTraining Loss: 1.275712 \tValidation Loss: 1.358732 \t time: 0.3\n",
      "Epoch: 1287 \tTraining Loss: 1.272193 \tValidation Loss: 1.358395 \t time: 0.2\n",
      "Epoch: 1288 \tTraining Loss: 1.273169 \tValidation Loss: 1.358231 \t time: 0.2\n",
      "Epoch: 1289 \tTraining Loss: 1.274119 \tValidation Loss: 1.358429 \t time: 0.3\n",
      "Epoch: 1290 \tTraining Loss: 1.272917 \tValidation Loss: 1.358986 \t time: 0.3\n",
      "Epoch: 1291 \tTraining Loss: 1.273387 \tValidation Loss: 1.359248 \t time: 0.2\n",
      "Epoch: 1292 \tTraining Loss: 1.273461 \tValidation Loss: 1.359280 \t time: 0.3\n",
      "Epoch: 1293 \tTraining Loss: 1.274679 \tValidation Loss: 1.358910 \t time: 0.3\n",
      "Epoch: 1294 \tTraining Loss: 1.273890 \tValidation Loss: 1.358574 \t time: 0.2\n",
      "Epoch: 1295 \tTraining Loss: 1.276789 \tValidation Loss: 1.358403 \t time: 0.3\n",
      "Epoch: 1296 \tTraining Loss: 1.275031 \tValidation Loss: 1.358673 \t time: 0.3\n",
      "Epoch: 1297 \tTraining Loss: 1.273276 \tValidation Loss: 1.358938 \t time: 0.3\n",
      "Epoch: 1298 \tTraining Loss: 1.276047 \tValidation Loss: 1.358878 \t time: 0.3\n",
      "Epoch: 1299 \tTraining Loss: 1.276791 \tValidation Loss: 1.358846 \t time: 0.3\n",
      "Epoch: 1300 \tTraining Loss: 1.274201 \tValidation Loss: 1.358856 \t time: 0.2\n",
      "Epoch: 1301 \tTraining Loss: 1.274791 \tValidation Loss: 1.358539 \t time: 0.3\n",
      "Epoch: 1302 \tTraining Loss: 1.273622 \tValidation Loss: 1.358531 \t time: 0.3\n",
      "Epoch: 1303 \tTraining Loss: 1.273211 \tValidation Loss: 1.358094 \t time: 0.3\n",
      "Validation loss decreased from 1.358221 to 1.358094. Model was saved\n",
      "Epoch: 1304 \tTraining Loss: 1.274883 \tValidation Loss: 1.357687 \t time: 0.3\n",
      "Validation loss decreased from 1.358094 to 1.357687. Model was saved\n",
      "Epoch: 1305 \tTraining Loss: 1.273361 \tValidation Loss: 1.357416 \t time: 0.2\n",
      "Validation loss decreased from 1.357687 to 1.357416. Model was saved\n",
      "Epoch: 1306 \tTraining Loss: 1.275045 \tValidation Loss: 1.357444 \t time: 0.2\n",
      "Epoch: 1307 \tTraining Loss: 1.273243 \tValidation Loss: 1.357551 \t time: 0.3\n",
      "Epoch: 1308 \tTraining Loss: 1.275212 \tValidation Loss: 1.357907 \t time: 0.3\n",
      "Epoch: 1309 \tTraining Loss: 1.274522 \tValidation Loss: 1.358490 \t time: 0.3\n",
      "Epoch: 1310 \tTraining Loss: 1.274553 \tValidation Loss: 1.359335 \t time: 0.3\n",
      "Epoch: 1311 \tTraining Loss: 1.272800 \tValidation Loss: 1.359913 \t time: 0.3\n",
      "Epoch: 1312 \tTraining Loss: 1.271958 \tValidation Loss: 1.360126 \t time: 0.3\n",
      "Epoch: 1313 \tTraining Loss: 1.273925 \tValidation Loss: 1.360156 \t time: 0.3\n",
      "Epoch: 1314 \tTraining Loss: 1.272654 \tValidation Loss: 1.360150 \t time: 0.3\n",
      "Epoch: 1315 \tTraining Loss: 1.273707 \tValidation Loss: 1.359817 \t time: 0.3\n",
      "Epoch: 1316 \tTraining Loss: 1.273322 \tValidation Loss: 1.359262 \t time: 0.2\n",
      "Epoch: 1317 \tTraining Loss: 1.271477 \tValidation Loss: 1.358745 \t time: 0.2\n",
      "Epoch: 1318 \tTraining Loss: 1.273314 \tValidation Loss: 1.358355 \t time: 0.2\n",
      "Epoch: 1319 \tTraining Loss: 1.272711 \tValidation Loss: 1.358185 \t time: 0.3\n",
      "Epoch: 1320 \tTraining Loss: 1.274884 \tValidation Loss: 1.357961 \t time: 0.2\n",
      "Epoch: 1321 \tTraining Loss: 1.271991 \tValidation Loss: 1.357990 \t time: 0.3\n",
      "Epoch: 1322 \tTraining Loss: 1.271583 \tValidation Loss: 1.357787 \t time: 0.2\n",
      "Epoch: 1323 \tTraining Loss: 1.273878 \tValidation Loss: 1.357146 \t time: 0.2\n",
      "Validation loss decreased from 1.357416 to 1.357146. Model was saved\n",
      "Epoch: 1324 \tTraining Loss: 1.275486 \tValidation Loss: 1.356766 \t time: 0.3\n",
      "Validation loss decreased from 1.357146 to 1.356766. Model was saved\n",
      "Epoch: 1325 \tTraining Loss: 1.274370 \tValidation Loss: 1.356296 \t time: 0.3\n",
      "Validation loss decreased from 1.356766 to 1.356296. Model was saved\n",
      "Epoch: 1326 \tTraining Loss: 1.272676 \tValidation Loss: 1.356062 \t time: 0.2\n",
      "Validation loss decreased from 1.356296 to 1.356062. Model was saved\n",
      "Epoch: 1327 \tTraining Loss: 1.275859 \tValidation Loss: 1.356033 \t time: 0.2\n",
      "Validation loss decreased from 1.356062 to 1.356033. Model was saved\n",
      "Epoch: 1328 \tTraining Loss: 1.273259 \tValidation Loss: 1.356552 \t time: 0.3\n",
      "Epoch: 1329 \tTraining Loss: 1.273676 \tValidation Loss: 1.357105 \t time: 0.3\n",
      "Epoch: 1330 \tTraining Loss: 1.271769 \tValidation Loss: 1.357844 \t time: 0.3\n",
      "Epoch: 1331 \tTraining Loss: 1.271664 \tValidation Loss: 1.358263 \t time: 0.3\n",
      "Epoch: 1332 \tTraining Loss: 1.272561 \tValidation Loss: 1.358373 \t time: 0.2\n",
      "Epoch: 1333 \tTraining Loss: 1.271670 \tValidation Loss: 1.358234 \t time: 0.3\n",
      "Epoch: 1334 \tTraining Loss: 1.272586 \tValidation Loss: 1.358324 \t time: 0.2\n",
      "Epoch: 1335 \tTraining Loss: 1.272690 \tValidation Loss: 1.358322 \t time: 0.3\n",
      "Epoch: 1336 \tTraining Loss: 1.274076 \tValidation Loss: 1.358197 \t time: 0.3\n",
      "Epoch: 1337 \tTraining Loss: 1.274999 \tValidation Loss: 1.358241 \t time: 0.2\n",
      "Epoch: 1338 \tTraining Loss: 1.274375 \tValidation Loss: 1.358355 \t time: 0.3\n",
      "Epoch: 1339 \tTraining Loss: 1.271817 \tValidation Loss: 1.358706 \t time: 0.3\n",
      "Epoch: 1340 \tTraining Loss: 1.272797 \tValidation Loss: 1.359232 \t time: 0.3\n",
      "Epoch: 1341 \tTraining Loss: 1.269871 \tValidation Loss: 1.359998 \t time: 0.3\n",
      "Epoch: 1342 \tTraining Loss: 1.270535 \tValidation Loss: 1.360465 \t time: 0.3\n",
      "Epoch: 1343 \tTraining Loss: 1.271217 \tValidation Loss: 1.360639 \t time: 0.3\n",
      "Epoch: 1344 \tTraining Loss: 1.271677 \tValidation Loss: 1.360831 \t time: 0.3\n",
      "Epoch: 1345 \tTraining Loss: 1.271217 \tValidation Loss: 1.361055 \t time: 0.3\n",
      "Epoch: 1346 \tTraining Loss: 1.273598 \tValidation Loss: 1.361130 \t time: 0.3\n",
      "Epoch: 1347 \tTraining Loss: 1.272195 \tValidation Loss: 1.361103 \t time: 0.3\n",
      "Epoch: 1348 \tTraining Loss: 1.274733 \tValidation Loss: 1.361079 \t time: 0.3\n",
      "Epoch: 1349 \tTraining Loss: 1.272126 \tValidation Loss: 1.360745 \t time: 0.3\n",
      "Epoch: 1350 \tTraining Loss: 1.272268 \tValidation Loss: 1.360245 \t time: 0.3\n",
      "Epoch: 1351 \tTraining Loss: 1.271705 \tValidation Loss: 1.359927 \t time: 0.3\n",
      "Epoch: 1352 \tTraining Loss: 1.268860 \tValidation Loss: 1.359435 \t time: 0.3\n",
      "Epoch: 1353 \tTraining Loss: 1.271109 \tValidation Loss: 1.358862 \t time: 0.3\n",
      "Epoch: 1354 \tTraining Loss: 1.271253 \tValidation Loss: 1.358602 \t time: 0.3\n",
      "Epoch: 1355 \tTraining Loss: 1.269648 \tValidation Loss: 1.358657 \t time: 0.3\n",
      "Epoch: 1356 \tTraining Loss: 1.270986 \tValidation Loss: 1.358802 \t time: 0.3\n",
      "Epoch: 1357 \tTraining Loss: 1.271713 \tValidation Loss: 1.358819 \t time: 0.3\n",
      "Epoch: 1358 \tTraining Loss: 1.272958 \tValidation Loss: 1.359166 \t time: 0.2\n",
      "Epoch: 1359 \tTraining Loss: 1.270591 \tValidation Loss: 1.359118 \t time: 0.3\n",
      "Epoch: 1360 \tTraining Loss: 1.271849 \tValidation Loss: 1.359117 \t time: 0.3\n",
      "Epoch: 1361 \tTraining Loss: 1.271912 \tValidation Loss: 1.358843 \t time: 0.2\n",
      "Epoch: 1362 \tTraining Loss: 1.271037 \tValidation Loss: 1.358668 \t time: 0.3\n",
      "Epoch: 1363 \tTraining Loss: 1.272762 \tValidation Loss: 1.358685 \t time: 0.2\n",
      "Epoch: 1364 \tTraining Loss: 1.266888 \tValidation Loss: 1.358825 \t time: 0.3\n",
      "Epoch: 1365 \tTraining Loss: 1.271085 \tValidation Loss: 1.358586 \t time: 0.2\n",
      "Epoch: 1366 \tTraining Loss: 1.271381 \tValidation Loss: 1.358388 \t time: 0.3\n",
      "Epoch: 1367 \tTraining Loss: 1.269794 \tValidation Loss: 1.358463 \t time: 0.2\n",
      "Epoch: 1368 \tTraining Loss: 1.272164 \tValidation Loss: 1.358384 \t time: 0.2\n",
      "Epoch: 1369 \tTraining Loss: 1.270373 \tValidation Loss: 1.358298 \t time: 0.3\n",
      "Epoch: 1370 \tTraining Loss: 1.269500 \tValidation Loss: 1.358267 \t time: 0.3\n",
      "Epoch: 1371 \tTraining Loss: 1.270143 \tValidation Loss: 1.358671 \t time: 0.3\n",
      "Epoch: 1372 \tTraining Loss: 1.269090 \tValidation Loss: 1.359307 \t time: 0.3\n",
      "Epoch: 1373 \tTraining Loss: 1.267568 \tValidation Loss: 1.359937 \t time: 0.2\n",
      "Epoch: 1374 \tTraining Loss: 1.269678 \tValidation Loss: 1.359839 \t time: 0.3\n",
      "Epoch: 1375 \tTraining Loss: 1.271328 \tValidation Loss: 1.359504 \t time: 0.2\n",
      "Epoch: 1376 \tTraining Loss: 1.269584 \tValidation Loss: 1.359352 \t time: 0.3\n",
      "Epoch: 1377 \tTraining Loss: 1.270794 \tValidation Loss: 1.359511 \t time: 0.3\n",
      "Epoch: 1378 \tTraining Loss: 1.268774 \tValidation Loss: 1.359935 \t time: 0.2\n",
      "Epoch: 1379 \tTraining Loss: 1.269412 \tValidation Loss: 1.359984 \t time: 0.3\n",
      "Epoch: 1380 \tTraining Loss: 1.270192 \tValidation Loss: 1.360039 \t time: 0.3\n",
      "Epoch: 1381 \tTraining Loss: 1.270051 \tValidation Loss: 1.359923 \t time: 0.3\n",
      "Epoch: 1382 \tTraining Loss: 1.269047 \tValidation Loss: 1.359681 \t time: 0.3\n",
      "Epoch: 1383 \tTraining Loss: 1.270423 \tValidation Loss: 1.359664 \t time: 0.3\n",
      "Epoch: 1384 \tTraining Loss: 1.269610 \tValidation Loss: 1.359762 \t time: 0.3\n",
      "Epoch: 1385 \tTraining Loss: 1.269941 \tValidation Loss: 1.359871 \t time: 0.3\n",
      "Epoch: 1386 \tTraining Loss: 1.272020 \tValidation Loss: 1.359278 \t time: 0.3\n",
      "Epoch: 1387 \tTraining Loss: 1.268705 \tValidation Loss: 1.359125 \t time: 0.3\n",
      "Epoch: 1388 \tTraining Loss: 1.268446 \tValidation Loss: 1.359300 \t time: 0.3\n",
      "Epoch: 1389 \tTraining Loss: 1.269268 \tValidation Loss: 1.359739 \t time: 0.3\n",
      "Epoch: 1390 \tTraining Loss: 1.266519 \tValidation Loss: 1.359560 \t time: 0.3\n",
      "Epoch: 1391 \tTraining Loss: 1.270107 \tValidation Loss: 1.359303 \t time: 0.3\n",
      "Epoch: 1392 \tTraining Loss: 1.271004 \tValidation Loss: 1.359007 \t time: 0.3\n",
      "Epoch: 1393 \tTraining Loss: 1.271026 \tValidation Loss: 1.358645 \t time: 0.3\n",
      "Epoch: 1394 \tTraining Loss: 1.270278 \tValidation Loss: 1.358217 \t time: 0.2\n",
      "Epoch: 1395 \tTraining Loss: 1.269415 \tValidation Loss: 1.357882 \t time: 0.3\n",
      "Epoch: 1396 \tTraining Loss: 1.268690 \tValidation Loss: 1.357619 \t time: 0.3\n",
      "Epoch: 1397 \tTraining Loss: 1.269037 \tValidation Loss: 1.357300 \t time: 0.2\n",
      "Epoch: 1398 \tTraining Loss: 1.269750 \tValidation Loss: 1.356920 \t time: 0.3\n",
      "Epoch: 1399 \tTraining Loss: 1.270678 \tValidation Loss: 1.357005 \t time: 0.2\n",
      "Epoch: 1400 \tTraining Loss: 1.269971 \tValidation Loss: 1.357203 \t time: 0.3\n",
      "Epoch: 1401 \tTraining Loss: 1.270425 \tValidation Loss: 1.357629 \t time: 0.2\n",
      "Epoch: 1402 \tTraining Loss: 1.269234 \tValidation Loss: 1.358157 \t time: 0.3\n",
      "Epoch: 1403 \tTraining Loss: 1.272267 \tValidation Loss: 1.358693 \t time: 0.2\n",
      "Epoch: 1404 \tTraining Loss: 1.270193 \tValidation Loss: 1.358118 \t time: 0.3\n",
      "Epoch: 1405 \tTraining Loss: 1.269585 \tValidation Loss: 1.357298 \t time: 0.3\n",
      "Epoch: 1406 \tTraining Loss: 1.272300 \tValidation Loss: 1.356520 \t time: 0.2\n",
      "Epoch: 1407 \tTraining Loss: 1.269029 \tValidation Loss: 1.355755 \t time: 0.3\n",
      "Validation loss decreased from 1.356033 to 1.355755. Model was saved\n",
      "Epoch: 1408 \tTraining Loss: 1.271775 \tValidation Loss: 1.355497 \t time: 0.2\n",
      "Validation loss decreased from 1.355755 to 1.355497. Model was saved\n",
      "Epoch: 1409 \tTraining Loss: 1.270286 \tValidation Loss: 1.355839 \t time: 0.3\n",
      "Epoch: 1410 \tTraining Loss: 1.268436 \tValidation Loss: 1.356540 \t time: 0.3\n",
      "Epoch: 1411 \tTraining Loss: 1.271191 \tValidation Loss: 1.357472 \t time: 0.3\n",
      "Epoch: 1412 \tTraining Loss: 1.271143 \tValidation Loss: 1.358168 \t time: 0.2\n",
      "Epoch: 1413 \tTraining Loss: 1.267113 \tValidation Loss: 1.358834 \t time: 0.3\n",
      "Epoch: 1414 \tTraining Loss: 1.270898 \tValidation Loss: 1.359208 \t time: 0.2\n",
      "Epoch: 1415 \tTraining Loss: 1.268070 \tValidation Loss: 1.359128 \t time: 0.3\n",
      "Epoch: 1416 \tTraining Loss: 1.269009 \tValidation Loss: 1.358855 \t time: 0.3\n",
      "Epoch: 1417 \tTraining Loss: 1.267815 \tValidation Loss: 1.358689 \t time: 0.3\n",
      "Epoch: 1418 \tTraining Loss: 1.269752 \tValidation Loss: 1.358423 \t time: 0.3\n",
      "Epoch: 1419 \tTraining Loss: 1.268072 \tValidation Loss: 1.358086 \t time: 0.3\n",
      "Epoch: 1420 \tTraining Loss: 1.270255 \tValidation Loss: 1.358079 \t time: 0.3\n",
      "Epoch: 1421 \tTraining Loss: 1.269218 \tValidation Loss: 1.357930 \t time: 0.3\n",
      "Epoch: 1422 \tTraining Loss: 1.269008 \tValidation Loss: 1.358016 \t time: 0.2\n",
      "Epoch: 1423 \tTraining Loss: 1.268196 \tValidation Loss: 1.358140 \t time: 0.3\n",
      "Epoch: 1424 \tTraining Loss: 1.267665 \tValidation Loss: 1.358453 \t time: 0.3\n",
      "Epoch: 1425 \tTraining Loss: 1.268687 \tValidation Loss: 1.358781 \t time: 0.3\n",
      "Epoch: 1426 \tTraining Loss: 1.269683 \tValidation Loss: 1.359293 \t time: 0.2\n",
      "Epoch: 1427 \tTraining Loss: 1.266914 \tValidation Loss: 1.359542 \t time: 0.3\n",
      "Epoch: 1428 \tTraining Loss: 1.269291 \tValidation Loss: 1.359851 \t time: 0.3\n",
      "Epoch: 1429 \tTraining Loss: 1.268129 \tValidation Loss: 1.360015 \t time: 0.3\n",
      "Epoch: 1430 \tTraining Loss: 1.268300 \tValidation Loss: 1.359855 \t time: 0.2\n",
      "Epoch: 1431 \tTraining Loss: 1.270869 \tValidation Loss: 1.359496 \t time: 0.2\n",
      "Epoch: 1432 \tTraining Loss: 1.268384 \tValidation Loss: 1.359043 \t time: 0.2\n",
      "Epoch: 1433 \tTraining Loss: 1.267561 \tValidation Loss: 1.358938 \t time: 0.2\n",
      "Epoch: 1434 \tTraining Loss: 1.269237 \tValidation Loss: 1.359064 \t time: 0.3\n",
      "Epoch: 1435 \tTraining Loss: 1.267482 \tValidation Loss: 1.359403 \t time: 0.3\n",
      "Epoch: 1436 \tTraining Loss: 1.266613 \tValidation Loss: 1.359814 \t time: 0.3\n",
      "Epoch: 1437 \tTraining Loss: 1.270455 \tValidation Loss: 1.360275 \t time: 0.3\n",
      "Epoch: 1438 \tTraining Loss: 1.267471 \tValidation Loss: 1.360195 \t time: 0.3\n",
      "Epoch: 1439 \tTraining Loss: 1.265889 \tValidation Loss: 1.359798 \t time: 0.3\n",
      "Epoch: 1440 \tTraining Loss: 1.269294 \tValidation Loss: 1.359255 \t time: 0.3\n",
      "Epoch: 1441 \tTraining Loss: 1.268949 \tValidation Loss: 1.358335 \t time: 0.3\n",
      "Epoch: 1442 \tTraining Loss: 1.266061 \tValidation Loss: 1.357709 \t time: 0.3\n",
      "Epoch: 1443 \tTraining Loss: 1.268407 \tValidation Loss: 1.357184 \t time: 0.3\n",
      "Epoch: 1444 \tTraining Loss: 1.268102 \tValidation Loss: 1.357156 \t time: 0.3\n",
      "Epoch: 1445 \tTraining Loss: 1.270187 \tValidation Loss: 1.357327 \t time: 0.2\n",
      "Epoch: 1446 \tTraining Loss: 1.268637 \tValidation Loss: 1.357947 \t time: 0.2\n",
      "Epoch: 1447 \tTraining Loss: 1.268346 \tValidation Loss: 1.358931 \t time: 0.3\n",
      "Epoch: 1448 \tTraining Loss: 1.269909 \tValidation Loss: 1.359906 \t time: 0.3\n",
      "Epoch: 1449 \tTraining Loss: 1.269138 \tValidation Loss: 1.360926 \t time: 0.3\n",
      "Epoch: 1450 \tTraining Loss: 1.265916 \tValidation Loss: 1.361210 \t time: 0.3\n",
      "Epoch: 1451 \tTraining Loss: 1.268443 \tValidation Loss: 1.361364 \t time: 0.3\n",
      "Epoch: 1452 \tTraining Loss: 1.268861 \tValidation Loss: 1.361139 \t time: 0.3\n",
      "Epoch: 1453 \tTraining Loss: 1.270364 \tValidation Loss: 1.360747 \t time: 0.3\n",
      "Epoch: 1454 \tTraining Loss: 1.266855 \tValidation Loss: 1.360448 \t time: 0.2\n",
      "Epoch: 1455 \tTraining Loss: 1.266815 \tValidation Loss: 1.360394 \t time: 0.2\n",
      "Epoch: 1456 \tTraining Loss: 1.267367 \tValidation Loss: 1.360284 \t time: 0.3\n",
      "Epoch: 1457 \tTraining Loss: 1.266470 \tValidation Loss: 1.360022 \t time: 0.2\n",
      "Epoch: 1458 \tTraining Loss: 1.266291 \tValidation Loss: 1.359850 \t time: 0.2\n",
      "Epoch: 1459 \tTraining Loss: 1.268228 \tValidation Loss: 1.359915 \t time: 0.3\n",
      "Epoch: 1460 \tTraining Loss: 1.268557 \tValidation Loss: 1.359964 \t time: 0.3\n",
      "Epoch: 1461 \tTraining Loss: 1.268684 \tValidation Loss: 1.360332 \t time: 0.3\n",
      "Epoch: 1462 \tTraining Loss: 1.262186 \tValidation Loss: 1.360425 \t time: 0.3\n",
      "Epoch: 1463 \tTraining Loss: 1.267930 \tValidation Loss: 1.360282 \t time: 0.3\n",
      "Epoch: 1464 \tTraining Loss: 1.269322 \tValidation Loss: 1.360063 \t time: 0.3\n",
      "Epoch: 1465 \tTraining Loss: 1.264920 \tValidation Loss: 1.359422 \t time: 0.2\n",
      "Epoch: 1466 \tTraining Loss: 1.268852 \tValidation Loss: 1.358894 \t time: 0.2\n",
      "Epoch: 1467 \tTraining Loss: 1.265762 \tValidation Loss: 1.358673 \t time: 0.3\n",
      "Epoch: 1468 \tTraining Loss: 1.268432 \tValidation Loss: 1.358810 \t time: 0.3\n",
      "Epoch: 1469 \tTraining Loss: 1.268531 \tValidation Loss: 1.359020 \t time: 0.2\n",
      "Epoch: 1470 \tTraining Loss: 1.266106 \tValidation Loss: 1.359142 \t time: 0.2\n",
      "Epoch: 1471 \tTraining Loss: 1.267675 \tValidation Loss: 1.359376 \t time: 0.2\n",
      "Epoch: 1472 \tTraining Loss: 1.265602 \tValidation Loss: 1.359712 \t time: 0.3\n",
      "Epoch: 1473 \tTraining Loss: 1.267461 \tValidation Loss: 1.359653 \t time: 0.2\n",
      "Epoch: 1474 \tTraining Loss: 1.269024 \tValidation Loss: 1.359634 \t time: 0.3\n",
      "Epoch: 1475 \tTraining Loss: 1.267380 \tValidation Loss: 1.359547 \t time: 0.3\n",
      "Epoch: 1476 \tTraining Loss: 1.269943 \tValidation Loss: 1.359138 \t time: 0.3\n",
      "Epoch: 1477 \tTraining Loss: 1.268979 \tValidation Loss: 1.358495 \t time: 0.2\n",
      "Epoch: 1478 \tTraining Loss: 1.265395 \tValidation Loss: 1.357824 \t time: 0.2\n",
      "Epoch: 1479 \tTraining Loss: 1.269104 \tValidation Loss: 1.357450 \t time: 0.3\n",
      "Epoch: 1480 \tTraining Loss: 1.265808 \tValidation Loss: 1.357355 \t time: 0.3\n",
      "Epoch: 1481 \tTraining Loss: 1.266438 \tValidation Loss: 1.357583 \t time: 0.3\n",
      "Epoch: 1482 \tTraining Loss: 1.265685 \tValidation Loss: 1.358056 \t time: 0.2\n",
      "Epoch: 1483 \tTraining Loss: 1.268733 \tValidation Loss: 1.358598 \t time: 0.3\n",
      "Epoch: 1484 \tTraining Loss: 1.266380 \tValidation Loss: 1.358780 \t time: 0.2\n",
      "Epoch: 1485 \tTraining Loss: 1.266775 \tValidation Loss: 1.358653 \t time: 0.3\n",
      "Epoch: 1486 \tTraining Loss: 1.266596 \tValidation Loss: 1.358356 \t time: 0.3\n",
      "Epoch: 1487 \tTraining Loss: 1.266634 \tValidation Loss: 1.358144 \t time: 0.2\n",
      "Epoch: 1488 \tTraining Loss: 1.266143 \tValidation Loss: 1.358376 \t time: 0.3\n",
      "Epoch: 1489 \tTraining Loss: 1.266816 \tValidation Loss: 1.358674 \t time: 0.2\n",
      "Epoch: 1490 \tTraining Loss: 1.265242 \tValidation Loss: 1.358921 \t time: 0.3\n",
      "Epoch: 1491 \tTraining Loss: 1.266333 \tValidation Loss: 1.359134 \t time: 0.2\n",
      "Epoch: 1492 \tTraining Loss: 1.266603 \tValidation Loss: 1.359584 \t time: 0.3\n",
      "Epoch: 1493 \tTraining Loss: 1.264162 \tValidation Loss: 1.359919 \t time: 0.3\n",
      "Epoch: 1494 \tTraining Loss: 1.265765 \tValidation Loss: 1.360175 \t time: 0.3\n",
      "Epoch: 1495 \tTraining Loss: 1.265044 \tValidation Loss: 1.360264 \t time: 0.3\n",
      "Epoch: 1496 \tTraining Loss: 1.267974 \tValidation Loss: 1.360590 \t time: 0.3\n",
      "Epoch: 1497 \tTraining Loss: 1.263747 \tValidation Loss: 1.360154 \t time: 0.3\n",
      "Epoch: 1498 \tTraining Loss: 1.265744 \tValidation Loss: 1.359612 \t time: 0.3\n",
      "Epoch: 1499 \tTraining Loss: 1.268571 \tValidation Loss: 1.359412 \t time: 0.3\n",
      "Epoch: 1500 \tTraining Loss: 1.266520 \tValidation Loss: 1.359100 \t time: 0.3\n",
      "Epoch: 1501 \tTraining Loss: 1.267346 \tValidation Loss: 1.358891 \t time: 0.2\n",
      "Epoch: 1502 \tTraining Loss: 1.266377 \tValidation Loss: 1.358771 \t time: 0.2\n",
      "Epoch: 1503 \tTraining Loss: 1.267770 \tValidation Loss: 1.358676 \t time: 0.2\n",
      "Epoch: 1504 \tTraining Loss: 1.265680 \tValidation Loss: 1.358740 \t time: 0.3\n",
      "Epoch: 1505 \tTraining Loss: 1.267091 \tValidation Loss: 1.358299 \t time: 0.3\n",
      "Epoch: 1506 \tTraining Loss: 1.265475 \tValidation Loss: 1.357815 \t time: 0.3\n",
      "Epoch: 1507 \tTraining Loss: 1.266748 \tValidation Loss: 1.357880 \t time: 0.3\n",
      "Epoch: 1508 \tTraining Loss: 1.266351 \tValidation Loss: 1.358379 \t time: 0.3\n",
      "Epoch: 1509 \tTraining Loss: 1.265669 \tValidation Loss: 1.358959 \t time: 0.2\n",
      "Epoch: 1510 \tTraining Loss: 1.265426 \tValidation Loss: 1.359204 \t time: 0.3\n",
      "Epoch: 1511 \tTraining Loss: 1.265365 \tValidation Loss: 1.359036 \t time: 0.3\n",
      "Epoch: 1512 \tTraining Loss: 1.266201 \tValidation Loss: 1.358861 \t time: 0.2\n",
      "Epoch: 1513 \tTraining Loss: 1.266024 \tValidation Loss: 1.359043 \t time: 0.2\n",
      "Epoch: 1514 \tTraining Loss: 1.267174 \tValidation Loss: 1.359246 \t time: 0.3\n",
      "Epoch: 1515 \tTraining Loss: 1.266706 \tValidation Loss: 1.359860 \t time: 0.2\n",
      "Epoch: 1516 \tTraining Loss: 1.265379 \tValidation Loss: 1.360500 \t time: 0.3\n",
      "Epoch: 1517 \tTraining Loss: 1.266688 \tValidation Loss: 1.360800 \t time: 0.2\n",
      "Epoch: 1518 \tTraining Loss: 1.267970 \tValidation Loss: 1.360934 \t time: 0.3\n",
      "Epoch: 1519 \tTraining Loss: 1.266108 \tValidation Loss: 1.360734 \t time: 0.3\n",
      "Epoch: 1520 \tTraining Loss: 1.267256 \tValidation Loss: 1.359690 \t time: 0.3\n",
      "Epoch: 1521 \tTraining Loss: 1.264994 \tValidation Loss: 1.358453 \t time: 0.3\n",
      "Epoch: 1522 \tTraining Loss: 1.264206 \tValidation Loss: 1.357994 \t time: 0.3\n",
      "Epoch: 1523 \tTraining Loss: 1.263682 \tValidation Loss: 1.358144 \t time: 0.3\n",
      "Epoch: 1524 \tTraining Loss: 1.266513 \tValidation Loss: 1.358806 \t time: 0.2\n",
      "Epoch: 1525 \tTraining Loss: 1.265524 \tValidation Loss: 1.359881 \t time: 0.3\n",
      "Epoch: 1526 \tTraining Loss: 1.267001 \tValidation Loss: 1.361088 \t time: 0.2\n",
      "Epoch: 1527 \tTraining Loss: 1.267196 \tValidation Loss: 1.361437 \t time: 0.3\n",
      "Epoch: 1528 \tTraining Loss: 1.265629 \tValidation Loss: 1.361233 \t time: 0.2\n",
      "Epoch: 1529 \tTraining Loss: 1.265872 \tValidation Loss: 1.360641 \t time: 0.3\n",
      "Epoch: 1530 \tTraining Loss: 1.266082 \tValidation Loss: 1.359844 \t time: 0.2\n",
      "Epoch: 1531 \tTraining Loss: 1.266117 \tValidation Loss: 1.359095 \t time: 0.3\n",
      "Epoch: 1532 \tTraining Loss: 1.264131 \tValidation Loss: 1.358696 \t time: 0.3\n",
      "Epoch: 1533 \tTraining Loss: 1.265564 \tValidation Loss: 1.358605 \t time: 0.2\n",
      "Epoch: 1534 \tTraining Loss: 1.262636 \tValidation Loss: 1.358343 \t time: 0.3\n",
      "Epoch: 1535 \tTraining Loss: 1.264576 \tValidation Loss: 1.358683 \t time: 0.2\n",
      "Epoch: 1536 \tTraining Loss: 1.263473 \tValidation Loss: 1.359181 \t time: 0.2\n",
      "Epoch: 1537 \tTraining Loss: 1.266878 \tValidation Loss: 1.360324 \t time: 0.3\n",
      "Epoch: 1538 \tTraining Loss: 1.264259 \tValidation Loss: 1.360813 \t time: 0.3\n",
      "Epoch: 1539 \tTraining Loss: 1.264646 \tValidation Loss: 1.360903 \t time: 0.3\n",
      "Epoch: 1540 \tTraining Loss: 1.265146 \tValidation Loss: 1.360700 \t time: 0.2\n",
      "Epoch: 1541 \tTraining Loss: 1.265396 \tValidation Loss: 1.360239 \t time: 0.2\n",
      "Epoch: 1542 \tTraining Loss: 1.263979 \tValidation Loss: 1.359726 \t time: 0.2\n",
      "Epoch: 1543 \tTraining Loss: 1.265722 \tValidation Loss: 1.359209 \t time: 0.2\n",
      "Epoch: 1544 \tTraining Loss: 1.264628 \tValidation Loss: 1.358609 \t time: 0.2\n",
      "Epoch: 1545 \tTraining Loss: 1.266498 \tValidation Loss: 1.358062 \t time: 0.2\n",
      "Epoch: 1546 \tTraining Loss: 1.265202 \tValidation Loss: 1.357774 \t time: 0.3\n",
      "Epoch: 1547 \tTraining Loss: 1.263523 \tValidation Loss: 1.357349 \t time: 0.3\n",
      "Epoch: 1548 \tTraining Loss: 1.264271 \tValidation Loss: 1.356938 \t time: 0.3\n",
      "Epoch: 1549 \tTraining Loss: 1.264150 \tValidation Loss: 1.357071 \t time: 0.3\n",
      "Epoch: 1550 \tTraining Loss: 1.264100 \tValidation Loss: 1.357635 \t time: 0.3\n",
      "Epoch: 1551 \tTraining Loss: 1.266566 \tValidation Loss: 1.357857 \t time: 0.3\n",
      "Epoch: 1552 \tTraining Loss: 1.262832 \tValidation Loss: 1.357949 \t time: 0.3\n",
      "Epoch: 1553 \tTraining Loss: 1.264322 \tValidation Loss: 1.358158 \t time: 0.3\n",
      "Epoch: 1554 \tTraining Loss: 1.263462 \tValidation Loss: 1.358614 \t time: 0.3\n",
      "Epoch: 1555 \tTraining Loss: 1.264993 \tValidation Loss: 1.359022 \t time: 0.2\n",
      "Epoch: 1556 \tTraining Loss: 1.265135 \tValidation Loss: 1.359195 \t time: 0.3\n",
      "Epoch: 1557 \tTraining Loss: 1.262937 \tValidation Loss: 1.359162 \t time: 0.3\n",
      "Epoch: 1558 \tTraining Loss: 1.265851 \tValidation Loss: 1.358682 \t time: 0.3\n",
      "Epoch: 1559 \tTraining Loss: 1.264176 \tValidation Loss: 1.357574 \t time: 0.3\n",
      "Epoch: 1560 \tTraining Loss: 1.263906 \tValidation Loss: 1.356706 \t time: 0.3\n",
      "Epoch: 1561 \tTraining Loss: 1.262926 \tValidation Loss: 1.356360 \t time: 0.2\n",
      "Epoch: 1562 \tTraining Loss: 1.264452 \tValidation Loss: 1.356389 \t time: 0.3\n",
      "Epoch: 1563 \tTraining Loss: 1.264421 \tValidation Loss: 1.356608 \t time: 0.3\n",
      "Epoch: 1564 \tTraining Loss: 1.264159 \tValidation Loss: 1.357092 \t time: 0.3\n",
      "Epoch: 1565 \tTraining Loss: 1.263810 \tValidation Loss: 1.357799 \t time: 0.3\n",
      "Epoch: 1566 \tTraining Loss: 1.267090 \tValidation Loss: 1.358630 \t time: 0.3\n",
      "Epoch: 1567 \tTraining Loss: 1.263837 \tValidation Loss: 1.359280 \t time: 0.3\n",
      "Epoch: 1568 \tTraining Loss: 1.262863 \tValidation Loss: 1.359724 \t time: 0.3\n",
      "Epoch: 1569 \tTraining Loss: 1.263178 \tValidation Loss: 1.360060 \t time: 0.3\n",
      "Epoch: 1570 \tTraining Loss: 1.263572 \tValidation Loss: 1.360007 \t time: 0.3\n",
      "Epoch: 1571 \tTraining Loss: 1.262052 \tValidation Loss: 1.359468 \t time: 0.2\n",
      "Epoch: 1572 \tTraining Loss: 1.265508 \tValidation Loss: 1.358818 \t time: 0.3\n",
      "Epoch: 1573 \tTraining Loss: 1.264796 \tValidation Loss: 1.358543 \t time: 0.2\n",
      "Epoch: 1574 \tTraining Loss: 1.264192 \tValidation Loss: 1.358793 \t time: 0.3\n",
      "Epoch: 1575 \tTraining Loss: 1.263447 \tValidation Loss: 1.359493 \t time: 0.3\n",
      "Epoch: 1576 \tTraining Loss: 1.263018 \tValidation Loss: 1.360061 \t time: 0.3\n",
      "Epoch: 1577 \tTraining Loss: 1.262744 \tValidation Loss: 1.360985 \t time: 0.2\n",
      "Epoch: 1578 \tTraining Loss: 1.263858 \tValidation Loss: 1.362240 \t time: 0.3\n",
      "Epoch: 1579 \tTraining Loss: 1.264524 \tValidation Loss: 1.362383 \t time: 0.3\n",
      "Epoch: 1580 \tTraining Loss: 1.263624 \tValidation Loss: 1.362263 \t time: 0.3\n",
      "Epoch: 1581 \tTraining Loss: 1.263173 \tValidation Loss: 1.361832 \t time: 0.2\n",
      "Epoch: 1582 \tTraining Loss: 1.264897 \tValidation Loss: 1.361264 \t time: 0.2\n",
      "Epoch: 1583 \tTraining Loss: 1.262669 \tValidation Loss: 1.360894 \t time: 0.3\n",
      "Epoch: 1584 \tTraining Loss: 1.266062 \tValidation Loss: 1.360587 \t time: 0.3\n",
      "Epoch: 1585 \tTraining Loss: 1.262447 \tValidation Loss: 1.360559 \t time: 0.3\n",
      "Epoch: 1586 \tTraining Loss: 1.263625 \tValidation Loss: 1.360605 \t time: 0.3\n",
      "Epoch: 1587 \tTraining Loss: 1.262692 \tValidation Loss: 1.360871 \t time: 0.3\n",
      "Epoch: 1588 \tTraining Loss: 1.264156 \tValidation Loss: 1.361149 \t time: 0.3\n",
      "Epoch: 1589 \tTraining Loss: 1.264155 \tValidation Loss: 1.361546 \t time: 0.3\n",
      "Epoch: 1590 \tTraining Loss: 1.261644 \tValidation Loss: 1.361987 \t time: 0.3\n",
      "Epoch: 1591 \tTraining Loss: 1.263172 \tValidation Loss: 1.361611 \t time: 0.3\n",
      "Epoch: 1592 \tTraining Loss: 1.264374 \tValidation Loss: 1.360651 \t time: 0.3\n",
      "Epoch: 1593 \tTraining Loss: 1.262565 \tValidation Loss: 1.359738 \t time: 0.2\n",
      "Epoch: 1594 \tTraining Loss: 1.262910 \tValidation Loss: 1.359347 \t time: 0.2\n",
      "Epoch: 1595 \tTraining Loss: 1.263675 \tValidation Loss: 1.359339 \t time: 0.3\n",
      "Epoch: 1596 \tTraining Loss: 1.262039 \tValidation Loss: 1.359362 \t time: 0.3\n",
      "Epoch: 1597 \tTraining Loss: 1.263792 \tValidation Loss: 1.359481 \t time: 0.3\n",
      "Epoch: 1598 \tTraining Loss: 1.267317 \tValidation Loss: 1.360113 \t time: 0.3\n",
      "Epoch: 1599 \tTraining Loss: 1.265667 \tValidation Loss: 1.360794 \t time: 0.3\n",
      "Epoch: 1600 \tTraining Loss: 1.263548 \tValidation Loss: 1.361048 \t time: 0.3\n",
      "Epoch: 1601 \tTraining Loss: 1.261429 \tValidation Loss: 1.360806 \t time: 0.3\n",
      "Epoch: 1602 \tTraining Loss: 1.261712 \tValidation Loss: 1.360298 \t time: 0.3\n",
      "Epoch: 1603 \tTraining Loss: 1.264029 \tValidation Loss: 1.359735 \t time: 0.3\n",
      "Epoch: 1604 \tTraining Loss: 1.262991 \tValidation Loss: 1.359088 \t time: 0.3\n",
      "Epoch: 1605 \tTraining Loss: 1.264159 \tValidation Loss: 1.358546 \t time: 0.2\n",
      "Epoch: 1606 \tTraining Loss: 1.261809 \tValidation Loss: 1.358181 \t time: 0.3\n",
      "Epoch: 1607 \tTraining Loss: 1.262532 \tValidation Loss: 1.358156 \t time: 0.3\n",
      "Epoch: 1608 \tTraining Loss: 1.263354 \tValidation Loss: 1.358561 \t time: 0.2\n",
      "Epoch: 1609 \tTraining Loss: 1.265668 \tValidation Loss: 1.359058 \t time: 0.3\n",
      "Epoch: 1610 \tTraining Loss: 1.262709 \tValidation Loss: 1.359615 \t time: 0.3\n",
      "Epoch: 1611 \tTraining Loss: 1.262578 \tValidation Loss: 1.359595 \t time: 0.3\n",
      "Epoch: 1612 \tTraining Loss: 1.260491 \tValidation Loss: 1.359568 \t time: 0.3\n",
      "Epoch: 1613 \tTraining Loss: 1.263358 \tValidation Loss: 1.359345 \t time: 0.3\n",
      "Epoch: 1614 \tTraining Loss: 1.266189 \tValidation Loss: 1.358908 \t time: 0.3\n",
      "Epoch: 1615 \tTraining Loss: 1.262726 \tValidation Loss: 1.358752 \t time: 0.3\n",
      "Epoch: 1616 \tTraining Loss: 1.264260 \tValidation Loss: 1.358818 \t time: 0.3\n",
      "Epoch: 1617 \tTraining Loss: 1.259331 \tValidation Loss: 1.358808 \t time: 0.3\n",
      "Epoch: 1618 \tTraining Loss: 1.260805 \tValidation Loss: 1.358512 \t time: 0.3\n",
      "Epoch: 1619 \tTraining Loss: 1.261185 \tValidation Loss: 1.358388 \t time: 0.3\n",
      "Epoch: 1620 \tTraining Loss: 1.264664 \tValidation Loss: 1.358238 \t time: 0.3\n",
      "Epoch: 1621 \tTraining Loss: 1.262856 \tValidation Loss: 1.358522 \t time: 0.2\n",
      "Epoch: 1622 \tTraining Loss: 1.261912 \tValidation Loss: 1.358840 \t time: 0.3\n",
      "Epoch: 1623 \tTraining Loss: 1.263299 \tValidation Loss: 1.358880 \t time: 0.3\n",
      "Epoch: 1624 \tTraining Loss: 1.262512 \tValidation Loss: 1.358873 \t time: 0.3\n",
      "Epoch: 1625 \tTraining Loss: 1.261499 \tValidation Loss: 1.358739 \t time: 0.3\n",
      "Epoch: 1626 \tTraining Loss: 1.264767 \tValidation Loss: 1.358268 \t time: 0.3\n",
      "Epoch: 1627 \tTraining Loss: 1.263522 \tValidation Loss: 1.358084 \t time: 0.3\n",
      "Epoch: 1628 \tTraining Loss: 1.261415 \tValidation Loss: 1.358232 \t time: 0.3\n",
      "Epoch: 1629 \tTraining Loss: 1.261307 \tValidation Loss: 1.358631 \t time: 0.3\n",
      "Epoch: 1630 \tTraining Loss: 1.261470 \tValidation Loss: 1.359191 \t time: 0.3\n",
      "Epoch: 1631 \tTraining Loss: 1.263968 \tValidation Loss: 1.359755 \t time: 0.3\n",
      "Epoch: 1632 \tTraining Loss: 1.262806 \tValidation Loss: 1.360048 \t time: 0.3\n",
      "Epoch: 1633 \tTraining Loss: 1.263266 \tValidation Loss: 1.360027 \t time: 0.3\n",
      "Epoch: 1634 \tTraining Loss: 1.261907 \tValidation Loss: 1.359560 \t time: 0.3\n",
      "Epoch: 1635 \tTraining Loss: 1.261735 \tValidation Loss: 1.359129 \t time: 0.2\n",
      "Epoch: 1636 \tTraining Loss: 1.261454 \tValidation Loss: 1.358670 \t time: 0.2\n",
      "Epoch: 1637 \tTraining Loss: 1.262465 \tValidation Loss: 1.358368 \t time: 0.3\n",
      "Epoch: 1638 \tTraining Loss: 1.262686 \tValidation Loss: 1.358291 \t time: 0.3\n",
      "Epoch: 1639 \tTraining Loss: 1.261738 \tValidation Loss: 1.358352 \t time: 0.3\n",
      "Epoch: 1640 \tTraining Loss: 1.262244 \tValidation Loss: 1.358730 \t time: 0.3\n",
      "Epoch: 1641 \tTraining Loss: 1.261974 \tValidation Loss: 1.359471 \t time: 0.3\n",
      "Epoch: 1642 \tTraining Loss: 1.263656 \tValidation Loss: 1.360432 \t time: 0.3\n",
      "Epoch: 1643 \tTraining Loss: 1.260750 \tValidation Loss: 1.361065 \t time: 0.3\n",
      "Epoch: 1644 \tTraining Loss: 1.262488 \tValidation Loss: 1.361513 \t time: 0.3\n",
      "Epoch: 1645 \tTraining Loss: 1.260757 \tValidation Loss: 1.361430 \t time: 0.3\n",
      "Epoch: 1646 \tTraining Loss: 1.260921 \tValidation Loss: 1.360528 \t time: 0.3\n",
      "Epoch: 1647 \tTraining Loss: 1.260805 \tValidation Loss: 1.359261 \t time: 0.3\n",
      "Epoch: 1648 \tTraining Loss: 1.260562 \tValidation Loss: 1.358338 \t time: 0.2\n",
      "Epoch: 1649 \tTraining Loss: 1.260015 \tValidation Loss: 1.357843 \t time: 0.2\n",
      "Epoch: 1650 \tTraining Loss: 1.261084 \tValidation Loss: 1.357812 \t time: 0.2\n",
      "Epoch: 1651 \tTraining Loss: 1.260753 \tValidation Loss: 1.357706 \t time: 0.3\n",
      "Epoch: 1652 \tTraining Loss: 1.263070 \tValidation Loss: 1.357835 \t time: 0.3\n",
      "Epoch: 1653 \tTraining Loss: 1.260506 \tValidation Loss: 1.358084 \t time: 0.2\n",
      "Epoch: 1654 \tTraining Loss: 1.262837 \tValidation Loss: 1.358998 \t time: 0.2\n",
      "Epoch: 1655 \tTraining Loss: 1.263616 \tValidation Loss: 1.359952 \t time: 0.3\n",
      "Epoch: 1656 \tTraining Loss: 1.260586 \tValidation Loss: 1.360579 \t time: 0.2\n",
      "Epoch: 1657 \tTraining Loss: 1.260657 \tValidation Loss: 1.360583 \t time: 0.2\n",
      "Epoch: 1658 \tTraining Loss: 1.260600 \tValidation Loss: 1.360437 \t time: 0.3\n",
      "Epoch: 1659 \tTraining Loss: 1.263278 \tValidation Loss: 1.360239 \t time: 0.3\n",
      "Epoch: 1660 \tTraining Loss: 1.261442 \tValidation Loss: 1.359675 \t time: 0.2\n",
      "Epoch: 1661 \tTraining Loss: 1.263209 \tValidation Loss: 1.359344 \t time: 0.3\n",
      "Epoch: 1662 \tTraining Loss: 1.261386 \tValidation Loss: 1.358991 \t time: 0.3\n",
      "Epoch: 1663 \tTraining Loss: 1.260997 \tValidation Loss: 1.358743 \t time: 0.3\n",
      "Epoch: 1664 \tTraining Loss: 1.261215 \tValidation Loss: 1.358483 \t time: 0.2\n",
      "Epoch: 1665 \tTraining Loss: 1.259880 \tValidation Loss: 1.358113 \t time: 0.3\n",
      "Epoch: 1666 \tTraining Loss: 1.260370 \tValidation Loss: 1.357945 \t time: 0.3\n",
      "Epoch: 1667 \tTraining Loss: 1.259034 \tValidation Loss: 1.358222 \t time: 0.3\n",
      "Epoch: 1668 \tTraining Loss: 1.264764 \tValidation Loss: 1.358984 \t time: 0.3\n",
      "Epoch: 1669 \tTraining Loss: 1.263719 \tValidation Loss: 1.359807 \t time: 0.2\n",
      "Epoch: 1670 \tTraining Loss: 1.261276 \tValidation Loss: 1.360280 \t time: 0.3\n",
      "Epoch: 1671 \tTraining Loss: 1.261371 \tValidation Loss: 1.360428 \t time: 0.2\n",
      "Epoch: 1672 \tTraining Loss: 1.260568 \tValidation Loss: 1.360498 \t time: 0.3\n",
      "Epoch: 1673 \tTraining Loss: 1.260338 \tValidation Loss: 1.360386 \t time: 0.3\n",
      "Epoch: 1674 \tTraining Loss: 1.259847 \tValidation Loss: 1.359834 \t time: 0.2\n",
      "Epoch: 1675 \tTraining Loss: 1.259735 \tValidation Loss: 1.359661 \t time: 0.2\n",
      "Epoch: 1676 \tTraining Loss: 1.260411 \tValidation Loss: 1.359523 \t time: 0.2\n",
      "Epoch: 1677 \tTraining Loss: 1.260404 \tValidation Loss: 1.359437 \t time: 0.3\n",
      "Epoch: 1678 \tTraining Loss: 1.263863 \tValidation Loss: 1.359349 \t time: 0.3\n",
      "Epoch: 1679 \tTraining Loss: 1.261566 \tValidation Loss: 1.359364 \t time: 0.3\n",
      "Epoch: 1680 \tTraining Loss: 1.260669 \tValidation Loss: 1.359336 \t time: 0.3\n",
      "Epoch: 1681 \tTraining Loss: 1.257855 \tValidation Loss: 1.359344 \t time: 0.3\n",
      "Epoch: 1682 \tTraining Loss: 1.262664 \tValidation Loss: 1.359443 \t time: 0.3\n",
      "Epoch: 1683 \tTraining Loss: 1.262215 \tValidation Loss: 1.359388 \t time: 0.3\n",
      "Epoch: 1684 \tTraining Loss: 1.259778 \tValidation Loss: 1.359279 \t time: 0.3\n",
      "Epoch: 1685 \tTraining Loss: 1.262651 \tValidation Loss: 1.358909 \t time: 0.3\n",
      "Epoch: 1686 \tTraining Loss: 1.260361 \tValidation Loss: 1.358605 \t time: 0.3\n",
      "Epoch: 1687 \tTraining Loss: 1.261774 \tValidation Loss: 1.358583 \t time: 0.3\n",
      "Epoch: 1688 \tTraining Loss: 1.261154 \tValidation Loss: 1.358803 \t time: 0.3\n",
      "Epoch: 1689 \tTraining Loss: 1.258592 \tValidation Loss: 1.359256 \t time: 0.3\n",
      "Epoch: 1690 \tTraining Loss: 1.259574 \tValidation Loss: 1.359759 \t time: 0.3\n",
      "Epoch: 1691 \tTraining Loss: 1.259614 \tValidation Loss: 1.360068 \t time: 0.3\n",
      "Epoch: 1692 \tTraining Loss: 1.262886 \tValidation Loss: 1.360226 \t time: 0.3\n",
      "Epoch: 1693 \tTraining Loss: 1.260079 \tValidation Loss: 1.360414 \t time: 0.3\n",
      "Epoch: 1694 \tTraining Loss: 1.260408 \tValidation Loss: 1.360721 \t time: 0.3\n",
      "Epoch: 1695 \tTraining Loss: 1.260029 \tValidation Loss: 1.360942 \t time: 0.3\n",
      "Epoch: 1696 \tTraining Loss: 1.257255 \tValidation Loss: 1.361151 \t time: 0.3\n",
      "Epoch: 1697 \tTraining Loss: 1.262280 \tValidation Loss: 1.361438 \t time: 0.2\n",
      "Epoch: 1698 \tTraining Loss: 1.260864 \tValidation Loss: 1.361551 \t time: 0.2\n",
      "Epoch: 1699 \tTraining Loss: 1.257775 \tValidation Loss: 1.361480 \t time: 0.3\n",
      "Epoch: 1700 \tTraining Loss: 1.261051 \tValidation Loss: 1.360937 \t time: 0.3\n",
      "Epoch: 1701 \tTraining Loss: 1.259626 \tValidation Loss: 1.360358 \t time: 0.3\n",
      "Epoch: 1702 \tTraining Loss: 1.261352 \tValidation Loss: 1.359755 \t time: 0.3\n",
      "Epoch: 1703 \tTraining Loss: 1.260106 \tValidation Loss: 1.359080 \t time: 0.3\n",
      "Epoch: 1704 \tTraining Loss: 1.260199 \tValidation Loss: 1.358572 \t time: 0.3\n",
      "Epoch: 1705 \tTraining Loss: 1.259269 \tValidation Loss: 1.358379 \t time: 0.3\n",
      "Epoch: 1706 \tTraining Loss: 1.259720 \tValidation Loss: 1.358490 \t time: 0.3\n",
      "Epoch: 1707 \tTraining Loss: 1.260278 \tValidation Loss: 1.358711 \t time: 0.3\n",
      "Epoch: 1708 \tTraining Loss: 1.260033 \tValidation Loss: 1.358930 \t time: 0.2\n",
      "Epoch: 1709 \tTraining Loss: 1.261508 \tValidation Loss: 1.359010 \t time: 0.2\n",
      "Epoch: 1710 \tTraining Loss: 1.257955 \tValidation Loss: 1.359256 \t time: 0.3\n",
      "Epoch: 1711 \tTraining Loss: 1.256315 \tValidation Loss: 1.359031 \t time: 0.3\n",
      "Epoch: 1712 \tTraining Loss: 1.259633 \tValidation Loss: 1.358665 \t time: 0.2\n",
      "Epoch: 1713 \tTraining Loss: 1.259619 \tValidation Loss: 1.358502 \t time: 0.2\n",
      "Epoch: 1714 \tTraining Loss: 1.257197 \tValidation Loss: 1.358533 \t time: 0.3\n",
      "Epoch: 1715 \tTraining Loss: 1.260835 \tValidation Loss: 1.358743 \t time: 0.2\n",
      "Epoch: 1716 \tTraining Loss: 1.259369 \tValidation Loss: 1.358759 \t time: 0.2\n",
      "Epoch: 1717 \tTraining Loss: 1.260319 \tValidation Loss: 1.358969 \t time: 0.2\n",
      "Epoch: 1718 \tTraining Loss: 1.259258 \tValidation Loss: 1.358679 \t time: 0.2\n",
      "Epoch: 1719 \tTraining Loss: 1.258736 \tValidation Loss: 1.358430 \t time: 0.2\n",
      "Epoch: 1720 \tTraining Loss: 1.259415 \tValidation Loss: 1.358267 \t time: 0.3\n",
      "Epoch: 1721 \tTraining Loss: 1.260512 \tValidation Loss: 1.358146 \t time: 0.3\n",
      "Epoch: 1722 \tTraining Loss: 1.261420 \tValidation Loss: 1.357978 \t time: 0.3\n",
      "Epoch: 1723 \tTraining Loss: 1.259606 \tValidation Loss: 1.357737 \t time: 0.3\n",
      "Epoch: 1724 \tTraining Loss: 1.259996 \tValidation Loss: 1.357580 \t time: 0.2\n",
      "Epoch: 1725 \tTraining Loss: 1.259114 \tValidation Loss: 1.357813 \t time: 0.3\n",
      "Epoch: 1726 \tTraining Loss: 1.257638 \tValidation Loss: 1.358144 \t time: 0.3\n",
      "Epoch: 1727 \tTraining Loss: 1.261835 \tValidation Loss: 1.358068 \t time: 0.3\n",
      "Epoch: 1728 \tTraining Loss: 1.257091 \tValidation Loss: 1.357840 \t time: 0.3\n",
      "Epoch: 1729 \tTraining Loss: 1.258644 \tValidation Loss: 1.357268 \t time: 0.3\n",
      "Epoch: 1730 \tTraining Loss: 1.259791 \tValidation Loss: 1.356677 \t time: 0.3\n",
      "Epoch: 1731 \tTraining Loss: 1.259092 \tValidation Loss: 1.355944 \t time: 0.3\n",
      "Epoch: 1732 \tTraining Loss: 1.260713 \tValidation Loss: 1.355731 \t time: 0.3\n",
      "Epoch: 1733 \tTraining Loss: 1.258444 \tValidation Loss: 1.355465 \t time: 0.3\n",
      "Validation loss decreased from 1.355497 to 1.355465. Model was saved\n",
      "Epoch: 1734 \tTraining Loss: 1.258716 \tValidation Loss: 1.355289 \t time: 0.3\n",
      "Validation loss decreased from 1.355465 to 1.355289. Model was saved\n",
      "Epoch: 1735 \tTraining Loss: 1.256950 \tValidation Loss: 1.355254 \t time: 0.3\n",
      "Validation loss decreased from 1.355289 to 1.355254. Model was saved\n",
      "Epoch: 1736 \tTraining Loss: 1.258217 \tValidation Loss: 1.355636 \t time: 0.2\n",
      "Epoch: 1737 \tTraining Loss: 1.260377 \tValidation Loss: 1.356043 \t time: 0.2\n",
      "Epoch: 1738 \tTraining Loss: 1.258386 \tValidation Loss: 1.356229 \t time: 0.3\n",
      "Epoch: 1739 \tTraining Loss: 1.259819 \tValidation Loss: 1.356611 \t time: 0.3\n",
      "Epoch: 1740 \tTraining Loss: 1.259847 \tValidation Loss: 1.357426 \t time: 0.2\n",
      "Epoch: 1741 \tTraining Loss: 1.258910 \tValidation Loss: 1.357943 \t time: 0.3\n",
      "Epoch: 1742 \tTraining Loss: 1.261680 \tValidation Loss: 1.357804 \t time: 0.3\n",
      "Epoch: 1743 \tTraining Loss: 1.258575 \tValidation Loss: 1.357263 \t time: 0.2\n",
      "Epoch: 1744 \tTraining Loss: 1.259648 \tValidation Loss: 1.356820 \t time: 0.3\n",
      "Epoch: 1745 \tTraining Loss: 1.261143 \tValidation Loss: 1.356813 \t time: 0.3\n",
      "Epoch: 1746 \tTraining Loss: 1.259540 \tValidation Loss: 1.356591 \t time: 0.3\n",
      "Epoch: 1747 \tTraining Loss: 1.257747 \tValidation Loss: 1.356431 \t time: 0.3\n",
      "Epoch: 1748 \tTraining Loss: 1.261206 \tValidation Loss: 1.356529 \t time: 0.3\n",
      "Epoch: 1749 \tTraining Loss: 1.260670 \tValidation Loss: 1.356863 \t time: 0.3\n",
      "Epoch: 1750 \tTraining Loss: 1.255973 \tValidation Loss: 1.357172 \t time: 0.2\n",
      "Epoch: 1751 \tTraining Loss: 1.258894 \tValidation Loss: 1.357509 \t time: 0.2\n",
      "Epoch: 1752 \tTraining Loss: 1.258073 \tValidation Loss: 1.357640 \t time: 0.3\n",
      "Epoch: 1753 \tTraining Loss: 1.257193 \tValidation Loss: 1.357737 \t time: 0.2\n",
      "Epoch: 1754 \tTraining Loss: 1.260070 \tValidation Loss: 1.357751 \t time: 0.3\n",
      "Epoch: 1755 \tTraining Loss: 1.257190 \tValidation Loss: 1.357712 \t time: 0.2\n",
      "Epoch: 1756 \tTraining Loss: 1.259593 \tValidation Loss: 1.357454 \t time: 0.2\n",
      "Epoch: 1757 \tTraining Loss: 1.257246 \tValidation Loss: 1.357447 \t time: 0.3\n",
      "Epoch: 1758 \tTraining Loss: 1.257553 \tValidation Loss: 1.357586 \t time: 0.3\n",
      "Epoch: 1759 \tTraining Loss: 1.258145 \tValidation Loss: 1.357682 \t time: 0.2\n",
      "Epoch: 1760 \tTraining Loss: 1.257989 \tValidation Loss: 1.357866 \t time: 0.3\n",
      "Epoch: 1761 \tTraining Loss: 1.259691 \tValidation Loss: 1.357843 \t time: 0.3\n",
      "Epoch: 1762 \tTraining Loss: 1.257351 \tValidation Loss: 1.357568 \t time: 0.3\n",
      "Epoch: 1763 \tTraining Loss: 1.259610 \tValidation Loss: 1.357275 \t time: 0.3\n",
      "Epoch: 1764 \tTraining Loss: 1.257880 \tValidation Loss: 1.357213 \t time: 0.3\n",
      "Epoch: 1765 \tTraining Loss: 1.258830 \tValidation Loss: 1.357279 \t time: 0.3\n",
      "Epoch: 1766 \tTraining Loss: 1.258942 \tValidation Loss: 1.357123 \t time: 0.3\n",
      "Epoch: 1767 \tTraining Loss: 1.258453 \tValidation Loss: 1.356655 \t time: 0.3\n",
      "Epoch: 1768 \tTraining Loss: 1.259064 \tValidation Loss: 1.356020 \t time: 0.3\n",
      "Epoch: 1769 \tTraining Loss: 1.257317 \tValidation Loss: 1.355582 \t time: 0.3\n",
      "Epoch: 1770 \tTraining Loss: 1.257162 \tValidation Loss: 1.355173 \t time: 0.3\n",
      "Validation loss decreased from 1.355254 to 1.355173. Model was saved\n",
      "Epoch: 1771 \tTraining Loss: 1.255286 \tValidation Loss: 1.354772 \t time: 0.3\n",
      "Validation loss decreased from 1.355173 to 1.354772. Model was saved\n",
      "Epoch: 1772 \tTraining Loss: 1.255687 \tValidation Loss: 1.354470 \t time: 0.2\n",
      "Validation loss decreased from 1.354772 to 1.354470. Model was saved\n",
      "Epoch: 1773 \tTraining Loss: 1.258801 \tValidation Loss: 1.353592 \t time: 0.3\n",
      "Validation loss decreased from 1.354470 to 1.353592. Model was saved\n",
      "Epoch: 1774 \tTraining Loss: 1.257753 \tValidation Loss: 1.352871 \t time: 0.2\n",
      "Validation loss decreased from 1.353592 to 1.352871. Model was saved\n",
      "Epoch: 1775 \tTraining Loss: 1.257544 \tValidation Loss: 1.352930 \t time: 0.3\n",
      "Epoch: 1776 \tTraining Loss: 1.256924 \tValidation Loss: 1.353681 \t time: 0.2\n",
      "Epoch: 1777 \tTraining Loss: 1.254964 \tValidation Loss: 1.354557 \t time: 0.3\n",
      "Epoch: 1778 \tTraining Loss: 1.258927 \tValidation Loss: 1.354982 \t time: 0.3\n",
      "Epoch: 1779 \tTraining Loss: 1.259018 \tValidation Loss: 1.355222 \t time: 0.3\n",
      "Epoch: 1780 \tTraining Loss: 1.254869 \tValidation Loss: 1.355059 \t time: 0.2\n",
      "Epoch: 1781 \tTraining Loss: 1.258479 \tValidation Loss: 1.354713 \t time: 0.3\n",
      "Epoch: 1782 \tTraining Loss: 1.257391 \tValidation Loss: 1.354519 \t time: 0.2\n",
      "Epoch: 1783 \tTraining Loss: 1.260150 \tValidation Loss: 1.354367 \t time: 0.3\n",
      "Epoch: 1784 \tTraining Loss: 1.256629 \tValidation Loss: 1.354394 \t time: 0.3\n",
      "Epoch: 1785 \tTraining Loss: 1.255912 \tValidation Loss: 1.354352 \t time: 0.3\n",
      "Epoch: 1786 \tTraining Loss: 1.257169 \tValidation Loss: 1.354422 \t time: 0.3\n",
      "Epoch: 1787 \tTraining Loss: 1.257316 \tValidation Loss: 1.354680 \t time: 0.2\n",
      "Epoch: 1788 \tTraining Loss: 1.258996 \tValidation Loss: 1.354801 \t time: 0.2\n",
      "Epoch: 1789 \tTraining Loss: 1.258708 \tValidation Loss: 1.354926 \t time: 0.3\n",
      "Epoch: 1790 \tTraining Loss: 1.257575 \tValidation Loss: 1.355164 \t time: 0.3\n",
      "Epoch: 1791 \tTraining Loss: 1.256810 \tValidation Loss: 1.355459 \t time: 0.3\n",
      "Epoch: 1792 \tTraining Loss: 1.259261 \tValidation Loss: 1.355340 \t time: 0.3\n",
      "Epoch: 1793 \tTraining Loss: 1.255864 \tValidation Loss: 1.355243 \t time: 0.2\n",
      "Epoch: 1794 \tTraining Loss: 1.258622 \tValidation Loss: 1.354848 \t time: 0.2\n",
      "Epoch: 1795 \tTraining Loss: 1.257798 \tValidation Loss: 1.354381 \t time: 0.3\n",
      "Epoch: 1796 \tTraining Loss: 1.256172 \tValidation Loss: 1.354009 \t time: 0.3\n",
      "Epoch: 1797 \tTraining Loss: 1.259693 \tValidation Loss: 1.353772 \t time: 0.3\n",
      "Epoch: 1798 \tTraining Loss: 1.258542 \tValidation Loss: 1.353641 \t time: 0.3\n",
      "Epoch: 1799 \tTraining Loss: 1.257108 \tValidation Loss: 1.353647 \t time: 0.2\n",
      "Epoch: 1800 \tTraining Loss: 1.258404 \tValidation Loss: 1.353605 \t time: 0.3\n",
      "Epoch: 1801 \tTraining Loss: 1.253777 \tValidation Loss: 1.353954 \t time: 0.3\n",
      "Epoch: 1802 \tTraining Loss: 1.257883 \tValidation Loss: 1.354561 \t time: 0.3\n",
      "Epoch: 1803 \tTraining Loss: 1.255236 \tValidation Loss: 1.355656 \t time: 0.3\n",
      "Epoch: 1804 \tTraining Loss: 1.256322 \tValidation Loss: 1.356872 \t time: 0.3\n",
      "Epoch: 1805 \tTraining Loss: 1.256821 \tValidation Loss: 1.357905 \t time: 0.3\n",
      "Epoch: 1806 \tTraining Loss: 1.255502 \tValidation Loss: 1.358566 \t time: 0.3\n",
      "Epoch: 1807 \tTraining Loss: 1.257399 \tValidation Loss: 1.358898 \t time: 0.3\n",
      "Epoch: 1808 \tTraining Loss: 1.257837 \tValidation Loss: 1.358738 \t time: 0.3\n",
      "Epoch: 1809 \tTraining Loss: 1.257881 \tValidation Loss: 1.358346 \t time: 0.3\n",
      "Epoch: 1810 \tTraining Loss: 1.257252 \tValidation Loss: 1.358142 \t time: 0.3\n",
      "Epoch: 1811 \tTraining Loss: 1.256593 \tValidation Loss: 1.357912 \t time: 0.3\n",
      "Epoch: 1812 \tTraining Loss: 1.257854 \tValidation Loss: 1.357723 \t time: 0.3\n",
      "Epoch: 1813 \tTraining Loss: 1.256571 \tValidation Loss: 1.357419 \t time: 0.3\n",
      "Epoch: 1814 \tTraining Loss: 1.258274 \tValidation Loss: 1.356820 \t time: 0.3\n",
      "Epoch: 1815 \tTraining Loss: 1.258232 \tValidation Loss: 1.355773 \t time: 0.3\n",
      "Epoch: 1816 \tTraining Loss: 1.255980 \tValidation Loss: 1.355110 \t time: 0.3\n",
      "Epoch: 1817 \tTraining Loss: 1.256785 \tValidation Loss: 1.354623 \t time: 0.3\n",
      "Epoch: 1818 \tTraining Loss: 1.255448 \tValidation Loss: 1.354407 \t time: 0.3\n",
      "Epoch: 1819 \tTraining Loss: 1.255432 \tValidation Loss: 1.354506 \t time: 0.3\n",
      "Epoch: 1820 \tTraining Loss: 1.257827 \tValidation Loss: 1.354810 \t time: 0.3\n",
      "Epoch: 1821 \tTraining Loss: 1.255770 \tValidation Loss: 1.355204 \t time: 0.3\n",
      "Epoch: 1822 \tTraining Loss: 1.256267 \tValidation Loss: 1.355609 \t time: 0.3\n",
      "Epoch: 1823 \tTraining Loss: 1.257888 \tValidation Loss: 1.355814 \t time: 0.3\n",
      "Epoch: 1824 \tTraining Loss: 1.257378 \tValidation Loss: 1.355946 \t time: 0.3\n",
      "Epoch: 1825 \tTraining Loss: 1.257256 \tValidation Loss: 1.356051 \t time: 0.3\n",
      "Epoch: 1826 \tTraining Loss: 1.256681 \tValidation Loss: 1.355639 \t time: 0.3\n",
      "Epoch: 1827 \tTraining Loss: 1.257013 \tValidation Loss: 1.355134 \t time: 0.3\n",
      "Epoch: 1828 \tTraining Loss: 1.258103 \tValidation Loss: 1.354803 \t time: 0.3\n",
      "Epoch: 1829 \tTraining Loss: 1.257510 \tValidation Loss: 1.354390 \t time: 0.3\n",
      "Epoch: 1830 \tTraining Loss: 1.256919 \tValidation Loss: 1.354286 \t time: 0.3\n",
      "Epoch: 1831 \tTraining Loss: 1.255766 \tValidation Loss: 1.354544 \t time: 0.3\n",
      "Epoch: 1832 \tTraining Loss: 1.255464 \tValidation Loss: 1.354673 \t time: 0.3\n",
      "Epoch: 1833 \tTraining Loss: 1.257199 \tValidation Loss: 1.354774 \t time: 0.3\n",
      "Epoch: 1834 \tTraining Loss: 1.258748 \tValidation Loss: 1.354834 \t time: 0.3\n",
      "Epoch: 1835 \tTraining Loss: 1.256643 \tValidation Loss: 1.354667 \t time: 0.3\n",
      "Epoch: 1836 \tTraining Loss: 1.258787 \tValidation Loss: 1.354042 \t time: 0.3\n",
      "Epoch: 1837 \tTraining Loss: 1.255878 \tValidation Loss: 1.353528 \t time: 0.3\n",
      "Epoch: 1838 \tTraining Loss: 1.258234 \tValidation Loss: 1.353293 \t time: 0.3\n",
      "Epoch: 1839 \tTraining Loss: 1.254672 \tValidation Loss: 1.353499 \t time: 0.3\n",
      "Epoch: 1840 \tTraining Loss: 1.256045 \tValidation Loss: 1.353848 \t time: 0.2\n",
      "Epoch: 1841 \tTraining Loss: 1.257128 \tValidation Loss: 1.354257 \t time: 0.3\n",
      "Epoch: 1842 \tTraining Loss: 1.253101 \tValidation Loss: 1.354751 \t time: 0.3\n",
      "Epoch: 1843 \tTraining Loss: 1.256401 \tValidation Loss: 1.355245 \t time: 0.3\n",
      "Epoch: 1844 \tTraining Loss: 1.258735 \tValidation Loss: 1.355924 \t time: 0.3\n",
      "Epoch: 1845 \tTraining Loss: 1.257315 \tValidation Loss: 1.356518 \t time: 0.3\n",
      "Epoch: 1846 \tTraining Loss: 1.257306 \tValidation Loss: 1.356578 \t time: 0.3\n",
      "Epoch: 1847 \tTraining Loss: 1.254540 \tValidation Loss: 1.356268 \t time: 0.3\n",
      "Epoch: 1848 \tTraining Loss: 1.254756 \tValidation Loss: 1.355778 \t time: 0.2\n",
      "Epoch: 1849 \tTraining Loss: 1.259065 \tValidation Loss: 1.355172 \t time: 0.3\n",
      "Epoch: 1850 \tTraining Loss: 1.256986 \tValidation Loss: 1.354609 \t time: 0.3\n",
      "Epoch: 1851 \tTraining Loss: 1.256267 \tValidation Loss: 1.354671 \t time: 0.3\n",
      "Epoch: 1852 \tTraining Loss: 1.252985 \tValidation Loss: 1.354736 \t time: 0.3\n",
      "Epoch: 1853 \tTraining Loss: 1.256724 \tValidation Loss: 1.354867 \t time: 0.3\n",
      "Epoch: 1854 \tTraining Loss: 1.256690 \tValidation Loss: 1.354965 \t time: 0.3\n",
      "Epoch: 1855 \tTraining Loss: 1.257554 \tValidation Loss: 1.355114 \t time: 0.3\n",
      "Epoch: 1856 \tTraining Loss: 1.257057 \tValidation Loss: 1.355039 \t time: 0.3\n",
      "Epoch: 1857 \tTraining Loss: 1.254749 \tValidation Loss: 1.354323 \t time: 0.3\n",
      "Epoch: 1858 \tTraining Loss: 1.257573 \tValidation Loss: 1.353897 \t time: 0.3\n",
      "Epoch: 1859 \tTraining Loss: 1.258637 \tValidation Loss: 1.353797 \t time: 0.3\n",
      "Epoch: 1860 \tTraining Loss: 1.254619 \tValidation Loss: 1.353769 \t time: 0.3\n",
      "Epoch: 1861 \tTraining Loss: 1.253040 \tValidation Loss: 1.353937 \t time: 0.3\n",
      "Epoch: 1862 \tTraining Loss: 1.255088 \tValidation Loss: 1.354049 \t time: 0.2\n",
      "Epoch: 1863 \tTraining Loss: 1.256470 \tValidation Loss: 1.354443 \t time: 0.2\n",
      "Epoch: 1864 \tTraining Loss: 1.256345 \tValidation Loss: 1.355218 \t time: 0.2\n",
      "Epoch: 1865 \tTraining Loss: 1.256275 \tValidation Loss: 1.356075 \t time: 0.2\n",
      "Epoch: 1866 \tTraining Loss: 1.257124 \tValidation Loss: 1.356794 \t time: 0.2\n",
      "Epoch: 1867 \tTraining Loss: 1.258069 \tValidation Loss: 1.357240 \t time: 0.2\n",
      "Epoch: 1868 \tTraining Loss: 1.254681 \tValidation Loss: 1.357518 \t time: 0.2\n",
      "Epoch: 1869 \tTraining Loss: 1.255360 \tValidation Loss: 1.357433 \t time: 0.3\n",
      "Epoch: 1870 \tTraining Loss: 1.254853 \tValidation Loss: 1.356948 \t time: 0.3\n",
      "Epoch: 1871 \tTraining Loss: 1.253696 \tValidation Loss: 1.356010 \t time: 0.3\n",
      "Epoch: 1872 \tTraining Loss: 1.255891 \tValidation Loss: 1.354879 \t time: 0.3\n",
      "Epoch: 1873 \tTraining Loss: 1.254179 \tValidation Loss: 1.354251 \t time: 0.3\n",
      "Epoch: 1874 \tTraining Loss: 1.254221 \tValidation Loss: 1.354077 \t time: 0.3\n",
      "Epoch: 1875 \tTraining Loss: 1.255196 \tValidation Loss: 1.354101 \t time: 0.3\n",
      "Epoch: 1876 \tTraining Loss: 1.255188 \tValidation Loss: 1.354563 \t time: 0.3\n",
      "Epoch: 1877 \tTraining Loss: 1.256386 \tValidation Loss: 1.355501 \t time: 0.3\n",
      "Epoch: 1878 \tTraining Loss: 1.254238 \tValidation Loss: 1.356073 \t time: 0.3\n",
      "Epoch: 1879 \tTraining Loss: 1.254667 \tValidation Loss: 1.355996 \t time: 0.3\n",
      "Epoch: 1880 \tTraining Loss: 1.259654 \tValidation Loss: 1.355350 \t time: 0.3\n",
      "Epoch: 1881 \tTraining Loss: 1.255898 \tValidation Loss: 1.354385 \t time: 0.3\n",
      "Epoch: 1882 \tTraining Loss: 1.254796 \tValidation Loss: 1.353745 \t time: 0.3\n",
      "Epoch: 1883 \tTraining Loss: 1.255902 \tValidation Loss: 1.353798 \t time: 0.2\n",
      "Epoch: 1884 \tTraining Loss: 1.253381 \tValidation Loss: 1.353912 \t time: 0.2\n",
      "Epoch: 1885 \tTraining Loss: 1.253778 \tValidation Loss: 1.354546 \t time: 0.2\n",
      "Epoch: 1886 \tTraining Loss: 1.255496 \tValidation Loss: 1.355349 \t time: 0.2\n",
      "Epoch: 1887 \tTraining Loss: 1.254180 \tValidation Loss: 1.355938 \t time: 0.3\n",
      "Epoch: 1888 \tTraining Loss: 1.252836 \tValidation Loss: 1.356267 \t time: 0.3\n",
      "Epoch: 1889 \tTraining Loss: 1.256470 \tValidation Loss: 1.356381 \t time: 0.3\n",
      "Epoch: 1890 \tTraining Loss: 1.252903 \tValidation Loss: 1.356430 \t time: 0.3\n",
      "Epoch: 1891 \tTraining Loss: 1.253208 \tValidation Loss: 1.355959 \t time: 0.2\n",
      "Epoch: 1892 \tTraining Loss: 1.254982 \tValidation Loss: 1.355084 \t time: 0.3\n",
      "Epoch: 1893 \tTraining Loss: 1.258929 \tValidation Loss: 1.354390 \t time: 0.3\n",
      "Epoch: 1894 \tTraining Loss: 1.252445 \tValidation Loss: 1.354085 \t time: 0.3\n",
      "Epoch: 1895 \tTraining Loss: 1.257017 \tValidation Loss: 1.353985 \t time: 0.2\n",
      "Epoch: 1896 \tTraining Loss: 1.257132 \tValidation Loss: 1.353908 \t time: 0.3\n",
      "Epoch: 1897 \tTraining Loss: 1.255294 \tValidation Loss: 1.353905 \t time: 0.3\n",
      "Epoch: 1898 \tTraining Loss: 1.255874 \tValidation Loss: 1.353982 \t time: 0.2\n",
      "Epoch: 1899 \tTraining Loss: 1.254999 \tValidation Loss: 1.354145 \t time: 0.2\n",
      "Epoch: 1900 \tTraining Loss: 1.254178 \tValidation Loss: 1.354080 \t time: 0.3\n",
      "Epoch: 1901 \tTraining Loss: 1.251862 \tValidation Loss: 1.354011 \t time: 0.3\n",
      "Epoch: 1902 \tTraining Loss: 1.254579 \tValidation Loss: 1.354015 \t time: 0.3\n",
      "Epoch: 1903 \tTraining Loss: 1.255793 \tValidation Loss: 1.353975 \t time: 0.3\n",
      "Epoch: 1904 \tTraining Loss: 1.253857 \tValidation Loss: 1.354051 \t time: 0.3\n",
      "Epoch: 1905 \tTraining Loss: 1.255398 \tValidation Loss: 1.354008 \t time: 0.3\n",
      "Epoch: 1906 \tTraining Loss: 1.255487 \tValidation Loss: 1.353999 \t time: 0.3\n",
      "Epoch: 1907 \tTraining Loss: 1.256591 \tValidation Loss: 1.354045 \t time: 0.2\n",
      "Epoch: 1908 \tTraining Loss: 1.254293 \tValidation Loss: 1.354160 \t time: 0.2\n",
      "Epoch: 1909 \tTraining Loss: 1.254582 \tValidation Loss: 1.354341 \t time: 0.3\n",
      "Epoch: 1910 \tTraining Loss: 1.254488 \tValidation Loss: 1.354597 \t time: 0.3\n",
      "Epoch: 1911 \tTraining Loss: 1.253339 \tValidation Loss: 1.354830 \t time: 0.3\n",
      "Epoch: 1912 \tTraining Loss: 1.254014 \tValidation Loss: 1.355236 \t time: 0.3\n",
      "Epoch: 1913 \tTraining Loss: 1.254649 \tValidation Loss: 1.355720 \t time: 0.3\n",
      "Epoch: 1914 \tTraining Loss: 1.255902 \tValidation Loss: 1.355991 \t time: 0.3\n",
      "Epoch: 1915 \tTraining Loss: 1.255301 \tValidation Loss: 1.356157 \t time: 0.3\n",
      "Epoch: 1916 \tTraining Loss: 1.253936 \tValidation Loss: 1.356170 \t time: 0.3\n",
      "Epoch: 1917 \tTraining Loss: 1.254766 \tValidation Loss: 1.356157 \t time: 0.3\n",
      "Epoch: 1918 \tTraining Loss: 1.252974 \tValidation Loss: 1.355886 \t time: 0.2\n",
      "Epoch: 1919 \tTraining Loss: 1.252563 \tValidation Loss: 1.355581 \t time: 0.3\n",
      "Epoch: 1920 \tTraining Loss: 1.256441 \tValidation Loss: 1.355346 \t time: 0.3\n",
      "Epoch: 1921 \tTraining Loss: 1.255381 \tValidation Loss: 1.354818 \t time: 0.2\n",
      "Epoch: 1922 \tTraining Loss: 1.255036 \tValidation Loss: 1.354379 \t time: 0.3\n",
      "Epoch: 1923 \tTraining Loss: 1.252291 \tValidation Loss: 1.353999 \t time: 0.3\n",
      "Epoch: 1924 \tTraining Loss: 1.254159 \tValidation Loss: 1.353758 \t time: 0.2\n",
      "Epoch: 1925 \tTraining Loss: 1.253611 \tValidation Loss: 1.353733 \t time: 0.3\n",
      "Epoch: 1926 \tTraining Loss: 1.252911 \tValidation Loss: 1.353741 \t time: 0.2\n",
      "Epoch: 1927 \tTraining Loss: 1.253961 \tValidation Loss: 1.353922 \t time: 0.2\n",
      "Epoch: 1928 \tTraining Loss: 1.253182 \tValidation Loss: 1.354047 \t time: 0.2\n",
      "Epoch: 1929 \tTraining Loss: 1.254572 \tValidation Loss: 1.353970 \t time: 0.3\n",
      "Epoch: 1930 \tTraining Loss: 1.252037 \tValidation Loss: 1.353969 \t time: 0.2\n",
      "Epoch: 1931 \tTraining Loss: 1.251352 \tValidation Loss: 1.353715 \t time: 0.3\n",
      "Epoch: 1932 \tTraining Loss: 1.254667 \tValidation Loss: 1.354071 \t time: 0.3\n",
      "Epoch: 1933 \tTraining Loss: 1.253153 \tValidation Loss: 1.354738 \t time: 0.2\n",
      "Epoch: 1934 \tTraining Loss: 1.255524 \tValidation Loss: 1.355389 \t time: 0.3\n",
      "Epoch: 1935 \tTraining Loss: 1.256812 \tValidation Loss: 1.355872 \t time: 0.3\n",
      "Epoch: 1936 \tTraining Loss: 1.255672 \tValidation Loss: 1.355950 \t time: 0.3\n",
      "Epoch: 1937 \tTraining Loss: 1.254651 \tValidation Loss: 1.355909 \t time: 0.3\n",
      "Epoch: 1938 \tTraining Loss: 1.252402 \tValidation Loss: 1.355900 \t time: 0.3\n",
      "Epoch: 1939 \tTraining Loss: 1.254712 \tValidation Loss: 1.356191 \t time: 0.3\n",
      "Epoch: 1940 \tTraining Loss: 1.254331 \tValidation Loss: 1.356681 \t time: 0.3\n",
      "Epoch: 1941 \tTraining Loss: 1.254814 \tValidation Loss: 1.357019 \t time: 0.3\n",
      "Epoch: 1942 \tTraining Loss: 1.254956 \tValidation Loss: 1.357452 \t time: 0.3\n",
      "Epoch: 1943 \tTraining Loss: 1.253689 \tValidation Loss: 1.357854 \t time: 0.3\n",
      "Epoch: 1944 \tTraining Loss: 1.254355 \tValidation Loss: 1.358295 \t time: 0.3\n",
      "Epoch: 1945 \tTraining Loss: 1.253699 \tValidation Loss: 1.358842 \t time: 0.3\n",
      "Epoch: 1946 \tTraining Loss: 1.253014 \tValidation Loss: 1.359250 \t time: 0.3\n",
      "Epoch: 1947 \tTraining Loss: 1.253331 \tValidation Loss: 1.358893 \t time: 0.3\n",
      "Epoch: 1948 \tTraining Loss: 1.253504 \tValidation Loss: 1.358414 \t time: 0.3\n",
      "Epoch: 1949 \tTraining Loss: 1.251609 \tValidation Loss: 1.357800 \t time: 0.3\n",
      "Epoch: 1950 \tTraining Loss: 1.252423 \tValidation Loss: 1.357089 \t time: 0.3\n",
      "Epoch: 1951 \tTraining Loss: 1.253279 \tValidation Loss: 1.356194 \t time: 0.3\n",
      "Epoch: 1952 \tTraining Loss: 1.253974 \tValidation Loss: 1.355441 \t time: 0.3\n",
      "Epoch: 1953 \tTraining Loss: 1.256064 \tValidation Loss: 1.354836 \t time: 0.3\n",
      "Epoch: 1954 \tTraining Loss: 1.251859 \tValidation Loss: 1.354201 \t time: 0.3\n",
      "Epoch: 1955 \tTraining Loss: 1.252834 \tValidation Loss: 1.353507 \t time: 0.3\n",
      "Epoch: 1956 \tTraining Loss: 1.254431 \tValidation Loss: 1.353131 \t time: 0.3\n",
      "Epoch: 1957 \tTraining Loss: 1.253886 \tValidation Loss: 1.352800 \t time: 0.3\n",
      "Validation loss decreased from 1.352871 to 1.352800. Model was saved\n",
      "Epoch: 1958 \tTraining Loss: 1.251358 \tValidation Loss: 1.352593 \t time: 0.3\n",
      "Validation loss decreased from 1.352800 to 1.352593. Model was saved\n",
      "Epoch: 1959 \tTraining Loss: 1.255114 \tValidation Loss: 1.352945 \t time: 0.3\n",
      "Epoch: 1960 \tTraining Loss: 1.252446 \tValidation Loss: 1.353598 \t time: 0.2\n",
      "Epoch: 1961 \tTraining Loss: 1.254212 \tValidation Loss: 1.354048 \t time: 0.3\n",
      "Epoch: 1962 \tTraining Loss: 1.253259 \tValidation Loss: 1.354533 \t time: 0.3\n",
      "Epoch: 1963 \tTraining Loss: 1.252530 \tValidation Loss: 1.354653 \t time: 0.2\n",
      "Epoch: 1964 \tTraining Loss: 1.251493 \tValidation Loss: 1.354542 \t time: 0.3\n",
      "Epoch: 1965 \tTraining Loss: 1.253491 \tValidation Loss: 1.354157 \t time: 0.3\n",
      "Epoch: 1966 \tTraining Loss: 1.252618 \tValidation Loss: 1.353747 \t time: 0.2\n",
      "Epoch: 1967 \tTraining Loss: 1.253245 \tValidation Loss: 1.353297 \t time: 0.3\n",
      "Epoch: 1968 \tTraining Loss: 1.254830 \tValidation Loss: 1.353128 \t time: 0.3\n",
      "Epoch: 1969 \tTraining Loss: 1.254718 \tValidation Loss: 1.352982 \t time: 0.3\n",
      "Epoch: 1970 \tTraining Loss: 1.250686 \tValidation Loss: 1.352929 \t time: 0.3\n",
      "Epoch: 1971 \tTraining Loss: 1.255016 \tValidation Loss: 1.352766 \t time: 0.3\n",
      "Epoch: 1972 \tTraining Loss: 1.253423 \tValidation Loss: 1.352670 \t time: 0.3\n",
      "Epoch: 1973 \tTraining Loss: 1.254388 \tValidation Loss: 1.352927 \t time: 0.3\n",
      "Epoch: 1974 \tTraining Loss: 1.253424 \tValidation Loss: 1.353586 \t time: 0.2\n",
      "Epoch: 1975 \tTraining Loss: 1.253882 \tValidation Loss: 1.354436 \t time: 0.3\n",
      "Epoch: 1976 \tTraining Loss: 1.254453 \tValidation Loss: 1.355072 \t time: 0.3\n",
      "Epoch: 1977 \tTraining Loss: 1.253909 \tValidation Loss: 1.355593 \t time: 0.3\n",
      "Epoch: 1978 \tTraining Loss: 1.250761 \tValidation Loss: 1.355830 \t time: 0.3\n",
      "Epoch: 1979 \tTraining Loss: 1.253299 \tValidation Loss: 1.355319 \t time: 0.3\n",
      "Epoch: 1980 \tTraining Loss: 1.250490 \tValidation Loss: 1.354936 \t time: 0.3\n",
      "Epoch: 1981 \tTraining Loss: 1.255350 \tValidation Loss: 1.354813 \t time: 0.3\n",
      "Epoch: 1982 \tTraining Loss: 1.253518 \tValidation Loss: 1.354959 \t time: 0.3\n",
      "Epoch: 1983 \tTraining Loss: 1.254673 \tValidation Loss: 1.355295 \t time: 0.2\n",
      "Epoch: 1984 \tTraining Loss: 1.252663 \tValidation Loss: 1.355578 \t time: 0.3\n",
      "Epoch: 1985 \tTraining Loss: 1.253409 \tValidation Loss: 1.355881 \t time: 0.2\n",
      "Epoch: 1986 \tTraining Loss: 1.252313 \tValidation Loss: 1.356122 \t time: 0.3\n",
      "Epoch: 1987 \tTraining Loss: 1.253079 \tValidation Loss: 1.356185 \t time: 0.3\n",
      "Epoch: 1988 \tTraining Loss: 1.251175 \tValidation Loss: 1.356084 \t time: 0.3\n",
      "Epoch: 1989 \tTraining Loss: 1.253564 \tValidation Loss: 1.355991 \t time: 0.3\n",
      "Epoch: 1990 \tTraining Loss: 1.253505 \tValidation Loss: 1.355873 \t time: 0.3\n",
      "Epoch: 1991 \tTraining Loss: 1.254152 \tValidation Loss: 1.355785 \t time: 0.3\n",
      "Epoch: 1992 \tTraining Loss: 1.254571 \tValidation Loss: 1.355502 \t time: 0.2\n",
      "Epoch: 1993 \tTraining Loss: 1.251752 \tValidation Loss: 1.355231 \t time: 0.3\n",
      "Epoch: 1994 \tTraining Loss: 1.253266 \tValidation Loss: 1.355024 \t time: 0.2\n",
      "Epoch: 1995 \tTraining Loss: 1.253551 \tValidation Loss: 1.354995 \t time: 0.3\n",
      "Epoch: 1996 \tTraining Loss: 1.252730 \tValidation Loss: 1.354976 \t time: 0.3\n",
      "Epoch: 1997 \tTraining Loss: 1.252696 \tValidation Loss: 1.355106 \t time: 0.3\n",
      "Epoch: 1998 \tTraining Loss: 1.254412 \tValidation Loss: 1.354738 \t time: 0.2\n",
      "Epoch: 1999 \tTraining Loss: 1.252364 \tValidation Loss: 1.354687 \t time: 0.3\n",
      "Epoch: 2000 \tTraining Loss: 1.252109 \tValidation Loss: 1.354673 \t time: 0.3\n",
      "Epoch: 2001 \tTraining Loss: 1.254143 \tValidation Loss: 1.354623 \t time: 0.3\n",
      "Epoch: 2002 \tTraining Loss: 1.251736 \tValidation Loss: 1.354708 \t time: 0.2\n",
      "Epoch: 2003 \tTraining Loss: 1.252251 \tValidation Loss: 1.354804 \t time: 0.3\n",
      "Epoch: 2004 \tTraining Loss: 1.252706 \tValidation Loss: 1.355038 \t time: 0.3\n",
      "Epoch: 2005 \tTraining Loss: 1.251731 \tValidation Loss: 1.355018 \t time: 0.3\n",
      "Epoch: 2006 \tTraining Loss: 1.252250 \tValidation Loss: 1.354653 \t time: 0.3\n",
      "Epoch: 2007 \tTraining Loss: 1.251969 \tValidation Loss: 1.354234 \t time: 0.3\n",
      "Epoch: 2008 \tTraining Loss: 1.254525 \tValidation Loss: 1.353868 \t time: 0.3\n",
      "Epoch: 2009 \tTraining Loss: 1.252223 \tValidation Loss: 1.353405 \t time: 0.3\n",
      "Epoch: 2010 \tTraining Loss: 1.252881 \tValidation Loss: 1.353102 \t time: 0.3\n",
      "Epoch: 2011 \tTraining Loss: 1.252131 \tValidation Loss: 1.353172 \t time: 0.3\n",
      "Epoch: 2012 \tTraining Loss: 1.251920 \tValidation Loss: 1.353297 \t time: 0.3\n",
      "Epoch: 2013 \tTraining Loss: 1.251744 \tValidation Loss: 1.353407 \t time: 0.3\n",
      "Epoch: 2014 \tTraining Loss: 1.251063 \tValidation Loss: 1.353684 \t time: 0.3\n",
      "Epoch: 2015 \tTraining Loss: 1.253192 \tValidation Loss: 1.354135 \t time: 0.3\n",
      "Epoch: 2016 \tTraining Loss: 1.252676 \tValidation Loss: 1.354260 \t time: 0.3\n",
      "Epoch: 2017 \tTraining Loss: 1.250999 \tValidation Loss: 1.354155 \t time: 0.3\n",
      "Epoch: 2018 \tTraining Loss: 1.254930 \tValidation Loss: 1.353623 \t time: 0.3\n",
      "Epoch: 2019 \tTraining Loss: 1.252115 \tValidation Loss: 1.353058 \t time: 0.3\n",
      "Epoch: 2020 \tTraining Loss: 1.251247 \tValidation Loss: 1.352846 \t time: 0.3\n",
      "Epoch: 2021 \tTraining Loss: 1.251771 \tValidation Loss: 1.352905 \t time: 0.3\n",
      "Epoch: 2022 \tTraining Loss: 1.254734 \tValidation Loss: 1.353019 \t time: 0.3\n",
      "Epoch: 2023 \tTraining Loss: 1.252988 \tValidation Loss: 1.353423 \t time: 0.3\n",
      "Epoch: 2024 \tTraining Loss: 1.254038 \tValidation Loss: 1.354027 \t time: 0.2\n",
      "Epoch: 2025 \tTraining Loss: 1.250129 \tValidation Loss: 1.354406 \t time: 0.2\n",
      "Epoch: 2026 \tTraining Loss: 1.253837 \tValidation Loss: 1.354473 \t time: 0.3\n",
      "Epoch: 2027 \tTraining Loss: 1.254145 \tValidation Loss: 1.354227 \t time: 0.3\n",
      "Epoch: 2028 \tTraining Loss: 1.253251 \tValidation Loss: 1.353969 \t time: 0.3\n",
      "Epoch: 2029 \tTraining Loss: 1.250914 \tValidation Loss: 1.353731 \t time: 0.3\n",
      "Epoch: 2030 \tTraining Loss: 1.251550 \tValidation Loss: 1.353518 \t time: 0.3\n",
      "Epoch: 2031 \tTraining Loss: 1.249876 \tValidation Loss: 1.353251 \t time: 0.2\n",
      "Epoch: 2032 \tTraining Loss: 1.253069 \tValidation Loss: 1.353078 \t time: 0.3\n",
      "Epoch: 2033 \tTraining Loss: 1.250854 \tValidation Loss: 1.353028 \t time: 0.2\n",
      "Epoch: 2034 \tTraining Loss: 1.252634 \tValidation Loss: 1.353159 \t time: 0.2\n",
      "Epoch: 2035 \tTraining Loss: 1.251457 \tValidation Loss: 1.353476 \t time: 0.3\n",
      "Epoch: 2036 \tTraining Loss: 1.252949 \tValidation Loss: 1.353618 \t time: 0.3\n",
      "Epoch: 2037 \tTraining Loss: 1.249109 \tValidation Loss: 1.353742 \t time: 0.2\n",
      "Epoch: 2038 \tTraining Loss: 1.252965 \tValidation Loss: 1.353604 \t time: 0.3\n",
      "Epoch: 2039 \tTraining Loss: 1.249389 \tValidation Loss: 1.353678 \t time: 0.3\n",
      "Epoch: 2040 \tTraining Loss: 1.252668 \tValidation Loss: 1.353868 \t time: 0.3\n",
      "Epoch: 2041 \tTraining Loss: 1.251680 \tValidation Loss: 1.353970 \t time: 0.3\n",
      "Epoch: 2042 \tTraining Loss: 1.251085 \tValidation Loss: 1.354225 \t time: 0.3\n",
      "Epoch: 2043 \tTraining Loss: 1.253253 \tValidation Loss: 1.354439 \t time: 0.3\n",
      "Epoch: 2044 \tTraining Loss: 1.251729 \tValidation Loss: 1.354180 \t time: 0.3\n",
      "Epoch: 2045 \tTraining Loss: 1.253070 \tValidation Loss: 1.353673 \t time: 0.3\n",
      "Epoch: 2046 \tTraining Loss: 1.251256 \tValidation Loss: 1.353187 \t time: 0.3\n",
      "Epoch: 2047 \tTraining Loss: 1.250623 \tValidation Loss: 1.352987 \t time: 0.3\n",
      "Epoch: 2048 \tTraining Loss: 1.254714 \tValidation Loss: 1.352843 \t time: 0.3\n",
      "Epoch: 2049 \tTraining Loss: 1.251689 \tValidation Loss: 1.352889 \t time: 0.3\n",
      "Epoch: 2050 \tTraining Loss: 1.254434 \tValidation Loss: 1.353266 \t time: 0.3\n",
      "Epoch: 2051 \tTraining Loss: 1.252056 \tValidation Loss: 1.353481 \t time: 0.3\n",
      "Epoch: 2052 \tTraining Loss: 1.249866 \tValidation Loss: 1.353396 \t time: 0.3\n",
      "Epoch: 2053 \tTraining Loss: 1.250468 \tValidation Loss: 1.353286 \t time: 0.3\n",
      "Epoch: 2054 \tTraining Loss: 1.250122 \tValidation Loss: 1.353039 \t time: 0.3\n",
      "Epoch: 2055 \tTraining Loss: 1.251587 \tValidation Loss: 1.352719 \t time: 0.3\n",
      "Epoch: 2056 \tTraining Loss: 1.252975 \tValidation Loss: 1.352413 \t time: 0.3\n",
      "Validation loss decreased from 1.352593 to 1.352413. Model was saved\n",
      "Epoch: 2057 \tTraining Loss: 1.252483 \tValidation Loss: 1.352152 \t time: 0.3\n",
      "Validation loss decreased from 1.352413 to 1.352152. Model was saved\n",
      "Epoch: 2058 \tTraining Loss: 1.252333 \tValidation Loss: 1.352259 \t time: 0.3\n",
      "Epoch: 2059 \tTraining Loss: 1.251253 \tValidation Loss: 1.352707 \t time: 0.3\n",
      "Epoch: 2060 \tTraining Loss: 1.252453 \tValidation Loss: 1.352958 \t time: 0.3\n",
      "Epoch: 2061 \tTraining Loss: 1.248595 \tValidation Loss: 1.353534 \t time: 0.2\n",
      "Epoch: 2062 \tTraining Loss: 1.253017 \tValidation Loss: 1.353959 \t time: 0.2\n",
      "Epoch: 2063 \tTraining Loss: 1.249619 \tValidation Loss: 1.354103 \t time: 0.3\n",
      "Epoch: 2064 \tTraining Loss: 1.252584 \tValidation Loss: 1.353860 \t time: 0.3\n",
      "Epoch: 2065 \tTraining Loss: 1.251654 \tValidation Loss: 1.353521 \t time: 0.3\n",
      "Epoch: 2066 \tTraining Loss: 1.252168 \tValidation Loss: 1.353223 \t time: 0.2\n",
      "Epoch: 2067 \tTraining Loss: 1.250757 \tValidation Loss: 1.353026 \t time: 0.3\n",
      "Epoch: 2068 \tTraining Loss: 1.254358 \tValidation Loss: 1.352954 \t time: 0.2\n",
      "Epoch: 2069 \tTraining Loss: 1.251272 \tValidation Loss: 1.352885 \t time: 0.2\n",
      "Epoch: 2070 \tTraining Loss: 1.252377 \tValidation Loss: 1.352957 \t time: 0.3\n",
      "Epoch: 2071 \tTraining Loss: 1.252277 \tValidation Loss: 1.353069 \t time: 0.3\n",
      "Epoch: 2072 \tTraining Loss: 1.251855 \tValidation Loss: 1.353146 \t time: 0.3\n",
      "Epoch: 2073 \tTraining Loss: 1.251857 \tValidation Loss: 1.353148 \t time: 0.3\n",
      "Epoch: 2074 \tTraining Loss: 1.252375 \tValidation Loss: 1.353303 \t time: 0.2\n",
      "Epoch: 2075 \tTraining Loss: 1.249408 \tValidation Loss: 1.353304 \t time: 0.2\n",
      "Epoch: 2076 \tTraining Loss: 1.250671 \tValidation Loss: 1.353231 \t time: 0.3\n",
      "Epoch: 2077 \tTraining Loss: 1.248928 \tValidation Loss: 1.353179 \t time: 0.3\n",
      "Epoch: 2078 \tTraining Loss: 1.252935 \tValidation Loss: 1.352888 \t time: 0.3\n",
      "Epoch: 2079 \tTraining Loss: 1.250332 \tValidation Loss: 1.352732 \t time: 0.3\n",
      "Epoch: 2080 \tTraining Loss: 1.251856 \tValidation Loss: 1.352487 \t time: 0.3\n",
      "Epoch: 2081 \tTraining Loss: 1.253728 \tValidation Loss: 1.352152 \t time: 0.2\n",
      "Validation loss decreased from 1.352152 to 1.352152. Model was saved\n",
      "Epoch: 2082 \tTraining Loss: 1.252446 \tValidation Loss: 1.351599 \t time: 0.3\n",
      "Validation loss decreased from 1.352152 to 1.351599. Model was saved\n",
      "Epoch: 2083 \tTraining Loss: 1.250022 \tValidation Loss: 1.351292 \t time: 0.3\n",
      "Validation loss decreased from 1.351599 to 1.351292. Model was saved\n",
      "Epoch: 2084 \tTraining Loss: 1.250587 \tValidation Loss: 1.351196 \t time: 0.2\n",
      "Validation loss decreased from 1.351292 to 1.351196. Model was saved\n",
      "Epoch: 2085 \tTraining Loss: 1.253031 \tValidation Loss: 1.351411 \t time: 0.2\n",
      "Epoch: 2086 \tTraining Loss: 1.250439 \tValidation Loss: 1.351431 \t time: 0.3\n",
      "Epoch: 2087 \tTraining Loss: 1.250697 \tValidation Loss: 1.351725 \t time: 0.3\n",
      "Epoch: 2088 \tTraining Loss: 1.250326 \tValidation Loss: 1.352067 \t time: 0.3\n",
      "Epoch: 2089 \tTraining Loss: 1.249991 \tValidation Loss: 1.352577 \t time: 0.3\n",
      "Epoch: 2090 \tTraining Loss: 1.249422 \tValidation Loss: 1.353136 \t time: 0.3\n",
      "Epoch: 2091 \tTraining Loss: 1.251277 \tValidation Loss: 1.353561 \t time: 0.3\n",
      "Epoch: 2092 \tTraining Loss: 1.252889 \tValidation Loss: 1.353770 \t time: 0.2\n",
      "Epoch: 2093 \tTraining Loss: 1.250836 \tValidation Loss: 1.353685 \t time: 0.3\n",
      "Epoch: 2094 \tTraining Loss: 1.251380 \tValidation Loss: 1.353942 \t time: 0.2\n",
      "Epoch: 2095 \tTraining Loss: 1.249978 \tValidation Loss: 1.354001 \t time: 0.3\n",
      "Epoch: 2096 \tTraining Loss: 1.251855 \tValidation Loss: 1.353731 \t time: 0.3\n",
      "Epoch: 2097 \tTraining Loss: 1.249230 \tValidation Loss: 1.353376 \t time: 0.3\n",
      "Epoch: 2098 \tTraining Loss: 1.249356 \tValidation Loss: 1.353418 \t time: 0.2\n",
      "Epoch: 2099 \tTraining Loss: 1.250231 \tValidation Loss: 1.353402 \t time: 0.3\n",
      "Epoch: 2100 \tTraining Loss: 1.251025 \tValidation Loss: 1.353346 \t time: 0.3\n",
      "Epoch: 2101 \tTraining Loss: 1.251620 \tValidation Loss: 1.353257 \t time: 0.3\n",
      "Epoch: 2102 \tTraining Loss: 1.251353 \tValidation Loss: 1.353216 \t time: 0.3\n",
      "Epoch: 2103 \tTraining Loss: 1.251003 \tValidation Loss: 1.353279 \t time: 0.3\n",
      "Epoch: 2104 \tTraining Loss: 1.249714 \tValidation Loss: 1.353144 \t time: 0.3\n",
      "Epoch: 2105 \tTraining Loss: 1.252209 \tValidation Loss: 1.353002 \t time: 0.2\n",
      "Epoch: 2106 \tTraining Loss: 1.251698 \tValidation Loss: 1.352859 \t time: 0.3\n",
      "Epoch: 2107 \tTraining Loss: 1.250664 \tValidation Loss: 1.352670 \t time: 0.3\n",
      "Epoch: 2108 \tTraining Loss: 1.250071 \tValidation Loss: 1.352547 \t time: 0.3\n",
      "Epoch: 2109 \tTraining Loss: 1.253426 \tValidation Loss: 1.352432 \t time: 0.3\n",
      "Epoch: 2110 \tTraining Loss: 1.250994 \tValidation Loss: 1.352354 \t time: 0.3\n",
      "Epoch: 2111 \tTraining Loss: 1.251564 \tValidation Loss: 1.352184 \t time: 0.3\n",
      "Epoch: 2112 \tTraining Loss: 1.250522 \tValidation Loss: 1.352043 \t time: 0.2\n",
      "Epoch: 2113 \tTraining Loss: 1.251541 \tValidation Loss: 1.351844 \t time: 0.2\n",
      "Epoch: 2114 \tTraining Loss: 1.249916 \tValidation Loss: 1.352063 \t time: 0.3\n",
      "Epoch: 2115 \tTraining Loss: 1.252435 \tValidation Loss: 1.352347 \t time: 0.2\n",
      "Epoch: 2116 \tTraining Loss: 1.247683 \tValidation Loss: 1.352538 \t time: 0.3\n",
      "Epoch: 2117 \tTraining Loss: 1.254525 \tValidation Loss: 1.352884 \t time: 0.3\n",
      "Epoch: 2118 \tTraining Loss: 1.251128 \tValidation Loss: 1.353134 \t time: 0.3\n",
      "Epoch: 2119 \tTraining Loss: 1.251667 \tValidation Loss: 1.353658 \t time: 0.2\n",
      "Epoch: 2120 \tTraining Loss: 1.248509 \tValidation Loss: 1.354060 \t time: 0.3\n",
      "Epoch: 2121 \tTraining Loss: 1.249300 \tValidation Loss: 1.354489 \t time: 0.3\n",
      "Epoch: 2122 \tTraining Loss: 1.250257 \tValidation Loss: 1.354590 \t time: 0.3\n",
      "Epoch: 2123 \tTraining Loss: 1.250431 \tValidation Loss: 1.354371 \t time: 0.3\n",
      "Epoch: 2124 \tTraining Loss: 1.247503 \tValidation Loss: 1.354469 \t time: 0.3\n",
      "Epoch: 2125 \tTraining Loss: 1.250195 \tValidation Loss: 1.354515 \t time: 0.3\n",
      "Epoch: 2126 \tTraining Loss: 1.249691 \tValidation Loss: 1.354588 \t time: 0.3\n",
      "Epoch: 2127 \tTraining Loss: 1.252648 \tValidation Loss: 1.354544 \t time: 0.3\n",
      "Epoch: 2128 \tTraining Loss: 1.247938 \tValidation Loss: 1.354367 \t time: 0.3\n",
      "Epoch: 2129 \tTraining Loss: 1.251101 \tValidation Loss: 1.354082 \t time: 0.2\n",
      "Epoch: 2130 \tTraining Loss: 1.251003 \tValidation Loss: 1.353797 \t time: 0.2\n",
      "Epoch: 2131 \tTraining Loss: 1.248699 \tValidation Loss: 1.353497 \t time: 0.3\n",
      "Epoch: 2132 \tTraining Loss: 1.250197 \tValidation Loss: 1.353264 \t time: 0.3\n",
      "Epoch: 2133 \tTraining Loss: 1.252462 \tValidation Loss: 1.352906 \t time: 0.2\n",
      "Epoch: 2134 \tTraining Loss: 1.250886 \tValidation Loss: 1.352662 \t time: 0.2\n",
      "Epoch: 2135 \tTraining Loss: 1.250359 \tValidation Loss: 1.352516 \t time: 0.3\n",
      "Epoch: 2136 \tTraining Loss: 1.250486 \tValidation Loss: 1.352147 \t time: 0.3\n",
      "Epoch: 2137 \tTraining Loss: 1.249304 \tValidation Loss: 1.351778 \t time: 0.3\n",
      "Epoch: 2138 \tTraining Loss: 1.249318 \tValidation Loss: 1.351665 \t time: 0.2\n",
      "Epoch: 2139 \tTraining Loss: 1.248541 \tValidation Loss: 1.351823 \t time: 0.2\n",
      "Epoch: 2140 \tTraining Loss: 1.251792 \tValidation Loss: 1.352373 \t time: 0.2\n",
      "Epoch: 2141 \tTraining Loss: 1.251810 \tValidation Loss: 1.353204 \t time: 0.2\n",
      "Epoch: 2142 \tTraining Loss: 1.250372 \tValidation Loss: 1.353716 \t time: 0.3\n",
      "Epoch: 2143 \tTraining Loss: 1.248661 \tValidation Loss: 1.354103 \t time: 0.3\n",
      "Epoch: 2144 \tTraining Loss: 1.250084 \tValidation Loss: 1.354251 \t time: 0.3\n",
      "Epoch: 2145 \tTraining Loss: 1.250353 \tValidation Loss: 1.354113 \t time: 0.2\n",
      "Epoch: 2146 \tTraining Loss: 1.250344 \tValidation Loss: 1.353723 \t time: 0.3\n",
      "Epoch: 2147 \tTraining Loss: 1.250384 \tValidation Loss: 1.353361 \t time: 0.3\n",
      "Epoch: 2148 \tTraining Loss: 1.248780 \tValidation Loss: 1.353266 \t time: 0.3\n",
      "Epoch: 2149 \tTraining Loss: 1.250561 \tValidation Loss: 1.353214 \t time: 0.3\n",
      "Epoch: 2150 \tTraining Loss: 1.250413 \tValidation Loss: 1.353406 \t time: 0.3\n",
      "Epoch: 2151 \tTraining Loss: 1.252491 \tValidation Loss: 1.353657 \t time: 0.3\n",
      "Epoch: 2152 \tTraining Loss: 1.251206 \tValidation Loss: 1.353629 \t time: 0.3\n",
      "Epoch: 2153 \tTraining Loss: 1.249790 \tValidation Loss: 1.353651 \t time: 0.3\n",
      "Epoch: 2154 \tTraining Loss: 1.252715 \tValidation Loss: 1.353729 \t time: 0.3\n",
      "Epoch: 2155 \tTraining Loss: 1.249230 \tValidation Loss: 1.354004 \t time: 0.3\n",
      "Epoch: 2156 \tTraining Loss: 1.247974 \tValidation Loss: 1.354407 \t time: 0.3\n",
      "Epoch: 2157 \tTraining Loss: 1.249152 \tValidation Loss: 1.354938 \t time: 0.3\n",
      "Epoch: 2158 \tTraining Loss: 1.248474 \tValidation Loss: 1.355157 \t time: 0.3\n",
      "Epoch: 2159 \tTraining Loss: 1.251839 \tValidation Loss: 1.355384 \t time: 0.3\n",
      "Epoch: 2160 \tTraining Loss: 1.251120 \tValidation Loss: 1.355542 \t time: 0.3\n",
      "Epoch: 2161 \tTraining Loss: 1.250071 \tValidation Loss: 1.355386 \t time: 0.3\n",
      "Epoch: 2162 \tTraining Loss: 1.250147 \tValidation Loss: 1.354892 \t time: 0.3\n",
      "Epoch: 2163 \tTraining Loss: 1.248229 \tValidation Loss: 1.354417 \t time: 0.3\n",
      "Epoch: 2164 \tTraining Loss: 1.250347 \tValidation Loss: 1.354011 \t time: 0.3\n",
      "Epoch: 2165 \tTraining Loss: 1.246900 \tValidation Loss: 1.353500 \t time: 0.3\n",
      "Epoch: 2166 \tTraining Loss: 1.249038 \tValidation Loss: 1.353063 \t time: 0.3\n",
      "Epoch: 2167 \tTraining Loss: 1.251066 \tValidation Loss: 1.352759 \t time: 0.3\n",
      "Epoch: 2168 \tTraining Loss: 1.250797 \tValidation Loss: 1.352557 \t time: 0.3\n",
      "Epoch: 2169 \tTraining Loss: 1.249567 \tValidation Loss: 1.352498 \t time: 0.3\n",
      "Epoch: 2170 \tTraining Loss: 1.249825 \tValidation Loss: 1.352290 \t time: 0.3\n",
      "Epoch: 2171 \tTraining Loss: 1.248329 \tValidation Loss: 1.352370 \t time: 0.3\n",
      "Epoch: 2172 \tTraining Loss: 1.250146 \tValidation Loss: 1.352355 \t time: 0.3\n",
      "Epoch: 2173 \tTraining Loss: 1.250460 \tValidation Loss: 1.352102 \t time: 0.3\n",
      "Epoch: 2174 \tTraining Loss: 1.251297 \tValidation Loss: 1.352046 \t time: 0.3\n",
      "Epoch: 2175 \tTraining Loss: 1.246556 \tValidation Loss: 1.352071 \t time: 0.2\n",
      "Epoch: 2176 \tTraining Loss: 1.250387 \tValidation Loss: 1.352318 \t time: 0.3\n",
      "Epoch: 2177 \tTraining Loss: 1.248175 \tValidation Loss: 1.352670 \t time: 0.3\n",
      "Epoch: 2178 \tTraining Loss: 1.248314 \tValidation Loss: 1.352937 \t time: 0.3\n",
      "Epoch: 2179 \tTraining Loss: 1.248516 \tValidation Loss: 1.353092 \t time: 0.3\n",
      "Epoch: 2180 \tTraining Loss: 1.249735 \tValidation Loss: 1.353253 \t time: 0.3\n",
      "Epoch: 2181 \tTraining Loss: 1.248461 \tValidation Loss: 1.353363 \t time: 0.3\n",
      "Epoch: 2182 \tTraining Loss: 1.249991 \tValidation Loss: 1.353268 \t time: 0.3\n",
      "Epoch: 2183 \tTraining Loss: 1.250799 \tValidation Loss: 1.353227 \t time: 0.2\n",
      "Epoch: 2184 \tTraining Loss: 1.249996 \tValidation Loss: 1.353278 \t time: 0.3\n",
      "Epoch: 2185 \tTraining Loss: 1.248302 \tValidation Loss: 1.353109 \t time: 0.3\n",
      "Epoch: 2186 \tTraining Loss: 1.249140 \tValidation Loss: 1.352858 \t time: 0.2\n",
      "Epoch: 2187 \tTraining Loss: 1.249807 \tValidation Loss: 1.352706 \t time: 0.3\n",
      "Epoch: 2188 \tTraining Loss: 1.247327 \tValidation Loss: 1.352655 \t time: 0.3\n",
      "Epoch: 2189 \tTraining Loss: 1.247187 \tValidation Loss: 1.352691 \t time: 0.3\n",
      "Epoch: 2190 \tTraining Loss: 1.249414 \tValidation Loss: 1.352774 \t time: 0.3\n",
      "Epoch: 2191 \tTraining Loss: 1.246877 \tValidation Loss: 1.352643 \t time: 0.3\n",
      "Epoch: 2192 \tTraining Loss: 1.249451 \tValidation Loss: 1.352544 \t time: 0.3\n",
      "Epoch: 2193 \tTraining Loss: 1.247277 \tValidation Loss: 1.352504 \t time: 0.3\n",
      "Epoch: 2194 \tTraining Loss: 1.248193 \tValidation Loss: 1.352353 \t time: 0.3\n",
      "Epoch: 2195 \tTraining Loss: 1.248222 \tValidation Loss: 1.352156 \t time: 0.3\n",
      "Epoch: 2196 \tTraining Loss: 1.248971 \tValidation Loss: 1.351918 \t time: 0.3\n",
      "Epoch: 2197 \tTraining Loss: 1.249329 \tValidation Loss: 1.351527 \t time: 0.3\n",
      "Epoch: 2198 \tTraining Loss: 1.249413 \tValidation Loss: 1.351217 \t time: 0.3\n",
      "Epoch: 2199 \tTraining Loss: 1.249890 \tValidation Loss: 1.350988 \t time: 0.3\n",
      "Validation loss decreased from 1.351196 to 1.350988. Model was saved\n",
      "Epoch: 2200 \tTraining Loss: 1.250313 \tValidation Loss: 1.350755 \t time: 0.3\n",
      "Validation loss decreased from 1.350988 to 1.350755. Model was saved\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "    \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(2200, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.348660\n",
      "\n",
      "\n",
      "Test Accuracy: 60% (118/194)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 5, 3, 1, 2, 5, 1, 1, 3, 1, 3, 5, 5, 3, 5, 5, 0, 3, 5, 5,\n",
       "       2, 5, 0, 3, 3, 1, 5, 5, 3, 2, 2, 5, 3, 2, 3, 5, 0, 0, 1, 3, 2, 3,\n",
       "       5, 5, 1, 5, 0, 0, 2, 5, 0, 0, 3, 3, 0, 3, 0, 1, 1, 1, 3, 3, 3, 3,\n",
       "       5, 5, 3, 3, 2, 0, 2, 1, 2, 1, 0, 0, 3, 5, 3, 5, 3, 3, 0, 0, 3, 2,\n",
       "       3, 5, 5, 3, 2, 3, 5, 5, 1, 3, 5, 3, 2, 5, 3, 3, 3, 1, 5, 5, 1, 3,\n",
       "       5, 5, 1, 5, 5, 3, 3, 3, 3, 5, 5, 3, 5, 3, 2, 3, 3, 3, 3, 0, 1, 1,\n",
       "       5, 3, 2, 2, 3, 0, 2, 0, 5, 0, 3, 3, 0, 2, 3, 2, 0, 3, 3, 5, 2, 1,\n",
       "       1, 0, 5, 1, 3, 5, 1, 0, 0, 1, 0, 2, 0, 2, 2, 5, 2, 2, 0, 5, 3, 3,\n",
       "       3, 2, 0, 3, 3, 1, 0, 3, 3, 5, 3, 3, 1, 5, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,l = next(iter(loaders['test']))\n",
    "if use_cuda:\n",
    "    i, l = i.cuda(), l.cuda()\n",
    "\n",
    "output = model(i)\n",
    "\n",
    "result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([31.,  0., 28.,  0., 27.,  0., 63.,  0.,  0., 45.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = result[:,0]\n",
    "plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([32.,  0., 32.,  0., 32.,  0., 32.,  0., 33., 33.]),\n",
       " array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
