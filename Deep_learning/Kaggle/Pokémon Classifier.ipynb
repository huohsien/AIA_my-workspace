{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6\n",
    "# how many data per batch to load\n",
    "batch_size = 10000\n",
    "# data split ratio\n",
    "train_ratio = 0.99\n",
    "test_ratio = 0.08\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "lr=0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Counter({'class_0': 1611, 'class_2': 1478, 'class_5': 1411, 'class_1': 920, 'class_3': 889, 'class_4': 851})\n",
      "After:\n",
      "Counter({'class_0': 1611, 'class_1': 1611, 'class_2': 1611, 'class_3': 1611, 'class_4': 1611, 'class_5': 1611})\n"
     ]
    }
   ],
   "source": [
    "# make number of data for each class equal\n",
    "#\n",
    "from collections import Counter\n",
    "\n",
    "class_counter = Counter()\n",
    "\n",
    "class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('Before:')\n",
    "print(class_counter)\n",
    "\n",
    "max_count = -np.Inf\n",
    "for i in range(number_of_class):\n",
    "    if class_counter['class_' + str(i)] > max_count:\n",
    "        max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "    num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "    num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "    for j in range(num_resample_batch):\n",
    "        add_df = train_classified[i]\n",
    "        train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "        train =  train.append(df_to_be_added)\n",
    "        \n",
    "    df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "    train =  train.append(df_to_be_added)\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    class_counter['class_' + str(i)] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('After:')\n",
    "print(class_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9666, 297)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "# features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9569, 297), (89, 297), (8, 297))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "# a =plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 160)\n",
    "        self.fc2 = nn.Linear(160, 40)\n",
    "        self.fc3 = nn.Linear(40, 6)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "#             print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "#         print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tValidation loss decreased from inf to 1.811338. Model was saved\n",
      "Epoch: 2 \tValidation loss decreased from 1.811338 to 1.800114. Model was saved\n",
      "Epoch: 3 \tValidation loss decreased from 1.800114 to 1.792172. Model was saved\n",
      "Epoch: 4 \tValidation loss decreased from 1.792172 to 1.789877. Model was saved\n",
      "Epoch: 5 \tValidation loss decreased from 1.789877 to 1.788481. Model was saved\n",
      "Epoch: 6 \tValidation loss decreased from 1.788481 to 1.784302. Model was saved\n",
      "Epoch: 7 \tValidation loss decreased from 1.784302 to 1.776664. Model was saved\n",
      "Epoch: 8 \tValidation loss decreased from 1.776664 to 1.766786. Model was saved\n",
      "Epoch: 9 \tValidation loss decreased from 1.766786 to 1.755084. Model was saved\n",
      "Epoch: 10 \tValidation loss decreased from 1.755084 to 1.741509. Model was saved\n",
      "Epoch: 11 \tValidation loss decreased from 1.741509 to 1.728378. Model was saved\n",
      "Epoch: 12 \tValidation loss decreased from 1.728378 to 1.713992. Model was saved\n",
      "Epoch: 13 \tValidation loss decreased from 1.713992 to 1.700964. Model was saved\n",
      "Epoch: 14 \tValidation loss decreased from 1.700964 to 1.689506. Model was saved\n",
      "Epoch: 15 \tValidation loss decreased from 1.689506 to 1.677587. Model was saved\n",
      "Epoch: 16 \tValidation loss decreased from 1.677587 to 1.667727. Model was saved\n",
      "Epoch: 17 \tValidation loss decreased from 1.667727 to 1.652264. Model was saved\n",
      "Epoch: 18 \tValidation loss decreased from 1.652264 to 1.646395. Model was saved\n",
      "Epoch: 19 \tValidation loss decreased from 1.646395 to 1.633680. Model was saved\n",
      "Epoch: 20 \tValidation loss decreased from 1.633680 to 1.631440. Model was saved\n",
      "Epoch: 21 \tValidation loss decreased from 1.631440 to 1.614640. Model was saved\n",
      "Epoch: 22 \tValidation loss decreased from 1.614640 to 1.604674. Model was saved\n",
      "Epoch: 23 \tValidation loss decreased from 1.604674 to 1.600942. Model was saved\n",
      "Epoch: 24 \tValidation loss decreased from 1.600942 to 1.595161. Model was saved\n",
      "Epoch: 25 \tValidation loss decreased from 1.595161 to 1.581668. Model was saved\n",
      "Epoch: 26 \tValidation loss decreased from 1.581668 to 1.575375. Model was saved\n",
      "Epoch: 27 \tValidation loss decreased from 1.575375 to 1.574089. Model was saved\n",
      "Epoch: 28 \tValidation loss decreased from 1.574089 to 1.568956. Model was saved\n",
      "Epoch: 29 \tValidation loss decreased from 1.568956 to 1.566456. Model was saved\n",
      "Epoch: 31 \tValidation loss decreased from 1.566456 to 1.565056. Model was saved\n",
      "Epoch: 32 \tValidation loss decreased from 1.565056 to 1.563300. Model was saved\n",
      "Epoch: 47 \tValidation loss decreased from 1.563300 to 1.562479. Model was saved\n",
      "Epoch: 48 \tValidation loss decreased from 1.562479 to 1.558790. Model was saved\n",
      "Epoch: 49 \tValidation loss decreased from 1.558790 to 1.558017. Model was saved\n",
      "Epoch: 50 \tValidation loss decreased from 1.558017 to 1.555855. Model was saved\n",
      "Epoch: 51 \tValidation loss decreased from 1.555855 to 1.550512. Model was saved\n",
      "Epoch: 53 \tValidation loss decreased from 1.550512 to 1.546228. Model was saved\n",
      "Epoch: 56 \tValidation loss decreased from 1.546228 to 1.546139. Model was saved\n",
      "Epoch: 57 \tValidation loss decreased from 1.546139 to 1.545959. Model was saved\n",
      "Epoch: 58 \tValidation loss decreased from 1.545959 to 1.542238. Model was saved\n",
      "Epoch: 62 \tValidation loss decreased from 1.542238 to 1.539584. Model was saved\n",
      "Epoch: 63 \tValidation loss decreased from 1.539584 to 1.539411. Model was saved\n",
      "Epoch: 64 \tValidation loss decreased from 1.539411 to 1.539113. Model was saved\n",
      "Epoch: 65 \tValidation loss decreased from 1.539113 to 1.536214. Model was saved\n",
      "Epoch: 66 \tValidation loss decreased from 1.536214 to 1.533970. Model was saved\n",
      "Epoch: 68 \tValidation loss decreased from 1.533970 to 1.532168. Model was saved\n",
      "Epoch: 69 \tValidation loss decreased from 1.532168 to 1.527222. Model was saved\n",
      "Epoch: 71 \tValidation loss decreased from 1.527222 to 1.523993. Model was saved\n",
      "Epoch: 72 \tValidation loss decreased from 1.523993 to 1.517376. Model was saved\n",
      "Epoch: 73 \tValidation loss decreased from 1.517376 to 1.517029. Model was saved\n",
      "Epoch: 74 \tValidation loss decreased from 1.517029 to 1.515205. Model was saved\n",
      "Epoch: 75 \tValidation loss decreased from 1.515205 to 1.510396. Model was saved\n",
      "Epoch: 76 \tValidation loss decreased from 1.510396 to 1.509606. Model was saved\n",
      "Epoch: 78 \tValidation loss decreased from 1.509606 to 1.505656. Model was saved\n",
      "Epoch: 79 \tValidation loss decreased from 1.505656 to 1.503443. Model was saved\n",
      "Epoch: 81 \tValidation loss decreased from 1.503443 to 1.500953. Model was saved\n",
      "Epoch: 82 \tValidation loss decreased from 1.500953 to 1.498125. Model was saved\n",
      "Epoch: 84 \tValidation loss decreased from 1.498125 to 1.496369. Model was saved\n",
      "Epoch: 85 \tValidation loss decreased from 1.496369 to 1.493784. Model was saved\n",
      "Epoch: 87 \tValidation loss decreased from 1.493784 to 1.492410. Model was saved\n",
      "Epoch: 88 \tValidation loss decreased from 1.492410 to 1.490519. Model was saved\n",
      "Epoch: 90 \tValidation loss decreased from 1.490519 to 1.488240. Model was saved\n",
      "Epoch: 93 \tValidation loss decreased from 1.488240 to 1.483318. Model was saved\n",
      "Epoch: 95 \tValidation loss decreased from 1.483318 to 1.481132. Model was saved\n",
      "Epoch: 96 \tValidation loss decreased from 1.481132 to 1.480307. Model was saved\n",
      "Epoch: 98 \tValidation loss decreased from 1.480307 to 1.477923. Model was saved\n",
      "Epoch: 100 \tValidation loss decreased from 1.477923 to 1.477782. Model was saved\n",
      "Epoch: 103 \tValidation loss decreased from 1.477782 to 1.477490. Model was saved\n",
      "Epoch: 106 \tValidation loss decreased from 1.477490 to 1.477114. Model was saved\n",
      "Epoch: 108 \tValidation loss decreased from 1.477114 to 1.476406. Model was saved\n",
      "Epoch: 110 \tValidation loss decreased from 1.476406 to 1.476375. Model was saved\n",
      "Epoch: 111 \tValidation loss decreased from 1.476375 to 1.474388. Model was saved\n",
      "Epoch: 114 \tValidation loss decreased from 1.474388 to 1.473466. Model was saved\n",
      "Epoch: 117 \tValidation loss decreased from 1.473466 to 1.470775. Model was saved\n",
      "Epoch: 120 \tValidation loss decreased from 1.470775 to 1.468652. Model was saved\n",
      "Epoch: 121 \tValidation loss decreased from 1.468652 to 1.465748. Model was saved\n",
      "Epoch: 131 \tValidation loss decreased from 1.465748 to 1.464983. Model was saved\n",
      "Epoch: 139 \tValidation loss decreased from 1.464983 to 1.461666. Model was saved\n",
      "Epoch: 142 \tValidation loss decreased from 1.461666 to 1.459324. Model was saved\n",
      "Epoch: 144 \tValidation loss decreased from 1.459324 to 1.458607. Model was saved\n",
      "Epoch: 148 \tValidation loss decreased from 1.458607 to 1.457456. Model was saved\n",
      "Epoch: 150 \tValidation loss decreased from 1.457456 to 1.456124. Model was saved\n",
      "Epoch: 155 \tValidation loss decreased from 1.456124 to 1.453988. Model was saved\n",
      "Epoch: 157 \tValidation loss decreased from 1.453988 to 1.450650. Model was saved\n",
      "Epoch: 162 \tValidation loss decreased from 1.450650 to 1.450426. Model was saved\n",
      "Epoch: 168 \tValidation loss decreased from 1.450426 to 1.448059. Model was saved\n",
      "Epoch: 176 \tValidation loss decreased from 1.448059 to 1.445203. Model was saved\n",
      "Epoch: 178 \tValidation loss decreased from 1.445203 to 1.443802. Model was saved\n",
      "Epoch: 180 \tValidation loss decreased from 1.443802 to 1.443801. Model was saved\n",
      "Epoch: 183 \tValidation loss decreased from 1.443801 to 1.442276. Model was saved\n",
      "Epoch: 185 \tValidation loss decreased from 1.442276 to 1.441377. Model was saved\n",
      "Epoch: 188 \tValidation loss decreased from 1.441377 to 1.440803. Model was saved\n",
      "Epoch: 190 \tValidation loss decreased from 1.440803 to 1.440432. Model was saved\n",
      "Epoch: 191 \tValidation loss decreased from 1.440432 to 1.438995. Model was saved\n",
      "Epoch: 194 \tValidation loss decreased from 1.438995 to 1.438516. Model was saved\n",
      "Epoch: 195 \tValidation loss decreased from 1.438516 to 1.436294. Model was saved\n",
      "Epoch: 196 \tValidation loss decreased from 1.436294 to 1.434635. Model was saved\n",
      "Epoch: 198 \tValidation loss decreased from 1.434635 to 1.432515. Model was saved\n",
      "Epoch: 199 \tValidation loss decreased from 1.432515 to 1.429583. Model was saved\n",
      "Epoch: 202 \tValidation loss decreased from 1.429583 to 1.426005. Model was saved\n",
      "Epoch: 205 \tValidation loss decreased from 1.426005 to 1.422069. Model was saved\n",
      "Epoch: 206 \tValidation loss decreased from 1.422069 to 1.420119. Model was saved\n",
      "Epoch: 207 \tValidation loss decreased from 1.420119 to 1.419416. Model was saved\n",
      "Epoch: 209 \tValidation loss decreased from 1.419416 to 1.412787. Model was saved\n",
      "Epoch: 210 \tValidation loss decreased from 1.412787 to 1.411168. Model was saved\n",
      "Epoch: 211 \tValidation loss decreased from 1.411168 to 1.409785. Model was saved\n",
      "Epoch: 213 \tValidation loss decreased from 1.409785 to 1.408397. Model was saved\n",
      "Epoch: 215 \tValidation loss decreased from 1.408397 to 1.406809. Model was saved\n",
      "Epoch: 217 \tValidation loss decreased from 1.406809 to 1.404109. Model was saved\n",
      "Epoch: 218 \tValidation loss decreased from 1.404109 to 1.403732. Model was saved\n",
      "Epoch: 221 \tValidation loss decreased from 1.403732 to 1.402641. Model was saved\n",
      "Epoch: 222 \tValidation loss decreased from 1.402641 to 1.402188. Model was saved\n",
      "Epoch: 225 \tValidation loss decreased from 1.402188 to 1.400028. Model was saved\n",
      "Epoch: 226 \tValidation loss decreased from 1.400028 to 1.397838. Model was saved\n",
      "Epoch: 237 \tValidation loss decreased from 1.397838 to 1.396589. Model was saved\n",
      "Epoch: 240 \tValidation loss decreased from 1.396589 to 1.395586. Model was saved\n",
      "Epoch: 244 \tValidation loss decreased from 1.395586 to 1.394629. Model was saved\n",
      "Epoch: 247 \tValidation loss decreased from 1.394629 to 1.393901. Model was saved\n",
      "Epoch: 250 \tValidation loss decreased from 1.393901 to 1.393405. Model was saved\n",
      "Epoch: 269 \tValidation loss decreased from 1.393405 to 1.392772. Model was saved\n",
      "Epoch: 271 \tValidation loss decreased from 1.392772 to 1.392081. Model was saved\n",
      "Epoch: 273 \tValidation loss decreased from 1.392081 to 1.390528. Model was saved\n",
      "Epoch: 278 \tValidation loss decreased from 1.390528 to 1.390079. Model was saved\n",
      "Epoch: 287 \tValidation loss decreased from 1.390079 to 1.389686. Model was saved\n",
      "Epoch: 289 \tValidation loss decreased from 1.389686 to 1.388766. Model was saved\n",
      "Epoch: 295 \tValidation loss decreased from 1.388766 to 1.387928. Model was saved\n",
      "Epoch: 296 \tValidation loss decreased from 1.387928 to 1.387770. Model was saved\n",
      "Epoch: 297 \tValidation loss decreased from 1.387770 to 1.387739. Model was saved\n",
      "Epoch: 298 \tValidation loss decreased from 1.387739 to 1.387295. Model was saved\n",
      "Epoch: 299 \tValidation loss decreased from 1.387295 to 1.387194. Model was saved\n",
      "Epoch: 301 \tValidation loss decreased from 1.387194 to 1.386907. Model was saved\n",
      "Epoch: 305 \tValidation loss decreased from 1.386907 to 1.386865. Model was saved\n",
      "Epoch: 306 \tValidation loss decreased from 1.386865 to 1.386530. Model was saved\n",
      "Epoch: 307 \tValidation loss decreased from 1.386530 to 1.386374. Model was saved\n",
      "Epoch: 308 \tValidation loss decreased from 1.386374 to 1.386276. Model was saved\n",
      "Epoch: 309 \tValidation loss decreased from 1.386276 to 1.386180. Model was saved\n",
      "Epoch: 311 \tValidation loss decreased from 1.386180 to 1.385477. Model was saved\n",
      "Epoch: 312 \tValidation loss decreased from 1.385477 to 1.385006. Model was saved\n",
      "Epoch: 315 \tValidation loss decreased from 1.385006 to 1.384906. Model was saved\n",
      "Epoch: 317 \tValidation loss decreased from 1.384906 to 1.384299. Model was saved\n",
      "Epoch: 323 \tValidation loss decreased from 1.384299 to 1.383964. Model was saved\n",
      "Epoch: 344 \tValidation loss decreased from 1.383964 to 1.383144. Model was saved\n",
      "Epoch: 352 \tValidation loss decreased from 1.383144 to 1.382544. Model was saved\n",
      "Epoch: 355 \tValidation loss decreased from 1.382544 to 1.382132. Model was saved\n",
      "Epoch: 357 \tValidation loss decreased from 1.382132 to 1.382036. Model was saved\n",
      "Epoch: 358 \tValidation loss decreased from 1.382036 to 1.381557. Model was saved\n",
      "Epoch: 359 \tValidation loss decreased from 1.381557 to 1.381027. Model was saved\n",
      "Epoch: 368 \tValidation loss decreased from 1.381027 to 1.380803. Model was saved\n",
      "Epoch: 396 \tValidation loss decreased from 1.380803 to 1.380508. Model was saved\n",
      "Epoch: 398 \tValidation loss decreased from 1.380508 to 1.379622. Model was saved\n",
      "Epoch: 408 \tValidation loss decreased from 1.379622 to 1.379017. Model was saved\n",
      "Epoch: 409 \tValidation loss decreased from 1.379017 to 1.378734. Model was saved\n",
      "Epoch: 410 \tValidation loss decreased from 1.378734 to 1.378553. Model was saved\n",
      "Epoch: 411 \tValidation loss decreased from 1.378553 to 1.377794. Model was saved\n",
      "Epoch: 413 \tValidation loss decreased from 1.377794 to 1.377485. Model was saved\n",
      "Epoch: 415 \tValidation loss decreased from 1.377485 to 1.377260. Model was saved\n",
      "Epoch: 417 \tValidation loss decreased from 1.377260 to 1.376826. Model was saved\n",
      "Epoch: 419 \tValidation loss decreased from 1.376826 to 1.375941. Model was saved\n",
      "Epoch: 420 \tValidation loss decreased from 1.375941 to 1.375463. Model was saved\n",
      "Epoch: 421 \tValidation loss decreased from 1.375463 to 1.374469. Model was saved\n",
      "Epoch: 422 \tValidation loss decreased from 1.374469 to 1.373377. Model was saved\n",
      "Epoch: 423 \tValidation loss decreased from 1.373377 to 1.372367. Model was saved\n",
      "Epoch: 424 \tValidation loss decreased from 1.372367 to 1.371107. Model was saved\n",
      "Epoch: 425 \tValidation loss decreased from 1.371107 to 1.370596. Model was saved\n",
      "Epoch: 426 \tValidation loss decreased from 1.370596 to 1.369475. Model was saved\n",
      "Epoch: 428 \tValidation loss decreased from 1.369475 to 1.368658. Model was saved\n",
      "Epoch: 430 \tValidation loss decreased from 1.368658 to 1.368216. Model was saved\n",
      "Epoch: 432 \tValidation loss decreased from 1.368216 to 1.367489. Model was saved\n",
      "Epoch: 505 \tValidation loss decreased from 1.367489 to 1.367343. Model was saved\n",
      "Epoch: 506 \tValidation loss decreased from 1.367343 to 1.367301. Model was saved\n",
      "Epoch: 517 \tValidation loss decreased from 1.367301 to 1.367272. Model was saved\n",
      "Epoch: 518 \tValidation loss decreased from 1.367272 to 1.366949. Model was saved\n",
      "Epoch: 519 \tValidation loss decreased from 1.366949 to 1.366719. Model was saved\n",
      "Epoch: 520 \tValidation loss decreased from 1.366719 to 1.366582. Model was saved\n",
      "Epoch: 521 \tValidation loss decreased from 1.366582 to 1.366488. Model was saved\n",
      "Epoch: 522 \tValidation loss decreased from 1.366488 to 1.366312. Model was saved\n",
      "Epoch: 523 \tValidation loss decreased from 1.366312 to 1.365773. Model was saved\n",
      "Epoch: 524 \tValidation loss decreased from 1.365773 to 1.365249. Model was saved\n",
      "Epoch: 525 \tValidation loss decreased from 1.365249 to 1.365138. Model was saved\n",
      "Epoch: 526 \tValidation loss decreased from 1.365138 to 1.365119. Model was saved\n",
      "Epoch: 527 \tValidation loss decreased from 1.365119 to 1.364728. Model was saved\n",
      "Epoch: 528 \tValidation loss decreased from 1.364728 to 1.364063. Model was saved\n",
      "Epoch: 529 \tValidation loss decreased from 1.364063 to 1.363376. Model was saved\n",
      "Epoch: 530 \tValidation loss decreased from 1.363376 to 1.362779. Model was saved\n",
      "Epoch: 531 \tValidation loss decreased from 1.362779 to 1.362114. Model was saved\n",
      "Epoch: 532 \tValidation loss decreased from 1.362114 to 1.361216. Model was saved\n",
      "Epoch: 533 \tValidation loss decreased from 1.361216 to 1.360235. Model was saved\n",
      "Epoch: 534 \tValidation loss decreased from 1.360235 to 1.359483. Model was saved\n",
      "Epoch: 535 \tValidation loss decreased from 1.359483 to 1.359004. Model was saved\n",
      "Epoch: 536 \tValidation loss decreased from 1.359004 to 1.358630. Model was saved\n",
      "Epoch: 537 \tValidation loss decreased from 1.358630 to 1.358319. Model was saved\n",
      "Epoch: 538 \tValidation loss decreased from 1.358319 to 1.358147. Model was saved\n",
      "Epoch: 539 \tValidation loss decreased from 1.358147 to 1.358080. Model was saved\n",
      "Epoch: 540 \tValidation loss decreased from 1.358080 to 1.358017. Model was saved\n",
      "Epoch: 541 \tValidation loss decreased from 1.358017 to 1.357863. Model was saved\n",
      "Epoch: 542 \tValidation loss decreased from 1.357863 to 1.357682. Model was saved\n",
      "Epoch: 543 \tValidation loss decreased from 1.357682 to 1.357619. Model was saved\n",
      "Epoch: 545 \tValidation loss decreased from 1.357619 to 1.357526. Model was saved\n",
      "Epoch: 546 \tValidation loss decreased from 1.357526 to 1.357247. Model was saved\n",
      "Epoch: 547 \tValidation loss decreased from 1.357247 to 1.357045. Model was saved\n",
      "Epoch: 548 \tValidation loss decreased from 1.357045 to 1.356982. Model was saved\n",
      "Epoch: 549 \tValidation loss decreased from 1.356982 to 1.356954. Model was saved\n",
      "Epoch: 550 \tValidation loss decreased from 1.356954 to 1.356911. Model was saved\n",
      "Epoch: 551 \tValidation loss decreased from 1.356911 to 1.356850. Model was saved\n",
      "Epoch: 552 \tValidation loss decreased from 1.356850 to 1.356794. Model was saved\n",
      "Epoch: 553 \tValidation loss decreased from 1.356794 to 1.356778. Model was saved\n",
      "Epoch: 554 \tValidation loss decreased from 1.356778 to 1.356716. Model was saved\n",
      "Epoch: 555 \tValidation loss decreased from 1.356716 to 1.356584. Model was saved\n",
      "Epoch: 556 \tValidation loss decreased from 1.356584 to 1.356492. Model was saved\n",
      "Epoch: 557 \tValidation loss decreased from 1.356492 to 1.356421. Model was saved\n",
      "Epoch: 558 \tValidation loss decreased from 1.356421 to 1.356279. Model was saved\n",
      "Epoch: 559 \tValidation loss decreased from 1.356279 to 1.356103. Model was saved\n",
      "Epoch: 560 \tValidation loss decreased from 1.356103 to 1.355938. Model was saved\n",
      "Epoch: 561 \tValidation loss decreased from 1.355938 to 1.355791. Model was saved\n",
      "Epoch: 562 \tValidation loss decreased from 1.355791 to 1.355703. Model was saved\n",
      "Epoch: 563 \tValidation loss decreased from 1.355703 to 1.355606. Model was saved\n",
      "Epoch: 564 \tValidation loss decreased from 1.355606 to 1.355463. Model was saved\n",
      "Epoch: 565 \tValidation loss decreased from 1.355463 to 1.355369. Model was saved\n",
      "Epoch: 566 \tValidation loss decreased from 1.355369 to 1.355293. Model was saved\n",
      "Epoch: 567 \tValidation loss decreased from 1.355293 to 1.355166. Model was saved\n",
      "Epoch: 568 \tValidation loss decreased from 1.355166 to 1.355018. Model was saved\n",
      "Epoch: 569 \tValidation loss decreased from 1.355018 to 1.354823. Model was saved\n",
      "Epoch: 570 \tValidation loss decreased from 1.354823 to 1.354540. Model was saved\n",
      "Epoch: 571 \tValidation loss decreased from 1.354540 to 1.354149. Model was saved\n",
      "Epoch: 572 \tValidation loss decreased from 1.354149 to 1.353701. Model was saved\n",
      "Epoch: 573 \tValidation loss decreased from 1.353701 to 1.353227. Model was saved\n",
      "Epoch: 574 \tValidation loss decreased from 1.353227 to 1.352752. Model was saved\n",
      "Epoch: 575 \tValidation loss decreased from 1.352752 to 1.352333. Model was saved\n",
      "Epoch: 576 \tValidation loss decreased from 1.352333 to 1.352009. Model was saved\n",
      "Epoch: 577 \tValidation loss decreased from 1.352009 to 1.351819. Model was saved\n",
      "Epoch: 578 \tValidation loss decreased from 1.351819 to 1.351700. Model was saved\n",
      "Epoch: 579 \tValidation loss decreased from 1.351700 to 1.351615. Model was saved\n",
      "Epoch: 774 \tValidation loss decreased from 1.351615 to 1.351571. Model was saved\n",
      "Epoch: 775 \tValidation loss decreased from 1.351571 to 1.351470. Model was saved\n",
      "Epoch: 776 \tValidation loss decreased from 1.351470 to 1.351348. Model was saved\n",
      "Epoch: 777 \tValidation loss decreased from 1.351348 to 1.351223. Model was saved\n",
      "Epoch: 778 \tValidation loss decreased from 1.351223 to 1.351082. Model was saved\n",
      "Epoch: 779 \tValidation loss decreased from 1.351082 to 1.350913. Model was saved\n",
      "Epoch: 780 \tValidation loss decreased from 1.350913 to 1.350738. Model was saved\n",
      "Epoch: 781 \tValidation loss decreased from 1.350738 to 1.350557. Model was saved\n",
      "Epoch: 782 \tValidation loss decreased from 1.350557 to 1.350365. Model was saved\n",
      "Epoch: 783 \tValidation loss decreased from 1.350365 to 1.350195. Model was saved\n",
      "Epoch: 784 \tValidation loss decreased from 1.350195 to 1.350015. Model was saved\n",
      "Epoch: 785 \tValidation loss decreased from 1.350015 to 1.349810. Model was saved\n",
      "Epoch: 786 \tValidation loss decreased from 1.349810 to 1.349649. Model was saved\n",
      "Epoch: 787 \tValidation loss decreased from 1.349649 to 1.349422. Model was saved\n",
      "Epoch: 788 \tValidation loss decreased from 1.349422 to 1.349042. Model was saved\n",
      "Epoch: 789 \tValidation loss decreased from 1.349042 to 1.348708. Model was saved\n",
      "Epoch: 790 \tValidation loss decreased from 1.348708 to 1.348347. Model was saved\n",
      "Epoch: 791 \tValidation loss decreased from 1.348347 to 1.348047. Model was saved\n",
      "Epoch: 792 \tValidation loss decreased from 1.348047 to 1.347750. Model was saved\n",
      "Epoch: 793 \tValidation loss decreased from 1.347750 to 1.347512. Model was saved\n",
      "Epoch: 794 \tValidation loss decreased from 1.347512 to 1.347183. Model was saved\n",
      "Epoch: 795 \tValidation loss decreased from 1.347183 to 1.347028. Model was saved\n",
      "Epoch: 796 \tValidation loss decreased from 1.347028 to 1.346698. Model was saved\n",
      "Epoch: 797 \tValidation loss decreased from 1.346698 to 1.346629. Model was saved\n",
      "Epoch: 798 \tValidation loss decreased from 1.346629 to 1.346343. Model was saved\n",
      "Epoch: 800 \tValidation loss decreased from 1.346343 to 1.346327. Model was saved\n",
      "Epoch: 801 \tValidation loss decreased from 1.346327 to 1.346188. Model was saved\n",
      "Epoch: 813 \tValidation loss decreased from 1.346188 to 1.346006. Model was saved\n",
      "Epoch: 826 \tValidation loss decreased from 1.346006 to 1.345799. Model was saved\n",
      "Epoch: 856 \tValidation loss decreased from 1.345799 to 1.344331. Model was saved\n",
      "Epoch: 860 \tValidation loss decreased from 1.344331 to 1.340385. Model was saved\n",
      "Epoch: 861 \tValidation loss decreased from 1.340385 to 1.339198. Model was saved\n",
      "Epoch: 954 \tValidation loss decreased from 1.339198 to 1.339136. Model was saved\n",
      "Epoch: 955 \tValidation loss decreased from 1.339136 to 1.338880. Model was saved\n",
      "Epoch: 956 \tValidation loss decreased from 1.338880 to 1.338655. Model was saved\n",
      "Epoch: 957 \tValidation loss decreased from 1.338655 to 1.338359. Model was saved\n",
      "Epoch: 958 \tValidation loss decreased from 1.338359 to 1.338184. Model was saved\n",
      "Epoch: 959 \tValidation loss decreased from 1.338184 to 1.338091. Model was saved\n",
      "Epoch: 960 \tValidation loss decreased from 1.338091 to 1.337881. Model was saved\n",
      "Epoch: 961 \tValidation loss decreased from 1.337881 to 1.337600. Model was saved\n",
      "Epoch: 962 \tValidation loss decreased from 1.337600 to 1.337234. Model was saved\n",
      "Epoch: 963 \tValidation loss decreased from 1.337234 to 1.336749. Model was saved\n",
      "Epoch: 964 \tValidation loss decreased from 1.336749 to 1.336309. Model was saved\n",
      "Epoch: 965 \tValidation loss decreased from 1.336309 to 1.335962. Model was saved\n",
      "Epoch: 966 \tValidation loss decreased from 1.335962 to 1.335620. Model was saved\n",
      "Epoch: 967 \tValidation loss decreased from 1.335620 to 1.335342. Model was saved\n",
      "Epoch: 968 \tValidation loss decreased from 1.335342 to 1.335172. Model was saved\n",
      "Epoch: 969 \tValidation loss decreased from 1.335172 to 1.335081. Model was saved\n",
      "Epoch: 970 \tValidation loss decreased from 1.335081 to 1.335064. Model was saved\n",
      "Epoch: 971 \tValidation loss decreased from 1.335064 to 1.335061. Model was saved\n",
      "Epoch: 981 \tValidation loss decreased from 1.335061 to 1.334970. Model was saved\n",
      "Epoch: 982 \tValidation loss decreased from 1.334970 to 1.334750. Model was saved\n",
      "Epoch: 983 \tValidation loss decreased from 1.334750 to 1.334612. Model was saved\n",
      "Epoch: 984 \tValidation loss decreased from 1.334612 to 1.334522. Model was saved\n",
      "Epoch: 985 \tValidation loss decreased from 1.334522 to 1.334415. Model was saved\n",
      "Epoch: 986 \tValidation loss decreased from 1.334415 to 1.334248. Model was saved\n",
      "Epoch: 987 \tValidation loss decreased from 1.334248 to 1.334055. Model was saved\n",
      "Epoch: 988 \tValidation loss decreased from 1.334055 to 1.333843. Model was saved\n",
      "Epoch: 989 \tValidation loss decreased from 1.333843 to 1.333603. Model was saved\n",
      "Epoch: 990 \tValidation loss decreased from 1.333603 to 1.333400. Model was saved\n",
      "Epoch: 991 \tValidation loss decreased from 1.333400 to 1.333243. Model was saved\n",
      "Epoch: 992 \tValidation loss decreased from 1.333243 to 1.333062. Model was saved\n",
      "Epoch: 993 \tValidation loss decreased from 1.333062 to 1.332824. Model was saved\n",
      "Epoch: 994 \tValidation loss decreased from 1.332824 to 1.332532. Model was saved\n",
      "Epoch: 995 \tValidation loss decreased from 1.332532 to 1.332217. Model was saved\n",
      "Epoch: 996 \tValidation loss decreased from 1.332217 to 1.331894. Model was saved\n",
      "Epoch: 997 \tValidation loss decreased from 1.331894 to 1.331532. Model was saved\n",
      "Epoch: 998 \tValidation loss decreased from 1.331532 to 1.331171. Model was saved\n",
      "Epoch: 999 \tValidation loss decreased from 1.331171 to 1.330939. Model was saved\n",
      "Epoch: 1000 \tValidation loss decreased from 1.330939 to 1.330420. Model was saved\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    # open a new log file\n",
    "    history_file = open(\"training_history.txt\", \"w\")\n",
    "    history_file.close()\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        # reopen log file for appending new line of info\n",
    "        history_file = open(\"training_history.txt\", \"a\")\n",
    "\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ), file=history_file)\n",
    "\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ), file=history_file)\n",
    "            print('Epoch: {} \\tValidation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                epoch,\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        history_file.close()\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(n_epochs, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.221393\n",
      "\n",
      "\n",
      "Test Accuracy: 87% ( 7/ 8)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i,l = next(iter(loaders['test']))\n",
    "# if use_cuda:\n",
    "#     i, l = i.cuda(), l.cuda()\n",
    "\n",
    "# output = model(i)\n",
    "\n",
    "# result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "# result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = result[:,0]\n",
    "# plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 4, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
