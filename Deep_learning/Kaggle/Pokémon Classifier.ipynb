{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6\n",
    "# how many data per batch to load\n",
    "batch_size = 20000\n",
    "# data split ratio\n",
    "train_ratio = 0.98\n",
    "test_ratio = 0.1\n",
    "\n",
    "n_epochs = 4000\n",
    "\n",
    "lr=0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Counter({'class_0': 1611, 'class_2': 1478, 'class_5': 1411, 'class_1': 920, 'class_3': 889, 'class_4': 851})\n",
      "After:\n",
      "Counter({'class_0': 1611, 'class_1': 1611, 'class_2': 1611, 'class_3': 1611, 'class_4': 1611, 'class_5': 1611})\n"
     ]
    }
   ],
   "source": [
    "# make number of data for each class equal\n",
    "#\n",
    "from collections import Counter\n",
    "\n",
    "class_counter = Counter()\n",
    "\n",
    "class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('Before:')\n",
    "print(class_counter)\n",
    "\n",
    "max_count = -np.Inf\n",
    "for i in range(number_of_class):\n",
    "    if class_counter['class_' + str(i)] > max_count:\n",
    "        max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "    num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "    num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "    for j in range(num_resample_batch):\n",
    "        add_df = train_classified[i]\n",
    "        train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "        train =  train.append(df_to_be_added)\n",
    "        \n",
    "    df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "    train =  train.append(df_to_be_added)\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    class_counter['class_' + str(i)] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('After:')\n",
    "print(class_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9666, 297)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "# features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9472, 297), (174, 297), (20, 297))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "# a =plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 180)\n",
    "        self.fc2 = nn.Linear(180, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "#             print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "#         print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tValidation loss decreased from inf to 1.806818. Model was saved\n",
      "Epoch: 2 \tValidation loss decreased from 1.806818 to 1.797241. Model was saved\n",
      "Epoch: 3 \tValidation loss decreased from 1.797241 to 1.792401. Model was saved\n",
      "Epoch: 4 \tValidation loss decreased from 1.792401 to 1.788959. Model was saved\n",
      "Epoch: 5 \tValidation loss decreased from 1.788959 to 1.784393. Model was saved\n",
      "Epoch: 6 \tValidation loss decreased from 1.784393 to 1.779380. Model was saved\n",
      "Epoch: 7 \tValidation loss decreased from 1.779380 to 1.774434. Model was saved\n",
      "Epoch: 8 \tValidation loss decreased from 1.774434 to 1.768450. Model was saved\n",
      "Epoch: 9 \tValidation loss decreased from 1.768450 to 1.760289. Model was saved\n",
      "Epoch: 10 \tValidation loss decreased from 1.760289 to 1.749875. Model was saved\n",
      "Epoch: 11 \tValidation loss decreased from 1.749875 to 1.738261. Model was saved\n",
      "Epoch: 12 \tValidation loss decreased from 1.738261 to 1.726449. Model was saved\n",
      "Epoch: 13 \tValidation loss decreased from 1.726449 to 1.715110. Model was saved\n",
      "Epoch: 14 \tValidation loss decreased from 1.715110 to 1.704513. Model was saved\n",
      "Epoch: 15 \tValidation loss decreased from 1.704513 to 1.694304. Model was saved\n",
      "Epoch: 16 \tValidation loss decreased from 1.694304 to 1.684029. Model was saved\n",
      "Epoch: 17 \tValidation loss decreased from 1.684029 to 1.673968. Model was saved\n",
      "Epoch: 18 \tValidation loss decreased from 1.673968 to 1.664472. Model was saved\n",
      "Epoch: 19 \tValidation loss decreased from 1.664472 to 1.654990. Model was saved\n",
      "Epoch: 20 \tValidation loss decreased from 1.654990 to 1.645991. Model was saved\n",
      "Epoch: 21 \tValidation loss decreased from 1.645991 to 1.638968. Model was saved\n",
      "Epoch: 22 \tValidation loss decreased from 1.638968 to 1.633678. Model was saved\n",
      "Epoch: 23 \tValidation loss decreased from 1.633678 to 1.629368. Model was saved\n",
      "Epoch: 24 \tValidation loss decreased from 1.629368 to 1.625578. Model was saved\n",
      "Epoch: 25 \tValidation loss decreased from 1.625578 to 1.621509. Model was saved\n",
      "Epoch: 26 \tValidation loss decreased from 1.621509 to 1.617857. Model was saved\n",
      "Epoch: 27 \tValidation loss decreased from 1.617857 to 1.613888. Model was saved\n",
      "Epoch: 28 \tValidation loss decreased from 1.613888 to 1.609257. Model was saved\n",
      "Epoch: 29 \tValidation loss decreased from 1.609257 to 1.604600. Model was saved\n",
      "Epoch: 30 \tValidation loss decreased from 1.604600 to 1.600026. Model was saved\n",
      "Epoch: 31 \tValidation loss decreased from 1.600026 to 1.595639. Model was saved\n",
      "Epoch: 32 \tValidation loss decreased from 1.595639 to 1.591364. Model was saved\n",
      "Epoch: 33 \tValidation loss decreased from 1.591364 to 1.586459. Model was saved\n",
      "Epoch: 34 \tValidation loss decreased from 1.586459 to 1.581600. Model was saved\n",
      "Epoch: 35 \tValidation loss decreased from 1.581600 to 1.576683. Model was saved\n",
      "Epoch: 36 \tValidation loss decreased from 1.576683 to 1.571563. Model was saved\n",
      "Epoch: 37 \tValidation loss decreased from 1.571563 to 1.566966. Model was saved\n",
      "Epoch: 38 \tValidation loss decreased from 1.566966 to 1.562844. Model was saved\n",
      "Epoch: 39 \tValidation loss decreased from 1.562844 to 1.558033. Model was saved\n",
      "Epoch: 40 \tValidation loss decreased from 1.558033 to 1.553613. Model was saved\n",
      "Epoch: 41 \tValidation loss decreased from 1.553613 to 1.550291. Model was saved\n",
      "Epoch: 42 \tValidation loss decreased from 1.550291 to 1.547558. Model was saved\n",
      "Epoch: 43 \tValidation loss decreased from 1.547558 to 1.545056. Model was saved\n",
      "Epoch: 44 \tValidation loss decreased from 1.545056 to 1.542401. Model was saved\n",
      "Epoch: 45 \tValidation loss decreased from 1.542401 to 1.539436. Model was saved\n",
      "Epoch: 46 \tValidation loss decreased from 1.539436 to 1.536796. Model was saved\n",
      "Epoch: 47 \tValidation loss decreased from 1.536796 to 1.534075. Model was saved\n",
      "Epoch: 48 \tValidation loss decreased from 1.534075 to 1.530594. Model was saved\n",
      "Epoch: 49 \tValidation loss decreased from 1.530594 to 1.527507. Model was saved\n",
      "Epoch: 50 \tValidation loss decreased from 1.527507 to 1.525455. Model was saved\n",
      "Epoch: 51 \tValidation loss decreased from 1.525455 to 1.524075. Model was saved\n",
      "Epoch: 52 \tValidation loss decreased from 1.524075 to 1.523055. Model was saved\n",
      "Epoch: 53 \tValidation loss decreased from 1.523055 to 1.522720. Model was saved\n",
      "Epoch: 55 \tValidation loss decreased from 1.522720 to 1.522270. Model was saved\n",
      "Epoch: 56 \tValidation loss decreased from 1.522270 to 1.521766. Model was saved\n",
      "Epoch: 57 \tValidation loss decreased from 1.521766 to 1.521354. Model was saved\n",
      "Epoch: 58 \tValidation loss decreased from 1.521354 to 1.519704. Model was saved\n",
      "Epoch: 59 \tValidation loss decreased from 1.519704 to 1.518902. Model was saved\n",
      "Epoch: 60 \tValidation loss decreased from 1.518902 to 1.517728. Model was saved\n",
      "Epoch: 61 \tValidation loss decreased from 1.517728 to 1.517345. Model was saved\n",
      "Epoch: 62 \tValidation loss decreased from 1.517345 to 1.516697. Model was saved\n",
      "Epoch: 64 \tValidation loss decreased from 1.516697 to 1.516265. Model was saved\n",
      "Epoch: 66 \tValidation loss decreased from 1.516265 to 1.515485. Model was saved\n",
      "Epoch: 68 \tValidation loss decreased from 1.515485 to 1.515475. Model was saved\n",
      "Epoch: 69 \tValidation loss decreased from 1.515475 to 1.514949. Model was saved\n",
      "Epoch: 71 \tValidation loss decreased from 1.514949 to 1.513711. Model was saved\n",
      "Epoch: 73 \tValidation loss decreased from 1.513711 to 1.513175. Model was saved\n",
      "Epoch: 74 \tValidation loss decreased from 1.513175 to 1.512245. Model was saved\n",
      "Epoch: 76 \tValidation loss decreased from 1.512245 to 1.510956. Model was saved\n",
      "Epoch: 78 \tValidation loss decreased from 1.510956 to 1.510275. Model was saved\n",
      "Epoch: 79 \tValidation loss decreased from 1.510275 to 1.510124. Model was saved\n",
      "Epoch: 80 \tValidation loss decreased from 1.510124 to 1.510094. Model was saved\n",
      "Epoch: 81 \tValidation loss decreased from 1.510094 to 1.509667. Model was saved\n",
      "Epoch: 83 \tValidation loss decreased from 1.509667 to 1.509367. Model was saved\n",
      "Epoch: 85 \tValidation loss decreased from 1.509367 to 1.508475. Model was saved\n",
      "Epoch: 86 \tValidation loss decreased from 1.508475 to 1.508408. Model was saved\n",
      "Epoch: 87 \tValidation loss decreased from 1.508408 to 1.506915. Model was saved\n",
      "Epoch: 88 \tValidation loss decreased from 1.506915 to 1.506507. Model was saved\n",
      "Epoch: 89 \tValidation loss decreased from 1.506507 to 1.505096. Model was saved\n",
      "Epoch: 90 \tValidation loss decreased from 1.505096 to 1.504818. Model was saved\n",
      "Epoch: 91 \tValidation loss decreased from 1.504818 to 1.503731. Model was saved\n",
      "Epoch: 92 \tValidation loss decreased from 1.503731 to 1.503360. Model was saved\n",
      "Epoch: 93 \tValidation loss decreased from 1.503360 to 1.502731. Model was saved\n",
      "Epoch: 94 \tValidation loss decreased from 1.502731 to 1.501688. Model was saved\n",
      "Epoch: 95 \tValidation loss decreased from 1.501688 to 1.501383. Model was saved\n",
      "Epoch: 96 \tValidation loss decreased from 1.501383 to 1.499520. Model was saved\n",
      "Epoch: 98 \tValidation loss decreased from 1.499520 to 1.497058. Model was saved\n",
      "Epoch: 100 \tValidation loss decreased from 1.497058 to 1.495154. Model was saved\n",
      "Epoch: 101 \tValidation loss decreased from 1.495154 to 1.494537. Model was saved\n",
      "Epoch: 102 \tValidation loss decreased from 1.494537 to 1.494385. Model was saved\n",
      "Epoch: 103 \tValidation loss decreased from 1.494385 to 1.491493. Model was saved\n",
      "Epoch: 105 \tValidation loss decreased from 1.491493 to 1.490145. Model was saved\n",
      "Epoch: 106 \tValidation loss decreased from 1.490145 to 1.488885. Model was saved\n",
      "Epoch: 108 \tValidation loss decreased from 1.488885 to 1.486306. Model was saved\n",
      "Epoch: 110 \tValidation loss decreased from 1.486306 to 1.484756. Model was saved\n",
      "Epoch: 112 \tValidation loss decreased from 1.484756 to 1.484272. Model was saved\n",
      "Epoch: 113 \tValidation loss decreased from 1.484272 to 1.482861. Model was saved\n",
      "Epoch: 115 \tValidation loss decreased from 1.482861 to 1.480340. Model was saved\n",
      "Epoch: 117 \tValidation loss decreased from 1.480340 to 1.478930. Model was saved\n",
      "Epoch: 122 \tValidation loss decreased from 1.478930 to 1.478315. Model was saved\n",
      "Epoch: 124 \tValidation loss decreased from 1.478315 to 1.477172. Model was saved\n",
      "Epoch: 126 \tValidation loss decreased from 1.477172 to 1.474918. Model was saved\n",
      "Epoch: 128 \tValidation loss decreased from 1.474918 to 1.474251. Model was saved\n",
      "Epoch: 131 \tValidation loss decreased from 1.474251 to 1.471919. Model was saved\n",
      "Epoch: 136 \tValidation loss decreased from 1.471919 to 1.470179. Model was saved\n",
      "Epoch: 138 \tValidation loss decreased from 1.470179 to 1.468265. Model was saved\n",
      "Epoch: 140 \tValidation loss decreased from 1.468265 to 1.466221. Model was saved\n",
      "Epoch: 142 \tValidation loss decreased from 1.466221 to 1.464953. Model was saved\n",
      "Epoch: 144 \tValidation loss decreased from 1.464953 to 1.463596. Model was saved\n",
      "Epoch: 146 \tValidation loss decreased from 1.463596 to 1.461054. Model was saved\n",
      "Epoch: 148 \tValidation loss decreased from 1.461054 to 1.459385. Model was saved\n",
      "Epoch: 151 \tValidation loss decreased from 1.459385 to 1.457277. Model was saved\n",
      "Epoch: 154 \tValidation loss decreased from 1.457277 to 1.455465. Model was saved\n",
      "Epoch: 156 \tValidation loss decreased from 1.455465 to 1.454144. Model was saved\n",
      "Epoch: 158 \tValidation loss decreased from 1.454144 to 1.453850. Model was saved\n",
      "Epoch: 159 \tValidation loss decreased from 1.453850 to 1.452256. Model was saved\n",
      "Epoch: 161 \tValidation loss decreased from 1.452256 to 1.450552. Model was saved\n",
      "Epoch: 163 \tValidation loss decreased from 1.450552 to 1.450104. Model was saved\n",
      "Epoch: 166 \tValidation loss decreased from 1.450104 to 1.448961. Model was saved\n",
      "Epoch: 168 \tValidation loss decreased from 1.448961 to 1.447574. Model was saved\n",
      "Epoch: 170 \tValidation loss decreased from 1.447574 to 1.445494. Model was saved\n",
      "Epoch: 172 \tValidation loss decreased from 1.445494 to 1.443859. Model was saved\n",
      "Epoch: 180 \tValidation loss decreased from 1.443859 to 1.442754. Model was saved\n",
      "Epoch: 182 \tValidation loss decreased from 1.442754 to 1.442180. Model was saved\n",
      "Epoch: 185 \tValidation loss decreased from 1.442180 to 1.440715. Model was saved\n",
      "Epoch: 187 \tValidation loss decreased from 1.440715 to 1.439565. Model was saved\n",
      "Epoch: 189 \tValidation loss decreased from 1.439565 to 1.439020. Model was saved\n",
      "Epoch: 190 \tValidation loss decreased from 1.439020 to 1.438419. Model was saved\n",
      "Epoch: 192 \tValidation loss decreased from 1.438419 to 1.436500. Model was saved\n",
      "Epoch: 194 \tValidation loss decreased from 1.436500 to 1.434843. Model was saved\n",
      "Epoch: 196 \tValidation loss decreased from 1.434843 to 1.433477. Model was saved\n",
      "Epoch: 198 \tValidation loss decreased from 1.433477 to 1.432582. Model was saved\n",
      "Epoch: 200 \tValidation loss decreased from 1.432582 to 1.431829. Model was saved\n",
      "Epoch: 203 \tValidation loss decreased from 1.431829 to 1.431480. Model was saved\n",
      "Epoch: 205 \tValidation loss decreased from 1.431480 to 1.430376. Model was saved\n",
      "Epoch: 207 \tValidation loss decreased from 1.430376 to 1.429765. Model was saved\n",
      "Epoch: 210 \tValidation loss decreased from 1.429765 to 1.429178. Model was saved\n",
      "Epoch: 212 \tValidation loss decreased from 1.429178 to 1.428233. Model was saved\n",
      "Epoch: 214 \tValidation loss decreased from 1.428233 to 1.426324. Model was saved\n",
      "Epoch: 216 \tValidation loss decreased from 1.426324 to 1.425705. Model was saved\n",
      "Epoch: 217 \tValidation loss decreased from 1.425705 to 1.424622. Model was saved\n",
      "Epoch: 219 \tValidation loss decreased from 1.424622 to 1.423326. Model was saved\n",
      "Epoch: 221 \tValidation loss decreased from 1.423326 to 1.421463. Model was saved\n",
      "Epoch: 223 \tValidation loss decreased from 1.421463 to 1.419907. Model was saved\n",
      "Epoch: 224 \tValidation loss decreased from 1.419907 to 1.419554. Model was saved\n",
      "Epoch: 226 \tValidation loss decreased from 1.419554 to 1.418472. Model was saved\n",
      "Epoch: 228 \tValidation loss decreased from 1.418472 to 1.416894. Model was saved\n",
      "Epoch: 231 \tValidation loss decreased from 1.416894 to 1.415494. Model was saved\n",
      "Epoch: 233 \tValidation loss decreased from 1.415494 to 1.414160. Model was saved\n",
      "Epoch: 235 \tValidation loss decreased from 1.414160 to 1.413148. Model was saved\n",
      "Epoch: 237 \tValidation loss decreased from 1.413148 to 1.412681. Model was saved\n",
      "Epoch: 238 \tValidation loss decreased from 1.412681 to 1.411694. Model was saved\n",
      "Epoch: 240 \tValidation loss decreased from 1.411694 to 1.410530. Model was saved\n",
      "Epoch: 242 \tValidation loss decreased from 1.410530 to 1.409419. Model was saved\n",
      "Epoch: 244 \tValidation loss decreased from 1.409419 to 1.408504. Model was saved\n",
      "Epoch: 247 \tValidation loss decreased from 1.408504 to 1.407255. Model was saved\n",
      "Epoch: 249 \tValidation loss decreased from 1.407255 to 1.406136. Model was saved\n",
      "Epoch: 252 \tValidation loss decreased from 1.406136 to 1.405592. Model was saved\n",
      "Epoch: 254 \tValidation loss decreased from 1.405592 to 1.404601. Model was saved\n",
      "Epoch: 256 \tValidation loss decreased from 1.404601 to 1.404012. Model was saved\n",
      "Epoch: 258 \tValidation loss decreased from 1.404012 to 1.403803. Model was saved\n",
      "Epoch: 261 \tValidation loss decreased from 1.403803 to 1.403208. Model was saved\n",
      "Epoch: 263 \tValidation loss decreased from 1.403208 to 1.402565. Model was saved\n",
      "Epoch: 265 \tValidation loss decreased from 1.402565 to 1.401548. Model was saved\n",
      "Epoch: 267 \tValidation loss decreased from 1.401548 to 1.401285. Model was saved\n",
      "Epoch: 270 \tValidation loss decreased from 1.401285 to 1.400059. Model was saved\n",
      "Epoch: 272 \tValidation loss decreased from 1.400059 to 1.399720. Model was saved\n",
      "Epoch: 277 \tValidation loss decreased from 1.399720 to 1.399562. Model was saved\n",
      "Epoch: 279 \tValidation loss decreased from 1.399562 to 1.399310. Model was saved\n",
      "Epoch: 281 \tValidation loss decreased from 1.399310 to 1.398747. Model was saved\n",
      "Epoch: 283 \tValidation loss decreased from 1.398747 to 1.398503. Model was saved\n",
      "Epoch: 284 \tValidation loss decreased from 1.398503 to 1.398450. Model was saved\n",
      "Epoch: 286 \tValidation loss decreased from 1.398450 to 1.398170. Model was saved\n",
      "Epoch: 290 \tValidation loss decreased from 1.398170 to 1.397798. Model was saved\n",
      "Epoch: 295 \tValidation loss decreased from 1.397798 to 1.397776. Model was saved\n",
      "Epoch: 298 \tValidation loss decreased from 1.397776 to 1.397529. Model was saved\n",
      "Epoch: 301 \tValidation loss decreased from 1.397529 to 1.397195. Model was saved\n",
      "Epoch: 304 \tValidation loss decreased from 1.397195 to 1.397050. Model was saved\n",
      "Epoch: 308 \tValidation loss decreased from 1.397050 to 1.396654. Model was saved\n",
      "Epoch: 310 \tValidation loss decreased from 1.396654 to 1.396470. Model was saved\n",
      "Epoch: 311 \tValidation loss decreased from 1.396470 to 1.396194. Model was saved\n",
      "Epoch: 313 \tValidation loss decreased from 1.396194 to 1.395784. Model was saved\n",
      "Epoch: 315 \tValidation loss decreased from 1.395784 to 1.394868. Model was saved\n",
      "Epoch: 332 \tValidation loss decreased from 1.394868 to 1.394186. Model was saved\n",
      "Epoch: 340 \tValidation loss decreased from 1.394186 to 1.394132. Model was saved\n",
      "Epoch: 349 \tValidation loss decreased from 1.394132 to 1.393936. Model was saved\n",
      "Epoch: 351 \tValidation loss decreased from 1.393936 to 1.393296. Model was saved\n",
      "Epoch: 352 \tValidation loss decreased from 1.393296 to 1.393058. Model was saved\n",
      "Epoch: 355 \tValidation loss decreased from 1.393058 to 1.392465. Model was saved\n",
      "Epoch: 357 \tValidation loss decreased from 1.392465 to 1.391535. Model was saved\n",
      "Epoch: 359 \tValidation loss decreased from 1.391535 to 1.391039. Model was saved\n",
      "Epoch: 360 \tValidation loss decreased from 1.391039 to 1.389804. Model was saved\n",
      "Epoch: 366 \tValidation loss decreased from 1.389804 to 1.389289. Model was saved\n",
      "Epoch: 372 \tValidation loss decreased from 1.389289 to 1.389031. Model was saved\n",
      "Epoch: 374 \tValidation loss decreased from 1.389031 to 1.388225. Model was saved\n",
      "Epoch: 377 \tValidation loss decreased from 1.388225 to 1.388080. Model was saved\n",
      "Epoch: 381 \tValidation loss decreased from 1.388080 to 1.387923. Model was saved\n",
      "Epoch: 382 \tValidation loss decreased from 1.387923 to 1.386912. Model was saved\n",
      "Epoch: 383 \tValidation loss decreased from 1.386912 to 1.386560. Model was saved\n",
      "Epoch: 384 \tValidation loss decreased from 1.386560 to 1.386198. Model was saved\n",
      "Epoch: 388 \tValidation loss decreased from 1.386198 to 1.385882. Model was saved\n",
      "Epoch: 389 \tValidation loss decreased from 1.385882 to 1.385718. Model was saved\n",
      "Epoch: 390 \tValidation loss decreased from 1.385718 to 1.385295. Model was saved\n",
      "Epoch: 391 \tValidation loss decreased from 1.385295 to 1.384915. Model was saved\n",
      "Epoch: 393 \tValidation loss decreased from 1.384915 to 1.384698. Model was saved\n",
      "Epoch: 395 \tValidation loss decreased from 1.384698 to 1.383616. Model was saved\n",
      "Epoch: 398 \tValidation loss decreased from 1.383616 to 1.383206. Model was saved\n",
      "Epoch: 400 \tValidation loss decreased from 1.383206 to 1.382978. Model was saved\n",
      "Epoch: 402 \tValidation loss decreased from 1.382978 to 1.382455. Model was saved\n",
      "Epoch: 409 \tValidation loss decreased from 1.382455 to 1.382203. Model was saved\n",
      "Epoch: 411 \tValidation loss decreased from 1.382203 to 1.381698. Model was saved\n",
      "Epoch: 413 \tValidation loss decreased from 1.381698 to 1.381378. Model was saved\n",
      "Epoch: 415 \tValidation loss decreased from 1.381378 to 1.380767. Model was saved\n",
      "Epoch: 417 \tValidation loss decreased from 1.380767 to 1.380310. Model was saved\n",
      "Epoch: 419 \tValidation loss decreased from 1.380310 to 1.379888. Model was saved\n",
      "Epoch: 421 \tValidation loss decreased from 1.379888 to 1.378938. Model was saved\n",
      "Epoch: 423 \tValidation loss decreased from 1.378938 to 1.378470. Model was saved\n",
      "Epoch: 425 \tValidation loss decreased from 1.378470 to 1.378422. Model was saved\n",
      "Epoch: 426 \tValidation loss decreased from 1.378422 to 1.378199. Model was saved\n",
      "Epoch: 428 \tValidation loss decreased from 1.378199 to 1.377299. Model was saved\n",
      "Epoch: 430 \tValidation loss decreased from 1.377299 to 1.376629. Model was saved\n",
      "Epoch: 432 \tValidation loss decreased from 1.376629 to 1.376433. Model was saved\n",
      "Epoch: 434 \tValidation loss decreased from 1.376433 to 1.376276. Model was saved\n",
      "Epoch: 436 \tValidation loss decreased from 1.376276 to 1.376265. Model was saved\n",
      "Epoch: 437 \tValidation loss decreased from 1.376265 to 1.376044. Model was saved\n",
      "Epoch: 439 \tValidation loss decreased from 1.376044 to 1.374877. Model was saved\n",
      "Epoch: 441 \tValidation loss decreased from 1.374877 to 1.374506. Model was saved\n",
      "Epoch: 454 \tValidation loss decreased from 1.374506 to 1.374487. Model was saved\n",
      "Epoch: 456 \tValidation loss decreased from 1.374487 to 1.374113. Model was saved\n",
      "Epoch: 458 \tValidation loss decreased from 1.374113 to 1.374001. Model was saved\n",
      "Epoch: 464 \tValidation loss decreased from 1.374001 to 1.373806. Model was saved\n",
      "Epoch: 466 \tValidation loss decreased from 1.373806 to 1.372985. Model was saved\n",
      "Epoch: 468 \tValidation loss decreased from 1.372985 to 1.372369. Model was saved\n",
      "Epoch: 525 \tValidation loss decreased from 1.372369 to 1.371941. Model was saved\n",
      "Epoch: 526 \tValidation loss decreased from 1.371941 to 1.371834. Model was saved\n",
      "Epoch: 527 \tValidation loss decreased from 1.371834 to 1.371221. Model was saved\n",
      "Epoch: 529 \tValidation loss decreased from 1.371221 to 1.371148. Model was saved\n",
      "Epoch: 543 \tValidation loss decreased from 1.371148 to 1.370861. Model was saved\n",
      "Epoch: 545 \tValidation loss decreased from 1.370861 to 1.370722. Model was saved\n",
      "Epoch: 547 \tValidation loss decreased from 1.370722 to 1.370644. Model was saved\n",
      "Epoch: 549 \tValidation loss decreased from 1.370644 to 1.370606. Model was saved\n",
      "Epoch: 551 \tValidation loss decreased from 1.370606 to 1.370388. Model was saved\n",
      "Epoch: 553 \tValidation loss decreased from 1.370388 to 1.370345. Model was saved\n",
      "Epoch: 555 \tValidation loss decreased from 1.370345 to 1.370304. Model was saved\n",
      "Epoch: 557 \tValidation loss decreased from 1.370304 to 1.370272. Model was saved\n",
      "Epoch: 566 \tValidation loss decreased from 1.370272 to 1.369976. Model was saved\n",
      "Epoch: 567 \tValidation loss decreased from 1.369976 to 1.369723. Model was saved\n",
      "Epoch: 568 \tValidation loss decreased from 1.369723 to 1.369111. Model was saved\n",
      "Epoch: 569 \tValidation loss decreased from 1.369111 to 1.368755. Model was saved\n",
      "Epoch: 570 \tValidation loss decreased from 1.368755 to 1.368073. Model was saved\n",
      "Epoch: 571 \tValidation loss decreased from 1.368073 to 1.368007. Model was saved\n",
      "Epoch: 572 \tValidation loss decreased from 1.368007 to 1.367427. Model was saved\n",
      "Epoch: 574 \tValidation loss decreased from 1.367427 to 1.367050. Model was saved\n",
      "Epoch: 576 \tValidation loss decreased from 1.367050 to 1.366783. Model was saved\n",
      "Epoch: 578 \tValidation loss decreased from 1.366783 to 1.366416. Model was saved\n",
      "Epoch: 580 \tValidation loss decreased from 1.366416 to 1.365811. Model was saved\n",
      "Epoch: 582 \tValidation loss decreased from 1.365811 to 1.364787. Model was saved\n",
      "Epoch: 584 \tValidation loss decreased from 1.364787 to 1.363706. Model was saved\n",
      "Epoch: 589 \tValidation loss decreased from 1.363706 to 1.363415. Model was saved\n",
      "Epoch: 592 \tValidation loss decreased from 1.363415 to 1.363323. Model was saved\n",
      "Epoch: 594 \tValidation loss decreased from 1.363323 to 1.362908. Model was saved\n",
      "Epoch: 597 \tValidation loss decreased from 1.362908 to 1.361649. Model was saved\n",
      "Epoch: 630 \tValidation loss decreased from 1.361649 to 1.361208. Model was saved\n",
      "Epoch: 632 \tValidation loss decreased from 1.361208 to 1.360430. Model was saved\n",
      "Epoch: 633 \tValidation loss decreased from 1.360430 to 1.360267. Model was saved\n",
      "Epoch: 635 \tValidation loss decreased from 1.360267 to 1.359550. Model was saved\n",
      "Epoch: 636 \tValidation loss decreased from 1.359550 to 1.359419. Model was saved\n",
      "Epoch: 637 \tValidation loss decreased from 1.359419 to 1.358856. Model was saved\n",
      "Epoch: 638 \tValidation loss decreased from 1.358856 to 1.358563. Model was saved\n",
      "Epoch: 639 \tValidation loss decreased from 1.358563 to 1.358302. Model was saved\n",
      "Epoch: 640 \tValidation loss decreased from 1.358302 to 1.357839. Model was saved\n",
      "Epoch: 642 \tValidation loss decreased from 1.357839 to 1.357826. Model was saved\n",
      "Epoch: 659 \tValidation loss decreased from 1.357826 to 1.357800. Model was saved\n",
      "Epoch: 662 \tValidation loss decreased from 1.357800 to 1.357669. Model was saved\n",
      "Epoch: 664 \tValidation loss decreased from 1.357669 to 1.357641. Model was saved\n",
      "Epoch: 666 \tValidation loss decreased from 1.357641 to 1.357561. Model was saved\n",
      "Epoch: 667 \tValidation loss decreased from 1.357561 to 1.357463. Model was saved\n",
      "Epoch: 670 \tValidation loss decreased from 1.357463 to 1.357308. Model was saved\n",
      "Epoch: 671 \tValidation loss decreased from 1.357308 to 1.357114. Model was saved\n",
      "Epoch: 672 \tValidation loss decreased from 1.357114 to 1.357036. Model was saved\n",
      "Epoch: 673 \tValidation loss decreased from 1.357036 to 1.356942. Model was saved\n",
      "Epoch: 674 \tValidation loss decreased from 1.356942 to 1.356899. Model was saved\n",
      "Epoch: 675 \tValidation loss decreased from 1.356899 to 1.356834. Model was saved\n",
      "Epoch: 691 \tValidation loss decreased from 1.356834 to 1.356815. Model was saved\n",
      "Epoch: 692 \tValidation loss decreased from 1.356815 to 1.356668. Model was saved\n",
      "Epoch: 693 \tValidation loss decreased from 1.356668 to 1.356569. Model was saved\n",
      "Epoch: 694 \tValidation loss decreased from 1.356569 to 1.356475. Model was saved\n",
      "Epoch: 695 \tValidation loss decreased from 1.356475 to 1.356408. Model was saved\n",
      "Epoch: 696 \tValidation loss decreased from 1.356408 to 1.356338. Model was saved\n",
      "Epoch: 697 \tValidation loss decreased from 1.356338 to 1.356304. Model was saved\n",
      "Epoch: 715 \tValidation loss decreased from 1.356304 to 1.356226. Model was saved\n",
      "Epoch: 716 \tValidation loss decreased from 1.356226 to 1.355921. Model was saved\n",
      "Epoch: 717 \tValidation loss decreased from 1.355921 to 1.355611. Model was saved\n",
      "Epoch: 718 \tValidation loss decreased from 1.355611 to 1.355457. Model was saved\n",
      "Epoch: 719 \tValidation loss decreased from 1.355457 to 1.355344. Model was saved\n",
      "Epoch: 720 \tValidation loss decreased from 1.355344 to 1.355258. Model was saved\n",
      "Epoch: 721 \tValidation loss decreased from 1.355258 to 1.355195. Model was saved\n",
      "Epoch: 722 \tValidation loss decreased from 1.355195 to 1.355178. Model was saved\n",
      "Epoch: 759 \tValidation loss decreased from 1.355178 to 1.354633. Model was saved\n",
      "Epoch: 761 \tValidation loss decreased from 1.354633 to 1.354396. Model was saved\n",
      "Epoch: 763 \tValidation loss decreased from 1.354396 to 1.354125. Model was saved\n",
      "Epoch: 765 \tValidation loss decreased from 1.354125 to 1.353136. Model was saved\n",
      "Epoch: 1133 \tValidation loss decreased from 1.353136 to 1.352729. Model was saved\n",
      "Epoch: 1134 \tValidation loss decreased from 1.352729 to 1.352468. Model was saved\n",
      "Epoch: 1135 \tValidation loss decreased from 1.352468 to 1.352463. Model was saved\n",
      "Epoch: 1152 \tValidation loss decreased from 1.352463 to 1.352432. Model was saved\n",
      "Epoch: 1157 \tValidation loss decreased from 1.352432 to 1.351953. Model was saved\n",
      "Epoch: 1164 \tValidation loss decreased from 1.351953 to 1.351928. Model was saved\n",
      "Epoch: 1227 \tValidation loss decreased from 1.351928 to 1.351743. Model was saved\n",
      "Epoch: 1240 \tValidation loss decreased from 1.351743 to 1.351618. Model was saved\n",
      "Epoch: 1241 \tValidation loss decreased from 1.351618 to 1.351380. Model was saved\n",
      "Epoch: 1243 \tValidation loss decreased from 1.351380 to 1.351271. Model was saved\n",
      "Epoch: 1245 \tValidation loss decreased from 1.351271 to 1.350951. Model was saved\n",
      "Epoch: 1247 \tValidation loss decreased from 1.350951 to 1.350855. Model was saved\n",
      "Epoch: 1248 \tValidation loss decreased from 1.350855 to 1.350643. Model was saved\n",
      "Epoch: 1249 \tValidation loss decreased from 1.350643 to 1.350629. Model was saved\n",
      "Epoch: 1250 \tValidation loss decreased from 1.350629 to 1.350493. Model was saved\n",
      "Epoch: 1251 \tValidation loss decreased from 1.350493 to 1.350400. Model was saved\n",
      "Epoch: 1252 \tValidation loss decreased from 1.350400 to 1.350069. Model was saved\n",
      "Epoch: 1253 \tValidation loss decreased from 1.350069 to 1.349914. Model was saved\n",
      "Epoch: 1254 \tValidation loss decreased from 1.349914 to 1.349795. Model was saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-741272d6cb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m model = train(n_epochs, loaders, model, optimizer, \n\u001b[0;32m---> 97\u001b[0;31m                       criterion, use_cuda, 'model.pt')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-741272d6cb1e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#             data = data.type((torch.FloatTensor))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                 \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    # open a new log file\n",
    "    history_file = open(\"training_history.txt\", \"w\")\n",
    "    history_file.close()\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        # reopen log file for appending new line of info\n",
    "        history_file = open(\"training_history.txt\", \"a\")\n",
    "\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ), file=history_file)\n",
    "\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ), file=history_file)\n",
    "            print('Epoch: {} \\tValidation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                epoch,\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        history_file.close()\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(n_epochs, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.401779\n",
      "\n",
      "\n",
      "Test Accuracy: 50% (10/20)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i,l = next(iter(loaders['test']))\n",
    "# if use_cuda:\n",
    "#     i, l = i.cuda(), l.cuda()\n",
    "\n",
    "# output = model(i)\n",
    "\n",
    "# result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "# result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = result[:,0]\n",
    "# plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 1, 4, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
