{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_class = 6\n",
    "# how many data per batch to load\n",
    "batch_size = 20000\n",
    "# data split ratio\n",
    "train_ratio = 0.98\n",
    "test_ratio = 0.1\n",
    "\n",
    "n_epochs = 4000\n",
    "\n",
    "lr=0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Counter({'class_0': 1611, 'class_2': 1478, 'class_5': 1411, 'class_1': 920, 'class_3': 889, 'class_4': 851})\n",
      "After:\n",
      "Counter({'class_0': 1611, 'class_1': 1611, 'class_2': 1611, 'class_3': 1611, 'class_4': 1611, 'class_5': 1611})\n"
     ]
    }
   ],
   "source": [
    "# make number of data for each class equal\n",
    "#\n",
    "from collections import Counter\n",
    "\n",
    "class_counter = Counter()\n",
    "\n",
    "class_names =['class_' + str(i) for i in range(number_of_class)]\n",
    "for class_name in class_names:\n",
    "    class_counter[class_name] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('Before:')\n",
    "print(class_counter)\n",
    "\n",
    "max_count = -np.Inf\n",
    "for i in range(number_of_class):\n",
    "    if class_counter['class_' + str(i)] > max_count:\n",
    "        max_count = class_counter['class_' + str(i)]\n",
    "\n",
    "train_classified = [train[train['class'] == i] for i in range(number_of_class)]\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    num_need_resample = max_count - class_counter['class_' + str(i)]\n",
    "    num_resample_batch = num_need_resample // class_counter['class_' + str(i)]\n",
    "    num_resample_leftover = num_need_resample % class_counter['class_' + str(i)]\n",
    "    for j in range(num_resample_batch):\n",
    "        add_df = train_classified[i]\n",
    "        train =  pd.concat([train, add_df[0:dist_class[i][1]]], ignore_index=True)\n",
    "        train =  train.append(df_to_be_added)\n",
    "        \n",
    "    df_to_be_added = train_classified[i][:num_resample_leftover]\n",
    "    train =  train.append(df_to_be_added)\n",
    "\n",
    "for i in range(number_of_class):\n",
    "    class_counter['class_' + str(i)] = 0\n",
    "for i in train['class']:\n",
    "    class_counter['class_' + str(i)] += 1\n",
    "\n",
    "print('After:')\n",
    "print(class_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'appearedTimeOfDay':'cooc_151'],\n",
    "                      test.loc[:,'appearedTimeOfDay':'cooc_151']))\n",
    "id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.applymap(lambda x: 1.0 if x == True else x)\n",
    "all_data = all_data.applymap(lambda x: 0.0 if x == False else x)\n",
    "all_data = pd.get_dummies(all_data)\n",
    "# numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "# df = df[numeric_feats]\n",
    "apearedHour = all_data['appearedHour']\n",
    "appearedMinute = all_data['appearedMinute']\n",
    "appearedTimeDayCycle = apearedHour * 60 + appearedMinute\n",
    "appearedTimeDayCycle = np.sin(appearedTimeDayCycle / (24 * 60) * 2 * np.pi)\n",
    "# print('appearedTimeDayCycle= ',appearedTimeDayCycle)\n",
    "all_data = all_data.drop(['appearedHour'], axis=1)\n",
    "all_data = all_data.drop(['appearedMinute'], axis=1)\n",
    "all_data['appearedTimeDayCycle'] = appearedTimeDayCycle\n",
    "\n",
    "# df = df.drop(['temperature'], axis=1)\n",
    "# df = df.drop(['windSpeed'], axis=1)\n",
    "# df = df.drop(['pressure'], axis=1)\n",
    "# df = df.drop(['gymIn100m'], axis=1)\n",
    "# df = df.drop(['gymIn250m'], axis=1)\n",
    "# df = df.drop(['gymIn500m'], axis=1)\n",
    "# df = df.drop(['gymIn1000m'], axis=1)\n",
    "# df = df.drop(['gymIn2500m'], axis=1)\n",
    "# df = df.drop(['gymIn5000m'], axis=1)\n",
    "# df = df.drop(['rural'], axis=1)\n",
    "# df = df.drop(['midurban'], axis=1)\n",
    "# df = df.drop(['suburban'], axis=1)\n",
    "# df = df.drop(['urban'], axis=1)\n",
    "# df = df.drop(['pokestopIn100m'], axis=1)\n",
    "# df = df.drop(['pokestopIn250m'], axis=1)\n",
    "# df = df.drop(['pokestopIn500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn1000m'], axis=1)\n",
    "# df = df.drop(['pokestopIn2500m'], axis=1)\n",
    "# df = df.drop(['pokestopIn5000m'], axis=1)\n",
    "# df = df.drop(['terrainType'], axis=1)\n",
    "# df = df.drop(['closeToWater'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(all_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at the data :\n",
    "# matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# data = pd.DataFrame({\"x\":df['population_density'], \"y\":targets})\n",
    "\n",
    "# data.plot(x = \"x\", y = \"y\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normailize to 0-1\n",
    "for k in all_data.columns.values:\n",
    "    if (all_data[k].max() - all_data[k].min()) > 0:\n",
    "        all_data[k] = (all_data[k] - all_data[k].min())/(all_data[k].max() - all_data[k].min())\n",
    "    else:\n",
    "        all_data[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9666, 297)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = all_data[:train.shape[0]]\n",
    "features_test = all_data[train.shape[0]:]\n",
    "targets = train['class']\n",
    "\n",
    "# features.info()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = plt.hist(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9472, 297), (174, 297), (20, 297))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into training and validation sets\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(features.values, targets.values, test_size = 1 - train_ratio, stratify=targets.values, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size = test_ratio, stratify=y_valid, random_state=0)\n",
    "X_train.shape,X_valid.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(y_test)\n",
    "# plt.hist(y_valid)\n",
    "# a =plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "data_train = data_utils.TensorDataset(torch.from_numpy(X_train).type((torch.FloatTensor)), torch.from_numpy(y_train).type((torch.LongTensor)))\n",
    "data_valid = data_utils.TensorDataset(torch.from_numpy(X_valid).type((torch.FloatTensor)), torch.from_numpy(y_valid).type((torch.LongTensor)))\n",
    "data_test = data_utils.TensorDataset(torch.from_numpy(X_test).type((torch.FloatTensor)), torch.from_numpy(y_test).type((torch.LongTensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "\n",
    "loaders = {}\n",
    "loaders['train'] = torch.utils.data.DataLoader(data_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "\n",
    "loaders['valid'] = torch.utils.data.DataLoader(data_valid,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)\n",
    "loaders['test'] = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "#     print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(297, 180)\n",
    "        self.fc2 = nn.Linear(180, 32)\n",
    "        self.fc3 = nn.Linear(32, 6)\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model = Net()\n",
    "def init_weights(m):\n",
    "        print(m)\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.fill_(1.0)\n",
    "#             print(m.weight)\n",
    "            \n",
    "def init_ortho(m):\n",
    "    print()\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "#         print(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "# model.apply(init_ortho)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01,weight_decay= 1e-6, momentum = 0.9, nesterov = True)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tValidation loss decreased from inf to 1.803154. Model was saved\n",
      "Epoch: 2 \tValidation loss decreased from 1.803154 to 1.796782. Model was saved\n",
      "Epoch: 3 \tValidation loss decreased from 1.796782 to 1.792025. Model was saved\n",
      "Epoch: 4 \tValidation loss decreased from 1.792025 to 1.790007. Model was saved\n",
      "Epoch: 5 \tValidation loss decreased from 1.790007 to 1.787506. Model was saved\n",
      "Epoch: 6 \tValidation loss decreased from 1.787506 to 1.784308. Model was saved\n",
      "Epoch: 7 \tValidation loss decreased from 1.784308 to 1.778323. Model was saved\n",
      "Epoch: 8 \tValidation loss decreased from 1.778323 to 1.769254. Model was saved\n",
      "Epoch: 9 \tValidation loss decreased from 1.769254 to 1.757209. Model was saved\n",
      "Epoch: 10 \tValidation loss decreased from 1.757209 to 1.743306. Model was saved\n",
      "Epoch: 11 \tValidation loss decreased from 1.743306 to 1.728506. Model was saved\n",
      "Epoch: 12 \tValidation loss decreased from 1.728506 to 1.711424. Model was saved\n",
      "Epoch: 13 \tValidation loss decreased from 1.711424 to 1.695810. Model was saved\n",
      "Epoch: 14 \tValidation loss decreased from 1.695810 to 1.682634. Model was saved\n",
      "Epoch: 15 \tValidation loss decreased from 1.682634 to 1.669862. Model was saved\n",
      "Epoch: 16 \tValidation loss decreased from 1.669862 to 1.658526. Model was saved\n",
      "Epoch: 17 \tValidation loss decreased from 1.658526 to 1.648044. Model was saved\n",
      "Epoch: 18 \tValidation loss decreased from 1.648044 to 1.639762. Model was saved\n",
      "Epoch: 19 \tValidation loss decreased from 1.639762 to 1.633091. Model was saved\n",
      "Epoch: 20 \tValidation loss decreased from 1.633091 to 1.627875. Model was saved\n",
      "Epoch: 21 \tValidation loss decreased from 1.627875 to 1.619960. Model was saved\n",
      "Epoch: 22 \tValidation loss decreased from 1.619960 to 1.618559. Model was saved\n",
      "Epoch: 23 \tValidation loss decreased from 1.618559 to 1.608171. Model was saved\n",
      "Epoch: 24 \tValidation loss decreased from 1.608171 to 1.600614. Model was saved\n",
      "Epoch: 25 \tValidation loss decreased from 1.600614 to 1.592120. Model was saved\n",
      "Epoch: 26 \tValidation loss decreased from 1.592120 to 1.585764. Model was saved\n",
      "Epoch: 27 \tValidation loss decreased from 1.585764 to 1.582576. Model was saved\n",
      "Epoch: 28 \tValidation loss decreased from 1.582576 to 1.573116. Model was saved\n",
      "Epoch: 29 \tValidation loss decreased from 1.573116 to 1.568003. Model was saved\n",
      "Epoch: 30 \tValidation loss decreased from 1.568003 to 1.565283. Model was saved\n",
      "Epoch: 31 \tValidation loss decreased from 1.565283 to 1.563679. Model was saved\n",
      "Epoch: 32 \tValidation loss decreased from 1.563679 to 1.558688. Model was saved\n",
      "Epoch: 33 \tValidation loss decreased from 1.558688 to 1.556364. Model was saved\n",
      "Epoch: 34 \tValidation loss decreased from 1.556364 to 1.553476. Model was saved\n",
      "Epoch: 35 \tValidation loss decreased from 1.553476 to 1.549996. Model was saved\n",
      "Epoch: 36 \tValidation loss decreased from 1.549996 to 1.548274. Model was saved\n",
      "Epoch: 37 \tValidation loss decreased from 1.548274 to 1.544742. Model was saved\n",
      "Epoch: 38 \tValidation loss decreased from 1.544742 to 1.541637. Model was saved\n",
      "Epoch: 39 \tValidation loss decreased from 1.541637 to 1.540751. Model was saved\n",
      "Epoch: 40 \tValidation loss decreased from 1.540751 to 1.536425. Model was saved\n",
      "Epoch: 41 \tValidation loss decreased from 1.536425 to 1.534002. Model was saved\n",
      "Epoch: 42 \tValidation loss decreased from 1.534002 to 1.532495. Model was saved\n",
      "Epoch: 43 \tValidation loss decreased from 1.532495 to 1.531899. Model was saved\n",
      "Epoch: 44 \tValidation loss decreased from 1.531899 to 1.526483. Model was saved\n",
      "Epoch: 47 \tValidation loss decreased from 1.526483 to 1.521566. Model was saved\n",
      "Epoch: 48 \tValidation loss decreased from 1.521566 to 1.519816. Model was saved\n",
      "Epoch: 51 \tValidation loss decreased from 1.519816 to 1.515772. Model was saved\n",
      "Epoch: 52 \tValidation loss decreased from 1.515772 to 1.515639. Model was saved\n",
      "Epoch: 54 \tValidation loss decreased from 1.515639 to 1.514317. Model was saved\n",
      "Epoch: 55 \tValidation loss decreased from 1.514317 to 1.512650. Model was saved\n",
      "Epoch: 58 \tValidation loss decreased from 1.512650 to 1.509549. Model was saved\n",
      "Epoch: 59 \tValidation loss decreased from 1.509549 to 1.509388. Model was saved\n",
      "Epoch: 61 \tValidation loss decreased from 1.509388 to 1.507651. Model was saved\n",
      "Epoch: 62 \tValidation loss decreased from 1.507651 to 1.502565. Model was saved\n",
      "Epoch: 65 \tValidation loss decreased from 1.502565 to 1.499411. Model was saved\n",
      "Epoch: 66 \tValidation loss decreased from 1.499411 to 1.498649. Model was saved\n",
      "Epoch: 68 \tValidation loss decreased from 1.498649 to 1.495211. Model was saved\n",
      "Epoch: 69 \tValidation loss decreased from 1.495211 to 1.494018. Model was saved\n",
      "Epoch: 71 \tValidation loss decreased from 1.494018 to 1.490685. Model was saved\n",
      "Epoch: 72 \tValidation loss decreased from 1.490685 to 1.487662. Model was saved\n",
      "Epoch: 74 \tValidation loss decreased from 1.487662 to 1.485721. Model was saved\n",
      "Epoch: 75 \tValidation loss decreased from 1.485721 to 1.483016. Model was saved\n",
      "Epoch: 77 \tValidation loss decreased from 1.483016 to 1.482185. Model was saved\n",
      "Epoch: 78 \tValidation loss decreased from 1.482185 to 1.479539. Model was saved\n",
      "Epoch: 80 \tValidation loss decreased from 1.479539 to 1.479350. Model was saved\n",
      "Epoch: 81 \tValidation loss decreased from 1.479350 to 1.477512. Model was saved\n",
      "Epoch: 83 \tValidation loss decreased from 1.477512 to 1.476726. Model was saved\n",
      "Epoch: 84 \tValidation loss decreased from 1.476726 to 1.475618. Model was saved\n",
      "Epoch: 85 \tValidation loss decreased from 1.475618 to 1.475368. Model was saved\n",
      "Epoch: 86 \tValidation loss decreased from 1.475368 to 1.475130. Model was saved\n",
      "Epoch: 87 \tValidation loss decreased from 1.475130 to 1.474423. Model was saved\n",
      "Epoch: 89 \tValidation loss decreased from 1.474423 to 1.473999. Model was saved\n",
      "Epoch: 90 \tValidation loss decreased from 1.473999 to 1.470975. Model was saved\n",
      "Epoch: 93 \tValidation loss decreased from 1.470975 to 1.470710. Model was saved\n",
      "Epoch: 94 \tValidation loss decreased from 1.470710 to 1.467300. Model was saved\n",
      "Epoch: 95 \tValidation loss decreased from 1.467300 to 1.465545. Model was saved\n",
      "Epoch: 97 \tValidation loss decreased from 1.465545 to 1.461524. Model was saved\n",
      "Epoch: 98 \tValidation loss decreased from 1.461524 to 1.455580. Model was saved\n",
      "Epoch: 100 \tValidation loss decreased from 1.455580 to 1.454701. Model was saved\n",
      "Epoch: 101 \tValidation loss decreased from 1.454701 to 1.449738. Model was saved\n",
      "Epoch: 104 \tValidation loss decreased from 1.449738 to 1.445373. Model was saved\n",
      "Epoch: 105 \tValidation loss decreased from 1.445373 to 1.444621. Model was saved\n",
      "Epoch: 107 \tValidation loss decreased from 1.444621 to 1.441608. Model was saved\n",
      "Epoch: 108 \tValidation loss decreased from 1.441608 to 1.438362. Model was saved\n",
      "Epoch: 110 \tValidation loss decreased from 1.438362 to 1.438267. Model was saved\n",
      "Epoch: 111 \tValidation loss decreased from 1.438267 to 1.437554. Model was saved\n",
      "Epoch: 114 \tValidation loss decreased from 1.437554 to 1.436067. Model was saved\n",
      "Epoch: 118 \tValidation loss decreased from 1.436067 to 1.434894. Model was saved\n",
      "Epoch: 120 \tValidation loss decreased from 1.434894 to 1.432981. Model was saved\n",
      "Epoch: 123 \tValidation loss decreased from 1.432981 to 1.431981. Model was saved\n",
      "Epoch: 131 \tValidation loss decreased from 1.431981 to 1.431102. Model was saved\n",
      "Epoch: 132 \tValidation loss decreased from 1.431102 to 1.426925. Model was saved\n",
      "Epoch: 135 \tValidation loss decreased from 1.426925 to 1.426087. Model was saved\n",
      "Epoch: 136 \tValidation loss decreased from 1.426087 to 1.418760. Model was saved\n",
      "Epoch: 139 \tValidation loss decreased from 1.418760 to 1.418702. Model was saved\n",
      "Epoch: 140 \tValidation loss decreased from 1.418702 to 1.415003. Model was saved\n",
      "Epoch: 144 \tValidation loss decreased from 1.415003 to 1.413987. Model was saved\n",
      "Epoch: 145 \tValidation loss decreased from 1.413987 to 1.412234. Model was saved\n",
      "Epoch: 147 \tValidation loss decreased from 1.412234 to 1.412101. Model was saved\n",
      "Epoch: 148 \tValidation loss decreased from 1.412101 to 1.406746. Model was saved\n",
      "Epoch: 152 \tValidation loss decreased from 1.406746 to 1.404992. Model was saved\n",
      "Epoch: 153 \tValidation loss decreased from 1.404992 to 1.404455. Model was saved\n",
      "Epoch: 154 \tValidation loss decreased from 1.404455 to 1.402191. Model was saved\n",
      "Epoch: 166 \tValidation loss decreased from 1.402191 to 1.401314. Model was saved\n",
      "Epoch: 167 \tValidation loss decreased from 1.401314 to 1.400068. Model was saved\n",
      "Epoch: 169 \tValidation loss decreased from 1.400068 to 1.398447. Model was saved\n",
      "Epoch: 175 \tValidation loss decreased from 1.398447 to 1.398160. Model was saved\n",
      "Epoch: 176 \tValidation loss decreased from 1.398160 to 1.394799. Model was saved\n",
      "Epoch: 187 \tValidation loss decreased from 1.394799 to 1.394686. Model was saved\n",
      "Epoch: 189 \tValidation loss decreased from 1.394686 to 1.393446. Model was saved\n",
      "Epoch: 194 \tValidation loss decreased from 1.393446 to 1.392988. Model was saved\n",
      "Epoch: 195 \tValidation loss decreased from 1.392988 to 1.391402. Model was saved\n",
      "Epoch: 196 \tValidation loss decreased from 1.391402 to 1.390739. Model was saved\n",
      "Epoch: 198 \tValidation loss decreased from 1.390739 to 1.388879. Model was saved\n",
      "Epoch: 199 \tValidation loss decreased from 1.388879 to 1.386244. Model was saved\n",
      "Epoch: 203 \tValidation loss decreased from 1.386244 to 1.383607. Model was saved\n",
      "Epoch: 206 \tValidation loss decreased from 1.383607 to 1.383407. Model was saved\n",
      "Epoch: 207 \tValidation loss decreased from 1.383407 to 1.380144. Model was saved\n",
      "Epoch: 214 \tValidation loss decreased from 1.380144 to 1.379915. Model was saved\n",
      "Epoch: 217 \tValidation loss decreased from 1.379915 to 1.379014. Model was saved\n",
      "Epoch: 221 \tValidation loss decreased from 1.379014 to 1.378250. Model was saved\n",
      "Epoch: 226 \tValidation loss decreased from 1.378250 to 1.377798. Model was saved\n",
      "Epoch: 227 \tValidation loss decreased from 1.377798 to 1.376780. Model was saved\n",
      "Epoch: 233 \tValidation loss decreased from 1.376780 to 1.376039. Model was saved\n",
      "Epoch: 234 \tValidation loss decreased from 1.376039 to 1.375119. Model was saved\n",
      "Epoch: 244 \tValidation loss decreased from 1.375119 to 1.374543. Model was saved\n",
      "Epoch: 259 \tValidation loss decreased from 1.374543 to 1.374170. Model was saved\n",
      "Epoch: 262 \tValidation loss decreased from 1.374170 to 1.372484. Model was saved\n",
      "Epoch: 263 \tValidation loss decreased from 1.372484 to 1.372439. Model was saved\n",
      "Epoch: 266 \tValidation loss decreased from 1.372439 to 1.372049. Model was saved\n",
      "Epoch: 270 \tValidation loss decreased from 1.372049 to 1.370908. Model was saved\n",
      "Epoch: 473 \tValidation loss decreased from 1.370908 to 1.370775. Model was saved\n",
      "Epoch: 474 \tValidation loss decreased from 1.370775 to 1.367449. Model was saved\n",
      "Epoch: 477 \tValidation loss decreased from 1.367449 to 1.365735. Model was saved\n",
      "Epoch: 478 \tValidation loss decreased from 1.365735 to 1.359375. Model was saved\n",
      "Epoch: 542 \tValidation loss decreased from 1.359375 to 1.359309. Model was saved\n",
      "Epoch: 545 \tValidation loss decreased from 1.359309 to 1.359101. Model was saved\n",
      "Epoch: 546 \tValidation loss decreased from 1.359101 to 1.359008. Model was saved\n",
      "Epoch: 547 \tValidation loss decreased from 1.359008 to 1.358855. Model was saved\n",
      "Epoch: 548 \tValidation loss decreased from 1.358855 to 1.358399. Model was saved\n",
      "Epoch: 549 \tValidation loss decreased from 1.358399 to 1.358106. Model was saved\n",
      "Epoch: 550 \tValidation loss decreased from 1.358106 to 1.357932. Model was saved\n",
      "Epoch: 551 \tValidation loss decreased from 1.357932 to 1.357665. Model was saved\n",
      "Epoch: 552 \tValidation loss decreased from 1.357665 to 1.357644. Model was saved\n",
      "Epoch: 554 \tValidation loss decreased from 1.357644 to 1.357622. Model was saved\n",
      "Epoch: 557 \tValidation loss decreased from 1.357622 to 1.357615. Model was saved\n",
      "Epoch: 558 \tValidation loss decreased from 1.357615 to 1.357598. Model was saved\n",
      "Epoch: 559 \tValidation loss decreased from 1.357598 to 1.357487. Model was saved\n",
      "Epoch: 560 \tValidation loss decreased from 1.357487 to 1.357411. Model was saved\n",
      "Epoch: 581 \tValidation loss decreased from 1.357411 to 1.357402. Model was saved\n",
      "Epoch: 584 \tValidation loss decreased from 1.357402 to 1.357389. Model was saved\n",
      "Epoch: 586 \tValidation loss decreased from 1.357389 to 1.357380. Model was saved\n",
      "Epoch: 628 \tValidation loss decreased from 1.357380 to 1.357281. Model was saved\n",
      "Epoch: 629 \tValidation loss decreased from 1.357281 to 1.357175. Model was saved\n",
      "Epoch: 630 \tValidation loss decreased from 1.357175 to 1.356841. Model was saved\n",
      "Epoch: 631 \tValidation loss decreased from 1.356841 to 1.356506. Model was saved\n",
      "Epoch: 632 \tValidation loss decreased from 1.356506 to 1.356047. Model was saved\n",
      "Epoch: 633 \tValidation loss decreased from 1.356047 to 1.355723. Model was saved\n",
      "Epoch: 634 \tValidation loss decreased from 1.355723 to 1.355444. Model was saved\n",
      "Epoch: 635 \tValidation loss decreased from 1.355444 to 1.355334. Model was saved\n",
      "Epoch: 639 \tValidation loss decreased from 1.355334 to 1.355180. Model was saved\n",
      "Epoch: 641 \tValidation loss decreased from 1.355180 to 1.354663. Model was saved\n",
      "Epoch: 643 \tValidation loss decreased from 1.354663 to 1.354139. Model was saved\n",
      "Epoch: 645 \tValidation loss decreased from 1.354139 to 1.353935. Model was saved\n",
      "Epoch: 647 \tValidation loss decreased from 1.353935 to 1.353632. Model was saved\n",
      "Epoch: 649 \tValidation loss decreased from 1.353632 to 1.353099. Model was saved\n",
      "Epoch: 651 \tValidation loss decreased from 1.353099 to 1.352920. Model was saved\n",
      "Epoch: 656 \tValidation loss decreased from 1.352920 to 1.352908. Model was saved\n",
      "Epoch: 668 \tValidation loss decreased from 1.352908 to 1.352891. Model was saved\n",
      "Epoch: 676 \tValidation loss decreased from 1.352891 to 1.352738. Model was saved\n",
      "Epoch: 678 \tValidation loss decreased from 1.352738 to 1.351210. Model was saved\n",
      "Epoch: 680 \tValidation loss decreased from 1.351210 to 1.351093. Model was saved\n",
      "Epoch: 779 \tValidation loss decreased from 1.351093 to 1.346451. Model was saved\n",
      "Epoch: 786 \tValidation loss decreased from 1.346451 to 1.344227. Model was saved\n",
      "Epoch: 790 \tValidation loss decreased from 1.344227 to 1.341523. Model was saved\n",
      "Epoch: 791 \tValidation loss decreased from 1.341523 to 1.339676. Model was saved\n",
      "Epoch: 793 \tValidation loss decreased from 1.339676 to 1.338723. Model was saved\n",
      "Epoch: 796 \tValidation loss decreased from 1.338723 to 1.337656. Model was saved\n",
      "Epoch: 804 \tValidation loss decreased from 1.337656 to 1.336270. Model was saved\n",
      "Epoch: 805 \tValidation loss decreased from 1.336270 to 1.335691. Model was saved\n",
      "Epoch: 817 \tValidation loss decreased from 1.335691 to 1.335208. Model was saved\n",
      "Epoch: 818 \tValidation loss decreased from 1.335208 to 1.334599. Model was saved\n",
      "Epoch: 819 \tValidation loss decreased from 1.334599 to 1.334520. Model was saved\n",
      "Epoch: 825 \tValidation loss decreased from 1.334520 to 1.334497. Model was saved\n",
      "Epoch: 826 \tValidation loss decreased from 1.334497 to 1.334135. Model was saved\n",
      "Epoch: 834 \tValidation loss decreased from 1.334135 to 1.334080. Model was saved\n",
      "Epoch: 839 \tValidation loss decreased from 1.334080 to 1.333894. Model was saved\n",
      "Epoch: 840 \tValidation loss decreased from 1.333894 to 1.333711. Model was saved\n",
      "Epoch: 1032 \tValidation loss decreased from 1.333711 to 1.333535. Model was saved\n",
      "Epoch: 1033 \tValidation loss decreased from 1.333535 to 1.333368. Model was saved\n",
      "Epoch: 1034 \tValidation loss decreased from 1.333368 to 1.333263. Model was saved\n",
      "Epoch: 1035 \tValidation loss decreased from 1.333263 to 1.333045. Model was saved\n",
      "Epoch: 1036 \tValidation loss decreased from 1.333045 to 1.332929. Model was saved\n",
      "Epoch: 1037 \tValidation loss decreased from 1.332929 to 1.332783. Model was saved\n",
      "Epoch: 1038 \tValidation loss decreased from 1.332783 to 1.332684. Model was saved\n",
      "Epoch: 1039 \tValidation loss decreased from 1.332684 to 1.332613. Model was saved\n",
      "Epoch: 1040 \tValidation loss decreased from 1.332613 to 1.332422. Model was saved\n",
      "Epoch: 1041 \tValidation loss decreased from 1.332422 to 1.332336. Model was saved\n",
      "Epoch: 1042 \tValidation loss decreased from 1.332336 to 1.332227. Model was saved\n",
      "Epoch: 1043 \tValidation loss decreased from 1.332227 to 1.332125. Model was saved\n",
      "Epoch: 1044 \tValidation loss decreased from 1.332125 to 1.332004. Model was saved\n",
      "Epoch: 1045 \tValidation loss decreased from 1.332004 to 1.331878. Model was saved\n",
      "Epoch: 1046 \tValidation loss decreased from 1.331878 to 1.331823. Model was saved\n",
      "Epoch: 1047 \tValidation loss decreased from 1.331823 to 1.331713. Model was saved\n",
      "Epoch: 1048 \tValidation loss decreased from 1.331713 to 1.331665. Model was saved\n",
      "Epoch: 1049 \tValidation loss decreased from 1.331665 to 1.331560. Model was saved\n",
      "Epoch: 1050 \tValidation loss decreased from 1.331560 to 1.331534. Model was saved\n",
      "Epoch: 1051 \tValidation loss decreased from 1.331534 to 1.331457. Model was saved\n",
      "Epoch: 1053 \tValidation loss decreased from 1.331457 to 1.331403. Model was saved\n",
      "Epoch: 1055 \tValidation loss decreased from 1.331403 to 1.331367. Model was saved\n",
      "Epoch: 1057 \tValidation loss decreased from 1.331367 to 1.330917. Model was saved\n",
      "Epoch: 1059 \tValidation loss decreased from 1.330917 to 1.330660. Model was saved\n",
      "Epoch: 1062 \tValidation loss decreased from 1.330660 to 1.330566. Model was saved\n",
      "Epoch: 1067 \tValidation loss decreased from 1.330566 to 1.330433. Model was saved\n",
      "Epoch: 1069 \tValidation loss decreased from 1.330433 to 1.330342. Model was saved\n",
      "Epoch: 1071 \tValidation loss decreased from 1.330342 to 1.330129. Model was saved\n",
      "Epoch: 1072 \tValidation loss decreased from 1.330129 to 1.330005. Model was saved\n",
      "Epoch: 1073 \tValidation loss decreased from 1.330005 to 1.329726. Model was saved\n",
      "Epoch: 1074 \tValidation loss decreased from 1.329726 to 1.329396. Model was saved\n",
      "Epoch: 1075 \tValidation loss decreased from 1.329396 to 1.328894. Model was saved\n",
      "Epoch: 1077 \tValidation loss decreased from 1.328894 to 1.328624. Model was saved\n",
      "Epoch: 1078 \tValidation loss decreased from 1.328624 to 1.328474. Model was saved\n",
      "Epoch: 1079 \tValidation loss decreased from 1.328474 to 1.328409. Model was saved\n",
      "Epoch: 1080 \tValidation loss decreased from 1.328409 to 1.328145. Model was saved\n",
      "Epoch: 1082 \tValidation loss decreased from 1.328145 to 1.327903. Model was saved\n",
      "Epoch: 1083 \tValidation loss decreased from 1.327903 to 1.327436. Model was saved\n",
      "Epoch: 1084 \tValidation loss decreased from 1.327436 to 1.326604. Model was saved\n",
      "Epoch: 1085 \tValidation loss decreased from 1.326604 to 1.325722. Model was saved\n",
      "Epoch: 1086 \tValidation loss decreased from 1.325722 to 1.325014. Model was saved\n",
      "Epoch: 1087 \tValidation loss decreased from 1.325014 to 1.324493. Model was saved\n",
      "Epoch: 1088 \tValidation loss decreased from 1.324493 to 1.323997. Model was saved\n",
      "Epoch: 1089 \tValidation loss decreased from 1.323997 to 1.323580. Model was saved\n",
      "Epoch: 1090 \tValidation loss decreased from 1.323580 to 1.323165. Model was saved\n",
      "Epoch: 1091 \tValidation loss decreased from 1.323165 to 1.322634. Model was saved\n",
      "Epoch: 1092 \tValidation loss decreased from 1.322634 to 1.322295. Model was saved\n",
      "Epoch: 1093 \tValidation loss decreased from 1.322295 to 1.321855. Model was saved\n",
      "Epoch: 1095 \tValidation loss decreased from 1.321855 to 1.321458. Model was saved\n",
      "Epoch: 1097 \tValidation loss decreased from 1.321458 to 1.321393. Model was saved\n",
      "Epoch: 1099 \tValidation loss decreased from 1.321393 to 1.321115. Model was saved\n",
      "Epoch: 1100 \tValidation loss decreased from 1.321115 to 1.320932. Model was saved\n",
      "Epoch: 1112 \tValidation loss decreased from 1.320932 to 1.320917. Model was saved\n",
      "Epoch: 1114 \tValidation loss decreased from 1.320917 to 1.320851. Model was saved\n",
      "Epoch: 1117 \tValidation loss decreased from 1.320851 to 1.320845. Model was saved\n",
      "Epoch: 1554 \tValidation loss decreased from 1.320845 to 1.320806. Model was saved\n",
      "Epoch: 1555 \tValidation loss decreased from 1.320806 to 1.320616. Model was saved\n",
      "Epoch: 1556 \tValidation loss decreased from 1.320616 to 1.320416. Model was saved\n",
      "Epoch: 1557 \tValidation loss decreased from 1.320416 to 1.320403. Model was saved\n",
      "Epoch: 1602 \tValidation loss decreased from 1.320403 to 1.320296. Model was saved\n",
      "Epoch: 1603 \tValidation loss decreased from 1.320296 to 1.320261. Model was saved\n",
      "Epoch: 1627 \tValidation loss decreased from 1.320261 to 1.320242. Model was saved\n",
      "Epoch: 1628 \tValidation loss decreased from 1.320242 to 1.320221. Model was saved\n",
      "Epoch: 1629 \tValidation loss decreased from 1.320221 to 1.320213. Model was saved\n",
      "Epoch: 1630 \tValidation loss decreased from 1.320213 to 1.320202. Model was saved\n",
      "Epoch: 1633 \tValidation loss decreased from 1.320202 to 1.320106. Model was saved\n",
      "Epoch: 1634 \tValidation loss decreased from 1.320106 to 1.319924. Model was saved\n",
      "Epoch: 1635 \tValidation loss decreased from 1.319924 to 1.319824. Model was saved\n",
      "Epoch: 1636 \tValidation loss decreased from 1.319824 to 1.319814. Model was saved\n",
      "Epoch: 1637 \tValidation loss decreased from 1.319814 to 1.319773. Model was saved\n",
      "Epoch: 1638 \tValidation loss decreased from 1.319773 to 1.319729. Model was saved\n",
      "Epoch: 1887 \tValidation loss decreased from 1.319729 to 1.319396. Model was saved\n",
      "Epoch: 2045 \tValidation loss decreased from 1.319396 to 1.313887. Model was saved\n",
      "Epoch: 2082 \tValidation loss decreased from 1.313887 to 1.313787. Model was saved\n",
      "Epoch: 2083 \tValidation loss decreased from 1.313787 to 1.313480. Model was saved\n",
      "Epoch: 2084 \tValidation loss decreased from 1.313480 to 1.313211. Model was saved\n",
      "Epoch: 2085 \tValidation loss decreased from 1.313211 to 1.313112. Model was saved\n",
      "Epoch: 2089 \tValidation loss decreased from 1.313112 to 1.312995. Model was saved\n",
      "Epoch: 2090 \tValidation loss decreased from 1.312995 to 1.312788. Model was saved\n",
      "Epoch: 2091 \tValidation loss decreased from 1.312788 to 1.312647. Model was saved\n",
      "Epoch: 2096 \tValidation loss decreased from 1.312647 to 1.312637. Model was saved\n",
      "Epoch: 2097 \tValidation loss decreased from 1.312637 to 1.312484. Model was saved\n",
      "Epoch: 2102 \tValidation loss decreased from 1.312484 to 1.311847. Model was saved\n",
      "Epoch: 2103 \tValidation loss decreased from 1.311847 to 1.310900. Model was saved\n",
      "Epoch: 2104 \tValidation loss decreased from 1.310900 to 1.310563. Model was saved\n",
      "Epoch: 2110 \tValidation loss decreased from 1.310563 to 1.310351. Model was saved\n",
      "Epoch: 2111 \tValidation loss decreased from 1.310351 to 1.310226. Model was saved\n",
      "Epoch: 2112 \tValidation loss decreased from 1.310226 to 1.310168. Model was saved\n",
      "Epoch: 3212 \tValidation loss decreased from 1.310168 to 1.310056. Model was saved\n",
      "Epoch: 3213 \tValidation loss decreased from 1.310056 to 1.309514. Model was saved\n",
      "Epoch: 3239 \tValidation loss decreased from 1.309514 to 1.309103. Model was saved\n",
      "Epoch: 3248 \tValidation loss decreased from 1.309103 to 1.307877. Model was saved\n",
      "Epoch: 3299 \tValidation loss decreased from 1.307877 to 1.307588. Model was saved\n",
      "Epoch: 3304 \tValidation loss decreased from 1.307588 to 1.306975. Model was saved\n",
      "Epoch: 3321 \tValidation loss decreased from 1.306975 to 1.306691. Model was saved\n",
      "Epoch: 3322 \tValidation loss decreased from 1.306691 to 1.306541. Model was saved\n",
      "Epoch: 3323 \tValidation loss decreased from 1.306541 to 1.306419. Model was saved\n",
      "Epoch: 3324 \tValidation loss decreased from 1.306419 to 1.306395. Model was saved\n",
      "Epoch: 3325 \tValidation loss decreased from 1.306395 to 1.306028. Model was saved\n",
      "Epoch: 3546 \tValidation loss decreased from 1.306028 to 1.305596. Model was saved\n",
      "Epoch: 3588 \tValidation loss decreased from 1.305596 to 1.305301. Model was saved\n",
      "Epoch: 3589 \tValidation loss decreased from 1.305301 to 1.305285. Model was saved\n",
      "Epoch: 3590 \tValidation loss decreased from 1.305285 to 1.305108. Model was saved\n",
      "Epoch: 3595 \tValidation loss decreased from 1.305108 to 1.304705. Model was saved\n",
      "Epoch: 3596 \tValidation loss decreased from 1.304705 to 1.304316. Model was saved\n",
      "Epoch: 3597 \tValidation loss decreased from 1.304316 to 1.303803. Model was saved\n",
      "Epoch: 3598 \tValidation loss decreased from 1.303803 to 1.303333. Model was saved\n",
      "Epoch: 3607 \tValidation loss decreased from 1.303333 to 1.303101. Model was saved\n",
      "Epoch: 3612 \tValidation loss decreased from 1.303101 to 1.303064. Model was saved\n",
      "Epoch: 3617 \tValidation loss decreased from 1.303064 to 1.302838. Model was saved\n",
      "Epoch: 3620 \tValidation loss decreased from 1.302838 to 1.302185. Model was saved\n",
      "Epoch: 3621 \tValidation loss decreased from 1.302185 to 1.301590. Model was saved\n",
      "Epoch: 3622 \tValidation loss decreased from 1.301590 to 1.301456. Model was saved\n",
      "Epoch: 3625 \tValidation loss decreased from 1.301456 to 1.301385. Model was saved\n",
      "Epoch: 3626 \tValidation loss decreased from 1.301385 to 1.301182. Model was saved\n",
      "Epoch: 3629 \tValidation loss decreased from 1.301182 to 1.301010. Model was saved\n",
      "Epoch: 3630 \tValidation loss decreased from 1.301010 to 1.300983. Model was saved\n",
      "Epoch: 3632 \tValidation loss decreased from 1.300983 to 1.300343. Model was saved\n",
      "Epoch: 3633 \tValidation loss decreased from 1.300343 to 1.300332. Model was saved\n",
      "Epoch: 3636 \tValidation loss decreased from 1.300332 to 1.300279. Model was saved\n",
      "Epoch: 3645 \tValidation loss decreased from 1.300279 to 1.300248. Model was saved\n",
      "Epoch: 3649 \tValidation loss decreased from 1.300248 to 1.300239. Model was saved\n",
      "Epoch: 3650 \tValidation loss decreased from 1.300239 to 1.299775. Model was saved\n",
      "Epoch: 3889 \tValidation loss decreased from 1.299775 to 1.295487. Model was saved\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    # open a new log file\n",
    "    history_file = open(\"training_history.txt\", \"w\")\n",
    "    history_file.close()\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        \n",
    "        # reopen log file for appending new line of info\n",
    "        history_file = open(\"training_history.txt\", \"a\")\n",
    "\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "#             data = data.type((torch.FloatTensor))\n",
    "\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update accumulated training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            \n",
    "#             data = data.type((torch.FloatTensor))\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update accumulated validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'].dataset)\n",
    "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
    "        \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t time: {:.1f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time.time() - start\n",
    "            ), file=history_file)\n",
    "\n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ), file=history_file)\n",
    "            print('Epoch: {} \\tValidation loss decreased from {:.6f} to {:.6f}. Model was saved'.format(\n",
    "                epoch,\n",
    "                valid_loss_min,\n",
    "                valid_loss\n",
    "            ))\n",
    "            \n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        history_file.close()\n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "\n",
    "# train the model\n",
    "model = train(n_epochs, loaders, model, optimizer, \n",
    "                      criterion, use_cuda, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 215 \tTraining Loss: 1.329372 \tValidation Loss: 1.419149 \t time: 0.4\n",
    "Epoch: 216 \tTraining Loss: 1.328865 \tValidation Loss: 1.416587 \t time: 0.4\n",
    "Validation loss decreased from 1.417114 to 1.416587. Model was saved\n",
    "Kaggle score = 0.54438 (0.0006 IMPROVEMENT)\n",
    "\n",
    "Epoch: 216 \tTraining Loss: 1.326797 \tValidation Loss: 1.396590 \t time: 0.7\n",
    "Epoch: 217 \tTraining Loss: 1.326093 \tValidation Loss: 1.396514 \t time: 0.7\n",
    "Epoch: 218 \tTraining Loss: 1.325473 \tValidation Loss: 1.394434 \t time: 0.6\n",
    "Validation loss decreased from 1.396026 to 1.394434. Model was saved\n",
    "Kaggle score = 55245 (0.011 IMPROVEMENT)\n",
    "\n",
    "Epoch: 364 \tTraining Loss: 1.229904 \tValidation Loss: 1.381198 \t time: 0.3\n",
    "Validation loss decreased from 1.384373 to 1.381198. Model was saved\n",
    "Epoch: 365 \tTraining Loss: 1.231026 \tValidation Loss: 1.394960 \t time: 0.3\n",
    "Epoch: 366 \tTraining Loss: 1.231521 \tValidation Loss: 1.379200 \t time: 0.3\n",
    "Validation loss decreased from 1.381198 to 1.379200. Model was saved\n",
    "Epoch: 367 \tTraining Loss: 1.232151 \tValidation Loss: 1.395807 \t time: 0.3\n",
    "Epoch: 368 \tTraining Loss: 1.230561 \tValidation Loss: 1.391226 \t time: 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.346956\n",
      "\n",
      "\n",
      "Test Accuracy: 60% (12/20)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "#         data = data.type((torch.FloatTensor))\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "# call test function    \n",
    "test(loaders, model, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i,l = next(iter(loaders['test']))\n",
    "# if use_cuda:\n",
    "#     i, l = i.cuda(), l.cuda()\n",
    "\n",
    "# output = model(i)\n",
    "\n",
    "# result = output.cpu().data.max(1, keepdim=True)[1].numpy()\n",
    "# result[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = result[:,0]\n",
    "# plt.hist(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(l.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_data = torch.tensor(features_test.values).type((torch.FloatTensor))\n",
    "if use_cuda:\n",
    "    features_test_data = features_test_data.cuda()\n",
    "predicted_class = model(features_test_data)\n",
    "# We will look at the predicted prices to ensure we have something sensible.\n",
    "predicted_class = predicted_class.data.cpu().max(1, keepdim=True)[1].numpy()[:,0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"ID\":id, \"class\":predicted_class})\n",
    "solution.to_csv(\"pokemon_sol.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
